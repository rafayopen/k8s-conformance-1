Conformance test: not doing test setup.
I0427 16:05:29.957736    7325 test_context.go:423] Tolerating taints "node-role.kubernetes.io/master" when considering if nodes are ready
I0427 16:05:29.957970    7325 e2e.go:124] Starting e2e run "198d53a1-1549-45b7-8c2a-22ba5d8e39af" on Ginkgo node 1
{"msg":"Test Suite starting","total":277,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1588003527 - Will randomize all specs
Will run 277 of 4992 specs

Apr 27 16:05:30.227: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:05:30.228: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr 27 16:05:30.683: INFO: Waiting up to 10m0s for all pods (need at least 1) in namespace 'kube-system' to be running and ready
Apr 27 16:05:31.078: INFO: 22 / 22 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr 27 16:05:31.079: INFO: expected 12 pod replicas in namespace 'kube-system', 12 are Running and Ready.
Apr 27 16:05:31.079: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr 27 16:05:31.179: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Apr 27 16:05:31.179: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'csi-driver-node' (0 seconds elapsed)
Apr 27 16:05:31.179: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Apr 27 16:05:31.179: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Apr 27 16:05:31.179: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-problem-detector' (0 seconds elapsed)
Apr 27 16:05:31.179: INFO: e2e test version: v1.18.2
Apr 27 16:05:31.268: INFO: kube-apiserver version: v1.18.2
Apr 27 16:05:31.268: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:05:31.360: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:05:31.360: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
Apr 27 16:05:31.721: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Apr 27 16:05:31.997: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2200
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2200 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2200;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2200 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2200;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2200.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2200.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2200.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2200.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2200.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2200.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2200.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2200.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2200.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2200.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2200.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2200.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2200.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 5.251.109.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.109.251.5_udp@PTR;check="$$(dig +tcp +noall +answer +search 5.251.109.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.109.251.5_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2200 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2200;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2200 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2200;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2200.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2200.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2200.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2200.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2200.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2200.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2200.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2200.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2200.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2200.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2200.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2200.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2200.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 5.251.109.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.109.251.5_udp@PTR;check="$$(dig +tcp +noall +answer +search 5.251.109.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.109.251.5_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 16:05:45.187: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:45.279: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:45.372: INFO: Unable to read wheezy_udp@dns-test-service.dns-2200 from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:45.464: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2200 from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:45.557: INFO: Unable to read wheezy_udp@dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:45.649: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:45.742: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:45.835: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:46.494: INFO: Unable to read jessie_udp@dns-test-service from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:46.587: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:46.680: INFO: Unable to read jessie_udp@dns-test-service.dns-2200 from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:46.772: INFO: Unable to read jessie_tcp@dns-test-service.dns-2200 from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:46.865: INFO: Unable to read jessie_udp@dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:46.957: INFO: Unable to read jessie_tcp@dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:47.049: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:47.141: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:47.706: INFO: Lookups using dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-2200 wheezy_tcp@dns-test-service.dns-2200 wheezy_udp@dns-test-service.dns-2200.svc wheezy_tcp@dns-test-service.dns-2200.svc wheezy_udp@_http._tcp.dns-test-service.dns-2200.svc wheezy_tcp@_http._tcp.dns-test-service.dns-2200.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-2200 jessie_tcp@dns-test-service.dns-2200 jessie_udp@dns-test-service.dns-2200.svc jessie_tcp@dns-test-service.dns-2200.svc jessie_udp@_http._tcp.dns-test-service.dns-2200.svc jessie_tcp@_http._tcp.dns-test-service.dns-2200.svc]

Apr 27 16:05:52.799: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:52.892: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:52.984: INFO: Unable to read wheezy_udp@dns-test-service.dns-2200 from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:53.076: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2200 from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:53.169: INFO: Unable to read wheezy_udp@dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:53.261: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:53.353: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:53.452: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:54.166: INFO: Unable to read jessie_udp@dns-test-service from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:54.259: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:54.351: INFO: Unable to read jessie_udp@dns-test-service.dns-2200 from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:54.446: INFO: Unable to read jessie_tcp@dns-test-service.dns-2200 from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:54.539: INFO: Unable to read jessie_udp@dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:54.631: INFO: Unable to read jessie_tcp@dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:54.724: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:54.817: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:55.386: INFO: Lookups using dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-2200 wheezy_tcp@dns-test-service.dns-2200 wheezy_udp@dns-test-service.dns-2200.svc wheezy_tcp@dns-test-service.dns-2200.svc wheezy_udp@_http._tcp.dns-test-service.dns-2200.svc wheezy_tcp@_http._tcp.dns-test-service.dns-2200.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-2200 jessie_tcp@dns-test-service.dns-2200 jessie_udp@dns-test-service.dns-2200.svc jessie_tcp@dns-test-service.dns-2200.svc jessie_udp@_http._tcp.dns-test-service.dns-2200.svc jessie_tcp@_http._tcp.dns-test-service.dns-2200.svc]

Apr 27 16:05:57.800: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:57.893: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:57.985: INFO: Unable to read wheezy_udp@dns-test-service.dns-2200 from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:58.078: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2200 from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:58.171: INFO: Unable to read wheezy_udp@dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:58.263: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:58.356: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:58.449: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:59.109: INFO: Unable to read jessie_udp@dns-test-service from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:59.201: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:59.294: INFO: Unable to read jessie_udp@dns-test-service.dns-2200 from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:59.386: INFO: Unable to read jessie_tcp@dns-test-service.dns-2200 from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:59.479: INFO: Unable to read jessie_udp@dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:59.572: INFO: Unable to read jessie_tcp@dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:59.665: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:05:59.757: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:06:00.370: INFO: Lookups using dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-2200 wheezy_tcp@dns-test-service.dns-2200 wheezy_udp@dns-test-service.dns-2200.svc wheezy_tcp@dns-test-service.dns-2200.svc wheezy_udp@_http._tcp.dns-test-service.dns-2200.svc wheezy_tcp@_http._tcp.dns-test-service.dns-2200.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-2200 jessie_tcp@dns-test-service.dns-2200 jessie_udp@dns-test-service.dns-2200.svc jessie_tcp@dns-test-service.dns-2200.svc jessie_udp@_http._tcp.dns-test-service.dns-2200.svc jessie_tcp@_http._tcp.dns-test-service.dns-2200.svc]

Apr 27 16:06:02.799: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:06:02.896: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:06:02.989: INFO: Unable to read wheezy_udp@dns-test-service.dns-2200 from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:06:03.082: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2200 from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:06:03.175: INFO: Unable to read wheezy_udp@dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:06:03.268: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:06:03.361: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:06:03.454: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:06:04.116: INFO: Unable to read jessie_udp@dns-test-service from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:06:04.209: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:06:04.301: INFO: Unable to read jessie_udp@dns-test-service.dns-2200 from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:06:04.394: INFO: Unable to read jessie_tcp@dns-test-service.dns-2200 from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:06:04.487: INFO: Unable to read jessie_udp@dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:06:04.579: INFO: Unable to read jessie_tcp@dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:06:04.672: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:06:04.764: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:06:05.339: INFO: Lookups using dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-2200 wheezy_tcp@dns-test-service.dns-2200 wheezy_udp@dns-test-service.dns-2200.svc wheezy_tcp@dns-test-service.dns-2200.svc wheezy_udp@_http._tcp.dns-test-service.dns-2200.svc wheezy_tcp@_http._tcp.dns-test-service.dns-2200.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-2200 jessie_tcp@dns-test-service.dns-2200 jessie_udp@dns-test-service.dns-2200.svc jessie_tcp@dns-test-service.dns-2200.svc jessie_udp@_http._tcp.dns-test-service.dns-2200.svc jessie_tcp@_http._tcp.dns-test-service.dns-2200.svc]

Apr 27 16:06:08.460: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2200.svc from pod dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f: the server could not find the requested resource (get pods dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f)
Apr 27 16:06:10.360: INFO: Lookups using dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f failed for: [wheezy_tcp@_http._tcp.dns-test-service.dns-2200.svc]

Apr 27 16:06:15.359: INFO: DNS probes using dns-2200/dns-test-f143d351-1e2d-4d60-804b-a0d92d886d2f succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:06:15.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2200" for this suite.
•{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":277,"completed":1,"skipped":26,"failed":0}
S
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:06:15.826: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1751
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Apr 27 16:06:23.102: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0427 16:06:23.102647    7325 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:06:23.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1751" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":277,"completed":2,"skipped":27,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:06:23.286: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-1917
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Apr 27 16:06:24.107: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:06:24.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1917" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":277,"completed":3,"skipped":76,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:06:24.563: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9341
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:06:42.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9341" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":277,"completed":4,"skipped":83,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:06:43.114: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9160
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9160.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-9160.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9160.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9160.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-9160.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9160.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 16:06:47.051: INFO: DNS probes using dns-9160/dns-test-759f6ad0-0201-4ec5-b8a2-180ea9b3aa6a succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:06:47.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9160" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":277,"completed":5,"skipped":106,"failed":0}
S
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:06:47.418: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3348
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-projected-all-test-volume-d81b76fc-dd2d-4a33-81c8-d5d5a323588f
STEP: Creating secret with name secret-projected-all-test-volume-99ebb622-481b-4ccb-8ab0-02234b6afda4
STEP: Creating a pod to test Check all projections for projected volume plugin
Apr 27 16:06:48.333: INFO: Waiting up to 5m0s for pod "projected-volume-cb7fb00a-476b-41aa-bb4c-112e26ee4740" in namespace "projected-3348" to be "Succeeded or Failed"
Apr 27 16:06:48.425: INFO: Pod "projected-volume-cb7fb00a-476b-41aa-bb4c-112e26ee4740": Phase="Pending", Reason="", readiness=false. Elapsed: 91.763407ms
Apr 27 16:06:50.515: INFO: Pod "projected-volume-cb7fb00a-476b-41aa-bb4c-112e26ee4740": Phase="Pending", Reason="", readiness=false. Elapsed: 2.181990773s
Apr 27 16:06:52.609: INFO: Pod "projected-volume-cb7fb00a-476b-41aa-bb4c-112e26ee4740": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.276285722s
STEP: Saw pod success
Apr 27 16:06:52.609: INFO: Pod "projected-volume-cb7fb00a-476b-41aa-bb4c-112e26ee4740" satisfied condition "Succeeded or Failed"
Apr 27 16:06:52.699: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod projected-volume-cb7fb00a-476b-41aa-bb4c-112e26ee4740 container projected-all-volume-test: <nil>
STEP: delete the pod
Apr 27 16:06:52.979: INFO: Waiting for pod projected-volume-cb7fb00a-476b-41aa-bb4c-112e26ee4740 to disappear
Apr 27 16:06:53.069: INFO: Pod projected-volume-cb7fb00a-476b-41aa-bb4c-112e26ee4740 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:06:53.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3348" for this suite.
•{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":277,"completed":6,"skipped":107,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:06:53.250: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8057
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:06:53.899: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:06:54.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8057" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":277,"completed":7,"skipped":121,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:06:55.062: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2995
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:07:07.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2995" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":277,"completed":8,"skipped":151,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:07:07.520: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5799
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-5799/configmap-test-c481003d-3c96-4344-8c23-e924a9e7eb5a
STEP: Creating a pod to test consume configMaps
Apr 27 16:07:08.341: INFO: Waiting up to 5m0s for pod "pod-configmaps-2b128cb6-22f2-4b3f-beff-200207099b4f" in namespace "configmap-5799" to be "Succeeded or Failed"
Apr 27 16:07:08.431: INFO: Pod "pod-configmaps-2b128cb6-22f2-4b3f-beff-200207099b4f": Phase="Pending", Reason="", readiness=false. Elapsed: 89.516443ms
Apr 27 16:07:10.521: INFO: Pod "pod-configmaps-2b128cb6-22f2-4b3f-beff-200207099b4f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179977882s
STEP: Saw pod success
Apr 27 16:07:10.521: INFO: Pod "pod-configmaps-2b128cb6-22f2-4b3f-beff-200207099b4f" satisfied condition "Succeeded or Failed"
Apr 27 16:07:10.611: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-configmaps-2b128cb6-22f2-4b3f-beff-200207099b4f container env-test: <nil>
STEP: delete the pod
Apr 27 16:07:10.802: INFO: Waiting for pod pod-configmaps-2b128cb6-22f2-4b3f-beff-200207099b4f to disappear
Apr 27 16:07:10.893: INFO: Pod pod-configmaps-2b128cb6-22f2-4b3f-beff-200207099b4f no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:07:10.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5799" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":277,"completed":9,"skipped":218,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:07:11.075: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-873
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 27 16:07:13.076: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:07:13.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-873" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":10,"skipped":243,"failed":0}
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:07:13.441: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3475
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-3475
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 27 16:07:14.080: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 27 16:07:14.534: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:07:16.625: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:07:18.625: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:07:20.625: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:07:22.624: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:07:24.625: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:07:26.628: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:07:28.624: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:07:30.625: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:07:32.625: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr 27 16:07:32.875: INFO: The status of Pod netserver-1 is Running (Ready = false)
Apr 27 16:07:34.967: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Apr 27 16:07:37.785: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.1.19 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3475 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:07:37.785: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:07:39.542: INFO: Found all expected endpoints: [netserver-0]
Apr 27 16:07:39.631: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.0.17 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3475 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:07:39.631: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:07:41.354: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:07:41.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3475" for this suite.
•{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":11,"skipped":244,"failed":0}

------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:07:41.536: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4952
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:07:43.353: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600463, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600463, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600463, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600463, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:07:46.537: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Apr 27 16:07:51.178: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config attach --namespace=webhook-4952 to-be-attached-pod -i -c=container1'
Apr 27 16:07:51.872: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:07:51.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4952" for this suite.
STEP: Destroying namespace "webhook-4952-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":277,"completed":12,"skipped":244,"failed":0}
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:07:52.604: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6832
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:07:53.333: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b71f1fc2-ed32-4b81-8f2b-347ee97f6000" in namespace "downward-api-6832" to be "Succeeded or Failed"
Apr 27 16:07:53.422: INFO: Pod "downwardapi-volume-b71f1fc2-ed32-4b81-8f2b-347ee97f6000": Phase="Pending", Reason="", readiness=false. Elapsed: 89.566105ms
Apr 27 16:07:55.513: INFO: Pod "downwardapi-volume-b71f1fc2-ed32-4b81-8f2b-347ee97f6000": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179873198s
STEP: Saw pod success
Apr 27 16:07:55.513: INFO: Pod "downwardapi-volume-b71f1fc2-ed32-4b81-8f2b-347ee97f6000" satisfied condition "Succeeded or Failed"
Apr 27 16:07:55.603: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod downwardapi-volume-b71f1fc2-ed32-4b81-8f2b-347ee97f6000 container client-container: <nil>
STEP: delete the pod
Apr 27 16:07:55.794: INFO: Waiting for pod downwardapi-volume-b71f1fc2-ed32-4b81-8f2b-347ee97f6000 to disappear
Apr 27 16:07:55.883: INFO: Pod downwardapi-volume-b71f1fc2-ed32-4b81-8f2b-347ee97f6000 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:07:55.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6832" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":277,"completed":13,"skipped":248,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:07:56.066: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3988
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-16228436-5ea0-4c87-9c01-f348e1f426d7
STEP: Creating a pod to test consume configMaps
Apr 27 16:07:56.887: INFO: Waiting up to 5m0s for pod "pod-configmaps-eda3d933-3e45-4647-8e79-3078f43b1383" in namespace "configmap-3988" to be "Succeeded or Failed"
Apr 27 16:07:56.978: INFO: Pod "pod-configmaps-eda3d933-3e45-4647-8e79-3078f43b1383": Phase="Pending", Reason="", readiness=false. Elapsed: 90.634268ms
Apr 27 16:07:59.068: INFO: Pod "pod-configmaps-eda3d933-3e45-4647-8e79-3078f43b1383": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180985429s
STEP: Saw pod success
Apr 27 16:07:59.068: INFO: Pod "pod-configmaps-eda3d933-3e45-4647-8e79-3078f43b1383" satisfied condition "Succeeded or Failed"
Apr 27 16:07:59.158: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-configmaps-eda3d933-3e45-4647-8e79-3078f43b1383 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:07:59.349: INFO: Waiting for pod pod-configmaps-eda3d933-3e45-4647-8e79-3078f43b1383 to disappear
Apr 27 16:07:59.511: INFO: Pod pod-configmaps-eda3d933-3e45-4647-8e79-3078f43b1383 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:07:59.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3988" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":277,"completed":14,"skipped":266,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:07:59.693: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4715
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:08:02.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4715" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":277,"completed":15,"skipped":273,"failed":0}

------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:08:02.981: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5721
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-ef691a53-2506-4ee7-a6e9-f2b5c320777c
STEP: Creating a pod to test consume secrets
Apr 27 16:08:03.804: INFO: Waiting up to 5m0s for pod "pod-secrets-b686fe7a-46cc-490f-8abb-72ae7bccdc16" in namespace "secrets-5721" to be "Succeeded or Failed"
Apr 27 16:08:03.894: INFO: Pod "pod-secrets-b686fe7a-46cc-490f-8abb-72ae7bccdc16": Phase="Pending", Reason="", readiness=false. Elapsed: 89.864084ms
Apr 27 16:08:05.985: INFO: Pod "pod-secrets-b686fe7a-46cc-490f-8abb-72ae7bccdc16": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180233087s
STEP: Saw pod success
Apr 27 16:08:05.985: INFO: Pod "pod-secrets-b686fe7a-46cc-490f-8abb-72ae7bccdc16" satisfied condition "Succeeded or Failed"
Apr 27 16:08:06.074: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-secrets-b686fe7a-46cc-490f-8abb-72ae7bccdc16 container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:08:06.281: INFO: Waiting for pod pod-secrets-b686fe7a-46cc-490f-8abb-72ae7bccdc16 to disappear
Apr 27 16:08:06.371: INFO: Pod pod-secrets-b686fe7a-46cc-490f-8abb-72ae7bccdc16 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:08:06.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5721" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":16,"skipped":273,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:08:06.553: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6449
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:08:07.286: INFO: Waiting up to 5m0s for pod "downwardapi-volume-083d8cd9-979f-4a5b-b13d-c2d33dbef07c" in namespace "downward-api-6449" to be "Succeeded or Failed"
Apr 27 16:08:07.380: INFO: Pod "downwardapi-volume-083d8cd9-979f-4a5b-b13d-c2d33dbef07c": Phase="Pending", Reason="", readiness=false. Elapsed: 94.084307ms
Apr 27 16:08:09.473: INFO: Pod "downwardapi-volume-083d8cd9-979f-4a5b-b13d-c2d33dbef07c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.187139377s
STEP: Saw pod success
Apr 27 16:08:09.473: INFO: Pod "downwardapi-volume-083d8cd9-979f-4a5b-b13d-c2d33dbef07c" satisfied condition "Succeeded or Failed"
Apr 27 16:08:09.564: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod downwardapi-volume-083d8cd9-979f-4a5b-b13d-c2d33dbef07c container client-container: <nil>
STEP: delete the pod
Apr 27 16:08:09.754: INFO: Waiting for pod downwardapi-volume-083d8cd9-979f-4a5b-b13d-c2d33dbef07c to disappear
Apr 27 16:08:09.844: INFO: Pod downwardapi-volume-083d8cd9-979f-4a5b-b13d-c2d33dbef07c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:08:09.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6449" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":17,"skipped":295,"failed":0}

------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:08:10.026: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9865
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating api versions
Apr 27 16:08:10.665: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config api-versions'
Apr 27 16:08:11.122: INFO: stderr: ""
Apr 27 16:08:11.122: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncert.gardener.cloud/v1alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1beta1\ndns.gardener.cloud/v1alpha1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nsnapshot.storage.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:08:11.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9865" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":277,"completed":18,"skipped":295,"failed":0}
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:08:11.304: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1209
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 27 16:08:12.666: INFO: Number of nodes with available pods: 0
Apr 27 16:08:12.666: INFO: Node ip-10-250-10-186.ec2.internal is running more than one daemon pod
Apr 27 16:08:13.849: INFO: Number of nodes with available pods: 1
Apr 27 16:08:13.849: INFO: Node ip-10-250-8-65.ec2.internal is running more than one daemon pod
Apr 27 16:08:14.847: INFO: Number of nodes with available pods: 1
Apr 27 16:08:14.847: INFO: Node ip-10-250-8-65.ec2.internal is running more than one daemon pod
Apr 27 16:08:15.847: INFO: Number of nodes with available pods: 1
Apr 27 16:08:15.847: INFO: Node ip-10-250-8-65.ec2.internal is running more than one daemon pod
Apr 27 16:08:16.847: INFO: Number of nodes with available pods: 1
Apr 27 16:08:16.847: INFO: Node ip-10-250-8-65.ec2.internal is running more than one daemon pod
Apr 27 16:08:17.847: INFO: Number of nodes with available pods: 2
Apr 27 16:08:17.847: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Apr 27 16:08:18.300: INFO: Number of nodes with available pods: 1
Apr 27 16:08:18.300: INFO: Node ip-10-250-10-186.ec2.internal is running more than one daemon pod
Apr 27 16:08:19.482: INFO: Number of nodes with available pods: 1
Apr 27 16:08:19.482: INFO: Node ip-10-250-10-186.ec2.internal is running more than one daemon pod
Apr 27 16:08:20.482: INFO: Number of nodes with available pods: 2
Apr 27 16:08:20.482: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1209, will wait for the garbage collector to delete the pods
Apr 27 16:08:20.943: INFO: Deleting DaemonSet.extensions daemon-set took: 90.884334ms
Apr 27 16:08:21.544: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.269809ms
Apr 27 16:08:32.834: INFO: Number of nodes with available pods: 0
Apr 27 16:08:32.834: INFO: Number of running nodes: 0, number of available pods: 0
Apr 27 16:08:32.925: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1209/daemonsets","resourceVersion":"6305"},"items":null}

Apr 27 16:08:33.015: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1209/pods","resourceVersion":"6305"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:08:33.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1209" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":277,"completed":19,"skipped":298,"failed":0}
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:08:33.471: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7570
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 27 16:08:38.924: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:08:39.014: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 16:08:41.014: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:08:41.104: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 16:08:43.014: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:08:43.104: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 16:08:45.014: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:08:45.104: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 16:08:47.014: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:08:47.104: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 16:08:49.014: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:08:49.104: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 16:08:51.014: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:08:51.104: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 16:08:53.014: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:08:53.104: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:08:53.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7570" for this suite.
•{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":277,"completed":20,"skipped":299,"failed":0}
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:08:53.398: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3763
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:08:54.127: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2a0ec5f7-a892-4adc-b18b-43dd3a3e632b" in namespace "projected-3763" to be "Succeeded or Failed"
Apr 27 16:08:54.217: INFO: Pod "downwardapi-volume-2a0ec5f7-a892-4adc-b18b-43dd3a3e632b": Phase="Pending", Reason="", readiness=false. Elapsed: 89.839552ms
Apr 27 16:08:56.307: INFO: Pod "downwardapi-volume-2a0ec5f7-a892-4adc-b18b-43dd3a3e632b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180337681s
STEP: Saw pod success
Apr 27 16:08:56.307: INFO: Pod "downwardapi-volume-2a0ec5f7-a892-4adc-b18b-43dd3a3e632b" satisfied condition "Succeeded or Failed"
Apr 27 16:08:56.397: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod downwardapi-volume-2a0ec5f7-a892-4adc-b18b-43dd3a3e632b container client-container: <nil>
STEP: delete the pod
Apr 27 16:08:56.588: INFO: Waiting for pod downwardapi-volume-2a0ec5f7-a892-4adc-b18b-43dd3a3e632b to disappear
Apr 27 16:08:56.677: INFO: Pod downwardapi-volume-2a0ec5f7-a892-4adc-b18b-43dd3a3e632b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:08:56.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3763" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":21,"skipped":300,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:08:56.859: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-6323
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Apr 27 16:09:02.226: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6323 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:09:02.226: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:09:02.987: INFO: Exec stderr: ""
Apr 27 16:09:02.987: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6323 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:09:02.987: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:09:03.733: INFO: Exec stderr: ""
Apr 27 16:09:03.733: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6323 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:09:03.733: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:09:04.474: INFO: Exec stderr: ""
Apr 27 16:09:04.475: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6323 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:09:04.475: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:09:05.210: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Apr 27 16:09:05.210: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6323 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:09:05.210: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:09:05.946: INFO: Exec stderr: ""
Apr 27 16:09:05.946: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6323 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:09:05.946: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:09:06.700: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Apr 27 16:09:06.700: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6323 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:09:06.700: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:09:07.417: INFO: Exec stderr: ""
Apr 27 16:09:07.417: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6323 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:09:07.418: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:09:08.133: INFO: Exec stderr: ""
Apr 27 16:09:08.133: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6323 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:09:08.133: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:09:08.853: INFO: Exec stderr: ""
Apr 27 16:09:08.854: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6323 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:09:08.854: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:09:09.579: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:09:09.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-6323" for this suite.
•{"msg":"PASSED [k8s.io] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":22,"skipped":316,"failed":0}
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:09:09.760: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6090
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Apr 27 16:09:20.943: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:09:20.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0427 16:09:20.943442    7325 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-6090" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":277,"completed":23,"skipped":319,"failed":0}
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:09:21.125: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6259
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:09:23.214: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600562, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600562, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:09:26.398: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:09:26.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6259" for this suite.
STEP: Destroying namespace "webhook-6259-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":277,"completed":24,"skipped":320,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:09:27.402: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6669
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:09:39.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6669" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":277,"completed":25,"skipped":326,"failed":0}
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:09:39.859: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2023
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Apr 27 16:09:40.498: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 27 16:09:40.771: INFO: Waiting for terminating namespaces to be deleted...
Apr 27 16:09:40.861: INFO: 
Logging pods the kubelet thinks is on node ip-10-250-10-186.ec2.internal before test
Apr 27 16:09:40.964: INFO: node-problem-detector-f7dh2 from kube-system started at 2020-04-27 15:54:02 +0000 UTC (1 container statuses recorded)
Apr 27 16:09:40.964: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 16:09:40.964: INFO: test-pod from e2e-kubelet-etc-hosts-6323 started at 2020-04-27 16:08:57 +0000 UTC (3 container statuses recorded)
Apr 27 16:09:40.964: INFO: 	Container busybox-1 ready: true, restart count 0
Apr 27 16:09:40.964: INFO: 	Container busybox-2 ready: true, restart count 0
Apr 27 16:09:40.964: INFO: 	Container busybox-3 ready: true, restart count 0
Apr 27 16:09:40.964: INFO: kube-proxy-f8lnb from kube-system started at 2020-04-27 15:54:02 +0000 UTC (1 container statuses recorded)
Apr 27 16:09:40.964: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:09:40.964: INFO: csi-driver-node-qjp4d from kube-system started at 2020-04-27 15:54:02 +0000 UTC (3 container statuses recorded)
Apr 27 16:09:40.964: INFO: 	Container csi-driver ready: true, restart count 0
Apr 27 16:09:40.964: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 27 16:09:40.964: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 27 16:09:40.964: INFO: test-host-network-pod from e2e-kubelet-etc-hosts-6323 started at 2020-04-27 16:08:59 +0000 UTC (2 container statuses recorded)
Apr 27 16:09:40.964: INFO: 	Container busybox-1 ready: true, restart count 0
Apr 27 16:09:40.964: INFO: 	Container busybox-2 ready: true, restart count 0
Apr 27 16:09:40.964: INFO: node-exporter-zggrn from kube-system started at 2020-04-27 15:54:02 +0000 UTC (1 container statuses recorded)
Apr 27 16:09:40.964: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:09:40.964: INFO: calico-node-mvhvc from kube-system started at 2020-04-27 15:57:54 +0000 UTC (1 container statuses recorded)
Apr 27 16:09:40.964: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:09:40.964: INFO: 
Logging pods the kubelet thinks is on node ip-10-250-8-65.ec2.internal before test
Apr 27 16:09:41.148: INFO: node-exporter-vv796 from kube-system started at 2020-04-27 15:53:59 +0000 UTC (1 container statuses recorded)
Apr 27 16:09:41.148: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:09:41.148: INFO: calico-kube-controllers-77dcb8f688-f6jtd from kube-system started at 2020-04-27 15:54:17 +0000 UTC (1 container statuses recorded)
Apr 27 16:09:41.148: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 27 16:09:41.148: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-hqsfl from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:09:41.148: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr 27 16:09:41.148: INFO: calico-typha-horizontal-autoscaler-6fdd5d8746-vxwg5 from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:09:41.148: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 16:09:41.148: INFO: metrics-server-7dd4d485f9-ff6mk from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:09:41.148: INFO: 	Container metrics-server ready: true, restart count 0
Apr 27 16:09:41.148: INFO: calico-node-vertical-autoscaler-74d4897db8-g7wmv from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:09:41.148: INFO: 	Container autoscaler ready: true, restart count 3
Apr 27 16:09:41.149: INFO: calico-node-l4j7q from kube-system started at 2020-04-27 15:57:44 +0000 UTC (1 container statuses recorded)
Apr 27 16:09:41.149: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:09:41.149: INFO: blackbox-exporter-5dc75b79b7-hcrbp from kube-system started at 2020-04-27 15:53:59 +0000 UTC (1 container statuses recorded)
Apr 27 16:09:41.149: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 27 16:09:41.149: INFO: node-problem-detector-frcdg from kube-system started at 2020-04-27 15:53:59 +0000 UTC (1 container statuses recorded)
Apr 27 16:09:41.149: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 16:09:41.149: INFO: coredns-5cb857d789-m225g from kube-system started at 2020-04-27 15:54:14 +0000 UTC (1 container statuses recorded)
Apr 27 16:09:41.149: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:09:41.149: INFO: addons-nginx-ingress-controller-6cf77756b5-8sgd9 from kube-system started at 2020-04-27 15:54:17 +0000 UTC (1 container statuses recorded)
Apr 27 16:09:41.149: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 27 16:09:41.149: INFO: coredns-5cb857d789-bn7lm from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:09:41.149: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:09:41.149: INFO: calico-typha-deploy-784665cc66-dtz47 from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:09:41.149: INFO: 	Container calico-typha ready: true, restart count 0
Apr 27 16:09:41.149: INFO: kube-proxy-2tzh4 from kube-system started at 2020-04-27 15:53:59 +0000 UTC (1 container statuses recorded)
Apr 27 16:09:41.149: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:09:41.149: INFO: dashboard-metrics-scraper-76c7b697bc-ghctb from kubernetes-dashboard started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:09:41.149: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 27 16:09:41.149: INFO: kubernetes-dashboard-6b586c4cb4-jw8gc from kubernetes-dashboard started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:09:41.149: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 27 16:09:41.149: INFO: csi-driver-node-lqmtr from kube-system started at 2020-04-27 15:53:59 +0000 UTC (3 container statuses recorded)
Apr 27 16:09:41.149: INFO: 	Container csi-driver ready: true, restart count 0
Apr 27 16:09:41.149: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 27 16:09:41.149: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 27 16:09:41.149: INFO: calico-typha-vertical-autoscaler-5b477c88cf-lq56p from kube-system started at 2020-04-27 15:54:17 +0000 UTC (1 container statuses recorded)
Apr 27 16:09:41.149: INFO: 	Container autoscaler ready: true, restart count 3
Apr 27 16:09:41.149: INFO: vpn-shoot-5c755d796f-fvlqt from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:09:41.149: INFO: 	Container vpn-shoot ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-dc119bc7-a4bc-41eb-8425-3f69c03c83ee 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-dc119bc7-a4bc-41eb-8425-3f69c03c83ee off the node ip-10-250-10-186.ec2.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-dc119bc7-a4bc-41eb-8425-3f69c03c83ee
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:09:51.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2023" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]","total":277,"completed":26,"skipped":334,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:09:51.209: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4165
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-4165
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-4165
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4165
Apr 27 16:09:52.213: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Apr 27 16:10:02.308: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Apr 27 16:10:02.401: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:10:03.498: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:10:03.498: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:10:03.498: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:10:03.588: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 27 16:10:13.679: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:10:13.679: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:10:14.039: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999489s
Apr 27 16:10:15.129: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.909977004s
Apr 27 16:10:16.219: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.819628022s
Apr 27 16:10:17.310: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.72920051s
Apr 27 16:10:18.400: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.639007991s
Apr 27 16:10:19.490: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.548615909s
Apr 27 16:10:20.581: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.458162969s
Apr 27 16:10:21.671: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.367559522s
Apr 27 16:10:22.761: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.277143076s
Apr 27 16:10:23.854: INFO: Verifying statefulset ss doesn't scale past 1 for another 187.142699ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4165
Apr 27 16:10:24.945: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:10:26.012: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 16:10:26.012: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:10:26.012: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:10:26.102: INFO: Found 1 stateful pods, waiting for 3
Apr 27 16:10:36.193: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:10:36.193: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:10:36.193: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Apr 27 16:10:36.373: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:10:37.457: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:10:37.457: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:10:37.457: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:10:37.457: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:10:38.608: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:10:38.608: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:10:38.608: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:10:38.608: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:10:39.668: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:10:39.668: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:10:39.668: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:10:39.668: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:10:39.758: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Apr 27 16:10:49.939: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:10:49.939: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:10:49.939: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:10:50.210: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999175s
Apr 27 16:10:51.300: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.909603822s
Apr 27 16:10:52.392: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.818784765s
Apr 27 16:10:53.483: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.727158773s
Apr 27 16:10:54.573: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.636412567s
Apr 27 16:10:55.664: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.546136841s
Apr 27 16:10:56.755: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.455399356s
Apr 27 16:10:57.845: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.364543882s
Apr 27 16:10:58.936: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.273708334s
Apr 27 16:11:00.027: INFO: Verifying statefulset ss doesn't scale past 3 for another 182.927008ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4165
Apr 27 16:11:01.118: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:11:02.188: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 16:11:02.188: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:11:02.188: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:11:02.188: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:11:03.292: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 16:11:03.292: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:11:03.292: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:11:03.292: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:11:04.356: INFO: rc: 1
Apr 27 16:11:04.356: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: Internal error occurred: error executing command in container: container not running (747cd39edadaf09d0efbfb3bc47455007f2b9198a1600f5f6dee97fa0ac35f5f)

error:
exit status 1
Apr 27 16:11:14.356: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:11:14.778: INFO: rc: 1
Apr 27 16:11:14.778: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:11:24.778: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:11:25.199: INFO: rc: 1
Apr 27 16:11:25.199: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:11:35.199: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:11:35.617: INFO: rc: 1
Apr 27 16:11:35.618: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:11:45.618: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:11:46.048: INFO: rc: 1
Apr 27 16:11:46.048: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:11:56.048: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:11:56.522: INFO: rc: 1
Apr 27 16:11:56.522: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:12:06.522: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:12:06.942: INFO: rc: 1
Apr 27 16:12:06.943: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:12:16.944: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:12:17.360: INFO: rc: 1
Apr 27 16:12:17.360: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:12:27.360: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:12:27.783: INFO: rc: 1
Apr 27 16:12:27.783: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:12:37.784: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:12:38.208: INFO: rc: 1
Apr 27 16:12:38.208: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:12:48.208: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:12:48.625: INFO: rc: 1
Apr 27 16:12:48.625: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:12:58.625: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:13:04.052: INFO: rc: 1
Apr 27 16:13:04.053: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:13:14.053: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:13:14.477: INFO: rc: 1
Apr 27 16:13:14.477: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:13:24.477: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:13:24.899: INFO: rc: 1
Apr 27 16:13:24.900: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:13:34.900: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:13:35.326: INFO: rc: 1
Apr 27 16:13:35.326: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:13:45.327: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:13:45.748: INFO: rc: 1
Apr 27 16:13:45.748: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:13:55.748: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:13:56.175: INFO: rc: 1
Apr 27 16:13:56.175: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:14:06.175: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:14:06.594: INFO: rc: 1
Apr 27 16:14:06.594: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:14:16.594: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:14:17.124: INFO: rc: 1
Apr 27 16:14:17.124: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:14:27.125: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:14:27.549: INFO: rc: 1
Apr 27 16:14:27.549: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:14:37.550: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:14:42.987: INFO: rc: 1
Apr 27 16:14:42.987: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:14:52.988: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:14:53.415: INFO: rc: 1
Apr 27 16:14:53.415: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:15:03.415: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:15:03.939: INFO: rc: 1
Apr 27 16:15:03.939: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:15:13.940: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:15:14.366: INFO: rc: 1
Apr 27 16:15:14.366: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:15:24.366: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:15:25.088: INFO: rc: 1
Apr 27 16:15:25.088: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:15:35.088: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:15:35.513: INFO: rc: 1
Apr 27 16:15:35.513: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:15:45.513: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:15:45.952: INFO: rc: 1
Apr 27 16:15:45.952: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:15:55.952: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:15:56.379: INFO: rc: 1
Apr 27 16:15:56.379: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:16:06.379: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:16:06.798: INFO: rc: 1
Apr 27 16:16:06.798: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
Apr 27 16:16:06.798: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 16:16:07.071: INFO: Deleting all statefulset in ns statefulset-4165
Apr 27 16:16:07.247: INFO: Scaling statefulset ss to 0
Apr 27 16:16:07.517: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:16:07.606: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:16:07.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4165" for this suite.

• [SLOW TEST:376.850 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":277,"completed":27,"skipped":367,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:16:08.059: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8273
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Starting the proxy
Apr 27 16:16:08.698: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy --unix-socket=/tmp/kubectl-proxy-unix978630567/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:16:08.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8273" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":277,"completed":28,"skipped":392,"failed":0}
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:16:08.933: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-5282
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7098
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9639
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:16:17.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5282" for this suite.
STEP: Destroying namespace "nsdeletetest-7098" for this suite.
Apr 27 16:16:17.395: INFO: Namespace nsdeletetest-7098 was already deleted
STEP: Destroying namespace "nsdeletetest-9639" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":277,"completed":29,"skipped":395,"failed":0}
SSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:16:17.485: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7487
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 27 16:16:19.485: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:16:19.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7487" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":277,"completed":30,"skipped":405,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:16:19.849: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3831
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:16:20.675: INFO: (0) /api/v1/nodes/ip-10-250-8-65.ec2.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 97.04514ms)
Apr 27 16:16:20.767: INFO: (1) /api/v1/nodes/ip-10-250-8-65.ec2.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.508481ms)
Apr 27 16:16:20.860: INFO: (2) /api/v1/nodes/ip-10-250-8-65.ec2.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.430075ms)
Apr 27 16:16:20.953: INFO: (3) /api/v1/nodes/ip-10-250-8-65.ec2.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.531365ms)
Apr 27 16:16:21.045: INFO: (4) /api/v1/nodes/ip-10-250-8-65.ec2.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.609701ms)
Apr 27 16:16:21.138: INFO: (5) /api/v1/nodes/ip-10-250-8-65.ec2.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.427475ms)
Apr 27 16:16:21.231: INFO: (6) /api/v1/nodes/ip-10-250-8-65.ec2.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 93.442946ms)
Apr 27 16:16:21.324: INFO: (7) /api/v1/nodes/ip-10-250-8-65.ec2.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.513351ms)
Apr 27 16:16:21.417: INFO: (8) /api/v1/nodes/ip-10-250-8-65.ec2.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.783885ms)
Apr 27 16:16:21.510: INFO: (9) /api/v1/nodes/ip-10-250-8-65.ec2.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 93.031013ms)
Apr 27 16:16:21.603: INFO: (10) /api/v1/nodes/ip-10-250-8-65.ec2.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 93.2686ms)
Apr 27 16:16:21.697: INFO: (11) /api/v1/nodes/ip-10-250-8-65.ec2.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 93.522036ms)
Apr 27 16:16:21.790: INFO: (12) /api/v1/nodes/ip-10-250-8-65.ec2.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.897306ms)
Apr 27 16:16:21.883: INFO: (13) /api/v1/nodes/ip-10-250-8-65.ec2.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 93.208314ms)
Apr 27 16:16:21.976: INFO: (14) /api/v1/nodes/ip-10-250-8-65.ec2.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.755485ms)
Apr 27 16:16:22.069: INFO: (15) /api/v1/nodes/ip-10-250-8-65.ec2.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 93.064124ms)
Apr 27 16:16:22.162: INFO: (16) /api/v1/nodes/ip-10-250-8-65.ec2.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.854516ms)
Apr 27 16:16:22.255: INFO: (17) /api/v1/nodes/ip-10-250-8-65.ec2.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.812373ms)
Apr 27 16:16:22.360: INFO: (18) /api/v1/nodes/ip-10-250-8-65.ec2.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 105.274953ms)
Apr 27 16:16:22.452: INFO: (19) /api/v1/nodes/ip-10-250-8-65.ec2.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.102471ms)
[AfterEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:16:22.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3831" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node using proxy subresource  [Conformance]","total":277,"completed":31,"skipped":448,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:16:22.633: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-9879
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:16:26.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9879" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":277,"completed":32,"skipped":457,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:16:26.271: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9623
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-687cf0cc-9d35-4ad0-be68-1a9832020a09 in namespace container-probe-9623
Apr 27 16:16:29.182: INFO: Started pod liveness-687cf0cc-9d35-4ad0-be68-1a9832020a09 in namespace container-probe-9623
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 16:16:29.272: INFO: Initial restart count of pod liveness-687cf0cc-9d35-4ad0-be68-1a9832020a09 is 0
Apr 27 16:16:50.264: INFO: Restart count of pod container-probe-9623/liveness-687cf0cc-9d35-4ad0-be68-1a9832020a09 is now 1 (20.991763891s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:16:50.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9623" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":277,"completed":33,"skipped":478,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:16:50.538: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8876
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:16:52.440: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601012, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601012, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:16:55.625: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:16:57.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8876" for this suite.
STEP: Destroying namespace "webhook-8876-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":277,"completed":34,"skipped":497,"failed":0}
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:16:57.889: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8000
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Apr 27 16:17:39.161: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0427 16:17:39.161485    7325 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:17:39.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8000" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":277,"completed":35,"skipped":498,"failed":0}
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:17:39.342: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7306
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 27 16:17:44.794: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 16:17:44.884: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 27 16:17:46.885: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 16:17:46.975: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 27 16:17:48.885: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 16:17:48.975: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 27 16:17:50.885: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 16:17:50.975: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 27 16:17:52.885: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 16:17:52.975: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 27 16:17:54.885: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 16:17:54.975: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:17:55.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7306" for this suite.
•{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":277,"completed":36,"skipped":501,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:17:55.348: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6316
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:17:56.078: INFO: Waiting up to 5m0s for pod "downwardapi-volume-19957288-8aa9-4262-83cf-dd7c882fdaa4" in namespace "downward-api-6316" to be "Succeeded or Failed"
Apr 27 16:17:56.168: INFO: Pod "downwardapi-volume-19957288-8aa9-4262-83cf-dd7c882fdaa4": Phase="Pending", Reason="", readiness=false. Elapsed: 89.522695ms
Apr 27 16:17:58.258: INFO: Pod "downwardapi-volume-19957288-8aa9-4262-83cf-dd7c882fdaa4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179973783s
STEP: Saw pod success
Apr 27 16:17:58.259: INFO: Pod "downwardapi-volume-19957288-8aa9-4262-83cf-dd7c882fdaa4" satisfied condition "Succeeded or Failed"
Apr 27 16:17:58.349: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod downwardapi-volume-19957288-8aa9-4262-83cf-dd7c882fdaa4 container client-container: <nil>
STEP: delete the pod
Apr 27 16:17:58.539: INFO: Waiting for pod downwardapi-volume-19957288-8aa9-4262-83cf-dd7c882fdaa4 to disappear
Apr 27 16:17:58.629: INFO: Pod downwardapi-volume-19957288-8aa9-4262-83cf-dd7c882fdaa4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:17:58.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6316" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":277,"completed":37,"skipped":510,"failed":0}
SSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:17:58.811: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8244
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-6eb79984-17ad-4bdb-a586-b0b6228fdf59 in namespace container-probe-8244
Apr 27 16:18:01.727: INFO: Started pod liveness-6eb79984-17ad-4bdb-a586-b0b6228fdf59 in namespace container-probe-8244
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 16:18:01.818: INFO: Initial restart count of pod liveness-6eb79984-17ad-4bdb-a586-b0b6228fdf59 is 0
Apr 27 16:18:14.464: INFO: Restart count of pod container-probe-8244/liveness-6eb79984-17ad-4bdb-a586-b0b6228fdf59 is now 1 (12.645681442s elapsed)
Apr 27 16:18:35.367: INFO: Restart count of pod container-probe-8244/liveness-6eb79984-17ad-4bdb-a586-b0b6228fdf59 is now 2 (33.549547242s elapsed)
Apr 27 16:18:56.270: INFO: Restart count of pod container-probe-8244/liveness-6eb79984-17ad-4bdb-a586-b0b6228fdf59 is now 3 (54.452518308s elapsed)
Apr 27 16:19:15.083: INFO: Restart count of pod container-probe-8244/liveness-6eb79984-17ad-4bdb-a586-b0b6228fdf59 is now 4 (1m13.264857683s elapsed)
Apr 27 16:20:24.065: INFO: Restart count of pod container-probe-8244/liveness-6eb79984-17ad-4bdb-a586-b0b6228fdf59 is now 5 (2m22.247089859s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:20:24.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8244" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":277,"completed":38,"skipped":516,"failed":0}
SS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:20:24.340: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-9027
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
Apr 27 16:20:25.931: INFO: created pod pod-service-account-defaultsa
Apr 27 16:20:25.931: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr 27 16:20:26.023: INFO: created pod pod-service-account-mountsa
Apr 27 16:20:26.023: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr 27 16:20:26.113: INFO: created pod pod-service-account-nomountsa
Apr 27 16:20:26.113: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr 27 16:20:26.205: INFO: created pod pod-service-account-defaultsa-mountspec
Apr 27 16:20:26.205: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr 27 16:20:26.296: INFO: created pod pod-service-account-mountsa-mountspec
Apr 27 16:20:26.296: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr 27 16:20:26.391: INFO: created pod pod-service-account-nomountsa-mountspec
Apr 27 16:20:26.391: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr 27 16:20:26.482: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr 27 16:20:26.482: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr 27 16:20:26.574: INFO: created pod pod-service-account-mountsa-nomountspec
Apr 27 16:20:26.574: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr 27 16:20:26.665: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr 27 16:20:26.665: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:20:26.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9027" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":277,"completed":39,"skipped":518,"failed":0}
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:20:26.847: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-385
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:20:27.578: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c602c0ac-9d81-40a4-adc9-97f00cdd39c3" in namespace "projected-385" to be "Succeeded or Failed"
Apr 27 16:20:27.667: INFO: Pod "downwardapi-volume-c602c0ac-9d81-40a4-adc9-97f00cdd39c3": Phase="Pending", Reason="", readiness=false. Elapsed: 89.57711ms
Apr 27 16:20:29.758: INFO: Pod "downwardapi-volume-c602c0ac-9d81-40a4-adc9-97f00cdd39c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179884461s
STEP: Saw pod success
Apr 27 16:20:29.758: INFO: Pod "downwardapi-volume-c602c0ac-9d81-40a4-adc9-97f00cdd39c3" satisfied condition "Succeeded or Failed"
Apr 27 16:20:29.851: INFO: Trying to get logs from node ip-10-250-8-65.ec2.internal pod downwardapi-volume-c602c0ac-9d81-40a4-adc9-97f00cdd39c3 container client-container: <nil>
STEP: delete the pod
Apr 27 16:20:30.040: INFO: Waiting for pod downwardapi-volume-c602c0ac-9d81-40a4-adc9-97f00cdd39c3 to disappear
Apr 27 16:20:30.130: INFO: Pod downwardapi-volume-c602c0ac-9d81-40a4-adc9-97f00cdd39c3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:20:30.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-385" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":40,"skipped":520,"failed":0}
S
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:20:30.311: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6447
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Apr 27 16:20:31.489: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6447 /api/v1/namespaces/watch-6447/configmaps/e2e-watch-test-label-changed 023c5727-7e30-49fe-9fa5-e5a94cdf7824 10595 0 2020-04-27 16:20:31 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:20:31 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:20:31.489: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6447 /api/v1/namespaces/watch-6447/configmaps/e2e-watch-test-label-changed 023c5727-7e30-49fe-9fa5-e5a94cdf7824 10596 0 2020-04-27 16:20:31 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:20:31 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:20:31.489: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6447 /api/v1/namespaces/watch-6447/configmaps/e2e-watch-test-label-changed 023c5727-7e30-49fe-9fa5-e5a94cdf7824 10598 0 2020-04-27 16:20:31 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:20:31 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Apr 27 16:20:42.125: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6447 /api/v1/namespaces/watch-6447/configmaps/e2e-watch-test-label-changed 023c5727-7e30-49fe-9fa5-e5a94cdf7824 10680 0 2020-04-27 16:20:31 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:20:41 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:20:42.125: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6447 /api/v1/namespaces/watch-6447/configmaps/e2e-watch-test-label-changed 023c5727-7e30-49fe-9fa5-e5a94cdf7824 10681 0 2020-04-27 16:20:31 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:20:41 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:20:42.125: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6447 /api/v1/namespaces/watch-6447/configmaps/e2e-watch-test-label-changed 023c5727-7e30-49fe-9fa5-e5a94cdf7824 10684 0 2020-04-27 16:20:31 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:20:41 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:20:42.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6447" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":277,"completed":41,"skipped":521,"failed":0}
SSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:20:42.307: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-4008
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Apr 27 16:20:45.899: INFO: Successfully updated pod "adopt-release-h8smc"
STEP: Checking that the Job readopts the Pod
Apr 27 16:20:45.899: INFO: Waiting up to 15m0s for pod "adopt-release-h8smc" in namespace "job-4008" to be "adopted"
Apr 27 16:20:45.988: INFO: Pod "adopt-release-h8smc": Phase="Running", Reason="", readiness=true. Elapsed: 89.587475ms
Apr 27 16:20:45.988: INFO: Pod "adopt-release-h8smc" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Apr 27 16:20:46.671: INFO: Successfully updated pod "adopt-release-h8smc"
STEP: Checking that the Job releases the Pod
Apr 27 16:20:46.671: INFO: Waiting up to 15m0s for pod "adopt-release-h8smc" in namespace "job-4008" to be "released"
Apr 27 16:20:46.761: INFO: Pod "adopt-release-h8smc": Phase="Running", Reason="", readiness=true. Elapsed: 89.861745ms
Apr 27 16:20:46.761: INFO: Pod "adopt-release-h8smc" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:20:46.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4008" for this suite.
•{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":277,"completed":42,"skipped":527,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:20:46.942: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-699
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service multi-endpoint-test in namespace services-699
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-699 to expose endpoints map[]
Apr 27 16:20:47.767: INFO: successfully validated that service multi-endpoint-test in namespace services-699 exposes endpoints map[] (90.084111ms elapsed)
STEP: Creating pod pod1 in namespace services-699
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-699 to expose endpoints map[pod1:[100]]
Apr 27 16:20:49.219: INFO: successfully validated that service multi-endpoint-test in namespace services-699 exposes endpoints map[pod1:[100]] (1.359092518s elapsed)
STEP: Creating pod pod2 in namespace services-699
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-699 to expose endpoints map[pod1:[100] pod2:[101]]
Apr 27 16:20:52.118: INFO: successfully validated that service multi-endpoint-test in namespace services-699 exposes endpoints map[pod1:[100] pod2:[101]] (2.807726426s elapsed)
STEP: Deleting pod pod1 in namespace services-699
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-699 to expose endpoints map[pod2:[101]]
Apr 27 16:20:52.389: INFO: successfully validated that service multi-endpoint-test in namespace services-699 exposes endpoints map[pod2:[101]] (179.826323ms elapsed)
STEP: Deleting pod pod2 in namespace services-699
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-699 to expose endpoints map[]
Apr 27 16:20:52.569: INFO: successfully validated that service multi-endpoint-test in namespace services-699 exposes endpoints map[] (89.443151ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:20:52.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-699" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":277,"completed":43,"skipped":540,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:20:52.846: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-617
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Apr 27 16:20:53.577: INFO: Waiting up to 5m0s for pod "downward-api-51e918df-60b4-42f7-84d1-8be4a6e75165" in namespace "downward-api-617" to be "Succeeded or Failed"
Apr 27 16:20:53.666: INFO: Pod "downward-api-51e918df-60b4-42f7-84d1-8be4a6e75165": Phase="Pending", Reason="", readiness=false. Elapsed: 89.620358ms
Apr 27 16:20:55.757: INFO: Pod "downward-api-51e918df-60b4-42f7-84d1-8be4a6e75165": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180071635s
STEP: Saw pod success
Apr 27 16:20:55.757: INFO: Pod "downward-api-51e918df-60b4-42f7-84d1-8be4a6e75165" satisfied condition "Succeeded or Failed"
Apr 27 16:20:55.847: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod downward-api-51e918df-60b4-42f7-84d1-8be4a6e75165 container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:20:56.114: INFO: Waiting for pod downward-api-51e918df-60b4-42f7-84d1-8be4a6e75165 to disappear
Apr 27 16:20:56.204: INFO: Pod downward-api-51e918df-60b4-42f7-84d1-8be4a6e75165 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:20:56.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-617" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":277,"completed":44,"skipped":565,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:20:56.389: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8184
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:20:58.372: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601258, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601258, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601258, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601258, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:21:00.462: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601258, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601258, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601258, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601258, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:21:03.557: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:21:04.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8184" for this suite.
STEP: Destroying namespace "webhook-8184-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":277,"completed":45,"skipped":570,"failed":0}
SSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:21:04.983: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-9074
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:21:05.714: INFO: Waiting up to 5m0s for pod "busybox-user-65534-beaf08b8-7394-49ae-83f7-f9abac2675d9" in namespace "security-context-test-9074" to be "Succeeded or Failed"
Apr 27 16:21:05.804: INFO: Pod "busybox-user-65534-beaf08b8-7394-49ae-83f7-f9abac2675d9": Phase="Pending", Reason="", readiness=false. Elapsed: 89.81106ms
Apr 27 16:21:07.895: INFO: Pod "busybox-user-65534-beaf08b8-7394-49ae-83f7-f9abac2675d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.1802331s
Apr 27 16:21:07.895: INFO: Pod "busybox-user-65534-beaf08b8-7394-49ae-83f7-f9abac2675d9" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:21:07.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9074" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":46,"skipped":574,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:21:08.077: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3461
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:21:09.966: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601269, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601269, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601269, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601269, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:21:13.151: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:21:27.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3461" for this suite.
STEP: Destroying namespace "webhook-3461-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":277,"completed":47,"skipped":589,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:21:27.917: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5014
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Apr 27 16:21:28.556: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:21:55.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5014" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":277,"completed":48,"skipped":591,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:21:55.329: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4018
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-bef6814b-3194-4188-83ac-654f28dd2ebe
STEP: Creating a pod to test consume configMaps
Apr 27 16:21:56.262: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-027d83cc-9e5d-4eb7-a9d2-9310e1007046" in namespace "projected-4018" to be "Succeeded or Failed"
Apr 27 16:21:56.352: INFO: Pod "pod-projected-configmaps-027d83cc-9e5d-4eb7-a9d2-9310e1007046": Phase="Pending", Reason="", readiness=false. Elapsed: 89.850558ms
Apr 27 16:21:58.442: INFO: Pod "pod-projected-configmaps-027d83cc-9e5d-4eb7-a9d2-9310e1007046": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179951463s
STEP: Saw pod success
Apr 27 16:21:58.442: INFO: Pod "pod-projected-configmaps-027d83cc-9e5d-4eb7-a9d2-9310e1007046" satisfied condition "Succeeded or Failed"
Apr 27 16:21:58.532: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-projected-configmaps-027d83cc-9e5d-4eb7-a9d2-9310e1007046 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:21:58.721: INFO: Waiting for pod pod-projected-configmaps-027d83cc-9e5d-4eb7-a9d2-9310e1007046 to disappear
Apr 27 16:21:58.810: INFO: Pod pod-projected-configmaps-027d83cc-9e5d-4eb7-a9d2-9310e1007046 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:21:58.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4018" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":277,"completed":49,"skipped":596,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:21:58.994: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-9834
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:21:59.634: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:21:59.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9834" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":277,"completed":50,"skipped":597,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:22:00.178: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8508
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:22:01.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8508" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":277,"completed":51,"skipped":603,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:22:01.704: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5484
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:22:02.592: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1a0ede8f-7d0c-4612-8f37-649a2b6f7dfe" in namespace "downward-api-5484" to be "Succeeded or Failed"
Apr 27 16:22:02.682: INFO: Pod "downwardapi-volume-1a0ede8f-7d0c-4612-8f37-649a2b6f7dfe": Phase="Pending", Reason="", readiness=false. Elapsed: 89.885753ms
Apr 27 16:22:04.772: INFO: Pod "downwardapi-volume-1a0ede8f-7d0c-4612-8f37-649a2b6f7dfe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180286883s
STEP: Saw pod success
Apr 27 16:22:04.772: INFO: Pod "downwardapi-volume-1a0ede8f-7d0c-4612-8f37-649a2b6f7dfe" satisfied condition "Succeeded or Failed"
Apr 27 16:22:04.862: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod downwardapi-volume-1a0ede8f-7d0c-4612-8f37-649a2b6f7dfe container client-container: <nil>
STEP: delete the pod
Apr 27 16:22:05.052: INFO: Waiting for pod downwardapi-volume-1a0ede8f-7d0c-4612-8f37-649a2b6f7dfe to disappear
Apr 27 16:22:05.142: INFO: Pod downwardapi-volume-1a0ede8f-7d0c-4612-8f37-649a2b6f7dfe no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:22:05.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5484" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":52,"skipped":637,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:22:05.323: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5834
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 27 16:22:06.055: INFO: Waiting up to 5m0s for pod "pod-fbbd930a-f970-44f5-b157-f8004eb84d8a" in namespace "emptydir-5834" to be "Succeeded or Failed"
Apr 27 16:22:06.144: INFO: Pod "pod-fbbd930a-f970-44f5-b157-f8004eb84d8a": Phase="Pending", Reason="", readiness=false. Elapsed: 89.732902ms
Apr 27 16:22:08.235: INFO: Pod "pod-fbbd930a-f970-44f5-b157-f8004eb84d8a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179999148s
STEP: Saw pod success
Apr 27 16:22:08.235: INFO: Pod "pod-fbbd930a-f970-44f5-b157-f8004eb84d8a" satisfied condition "Succeeded or Failed"
Apr 27 16:22:08.324: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-fbbd930a-f970-44f5-b157-f8004eb84d8a container test-container: <nil>
STEP: delete the pod
Apr 27 16:22:08.567: INFO: Waiting for pod pod-fbbd930a-f970-44f5-b157-f8004eb84d8a to disappear
Apr 27 16:22:08.657: INFO: Pod pod-fbbd930a-f970-44f5-b157-f8004eb84d8a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:22:08.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5834" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":53,"skipped":650,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:22:08.840: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-364
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-364
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Apr 27 16:22:09.749: INFO: Found 1 stateful pods, waiting for 3
Apr 27 16:22:19.840: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:22:19.840: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:22:19.840: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:22:20.110: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-364 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:22:21.384: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:22:21.384: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:22:21.384: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Apr 27 16:22:31.937: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Apr 27 16:22:32.207: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-364 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:22:33.328: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 16:22:33.328: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:22:33.329: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:22:43.869: INFO: Waiting for StatefulSet statefulset-364/ss2 to complete update
Apr 27 16:22:43.869: INFO: Waiting for Pod statefulset-364/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 27 16:22:43.869: INFO: Waiting for Pod statefulset-364/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 27 16:22:54.049: INFO: Waiting for StatefulSet statefulset-364/ss2 to complete update
Apr 27 16:22:54.049: INFO: Waiting for Pod statefulset-364/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 27 16:23:04.050: INFO: Waiting for StatefulSet statefulset-364/ss2 to complete update
STEP: Rolling back to a previous revision
Apr 27 16:23:14.049: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-364 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:23:15.160: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:23:15.160: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:23:15.160: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:23:25.712: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Apr 27 16:23:25.983: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-364 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:23:27.032: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 16:23:27.032: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:23:27.032: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:23:47.573: INFO: Waiting for StatefulSet statefulset-364/ss2 to complete update
Apr 27 16:23:47.573: INFO: Waiting for Pod statefulset-364/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 16:23:57.753: INFO: Deleting all statefulset in ns statefulset-364
Apr 27 16:23:57.843: INFO: Scaling statefulset ss2 to 0
Apr 27 16:24:08.205: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:24:08.295: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:24:08.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-364" for this suite.
•{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":277,"completed":54,"skipped":692,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:24:08.747: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1027
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-a85c9897-584d-4ac5-9a5d-604a16dfd6c3
STEP: Creating secret with name s-test-opt-upd-f5baa4dc-a99b-4adb-ac27-8700b6f16bde
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-a85c9897-584d-4ac5-9a5d-604a16dfd6c3
STEP: Updating secret s-test-opt-upd-f5baa4dc-a99b-4adb-ac27-8700b6f16bde
STEP: Creating secret with name s-test-opt-create-b4b92dbb-3b35-4e9e-8658-be86fcd0a3fd
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:25:30.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1027" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":55,"skipped":713,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:25:30.787: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6522
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Apr 27 16:25:31.784: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6522 /api/v1/namespaces/watch-6522/configmaps/e2e-watch-test-watch-closed 41678cda-d823-4d6a-a4b4-dabce1eda0f6 12745 0 2020-04-27 16:25:31 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-04-27 16:25:31 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:25:31.785: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6522 /api/v1/namespaces/watch-6522/configmaps/e2e-watch-test-watch-closed 41678cda-d823-4d6a-a4b4-dabce1eda0f6 12748 0 2020-04-27 16:25:31 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-04-27 16:25:31 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Apr 27 16:25:32.145: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6522 /api/v1/namespaces/watch-6522/configmaps/e2e-watch-test-watch-closed 41678cda-d823-4d6a-a4b4-dabce1eda0f6 12749 0 2020-04-27 16:25:31 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-04-27 16:25:31 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:25:32.145: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6522 /api/v1/namespaces/watch-6522/configmaps/e2e-watch-test-watch-closed 41678cda-d823-4d6a-a4b4-dabce1eda0f6 12750 0 2020-04-27 16:25:31 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-04-27 16:25:31 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:25:32.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6522" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":277,"completed":56,"skipped":778,"failed":0}
SSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:25:32.326: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1072
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Apr 27 16:25:33.058: INFO: Waiting up to 5m0s for pod "downward-api-0ce1a5b0-83c9-43d4-b9b1-0211e34e4e82" in namespace "downward-api-1072" to be "Succeeded or Failed"
Apr 27 16:25:33.148: INFO: Pod "downward-api-0ce1a5b0-83c9-43d4-b9b1-0211e34e4e82": Phase="Pending", Reason="", readiness=false. Elapsed: 89.382061ms
Apr 27 16:25:35.238: INFO: Pod "downward-api-0ce1a5b0-83c9-43d4-b9b1-0211e34e4e82": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179699636s
STEP: Saw pod success
Apr 27 16:25:35.238: INFO: Pod "downward-api-0ce1a5b0-83c9-43d4-b9b1-0211e34e4e82" satisfied condition "Succeeded or Failed"
Apr 27 16:25:35.327: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod downward-api-0ce1a5b0-83c9-43d4-b9b1-0211e34e4e82 container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:25:35.516: INFO: Waiting for pod downward-api-0ce1a5b0-83c9-43d4-b9b1-0211e34e4e82 to disappear
Apr 27 16:25:35.605: INFO: Pod downward-api-0ce1a5b0-83c9-43d4-b9b1-0211e34e4e82 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:25:35.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1072" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":277,"completed":57,"skipped":782,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:25:35.787: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1320
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:25:37.880: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601537, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601537, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601537, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601537, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:25:41.065: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:25:42.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1320" for this suite.
STEP: Destroying namespace "webhook-1320-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":277,"completed":58,"skipped":799,"failed":0}
SSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:25:42.802: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-6875
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Apr 27 16:25:46.075: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:25:46.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6875" for this suite.
•{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":277,"completed":59,"skipped":806,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:25:46.530: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3622
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl label
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1206
STEP: creating the pod
Apr 27 16:25:47.169: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-3622'
Apr 27 16:25:48.275: INFO: stderr: ""
Apr 27 16:25:48.275: INFO: stdout: "pod/pause created\n"
Apr 27 16:25:48.275: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr 27 16:25:48.275: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-3622" to be "running and ready"
Apr 27 16:25:48.366: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 90.408101ms
Apr 27 16:25:50.456: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.180664316s
Apr 27 16:25:50.456: INFO: Pod "pause" satisfied condition "running and ready"
Apr 27 16:25:50.456: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: adding the label testing-label with value testing-label-value to a pod
Apr 27 16:25:50.456: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config label pods pause testing-label=testing-label-value --namespace=kubectl-3622'
Apr 27 16:25:50.887: INFO: stderr: ""
Apr 27 16:25:50.887: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Apr 27 16:25:50.887: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod pause -L testing-label --namespace=kubectl-3622'
Apr 27 16:25:51.218: INFO: stderr: ""
Apr 27 16:25:51.218: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Apr 27 16:25:51.218: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config label pods pause testing-label- --namespace=kubectl-3622'
Apr 27 16:25:51.642: INFO: stderr: ""
Apr 27 16:25:51.642: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Apr 27 16:25:51.642: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod pause -L testing-label --namespace=kubectl-3622'
Apr 27 16:25:51.972: INFO: stderr: ""
Apr 27 16:25:51.972: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1213
STEP: using delete to clean up resources
Apr 27 16:25:51.972: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-3622'
Apr 27 16:25:52.430: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 16:25:52.430: INFO: stdout: "pod \"pause\" force deleted\n"
Apr 27 16:25:52.430: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=pause --no-headers --namespace=kubectl-3622'
Apr 27 16:25:52.852: INFO: stderr: "No resources found in kubectl-3622 namespace.\n"
Apr 27 16:25:52.852: INFO: stdout: ""
Apr 27 16:25:52.852: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=pause --namespace=kubectl-3622 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 27 16:25:53.184: INFO: stderr: ""
Apr 27 16:25:53.184: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:25:53.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3622" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":277,"completed":60,"skipped":901,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:25:53.367: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-695
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:25:54.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-695" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":277,"completed":61,"skipped":958,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:25:54.369: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4203
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-d7efebf8-dd4d-4d67-a5c2-cd710abf186e in namespace container-probe-4203
Apr 27 16:25:57.279: INFO: Started pod busybox-d7efebf8-dd4d-4d67-a5c2-cd710abf186e in namespace container-probe-4203
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 16:25:57.369: INFO: Initial restart count of pod busybox-d7efebf8-dd4d-4d67-a5c2-cd710abf186e is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:29:57.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4203" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":277,"completed":62,"skipped":992,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:29:58.058: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7454
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 27 16:29:58.790: INFO: Waiting up to 5m0s for pod "pod-10b6ecd6-0975-495c-8488-a04b08baa855" in namespace "emptydir-7454" to be "Succeeded or Failed"
Apr 27 16:29:58.880: INFO: Pod "pod-10b6ecd6-0975-495c-8488-a04b08baa855": Phase="Pending", Reason="", readiness=false. Elapsed: 89.810243ms
Apr 27 16:30:00.970: INFO: Pod "pod-10b6ecd6-0975-495c-8488-a04b08baa855": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180077106s
STEP: Saw pod success
Apr 27 16:30:00.970: INFO: Pod "pod-10b6ecd6-0975-495c-8488-a04b08baa855" satisfied condition "Succeeded or Failed"
Apr 27 16:30:01.060: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-10b6ecd6-0975-495c-8488-a04b08baa855 container test-container: <nil>
STEP: delete the pod
Apr 27 16:30:01.361: INFO: Waiting for pod pod-10b6ecd6-0975-495c-8488-a04b08baa855 to disappear
Apr 27 16:30:01.453: INFO: Pod pod-10b6ecd6-0975-495c-8488-a04b08baa855 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:01.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7454" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":63,"skipped":1083,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:01.717: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5599
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:157
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:02.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5599" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":277,"completed":64,"skipped":1095,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:02.774: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6907
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with configMap that has name projected-configmap-test-upd-5d145823-63ae-4d5f-936d-66b743fed7cd
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-5d145823-63ae-4d5f-936d-66b743fed7cd
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:10.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6907" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":65,"skipped":1112,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:10.670: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3664
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 27 16:30:11.404: INFO: Waiting up to 5m0s for pod "pod-0366b6b1-e5e0-4f03-ad69-3c3a35f138eb" in namespace "emptydir-3664" to be "Succeeded or Failed"
Apr 27 16:30:11.494: INFO: Pod "pod-0366b6b1-e5e0-4f03-ad69-3c3a35f138eb": Phase="Pending", Reason="", readiness=false. Elapsed: 89.849578ms
Apr 27 16:30:13.584: INFO: Pod "pod-0366b6b1-e5e0-4f03-ad69-3c3a35f138eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180216353s
STEP: Saw pod success
Apr 27 16:30:13.584: INFO: Pod "pod-0366b6b1-e5e0-4f03-ad69-3c3a35f138eb" satisfied condition "Succeeded or Failed"
Apr 27 16:30:13.674: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-0366b6b1-e5e0-4f03-ad69-3c3a35f138eb container test-container: <nil>
STEP: delete the pod
Apr 27 16:30:13.862: INFO: Waiting for pod pod-0366b6b1-e5e0-4f03-ad69-3c3a35f138eb to disappear
Apr 27 16:30:13.952: INFO: Pod pod-0366b6b1-e5e0-4f03-ad69-3c3a35f138eb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:13.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3664" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":66,"skipped":1126,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:14.134: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1390
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Apr 27 16:30:14.774: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-1390'
Apr 27 16:30:15.295: INFO: stderr: ""
Apr 27 16:30:15.295: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 27 16:30:15.295: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1390'
Apr 27 16:30:15.632: INFO: stderr: ""
Apr 27 16:30:15.632: INFO: stdout: "update-demo-nautilus-9m47p update-demo-nautilus-bltbl "
Apr 27 16:30:15.632: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-9m47p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1390'
Apr 27 16:30:15.964: INFO: stderr: ""
Apr 27 16:30:15.964: INFO: stdout: ""
Apr 27 16:30:15.964: INFO: update-demo-nautilus-9m47p is created but not running
Apr 27 16:30:20.964: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1390'
Apr 27 16:30:21.300: INFO: stderr: ""
Apr 27 16:30:21.300: INFO: stdout: "update-demo-nautilus-9m47p update-demo-nautilus-bltbl "
Apr 27 16:30:21.300: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-9m47p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1390'
Apr 27 16:30:21.631: INFO: stderr: ""
Apr 27 16:30:21.631: INFO: stdout: "true"
Apr 27 16:30:21.631: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-9m47p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1390'
Apr 27 16:30:21.961: INFO: stderr: ""
Apr 27 16:30:21.961: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:30:21.961: INFO: validating pod update-demo-nautilus-9m47p
Apr 27 16:30:22.179: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:30:22.179: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:30:22.179: INFO: update-demo-nautilus-9m47p is verified up and running
Apr 27 16:30:22.179: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-bltbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1390'
Apr 27 16:30:22.509: INFO: stderr: ""
Apr 27 16:30:22.509: INFO: stdout: "true"
Apr 27 16:30:22.509: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-bltbl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1390'
Apr 27 16:30:22.839: INFO: stderr: ""
Apr 27 16:30:22.840: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:30:22.840: INFO: validating pod update-demo-nautilus-bltbl
Apr 27 16:30:23.019: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:30:23.019: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:30:23.019: INFO: update-demo-nautilus-bltbl is verified up and running
STEP: using delete to clean up resources
Apr 27 16:30:23.019: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-1390'
Apr 27 16:30:23.436: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 16:30:23.436: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 27 16:30:23.436: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1390'
Apr 27 16:30:23.857: INFO: stderr: "No resources found in kubectl-1390 namespace.\n"
Apr 27 16:30:23.857: INFO: stdout: ""
Apr 27 16:30:23.857: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-1390 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 27 16:30:24.189: INFO: stderr: ""
Apr 27 16:30:24.189: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:24.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1390" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":277,"completed":67,"skipped":1182,"failed":0}
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:24.370: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6809
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:27.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6809" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":68,"skipped":1192,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:27.651: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2484
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Apr 27 16:30:31.437: INFO: Successfully updated pod "labelsupdateb678baa6-86da-48e6-be05-4f0b929a1d3c"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:33.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2484" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":277,"completed":69,"skipped":1254,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:33.818: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-650
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:30:35.839: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601835, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601835, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601835, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601835, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:30:39.024: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:30:39.113: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6229-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:40.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-650" for this suite.
STEP: Destroying namespace "webhook-650-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":277,"completed":70,"skipped":1297,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:40.904: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6416
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Apr 27 16:30:41.595: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:44.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6416" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":277,"completed":71,"skipped":1305,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:44.782: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8700
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:30:45.512: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3bcf7604-916d-4833-a1d3-7bdbb0f876a3" in namespace "projected-8700" to be "Succeeded or Failed"
Apr 27 16:30:45.602: INFO: Pod "downwardapi-volume-3bcf7604-916d-4833-a1d3-7bdbb0f876a3": Phase="Pending", Reason="", readiness=false. Elapsed: 89.421532ms
Apr 27 16:30:47.692: INFO: Pod "downwardapi-volume-3bcf7604-916d-4833-a1d3-7bdbb0f876a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179654942s
STEP: Saw pod success
Apr 27 16:30:47.692: INFO: Pod "downwardapi-volume-3bcf7604-916d-4833-a1d3-7bdbb0f876a3" satisfied condition "Succeeded or Failed"
Apr 27 16:30:47.782: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod downwardapi-volume-3bcf7604-916d-4833-a1d3-7bdbb0f876a3 container client-container: <nil>
STEP: delete the pod
Apr 27 16:30:47.971: INFO: Waiting for pod downwardapi-volume-3bcf7604-916d-4833-a1d3-7bdbb0f876a3 to disappear
Apr 27 16:30:48.061: INFO: Pod downwardapi-volume-3bcf7604-916d-4833-a1d3-7bdbb0f876a3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:48.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8700" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":277,"completed":72,"skipped":1315,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:48.243: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4906
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service nodeport-service with the type=NodePort in namespace services-4906
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-4906
STEP: creating replication controller externalsvc in namespace services-4906
I0427 16:30:49.159174    7325 runners.go:190] Created replication controller with name: externalsvc, namespace: services-4906, replica count: 2
I0427 16:30:52.259801    7325 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Apr 27 16:30:52.535: INFO: Creating new exec pod
Apr 27 16:30:54.807: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-4906 execpodtc9qq -- /bin/sh -x -c nslookup nodeport-service'
Apr 27 16:30:55.895: INFO: stderr: "+ nslookup nodeport-service\n"
Apr 27 16:30:55.895: INFO: stdout: "Server:\t\t100.104.0.10\nAddress:\t100.104.0.10#53\n\nnodeport-service.services-4906.svc.cluster.local\tcanonical name = externalsvc.services-4906.svc.cluster.local.\nName:\texternalsvc.services-4906.svc.cluster.local\nAddress: 100.108.171.30\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-4906, will wait for the garbage collector to delete the pods
Apr 27 16:30:56.176: INFO: Deleting ReplicationController externalsvc took: 91.294793ms
Apr 27 16:30:56.776: INFO: Terminating ReplicationController externalsvc pods took: 600.311962ms
Apr 27 16:31:02.772: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:02.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4906" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":277,"completed":73,"skipped":1341,"failed":0}

------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:03.046: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7094
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-50fc1801-796f-4734-b08d-b24da59f166b
STEP: Creating a pod to test consume configMaps
Apr 27 16:31:03.868: INFO: Waiting up to 5m0s for pod "pod-configmaps-6c31a137-2c32-440a-9e37-2e0d396f62cc" in namespace "configmap-7094" to be "Succeeded or Failed"
Apr 27 16:31:03.958: INFO: Pod "pod-configmaps-6c31a137-2c32-440a-9e37-2e0d396f62cc": Phase="Pending", Reason="", readiness=false. Elapsed: 89.794487ms
Apr 27 16:31:06.048: INFO: Pod "pod-configmaps-6c31a137-2c32-440a-9e37-2e0d396f62cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180050427s
STEP: Saw pod success
Apr 27 16:31:06.048: INFO: Pod "pod-configmaps-6c31a137-2c32-440a-9e37-2e0d396f62cc" satisfied condition "Succeeded or Failed"
Apr 27 16:31:06.138: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-configmaps-6c31a137-2c32-440a-9e37-2e0d396f62cc container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:31:06.326: INFO: Waiting for pod pod-configmaps-6c31a137-2c32-440a-9e37-2e0d396f62cc to disappear
Apr 27 16:31:06.416: INFO: Pod pod-configmaps-6c31a137-2c32-440a-9e37-2e0d396f62cc no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:06.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7094" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":277,"completed":74,"skipped":1341,"failed":0}
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:06.598: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8817
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 27 16:31:12.238: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 27 16:31:12.328: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 27 16:31:14.329: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 27 16:31:14.419: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 27 16:31:16.329: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 27 16:31:16.419: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:16.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8817" for this suite.
•{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":277,"completed":75,"skipped":1345,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:16.601: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3091
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-3091
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 27 16:31:17.239: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 27 16:31:17.694: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:31:19.785: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:31:21.786: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:31:23.785: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:31:25.785: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:31:27.785: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:31:29.785: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:31:31.785: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:31:33.785: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:31:35.785: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr 27 16:31:35.965: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Apr 27 16:31:38.506: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.114:8080/dial?request=hostname&protocol=udp&host=100.64.1.113&port=8081&tries=1'] Namespace:pod-network-test-3091 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:31:38.506: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:31:39.267: INFO: Waiting for responses: map[]
Apr 27 16:31:39.357: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.114:8080/dial?request=hostname&protocol=udp&host=100.64.0.23&port=8081&tries=1'] Namespace:pod-network-test-3091 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:31:39.357: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:31:40.102: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:40.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3091" for this suite.
•{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":277,"completed":76,"skipped":1362,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:40.284: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3254
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-5970aaa7-c65c-40ac-aee8-945b3cd02935
STEP: Creating a pod to test consume secrets
Apr 27 16:31:41.105: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a05409bd-0c80-45b3-822b-94f9784acd58" in namespace "projected-3254" to be "Succeeded or Failed"
Apr 27 16:31:41.195: INFO: Pod "pod-projected-secrets-a05409bd-0c80-45b3-822b-94f9784acd58": Phase="Pending", Reason="", readiness=false. Elapsed: 89.605195ms
Apr 27 16:31:43.285: INFO: Pod "pod-projected-secrets-a05409bd-0c80-45b3-822b-94f9784acd58": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179641745s
STEP: Saw pod success
Apr 27 16:31:43.285: INFO: Pod "pod-projected-secrets-a05409bd-0c80-45b3-822b-94f9784acd58" satisfied condition "Succeeded or Failed"
Apr 27 16:31:43.379: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-projected-secrets-a05409bd-0c80-45b3-822b-94f9784acd58 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:31:43.569: INFO: Waiting for pod pod-projected-secrets-a05409bd-0c80-45b3-822b-94f9784acd58 to disappear
Apr 27 16:31:43.659: INFO: Pod pod-projected-secrets-a05409bd-0c80-45b3-822b-94f9784acd58 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:43.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3254" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":77,"skipped":1390,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:43.840: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6933
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:31:45.597: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601905, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601905, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601905, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601905, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:31:48.781: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:50.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6933" for this suite.
STEP: Destroying namespace "webhook-6933-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":277,"completed":78,"skipped":1419,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:50.703: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8488
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-c2b7e6ab-eb1d-4256-b49e-dcd0573e02c5 in namespace container-probe-8488
Apr 27 16:31:53.614: INFO: Started pod liveness-c2b7e6ab-eb1d-4256-b49e-dcd0573e02c5 in namespace container-probe-8488
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 16:31:53.704: INFO: Initial restart count of pod liveness-c2b7e6ab-eb1d-4256-b49e-dcd0573e02c5 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:35:54.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8488" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":277,"completed":79,"skipped":1431,"failed":0}
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:35:54.369: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5029
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 27 16:35:55.731: INFO: Number of nodes with available pods: 0
Apr 27 16:35:55.731: INFO: Node ip-10-250-10-186.ec2.internal is running more than one daemon pod
Apr 27 16:35:56.916: INFO: Number of nodes with available pods: 2
Apr 27 16:35:56.916: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Apr 27 16:35:57.370: INFO: Number of nodes with available pods: 1
Apr 27 16:35:57.370: INFO: Node ip-10-250-8-65.ec2.internal is running more than one daemon pod
Apr 27 16:35:58.552: INFO: Number of nodes with available pods: 1
Apr 27 16:35:58.552: INFO: Node ip-10-250-8-65.ec2.internal is running more than one daemon pod
Apr 27 16:35:59.609: INFO: Number of nodes with available pods: 1
Apr 27 16:35:59.609: INFO: Node ip-10-250-8-65.ec2.internal is running more than one daemon pod
Apr 27 16:36:00.551: INFO: Number of nodes with available pods: 1
Apr 27 16:36:00.551: INFO: Node ip-10-250-8-65.ec2.internal is running more than one daemon pod
Apr 27 16:36:01.551: INFO: Number of nodes with available pods: 1
Apr 27 16:36:01.551: INFO: Node ip-10-250-8-65.ec2.internal is running more than one daemon pod
Apr 27 16:36:02.551: INFO: Number of nodes with available pods: 1
Apr 27 16:36:02.552: INFO: Node ip-10-250-8-65.ec2.internal is running more than one daemon pod
Apr 27 16:36:03.552: INFO: Number of nodes with available pods: 1
Apr 27 16:36:03.552: INFO: Node ip-10-250-8-65.ec2.internal is running more than one daemon pod
Apr 27 16:36:04.552: INFO: Number of nodes with available pods: 1
Apr 27 16:36:04.552: INFO: Node ip-10-250-8-65.ec2.internal is running more than one daemon pod
Apr 27 16:36:05.552: INFO: Number of nodes with available pods: 2
Apr 27 16:36:05.552: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5029, will wait for the garbage collector to delete the pods
Apr 27 16:36:05.925: INFO: Deleting DaemonSet.extensions daemon-set took: 91.065191ms
Apr 27 16:36:06.525: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.265258ms
Apr 27 16:36:12.815: INFO: Number of nodes with available pods: 0
Apr 27 16:36:12.815: INFO: Number of running nodes: 0, number of available pods: 0
Apr 27 16:36:12.905: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5029/daemonsets","resourceVersion":"16617"},"items":null}

Apr 27 16:36:12.994: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5029/pods","resourceVersion":"16617"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:13.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5029" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":277,"completed":80,"skipped":1437,"failed":0}
SSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:13.446: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-885
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test hostPath mode
Apr 27 16:36:14.180: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-885" to be "Succeeded or Failed"
Apr 27 16:36:14.270: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 89.623499ms
Apr 27 16:36:16.361: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.181379583s
STEP: Saw pod success
Apr 27 16:36:16.361: INFO: Pod "pod-host-path-test" satisfied condition "Succeeded or Failed"
Apr 27 16:36:16.451: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Apr 27 16:36:16.732: INFO: Waiting for pod pod-host-path-test to disappear
Apr 27 16:36:16.822: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:16.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-885" for this suite.
•{"msg":"PASSED [sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":81,"skipped":1442,"failed":0}
SSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:17.004: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-274
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-274
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-274
I0427 16:36:18.009250    7325 runners.go:190] Created replication controller with name: externalname-service, namespace: services-274, replica count: 2
Apr 27 16:36:21.109: INFO: Creating new exec pod
I0427 16:36:21.109882    7325 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 27 16:36:24.473: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-274 execpodqd8m8 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Apr 27 16:36:31.044: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 27 16:36:31.045: INFO: stdout: ""
Apr 27 16:36:31.045: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-274 execpodqd8m8 -- /bin/sh -x -c nc -zv -t -w 2 100.106.112.228 80'
Apr 27 16:36:32.127: INFO: stderr: "+ nc -zv -t -w 2 100.106.112.228 80\nConnection to 100.106.112.228 80 port [tcp/http] succeeded!\n"
Apr 27 16:36:32.127: INFO: stdout: ""
Apr 27 16:36:32.127: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-274 execpodqd8m8 -- /bin/sh -x -c nc -zv -t -w 2 10.250.10.186 30687'
Apr 27 16:36:33.226: INFO: stderr: "+ nc -zv -t -w 2 10.250.10.186 30687\nConnection to 10.250.10.186 30687 port [tcp/30687] succeeded!\n"
Apr 27 16:36:33.226: INFO: stdout: ""
Apr 27 16:36:33.226: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-274 execpodqd8m8 -- /bin/sh -x -c nc -zv -t -w 2 10.250.8.65 30687'
Apr 27 16:36:34.285: INFO: stderr: "+ nc -zv -t -w 2 10.250.8.65 30687\nConnection to 10.250.8.65 30687 port [tcp/30687] succeeded!\n"
Apr 27 16:36:34.285: INFO: stdout: ""
Apr 27 16:36:34.285: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:34.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-274" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":277,"completed":82,"skipped":1451,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:34.567: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1264
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-a16153e2-f51b-42d6-99db-c36229f75f1c
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:37.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1264" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":83,"skipped":1469,"failed":0}
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:38.124: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6711
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-9b3c7031-d1af-4909-90dd-b48e1a06385c
STEP: Creating a pod to test consume configMaps
Apr 27 16:36:38.945: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-79c4bb2c-1a82-4ba6-8dc2-18cfe37a38ba" in namespace "projected-6711" to be "Succeeded or Failed"
Apr 27 16:36:39.035: INFO: Pod "pod-projected-configmaps-79c4bb2c-1a82-4ba6-8dc2-18cfe37a38ba": Phase="Pending", Reason="", readiness=false. Elapsed: 89.91684ms
Apr 27 16:36:41.125: INFO: Pod "pod-projected-configmaps-79c4bb2c-1a82-4ba6-8dc2-18cfe37a38ba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180227809s
STEP: Saw pod success
Apr 27 16:36:41.125: INFO: Pod "pod-projected-configmaps-79c4bb2c-1a82-4ba6-8dc2-18cfe37a38ba" satisfied condition "Succeeded or Failed"
Apr 27 16:36:41.215: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-projected-configmaps-79c4bb2c-1a82-4ba6-8dc2-18cfe37a38ba container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:36:41.405: INFO: Waiting for pod pod-projected-configmaps-79c4bb2c-1a82-4ba6-8dc2-18cfe37a38ba to disappear
Apr 27 16:36:41.495: INFO: Pod pod-projected-configmaps-79c4bb2c-1a82-4ba6-8dc2-18cfe37a38ba no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:41.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6711" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":277,"completed":84,"skipped":1473,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:41.676: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6350
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-9bebb7ec-a962-470e-8053-1ba0ab9ca417
STEP: Creating a pod to test consume configMaps
Apr 27 16:36:42.497: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-22fdc0f6-5afc-4cd8-9465-ae7f99c84d13" in namespace "projected-6350" to be "Succeeded or Failed"
Apr 27 16:36:42.587: INFO: Pod "pod-projected-configmaps-22fdc0f6-5afc-4cd8-9465-ae7f99c84d13": Phase="Pending", Reason="", readiness=false. Elapsed: 89.698679ms
Apr 27 16:36:44.677: INFO: Pod "pod-projected-configmaps-22fdc0f6-5afc-4cd8-9465-ae7f99c84d13": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179937351s
STEP: Saw pod success
Apr 27 16:36:44.677: INFO: Pod "pod-projected-configmaps-22fdc0f6-5afc-4cd8-9465-ae7f99c84d13" satisfied condition "Succeeded or Failed"
Apr 27 16:36:44.767: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-projected-configmaps-22fdc0f6-5afc-4cd8-9465-ae7f99c84d13 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:36:44.958: INFO: Waiting for pod pod-projected-configmaps-22fdc0f6-5afc-4cd8-9465-ae7f99c84d13 to disappear
Apr 27 16:36:45.048: INFO: Pod pod-projected-configmaps-22fdc0f6-5afc-4cd8-9465-ae7f99c84d13 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:45.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6350" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":85,"skipped":1502,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:45.230: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-5697
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Apr 27 16:36:45.868: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 27 16:36:46.141: INFO: Waiting for terminating namespaces to be deleted...
Apr 27 16:36:46.231: INFO: 
Logging pods the kubelet thinks is on node ip-10-250-10-186.ec2.internal before test
Apr 27 16:36:46.338: INFO: node-exporter-zggrn from kube-system started at 2020-04-27 15:54:02 +0000 UTC (1 container statuses recorded)
Apr 27 16:36:46.338: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:36:46.338: INFO: calico-node-mvhvc from kube-system started at 2020-04-27 15:57:54 +0000 UTC (1 container statuses recorded)
Apr 27 16:36:46.338: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:36:46.338: INFO: node-problem-detector-f7dh2 from kube-system started at 2020-04-27 15:54:02 +0000 UTC (1 container statuses recorded)
Apr 27 16:36:46.338: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 16:36:46.338: INFO: pod-configmaps-813673ec-e527-4e25-894b-b8be43c6131e from configmap-1264 started at 2020-04-27 16:36:35 +0000 UTC (2 container statuses recorded)
Apr 27 16:36:46.338: INFO: 	Container configmap-volume-binary-test ready: false, restart count 0
Apr 27 16:36:46.338: INFO: 	Container configmap-volume-data-test ready: false, restart count 0
Apr 27 16:36:46.338: INFO: kube-proxy-f8lnb from kube-system started at 2020-04-27 15:54:02 +0000 UTC (1 container statuses recorded)
Apr 27 16:36:46.338: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:36:46.338: INFO: csi-driver-node-qjp4d from kube-system started at 2020-04-27 15:54:02 +0000 UTC (3 container statuses recorded)
Apr 27 16:36:46.338: INFO: 	Container csi-driver ready: true, restart count 0
Apr 27 16:36:46.338: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 27 16:36:46.338: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 27 16:36:46.338: INFO: 
Logging pods the kubelet thinks is on node ip-10-250-8-65.ec2.internal before test
Apr 27 16:36:46.469: INFO: kube-proxy-2tzh4 from kube-system started at 2020-04-27 15:53:59 +0000 UTC (1 container statuses recorded)
Apr 27 16:36:46.469: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:36:46.469: INFO: dashboard-metrics-scraper-76c7b697bc-ghctb from kubernetes-dashboard started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:36:46.469: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 27 16:36:46.469: INFO: kubernetes-dashboard-6b586c4cb4-jw8gc from kubernetes-dashboard started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:36:46.469: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 27 16:36:46.469: INFO: csi-driver-node-lqmtr from kube-system started at 2020-04-27 15:53:59 +0000 UTC (3 container statuses recorded)
Apr 27 16:36:46.469: INFO: 	Container csi-driver ready: true, restart count 0
Apr 27 16:36:46.469: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 27 16:36:46.469: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 27 16:36:46.469: INFO: calico-typha-vertical-autoscaler-5b477c88cf-lq56p from kube-system started at 2020-04-27 15:54:17 +0000 UTC (1 container statuses recorded)
Apr 27 16:36:46.469: INFO: 	Container autoscaler ready: true, restart count 3
Apr 27 16:36:46.469: INFO: vpn-shoot-5c755d796f-fvlqt from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:36:46.469: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 27 16:36:46.469: INFO: calico-node-vertical-autoscaler-74d4897db8-g7wmv from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:36:46.469: INFO: 	Container autoscaler ready: true, restart count 3
Apr 27 16:36:46.469: INFO: calico-node-l4j7q from kube-system started at 2020-04-27 15:57:44 +0000 UTC (1 container statuses recorded)
Apr 27 16:36:46.469: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:36:46.469: INFO: node-exporter-vv796 from kube-system started at 2020-04-27 15:53:59 +0000 UTC (1 container statuses recorded)
Apr 27 16:36:46.469: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:36:46.469: INFO: calico-kube-controllers-77dcb8f688-f6jtd from kube-system started at 2020-04-27 15:54:17 +0000 UTC (1 container statuses recorded)
Apr 27 16:36:46.469: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 27 16:36:46.469: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-hqsfl from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:36:46.469: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr 27 16:36:46.469: INFO: calico-typha-horizontal-autoscaler-6fdd5d8746-vxwg5 from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:36:46.469: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 16:36:46.469: INFO: metrics-server-7dd4d485f9-ff6mk from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:36:46.469: INFO: 	Container metrics-server ready: true, restart count 0
Apr 27 16:36:46.469: INFO: coredns-5cb857d789-bn7lm from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:36:46.469: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:36:46.469: INFO: calico-typha-deploy-784665cc66-dtz47 from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:36:46.469: INFO: 	Container calico-typha ready: true, restart count 0
Apr 27 16:36:46.469: INFO: blackbox-exporter-5dc75b79b7-hcrbp from kube-system started at 2020-04-27 15:53:59 +0000 UTC (1 container statuses recorded)
Apr 27 16:36:46.469: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 27 16:36:46.469: INFO: node-problem-detector-frcdg from kube-system started at 2020-04-27 15:53:59 +0000 UTC (1 container statuses recorded)
Apr 27 16:36:46.469: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 16:36:46.469: INFO: coredns-5cb857d789-m225g from kube-system started at 2020-04-27 15:54:14 +0000 UTC (1 container statuses recorded)
Apr 27 16:36:46.469: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:36:46.469: INFO: addons-nginx-ingress-controller-6cf77756b5-8sgd9 from kube-system started at 2020-04-27 15:54:17 +0000 UTC (1 container statuses recorded)
Apr 27 16:36:46.469: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: verifying the node has the label node ip-10-250-10-186.ec2.internal
STEP: verifying the node has the label node ip-10-250-8-65.ec2.internal
Apr 27 16:36:47.031: INFO: Pod addons-nginx-ingress-controller-6cf77756b5-8sgd9 requesting resource cpu=100m on Node ip-10-250-8-65.ec2.internal
Apr 27 16:36:47.031: INFO: Pod addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-hqsfl requesting resource cpu=0m on Node ip-10-250-8-65.ec2.internal
Apr 27 16:36:47.031: INFO: Pod blackbox-exporter-5dc75b79b7-hcrbp requesting resource cpu=5m on Node ip-10-250-8-65.ec2.internal
Apr 27 16:36:47.031: INFO: Pod calico-kube-controllers-77dcb8f688-f6jtd requesting resource cpu=10m on Node ip-10-250-8-65.ec2.internal
Apr 27 16:36:47.031: INFO: Pod calico-node-l4j7q requesting resource cpu=250m on Node ip-10-250-8-65.ec2.internal
Apr 27 16:36:47.031: INFO: Pod calico-node-mvhvc requesting resource cpu=250m on Node ip-10-250-10-186.ec2.internal
Apr 27 16:36:47.031: INFO: Pod calico-node-vertical-autoscaler-74d4897db8-g7wmv requesting resource cpu=10m on Node ip-10-250-8-65.ec2.internal
Apr 27 16:36:47.031: INFO: Pod calico-typha-deploy-784665cc66-dtz47 requesting resource cpu=200m on Node ip-10-250-8-65.ec2.internal
Apr 27 16:36:47.031: INFO: Pod calico-typha-horizontal-autoscaler-6fdd5d8746-vxwg5 requesting resource cpu=10m on Node ip-10-250-8-65.ec2.internal
Apr 27 16:36:47.031: INFO: Pod calico-typha-vertical-autoscaler-5b477c88cf-lq56p requesting resource cpu=10m on Node ip-10-250-8-65.ec2.internal
Apr 27 16:36:47.031: INFO: Pod coredns-5cb857d789-bn7lm requesting resource cpu=50m on Node ip-10-250-8-65.ec2.internal
Apr 27 16:36:47.031: INFO: Pod coredns-5cb857d789-m225g requesting resource cpu=50m on Node ip-10-250-8-65.ec2.internal
Apr 27 16:36:47.031: INFO: Pod csi-driver-node-lqmtr requesting resource cpu=20m on Node ip-10-250-8-65.ec2.internal
Apr 27 16:36:47.031: INFO: Pod csi-driver-node-qjp4d requesting resource cpu=20m on Node ip-10-250-10-186.ec2.internal
Apr 27 16:36:47.031: INFO: Pod kube-proxy-2tzh4 requesting resource cpu=20m on Node ip-10-250-8-65.ec2.internal
Apr 27 16:36:47.031: INFO: Pod kube-proxy-f8lnb requesting resource cpu=20m on Node ip-10-250-10-186.ec2.internal
Apr 27 16:36:47.031: INFO: Pod metrics-server-7dd4d485f9-ff6mk requesting resource cpu=20m on Node ip-10-250-8-65.ec2.internal
Apr 27 16:36:47.031: INFO: Pod node-exporter-vv796 requesting resource cpu=5m on Node ip-10-250-8-65.ec2.internal
Apr 27 16:36:47.031: INFO: Pod node-exporter-zggrn requesting resource cpu=5m on Node ip-10-250-10-186.ec2.internal
Apr 27 16:36:47.031: INFO: Pod node-problem-detector-f7dh2 requesting resource cpu=20m on Node ip-10-250-10-186.ec2.internal
Apr 27 16:36:47.031: INFO: Pod node-problem-detector-frcdg requesting resource cpu=20m on Node ip-10-250-8-65.ec2.internal
Apr 27 16:36:47.031: INFO: Pod vpn-shoot-5c755d796f-fvlqt requesting resource cpu=100m on Node ip-10-250-8-65.ec2.internal
Apr 27 16:36:47.031: INFO: Pod dashboard-metrics-scraper-76c7b697bc-ghctb requesting resource cpu=0m on Node ip-10-250-8-65.ec2.internal
Apr 27 16:36:47.031: INFO: Pod kubernetes-dashboard-6b586c4cb4-jw8gc requesting resource cpu=50m on Node ip-10-250-8-65.ec2.internal
STEP: Starting Pods to consume most of the cluster CPU.
Apr 27 16:36:47.031: INFO: Creating a pod which consumes cpu=1123m on Node ip-10-250-10-186.ec2.internal
Apr 27 16:36:47.124: INFO: Creating a pod which consumes cpu=693m on Node ip-10-250-8-65.ec2.internal
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-158110ef-ab97-443e-af9e-939c8b8f7594.1609ba810e6cc9b0], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5697/filler-pod-158110ef-ab97-443e-af9e-939c8b8f7594 to ip-10-250-10-186.ec2.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-158110ef-ab97-443e-af9e-939c8b8f7594.1609ba813541b701], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-158110ef-ab97-443e-af9e-939c8b8f7594.1609ba81380a505e], Reason = [Created], Message = [Created container filler-pod-158110ef-ab97-443e-af9e-939c8b8f7594]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-158110ef-ab97-443e-af9e-939c8b8f7594.1609ba813d31261e], Reason = [Started], Message = [Started container filler-pod-158110ef-ab97-443e-af9e-939c8b8f7594]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8ce196e9-b037-4cf6-81f9-5d50c2cb8106.1609ba8113e2a040], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5697/filler-pod-8ce196e9-b037-4cf6-81f9-5d50c2cb8106 to ip-10-250-8-65.ec2.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8ce196e9-b037-4cf6-81f9-5d50c2cb8106.1609ba813be7cd8e], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.2"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8ce196e9-b037-4cf6-81f9-5d50c2cb8106.1609ba815fb49471], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.2"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8ce196e9-b037-4cf6-81f9-5d50c2cb8106.1609ba8162626263], Reason = [Created], Message = [Created container filler-pod-8ce196e9-b037-4cf6-81f9-5d50c2cb8106]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8ce196e9-b037-4cf6-81f9-5d50c2cb8106.1609ba816982ad17], Reason = [Started], Message = [Started container filler-pod-8ce196e9-b037-4cf6-81f9-5d50c2cb8106]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1609ba8227ee39c1], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1609ba8228273830], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node ip-10-250-10-186.ec2.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-250-8-65.ec2.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:53.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5697" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":277,"completed":86,"skipped":1530,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:53.752: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-854
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:37:06.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-854" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":277,"completed":87,"skipped":1542,"failed":0}
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:37:06.212: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4277
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-4277
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating stateful set ss in namespace statefulset-4277
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4277
Apr 27 16:37:07.123: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Apr 27 16:37:17.213: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Apr 27 16:37:17.303: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4277 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:37:18.371: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:37:18.371: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:37:18.371: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:37:18.462: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 27 16:37:28.552: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:37:28.552: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:37:28.913: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999551s
Apr 27 16:37:30.003: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.909570735s
Apr 27 16:37:31.101: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.815822634s
Apr 27 16:37:32.198: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.721204701s
Apr 27 16:37:33.289: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.623896279s
Apr 27 16:37:34.380: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.532963636s
Apr 27 16:37:35.474: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.442244346s
Apr 27 16:37:36.565: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.348365058s
Apr 27 16:37:37.656: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.25736385s
Apr 27 16:37:38.747: INFO: Verifying statefulset ss doesn't scale past 3 for another 166.540309ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4277
Apr 27 16:37:39.838: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4277 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:37:40.895: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 16:37:40.895: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:37:40.895: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:37:40.895: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4277 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:37:41.978: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 27 16:37:41.978: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:37:41.978: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:37:41.978: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4277 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:37:43.055: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 27 16:37:43.055: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:37:43.055: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:37:43.145: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:37:43.145: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:37:43.145: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Apr 27 16:37:43.235: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4277 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:37:44.300: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:37:44.300: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:37:44.300: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:37:44.300: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4277 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:37:45.356: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:37:45.356: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:37:45.356: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:37:45.356: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4277 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:37:46.461: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:37:46.462: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:37:46.462: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:37:46.462: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:37:46.551: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Apr 27 16:37:56.732: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:37:56.732: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:37:56.732: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:37:57.003: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Apr 27 16:37:57.003: INFO: ss-0  ip-10-250-10-186.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:06 +0000 UTC  }]
Apr 27 16:37:57.003: INFO: ss-1  ip-10-250-10-186.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:28 +0000 UTC  }]
Apr 27 16:37:57.003: INFO: ss-2  ip-10-250-10-186.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:28 +0000 UTC  }]
Apr 27 16:37:57.003: INFO: 
Apr 27 16:37:57.003: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 27 16:37:58.094: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Apr 27 16:37:58.094: INFO: ss-0  ip-10-250-10-186.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:06 +0000 UTC  }]
Apr 27 16:37:58.094: INFO: ss-1  ip-10-250-10-186.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:28 +0000 UTC  }]
Apr 27 16:37:58.094: INFO: ss-2  ip-10-250-10-186.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:37:28 +0000 UTC  }]
Apr 27 16:37:58.094: INFO: 
Apr 27 16:37:58.094: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 27 16:37:59.184: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.817924051s
Apr 27 16:38:00.274: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.72816136s
Apr 27 16:38:01.364: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.637927719s
Apr 27 16:38:02.454: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.547623724s
Apr 27 16:38:03.545: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.457539649s
Apr 27 16:38:04.635: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.367340314s
Apr 27 16:38:05.725: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.27742841s
Apr 27 16:38:06.815: INFO: Verifying statefulset ss doesn't scale past 0 for another 187.12597ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4277
Apr 27 16:38:07.905: INFO: Scaling statefulset ss to 0
Apr 27 16:38:08.175: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 16:38:08.265: INFO: Deleting all statefulset in ns statefulset-4277
Apr 27 16:38:08.355: INFO: Scaling statefulset ss to 0
Apr 27 16:38:08.624: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:38:08.714: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:08.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4277" for this suite.
•{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":277,"completed":88,"skipped":1544,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:09.167: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-6444
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:38:09.993: INFO: (0) /api/v1/nodes/ip-10-250-8-65.ec2.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 96.049334ms)
Apr 27 16:38:10.086: INFO: (1) /api/v1/nodes/ip-10-250-8-65.ec2.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.866879ms)
Apr 27 16:38:10.179: INFO: (2) /api/v1/nodes/ip-10-250-8-65.ec2.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 93.42455ms)
Apr 27 16:38:10.272: INFO: (3) /api/v1/nodes/ip-10-250-8-65.ec2.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 93.299624ms)
Apr 27 16:38:10.365: INFO: (4) /api/v1/nodes/ip-10-250-8-65.ec2.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 93.008881ms)
Apr 27 16:38:10.458: INFO: (5) /api/v1/nodes/ip-10-250-8-65.ec2.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.654791ms)
Apr 27 16:38:10.551: INFO: (6) /api/v1/nodes/ip-10-250-8-65.ec2.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.564764ms)
Apr 27 16:38:10.643: INFO: (7) /api/v1/nodes/ip-10-250-8-65.ec2.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.378952ms)
Apr 27 16:38:10.736: INFO: (8) /api/v1/nodes/ip-10-250-8-65.ec2.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.47827ms)
Apr 27 16:38:10.828: INFO: (9) /api/v1/nodes/ip-10-250-8-65.ec2.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.48868ms)
Apr 27 16:38:10.921: INFO: (10) /api/v1/nodes/ip-10-250-8-65.ec2.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.441552ms)
Apr 27 16:38:11.014: INFO: (11) /api/v1/nodes/ip-10-250-8-65.ec2.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.627127ms)
Apr 27 16:38:11.112: INFO: (12) /api/v1/nodes/ip-10-250-8-65.ec2.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 98.861823ms)
Apr 27 16:38:11.205: INFO: (13) /api/v1/nodes/ip-10-250-8-65.ec2.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.717194ms)
Apr 27 16:38:11.298: INFO: (14) /api/v1/nodes/ip-10-250-8-65.ec2.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 93.138912ms)
Apr 27 16:38:11.432: INFO: (15) /api/v1/nodes/ip-10-250-8-65.ec2.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 133.785143ms)
Apr 27 16:38:11.525: INFO: (16) /api/v1/nodes/ip-10-250-8-65.ec2.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.52267ms)
Apr 27 16:38:11.617: INFO: (17) /api/v1/nodes/ip-10-250-8-65.ec2.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.399121ms)
Apr 27 16:38:11.710: INFO: (18) /api/v1/nodes/ip-10-250-8-65.ec2.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.899948ms)
Apr 27 16:38:11.803: INFO: (19) /api/v1/nodes/ip-10-250-8-65.ec2.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 92.814545ms)
[AfterEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:11.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6444" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]","total":277,"completed":89,"skipped":1576,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:11.985: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9374
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating replication controller my-hostname-basic-c2e865d3-b541-4663-9ae7-ae2bc1ec546b
Apr 27 16:38:12.803: INFO: Pod name my-hostname-basic-c2e865d3-b541-4663-9ae7-ae2bc1ec546b: Found 1 pods out of 1
Apr 27 16:38:12.803: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-c2e865d3-b541-4663-9ae7-ae2bc1ec546b" are running
Apr 27 16:38:14.985: INFO: Pod "my-hostname-basic-c2e865d3-b541-4663-9ae7-ae2bc1ec546b-tdp8t" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 16:38:12 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 16:38:12 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-c2e865d3-b541-4663-9ae7-ae2bc1ec546b]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 16:38:12 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-c2e865d3-b541-4663-9ae7-ae2bc1ec546b]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 16:38:12 +0000 UTC Reason: Message:}])
Apr 27 16:38:14.985: INFO: Trying to dial the pod
Apr 27 16:38:20.347: INFO: Controller my-hostname-basic-c2e865d3-b541-4663-9ae7-ae2bc1ec546b: Got expected result from replica 1 [my-hostname-basic-c2e865d3-b541-4663-9ae7-ae2bc1ec546b-tdp8t]: "my-hostname-basic-c2e865d3-b541-4663-9ae7-ae2bc1ec546b-tdp8t", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:20.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9374" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":277,"completed":90,"skipped":1587,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:20.529: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9151
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-2b71845c-bffc-457c-a5f0-8bae9ebc7fee
STEP: Creating a pod to test consume secrets
Apr 27 16:38:21.349: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-675f2249-49db-4847-bdcb-cb2889e4206d" in namespace "projected-9151" to be "Succeeded or Failed"
Apr 27 16:38:21.440: INFO: Pod "pod-projected-secrets-675f2249-49db-4847-bdcb-cb2889e4206d": Phase="Pending", Reason="", readiness=false. Elapsed: 91.190042ms
Apr 27 16:38:23.530: INFO: Pod "pod-projected-secrets-675f2249-49db-4847-bdcb-cb2889e4206d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.1814618s
STEP: Saw pod success
Apr 27 16:38:23.530: INFO: Pod "pod-projected-secrets-675f2249-49db-4847-bdcb-cb2889e4206d" satisfied condition "Succeeded or Failed"
Apr 27 16:38:23.620: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-projected-secrets-675f2249-49db-4847-bdcb-cb2889e4206d container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:38:23.903: INFO: Waiting for pod pod-projected-secrets-675f2249-49db-4847-bdcb-cb2889e4206d to disappear
Apr 27 16:38:23.993: INFO: Pod pod-projected-secrets-675f2249-49db-4847-bdcb-cb2889e4206d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:23.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9151" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":91,"skipped":1637,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:24.175: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1215
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:38:26.203: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602305, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602305, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602305, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602305, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:38:29.388: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:29.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1215" for this suite.
STEP: Destroying namespace "webhook-1215-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":277,"completed":92,"skipped":1644,"failed":0}
SSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:30.594: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5632
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service nodeport-test with type=NodePort in namespace services-5632
STEP: creating replication controller nodeport-test in namespace services-5632
I0427 16:38:31.421969    7325 runners.go:190] Created replication controller with name: nodeport-test, namespace: services-5632, replica count: 2
Apr 27 16:38:34.522: INFO: Creating new exec pod
I0427 16:38:34.522575    7325 runners.go:190] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 27 16:38:37.885: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-5632 execpodhjgd4 -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Apr 27 16:38:38.976: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Apr 27 16:38:38.976: INFO: stdout: ""
Apr 27 16:38:38.977: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-5632 execpodhjgd4 -- /bin/sh -x -c nc -zv -t -w 2 100.106.169.48 80'
Apr 27 16:38:40.123: INFO: stderr: "+ nc -zv -t -w 2 100.106.169.48 80\nConnection to 100.106.169.48 80 port [tcp/http] succeeded!\n"
Apr 27 16:38:40.123: INFO: stdout: ""
Apr 27 16:38:40.123: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-5632 execpodhjgd4 -- /bin/sh -x -c nc -zv -t -w 2 10.250.10.186 31432'
Apr 27 16:38:41.176: INFO: stderr: "+ nc -zv -t -w 2 10.250.10.186 31432\nConnection to 10.250.10.186 31432 port [tcp/31432] succeeded!\n"
Apr 27 16:38:41.176: INFO: stdout: ""
Apr 27 16:38:41.176: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-5632 execpodhjgd4 -- /bin/sh -x -c nc -zv -t -w 2 10.250.8.65 31432'
Apr 27 16:38:42.246: INFO: stderr: "+ nc -zv -t -w 2 10.250.8.65 31432\nConnection to 10.250.8.65 31432 port [tcp/31432] succeeded!\n"
Apr 27 16:38:42.246: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:42.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5632" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":277,"completed":93,"skipped":1649,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:42.428: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-225
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override arguments
Apr 27 16:38:43.158: INFO: Waiting up to 5m0s for pod "client-containers-761cb1f5-59e2-4062-8f5d-48facde6a013" in namespace "containers-225" to be "Succeeded or Failed"
Apr 27 16:38:43.247: INFO: Pod "client-containers-761cb1f5-59e2-4062-8f5d-48facde6a013": Phase="Pending", Reason="", readiness=false. Elapsed: 89.565407ms
Apr 27 16:38:45.337: INFO: Pod "client-containers-761cb1f5-59e2-4062-8f5d-48facde6a013": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179526032s
STEP: Saw pod success
Apr 27 16:38:45.338: INFO: Pod "client-containers-761cb1f5-59e2-4062-8f5d-48facde6a013" satisfied condition "Succeeded or Failed"
Apr 27 16:38:45.427: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod client-containers-761cb1f5-59e2-4062-8f5d-48facde6a013 container test-container: <nil>
STEP: delete the pod
Apr 27 16:38:45.616: INFO: Waiting for pod client-containers-761cb1f5-59e2-4062-8f5d-48facde6a013 to disappear
Apr 27 16:38:45.706: INFO: Pod client-containers-761cb1f5-59e2-4062-8f5d-48facde6a013 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:45.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-225" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":277,"completed":94,"skipped":1670,"failed":0}
SSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:45.889: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-6352
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:38:46.527: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating replication controller svc-latency-rc in namespace svc-latency-6352
I0427 16:38:46.624875    7325 runners.go:190] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6352, replica count: 1
I0427 16:38:47.725455    7325 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0427 16:38:48.725666    7325 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 27 16:38:48.920: INFO: Created: latency-svc-m7nmn
Apr 27 16:38:48.922: INFO: Got endpoints: latency-svc-m7nmn [96.436442ms]
Apr 27 16:38:49.016: INFO: Created: latency-svc-lc45l
Apr 27 16:38:49.019: INFO: Got endpoints: latency-svc-lc45l [97.080234ms]
Apr 27 16:38:49.019: INFO: Created: latency-svc-jlwtf
Apr 27 16:38:49.023: INFO: Created: latency-svc-vcd48
Apr 27 16:38:49.024: INFO: Got endpoints: latency-svc-jlwtf [101.488458ms]
Apr 27 16:38:49.025: INFO: Got endpoints: latency-svc-vcd48 [102.346005ms]
Apr 27 16:38:49.103: INFO: Created: latency-svc-5zkt5
Apr 27 16:38:49.105: INFO: Got endpoints: latency-svc-5zkt5 [182.531983ms]
Apr 27 16:38:49.109: INFO: Created: latency-svc-nntz7
Apr 27 16:38:49.112: INFO: Created: latency-svc-9tgmf
Apr 27 16:38:49.112: INFO: Got endpoints: latency-svc-nntz7 [189.947541ms]
Apr 27 16:38:49.116: INFO: Created: latency-svc-s6xjg
Apr 27 16:38:49.116: INFO: Got endpoints: latency-svc-9tgmf [194.171371ms]
Apr 27 16:38:49.118: INFO: Got endpoints: latency-svc-s6xjg [195.406398ms]
Apr 27 16:38:49.122: INFO: Created: latency-svc-7kzfh
Apr 27 16:38:49.125: INFO: Got endpoints: latency-svc-7kzfh [202.795202ms]
Apr 27 16:38:49.125: INFO: Created: latency-svc-2dl22
Apr 27 16:38:49.127: INFO: Got endpoints: latency-svc-2dl22 [204.392617ms]
Apr 27 16:38:49.130: INFO: Created: latency-svc-httpk
Apr 27 16:38:49.131: INFO: Got endpoints: latency-svc-httpk [209.092572ms]
Apr 27 16:38:49.134: INFO: Created: latency-svc-qtwnd
Apr 27 16:38:49.136: INFO: Got endpoints: latency-svc-qtwnd [213.426996ms]
Apr 27 16:38:49.142: INFO: Created: latency-svc-mx99t
Apr 27 16:38:49.143: INFO: Got endpoints: latency-svc-mx99t [220.764826ms]
Apr 27 16:38:49.145: INFO: Created: latency-svc-5zml8
Apr 27 16:38:49.147: INFO: Got endpoints: latency-svc-5zml8 [224.143236ms]
Apr 27 16:38:49.149: INFO: Created: latency-svc-f7xns
Apr 27 16:38:49.152: INFO: Got endpoints: latency-svc-f7xns [230.132657ms]
Apr 27 16:38:49.155: INFO: Created: latency-svc-gx7gt
Apr 27 16:38:49.156: INFO: Got endpoints: latency-svc-gx7gt [233.884072ms]
Apr 27 16:38:49.158: INFO: Created: latency-svc-7qnkz
Apr 27 16:38:49.160: INFO: Got endpoints: latency-svc-7qnkz [140.28526ms]
Apr 27 16:38:49.161: INFO: Created: latency-svc-s8mkz
Apr 27 16:38:49.163: INFO: Got endpoints: latency-svc-s8mkz [139.177363ms]
Apr 27 16:38:49.166: INFO: Created: latency-svc-rd6vl
Apr 27 16:38:49.168: INFO: Got endpoints: latency-svc-rd6vl [143.305566ms]
Apr 27 16:38:49.198: INFO: Created: latency-svc-vhsjm
Apr 27 16:38:49.200: INFO: Got endpoints: latency-svc-vhsjm [94.748104ms]
Apr 27 16:38:49.208: INFO: Created: latency-svc-jldfm
Apr 27 16:38:49.211: INFO: Got endpoints: latency-svc-jldfm [98.902224ms]
Apr 27 16:38:49.218: INFO: Created: latency-svc-g9rws
Apr 27 16:38:49.219: INFO: Got endpoints: latency-svc-g9rws [102.915416ms]
Apr 27 16:38:49.222: INFO: Created: latency-svc-tvm5w
Apr 27 16:38:49.227: INFO: Got endpoints: latency-svc-tvm5w [108.905985ms]
Apr 27 16:38:49.227: INFO: Created: latency-svc-49kzs
Apr 27 16:38:49.228: INFO: Got endpoints: latency-svc-49kzs [103.233104ms]
Apr 27 16:38:49.231: INFO: Created: latency-svc-kssnw
Apr 27 16:38:49.235: INFO: Got endpoints: latency-svc-kssnw [107.957495ms]
Apr 27 16:38:49.235: INFO: Created: latency-svc-v2gj9
Apr 27 16:38:49.236: INFO: Got endpoints: latency-svc-v2gj9 [104.770934ms]
Apr 27 16:38:49.239: INFO: Created: latency-svc-xd5vj
Apr 27 16:38:49.240: INFO: Got endpoints: latency-svc-xd5vj [104.36684ms]
Apr 27 16:38:49.286: INFO: Created: latency-svc-pqdsr
Apr 27 16:38:49.289: INFO: Got endpoints: latency-svc-pqdsr [146.161736ms]
Apr 27 16:38:49.290: INFO: Created: latency-svc-9jvrj
Apr 27 16:38:49.293: INFO: Got endpoints: latency-svc-9jvrj [133.674329ms]
Apr 27 16:38:49.293: INFO: Created: latency-svc-27q5h
Apr 27 16:38:49.295: INFO: Got endpoints: latency-svc-27q5h [142.462927ms]
Apr 27 16:38:49.297: INFO: Created: latency-svc-6bbsm
Apr 27 16:38:49.299: INFO: Got endpoints: latency-svc-6bbsm [152.214951ms]
Apr 27 16:38:49.302: INFO: Created: latency-svc-6hkzq
Apr 27 16:38:49.304: INFO: Got endpoints: latency-svc-6hkzq [140.839628ms]
Apr 27 16:38:49.306: INFO: Created: latency-svc-l8db7
Apr 27 16:38:49.307: INFO: Got endpoints: latency-svc-l8db7 [151.010082ms]
Apr 27 16:38:49.310: INFO: Created: latency-svc-6pb7n
Apr 27 16:38:49.313: INFO: Got endpoints: latency-svc-6pb7n [144.821726ms]
Apr 27 16:38:49.313: INFO: Created: latency-svc-nkn7f
Apr 27 16:38:49.316: INFO: Got endpoints: latency-svc-nkn7f [116.696394ms]
Apr 27 16:38:49.317: INFO: Created: latency-svc-l2w4c
Apr 27 16:38:49.320: INFO: Created: latency-svc-694tt
Apr 27 16:38:49.320: INFO: Got endpoints: latency-svc-l2w4c [108.853659ms]
Apr 27 16:38:49.321: INFO: Got endpoints: latency-svc-694tt [101.953699ms]
Apr 27 16:38:49.324: INFO: Created: latency-svc-rhcbn
Apr 27 16:38:49.327: INFO: Created: latency-svc-kw266
Apr 27 16:38:49.331: INFO: Created: latency-svc-w4w4x
Apr 27 16:38:49.335: INFO: Created: latency-svc-hkkrn
Apr 27 16:38:49.338: INFO: Created: latency-svc-s5rbg
Apr 27 16:38:49.368: INFO: Got endpoints: latency-svc-rhcbn [141.495539ms]
Apr 27 16:38:49.383: INFO: Created: latency-svc-n5bt5
Apr 27 16:38:49.387: INFO: Created: latency-svc-bt9xz
Apr 27 16:38:49.391: INFO: Created: latency-svc-95xj6
Apr 27 16:38:49.394: INFO: Created: latency-svc-rmtkv
Apr 27 16:38:49.397: INFO: Created: latency-svc-bzrp7
Apr 27 16:38:49.401: INFO: Created: latency-svc-7cbs5
Apr 27 16:38:49.406: INFO: Created: latency-svc-tk2td
Apr 27 16:38:49.410: INFO: Created: latency-svc-wfvnd
Apr 27 16:38:49.413: INFO: Created: latency-svc-sntmj
Apr 27 16:38:49.417: INFO: Created: latency-svc-824s2
Apr 27 16:38:49.418: INFO: Got endpoints: latency-svc-kw266 [189.28438ms]
Apr 27 16:38:49.467: INFO: Created: latency-svc-47v6p
Apr 27 16:38:49.469: INFO: Got endpoints: latency-svc-w4w4x [234.561523ms]
Apr 27 16:38:49.511: INFO: Created: latency-svc-qjlmr
Apr 27 16:38:49.518: INFO: Got endpoints: latency-svc-hkkrn [282.266852ms]
Apr 27 16:38:49.563: INFO: Created: latency-svc-t2bdq
Apr 27 16:38:49.568: INFO: Got endpoints: latency-svc-s5rbg [327.674462ms]
Apr 27 16:38:49.613: INFO: Created: latency-svc-x5tpn
Apr 27 16:38:49.618: INFO: Got endpoints: latency-svc-n5bt5 [328.365818ms]
Apr 27 16:38:49.662: INFO: Created: latency-svc-76b6v
Apr 27 16:38:49.668: INFO: Got endpoints: latency-svc-bt9xz [374.782308ms]
Apr 27 16:38:49.711: INFO: Created: latency-svc-jlpk8
Apr 27 16:38:49.718: INFO: Got endpoints: latency-svc-95xj6 [422.916942ms]
Apr 27 16:38:49.762: INFO: Created: latency-svc-scsgr
Apr 27 16:38:49.768: INFO: Got endpoints: latency-svc-rmtkv [469.014717ms]
Apr 27 16:38:49.812: INFO: Created: latency-svc-d528g
Apr 27 16:38:49.818: INFO: Got endpoints: latency-svc-bzrp7 [514.722273ms]
Apr 27 16:38:49.864: INFO: Created: latency-svc-fk55q
Apr 27 16:38:49.867: INFO: Got endpoints: latency-svc-7cbs5 [560.15318ms]
Apr 27 16:38:49.912: INFO: Created: latency-svc-5g4pr
Apr 27 16:38:49.918: INFO: Got endpoints: latency-svc-tk2td [604.858552ms]
Apr 27 16:38:49.961: INFO: Created: latency-svc-j7s6n
Apr 27 16:38:49.968: INFO: Got endpoints: latency-svc-wfvnd [651.343782ms]
Apr 27 16:38:50.012: INFO: Created: latency-svc-lrp84
Apr 27 16:38:50.018: INFO: Got endpoints: latency-svc-sntmj [697.587173ms]
Apr 27 16:38:50.061: INFO: Created: latency-svc-tl9t4
Apr 27 16:38:50.068: INFO: Got endpoints: latency-svc-824s2 [746.505188ms]
Apr 27 16:38:50.111: INFO: Created: latency-svc-68htl
Apr 27 16:38:50.119: INFO: Got endpoints: latency-svc-47v6p [751.033993ms]
Apr 27 16:38:50.161: INFO: Created: latency-svc-pjdzr
Apr 27 16:38:50.170: INFO: Got endpoints: latency-svc-qjlmr [752.12403ms]
Apr 27 16:38:50.213: INFO: Created: latency-svc-2ml5k
Apr 27 16:38:50.218: INFO: Got endpoints: latency-svc-t2bdq [748.432207ms]
Apr 27 16:38:50.263: INFO: Created: latency-svc-ggmgw
Apr 27 16:38:50.268: INFO: Got endpoints: latency-svc-x5tpn [749.059165ms]
Apr 27 16:38:50.311: INFO: Created: latency-svc-qbcg4
Apr 27 16:38:50.319: INFO: Got endpoints: latency-svc-76b6v [751.390579ms]
Apr 27 16:38:50.361: INFO: Created: latency-svc-nl9hj
Apr 27 16:38:50.368: INFO: Got endpoints: latency-svc-jlpk8 [750.449674ms]
Apr 27 16:38:50.413: INFO: Created: latency-svc-x5pjj
Apr 27 16:38:50.418: INFO: Got endpoints: latency-svc-scsgr [750.177179ms]
Apr 27 16:38:50.462: INFO: Created: latency-svc-h4hxs
Apr 27 16:38:50.468: INFO: Got endpoints: latency-svc-d528g [749.840761ms]
Apr 27 16:38:50.513: INFO: Created: latency-svc-fd4wj
Apr 27 16:38:50.518: INFO: Got endpoints: latency-svc-fk55q [749.954775ms]
Apr 27 16:38:50.561: INFO: Created: latency-svc-kxh5p
Apr 27 16:38:50.568: INFO: Got endpoints: latency-svc-5g4pr [749.154783ms]
Apr 27 16:38:50.612: INFO: Created: latency-svc-fbg4f
Apr 27 16:38:50.618: INFO: Got endpoints: latency-svc-j7s6n [750.546305ms]
Apr 27 16:38:50.664: INFO: Created: latency-svc-dt5j5
Apr 27 16:38:50.668: INFO: Got endpoints: latency-svc-lrp84 [750.510467ms]
Apr 27 16:38:50.712: INFO: Created: latency-svc-6vlq9
Apr 27 16:38:50.718: INFO: Got endpoints: latency-svc-tl9t4 [750.445797ms]
Apr 27 16:38:50.762: INFO: Created: latency-svc-fmct2
Apr 27 16:38:50.768: INFO: Got endpoints: latency-svc-68htl [750.127239ms]
Apr 27 16:38:50.812: INFO: Created: latency-svc-9nk4q
Apr 27 16:38:50.818: INFO: Got endpoints: latency-svc-pjdzr [749.94178ms]
Apr 27 16:38:50.861: INFO: Created: latency-svc-b7x9k
Apr 27 16:38:50.869: INFO: Got endpoints: latency-svc-2ml5k [749.812437ms]
Apr 27 16:38:50.911: INFO: Created: latency-svc-zhksr
Apr 27 16:38:50.918: INFO: Got endpoints: latency-svc-ggmgw [747.70675ms]
Apr 27 16:38:50.962: INFO: Created: latency-svc-j5mbv
Apr 27 16:38:50.968: INFO: Got endpoints: latency-svc-qbcg4 [749.868642ms]
Apr 27 16:38:51.011: INFO: Created: latency-svc-c5lq5
Apr 27 16:38:51.018: INFO: Got endpoints: latency-svc-nl9hj [750.261574ms]
Apr 27 16:38:51.062: INFO: Created: latency-svc-dh2tm
Apr 27 16:38:51.068: INFO: Got endpoints: latency-svc-x5pjj [748.477139ms]
Apr 27 16:38:51.111: INFO: Created: latency-svc-lgznb
Apr 27 16:38:51.118: INFO: Got endpoints: latency-svc-h4hxs [749.211388ms]
Apr 27 16:38:51.161: INFO: Created: latency-svc-skhnk
Apr 27 16:38:51.168: INFO: Got endpoints: latency-svc-fd4wj [749.434932ms]
Apr 27 16:38:51.211: INFO: Created: latency-svc-tmhpv
Apr 27 16:38:51.218: INFO: Got endpoints: latency-svc-kxh5p [750.073183ms]
Apr 27 16:38:51.261: INFO: Created: latency-svc-p9l48
Apr 27 16:38:51.268: INFO: Got endpoints: latency-svc-fbg4f [750.57647ms]
Apr 27 16:38:51.311: INFO: Created: latency-svc-tmrb2
Apr 27 16:38:51.320: INFO: Got endpoints: latency-svc-dt5j5 [752.004236ms]
Apr 27 16:38:51.363: INFO: Created: latency-svc-trbl8
Apr 27 16:38:51.368: INFO: Got endpoints: latency-svc-6vlq9 [749.83415ms]
Apr 27 16:38:51.414: INFO: Created: latency-svc-2wxgm
Apr 27 16:38:51.418: INFO: Got endpoints: latency-svc-fmct2 [749.392655ms]
Apr 27 16:38:51.463: INFO: Created: latency-svc-nclb6
Apr 27 16:38:51.468: INFO: Got endpoints: latency-svc-9nk4q [749.629073ms]
Apr 27 16:38:51.511: INFO: Created: latency-svc-tvwgx
Apr 27 16:38:51.518: INFO: Got endpoints: latency-svc-b7x9k [750.017161ms]
Apr 27 16:38:51.562: INFO: Created: latency-svc-s9tvp
Apr 27 16:38:51.568: INFO: Got endpoints: latency-svc-zhksr [750.104268ms]
Apr 27 16:38:51.611: INFO: Created: latency-svc-km7z8
Apr 27 16:38:51.618: INFO: Got endpoints: latency-svc-j5mbv [748.463675ms]
Apr 27 16:38:51.662: INFO: Created: latency-svc-mlnmm
Apr 27 16:38:51.669: INFO: Got endpoints: latency-svc-c5lq5 [751.770219ms]
Apr 27 16:38:51.712: INFO: Created: latency-svc-669w5
Apr 27 16:38:51.718: INFO: Got endpoints: latency-svc-dh2tm [750.260148ms]
Apr 27 16:38:51.766: INFO: Created: latency-svc-njvrx
Apr 27 16:38:51.809: INFO: Got endpoints: latency-svc-lgznb [791.326392ms]
Apr 27 16:38:51.814: INFO: Created: latency-svc-jrvq9
Apr 27 16:38:51.910: INFO: Got endpoints: latency-svc-skhnk [841.666794ms]
Apr 27 16:38:51.910: INFO: Got endpoints: latency-svc-tmhpv [792.370456ms]
Apr 27 16:38:51.919: INFO: Created: latency-svc-9mwrn
Apr 27 16:38:52.008: INFO: Got endpoints: latency-svc-p9l48 [839.875733ms]
Apr 27 16:38:52.009: INFO: Got endpoints: latency-svc-tmrb2 [790.793458ms]
Apr 27 16:38:52.012: INFO: Created: latency-svc-gcgkh
Apr 27 16:38:52.015: INFO: Created: latency-svc-z49fx
Apr 27 16:38:52.019: INFO: Got endpoints: latency-svc-trbl8 [750.677338ms]
Apr 27 16:38:52.068: INFO: Got endpoints: latency-svc-2wxgm [747.963749ms]
Apr 27 16:38:52.101: INFO: Created: latency-svc-cfjjt
Apr 27 16:38:52.104: INFO: Created: latency-svc-cblxr
Apr 27 16:38:52.113: INFO: Created: latency-svc-m9t7c
Apr 27 16:38:52.118: INFO: Got endpoints: latency-svc-nclb6 [750.447896ms]
Apr 27 16:38:52.161: INFO: Created: latency-svc-d5hsf
Apr 27 16:38:52.167: INFO: Got endpoints: latency-svc-tvwgx [749.648445ms]
Apr 27 16:38:52.213: INFO: Created: latency-svc-lvd4k
Apr 27 16:38:52.219: INFO: Got endpoints: latency-svc-s9tvp [751.339028ms]
Apr 27 16:38:52.261: INFO: Created: latency-svc-hq7m5
Apr 27 16:38:52.268: INFO: Got endpoints: latency-svc-km7z8 [749.821332ms]
Apr 27 16:38:52.316: INFO: Created: latency-svc-glp5g
Apr 27 16:38:52.318: INFO: Got endpoints: latency-svc-mlnmm [749.600528ms]
Apr 27 16:38:52.361: INFO: Created: latency-svc-psmvz
Apr 27 16:38:52.368: INFO: Got endpoints: latency-svc-669w5 [750.567281ms]
Apr 27 16:38:52.411: INFO: Created: latency-svc-frsn6
Apr 27 16:38:52.419: INFO: Got endpoints: latency-svc-njvrx [749.06728ms]
Apr 27 16:38:52.462: INFO: Created: latency-svc-w4nqd
Apr 27 16:38:52.468: INFO: Got endpoints: latency-svc-jrvq9 [749.743201ms]
Apr 27 16:38:52.512: INFO: Created: latency-svc-tgtnk
Apr 27 16:38:52.518: INFO: Got endpoints: latency-svc-9mwrn [708.930437ms]
Apr 27 16:38:52.561: INFO: Created: latency-svc-z87r7
Apr 27 16:38:52.568: INFO: Got endpoints: latency-svc-gcgkh [658.147134ms]
Apr 27 16:38:52.612: INFO: Created: latency-svc-lqjbr
Apr 27 16:38:52.618: INFO: Got endpoints: latency-svc-z49fx [707.697358ms]
Apr 27 16:38:52.662: INFO: Created: latency-svc-npx5l
Apr 27 16:38:52.668: INFO: Got endpoints: latency-svc-cfjjt [659.835495ms]
Apr 27 16:38:52.711: INFO: Created: latency-svc-4xvkl
Apr 27 16:38:52.718: INFO: Got endpoints: latency-svc-cblxr [709.65197ms]
Apr 27 16:38:52.761: INFO: Created: latency-svc-vmpqq
Apr 27 16:38:52.768: INFO: Got endpoints: latency-svc-m9t7c [748.457833ms]
Apr 27 16:38:52.811: INFO: Created: latency-svc-kqplw
Apr 27 16:38:52.818: INFO: Got endpoints: latency-svc-d5hsf [750.467976ms]
Apr 27 16:38:52.861: INFO: Created: latency-svc-mk4n6
Apr 27 16:38:52.867: INFO: Got endpoints: latency-svc-lvd4k [748.955526ms]
Apr 27 16:38:52.912: INFO: Created: latency-svc-v46r2
Apr 27 16:38:52.917: INFO: Got endpoints: latency-svc-hq7m5 [749.87366ms]
Apr 27 16:38:52.960: INFO: Created: latency-svc-dsb2d
Apr 27 16:38:52.968: INFO: Got endpoints: latency-svc-glp5g [748.216156ms]
Apr 27 16:38:53.011: INFO: Created: latency-svc-jdzqp
Apr 27 16:38:53.018: INFO: Got endpoints: latency-svc-psmvz [750.146984ms]
Apr 27 16:38:53.061: INFO: Created: latency-svc-zq9d6
Apr 27 16:38:53.071: INFO: Got endpoints: latency-svc-frsn6 [753.00948ms]
Apr 27 16:38:53.111: INFO: Created: latency-svc-ks65j
Apr 27 16:38:53.118: INFO: Got endpoints: latency-svc-w4nqd [749.539934ms]
Apr 27 16:38:53.164: INFO: Created: latency-svc-mpzxc
Apr 27 16:38:53.167: INFO: Got endpoints: latency-svc-tgtnk [748.724885ms]
Apr 27 16:38:53.215: INFO: Created: latency-svc-lnct7
Apr 27 16:38:53.218: INFO: Got endpoints: latency-svc-z87r7 [749.786839ms]
Apr 27 16:38:53.261: INFO: Created: latency-svc-mffzp
Apr 27 16:38:53.268: INFO: Got endpoints: latency-svc-lqjbr [749.826104ms]
Apr 27 16:38:53.311: INFO: Created: latency-svc-dt872
Apr 27 16:38:53.318: INFO: Got endpoints: latency-svc-npx5l [749.949499ms]
Apr 27 16:38:53.365: INFO: Created: latency-svc-rzd6w
Apr 27 16:38:53.368: INFO: Got endpoints: latency-svc-4xvkl [750.464657ms]
Apr 27 16:38:53.411: INFO: Created: latency-svc-kpj86
Apr 27 16:38:53.418: INFO: Got endpoints: latency-svc-vmpqq [750.552472ms]
Apr 27 16:38:53.462: INFO: Created: latency-svc-v9qzp
Apr 27 16:38:53.470: INFO: Got endpoints: latency-svc-kqplw [751.328743ms]
Apr 27 16:38:53.512: INFO: Created: latency-svc-gsvqd
Apr 27 16:38:53.518: INFO: Got endpoints: latency-svc-mk4n6 [750.194157ms]
Apr 27 16:38:53.563: INFO: Created: latency-svc-t7f9m
Apr 27 16:38:53.568: INFO: Got endpoints: latency-svc-v46r2 [750.005119ms]
Apr 27 16:38:53.611: INFO: Created: latency-svc-dd54r
Apr 27 16:38:53.618: INFO: Got endpoints: latency-svc-dsb2d [750.728175ms]
Apr 27 16:38:53.662: INFO: Created: latency-svc-t2fl8
Apr 27 16:38:53.668: INFO: Got endpoints: latency-svc-jdzqp [750.803098ms]
Apr 27 16:38:53.712: INFO: Created: latency-svc-rl56s
Apr 27 16:38:53.718: INFO: Got endpoints: latency-svc-zq9d6 [749.908294ms]
Apr 27 16:38:53.764: INFO: Created: latency-svc-xsvj7
Apr 27 16:38:53.768: INFO: Got endpoints: latency-svc-ks65j [750.152614ms]
Apr 27 16:38:53.811: INFO: Created: latency-svc-bmzj4
Apr 27 16:38:53.818: INFO: Got endpoints: latency-svc-mpzxc [747.278426ms]
Apr 27 16:38:53.864: INFO: Created: latency-svc-wqdk6
Apr 27 16:38:53.868: INFO: Got endpoints: latency-svc-lnct7 [749.584138ms]
Apr 27 16:38:53.911: INFO: Created: latency-svc-46vb8
Apr 27 16:38:53.918: INFO: Got endpoints: latency-svc-mffzp [750.099938ms]
Apr 27 16:38:53.961: INFO: Created: latency-svc-r5w28
Apr 27 16:38:53.968: INFO: Got endpoints: latency-svc-dt872 [750.052336ms]
Apr 27 16:38:54.011: INFO: Created: latency-svc-2l67f
Apr 27 16:38:54.018: INFO: Got endpoints: latency-svc-rzd6w [750.124028ms]
Apr 27 16:38:54.061: INFO: Created: latency-svc-mctwj
Apr 27 16:38:54.070: INFO: Got endpoints: latency-svc-kpj86 [752.339548ms]
Apr 27 16:38:54.112: INFO: Created: latency-svc-cvrbx
Apr 27 16:38:54.118: INFO: Got endpoints: latency-svc-v9qzp [749.404348ms]
Apr 27 16:38:54.163: INFO: Created: latency-svc-2slhs
Apr 27 16:38:54.167: INFO: Got endpoints: latency-svc-gsvqd [749.193955ms]
Apr 27 16:38:54.211: INFO: Created: latency-svc-gp46l
Apr 27 16:38:54.218: INFO: Got endpoints: latency-svc-t7f9m [748.3166ms]
Apr 27 16:38:54.261: INFO: Created: latency-svc-rxmdh
Apr 27 16:38:54.268: INFO: Got endpoints: latency-svc-dd54r [749.781254ms]
Apr 27 16:38:54.311: INFO: Created: latency-svc-jsdcz
Apr 27 16:38:54.318: INFO: Got endpoints: latency-svc-t2fl8 [749.298505ms]
Apr 27 16:38:54.361: INFO: Created: latency-svc-pgkrl
Apr 27 16:38:54.369: INFO: Got endpoints: latency-svc-rl56s [750.930412ms]
Apr 27 16:38:54.411: INFO: Created: latency-svc-q74h9
Apr 27 16:38:54.418: INFO: Got endpoints: latency-svc-xsvj7 [749.288266ms]
Apr 27 16:38:54.463: INFO: Created: latency-svc-d6b98
Apr 27 16:38:54.469: INFO: Got endpoints: latency-svc-bmzj4 [750.80404ms]
Apr 27 16:38:54.512: INFO: Created: latency-svc-7bzn4
Apr 27 16:38:54.518: INFO: Got endpoints: latency-svc-wqdk6 [749.513206ms]
Apr 27 16:38:54.562: INFO: Created: latency-svc-n8t5p
Apr 27 16:38:54.568: INFO: Got endpoints: latency-svc-46vb8 [749.514035ms]
Apr 27 16:38:54.612: INFO: Created: latency-svc-htbzm
Apr 27 16:38:54.618: INFO: Got endpoints: latency-svc-r5w28 [750.077126ms]
Apr 27 16:38:54.661: INFO: Created: latency-svc-pdsb5
Apr 27 16:38:54.668: INFO: Got endpoints: latency-svc-2l67f [750.167062ms]
Apr 27 16:38:54.711: INFO: Created: latency-svc-fpmnn
Apr 27 16:38:54.718: INFO: Got endpoints: latency-svc-mctwj [750.234542ms]
Apr 27 16:38:54.761: INFO: Created: latency-svc-p59kw
Apr 27 16:38:54.768: INFO: Got endpoints: latency-svc-cvrbx [749.424089ms]
Apr 27 16:38:54.811: INFO: Created: latency-svc-m8zv4
Apr 27 16:38:54.818: INFO: Got endpoints: latency-svc-2slhs [747.624235ms]
Apr 27 16:38:54.861: INFO: Created: latency-svc-4cmz4
Apr 27 16:38:54.869: INFO: Got endpoints: latency-svc-gp46l [751.567984ms]
Apr 27 16:38:54.912: INFO: Created: latency-svc-8w5xt
Apr 27 16:38:54.918: INFO: Got endpoints: latency-svc-rxmdh [750.100626ms]
Apr 27 16:38:54.963: INFO: Created: latency-svc-rbdw7
Apr 27 16:38:54.968: INFO: Got endpoints: latency-svc-jsdcz [749.398271ms]
Apr 27 16:38:55.011: INFO: Created: latency-svc-pr726
Apr 27 16:38:55.018: INFO: Got endpoints: latency-svc-pgkrl [749.974553ms]
Apr 27 16:38:55.061: INFO: Created: latency-svc-sg2b7
Apr 27 16:38:55.068: INFO: Got endpoints: latency-svc-q74h9 [750.033417ms]
Apr 27 16:38:55.111: INFO: Created: latency-svc-4tnz9
Apr 27 16:38:55.119: INFO: Got endpoints: latency-svc-d6b98 [750.012074ms]
Apr 27 16:38:55.161: INFO: Created: latency-svc-xbs82
Apr 27 16:38:55.168: INFO: Got endpoints: latency-svc-7bzn4 [750.427187ms]
Apr 27 16:38:55.213: INFO: Created: latency-svc-99b2x
Apr 27 16:38:55.218: INFO: Got endpoints: latency-svc-n8t5p [749.633662ms]
Apr 27 16:38:55.262: INFO: Created: latency-svc-fp6ql
Apr 27 16:38:55.268: INFO: Got endpoints: latency-svc-htbzm [749.792674ms]
Apr 27 16:38:55.313: INFO: Created: latency-svc-kk4t9
Apr 27 16:38:55.318: INFO: Got endpoints: latency-svc-pdsb5 [750.225502ms]
Apr 27 16:38:55.361: INFO: Created: latency-svc-sg6bj
Apr 27 16:38:55.368: INFO: Got endpoints: latency-svc-fpmnn [750.462751ms]
Apr 27 16:38:55.413: INFO: Created: latency-svc-nrsvk
Apr 27 16:38:55.418: INFO: Got endpoints: latency-svc-p59kw [750.335041ms]
Apr 27 16:38:55.462: INFO: Created: latency-svc-zb57b
Apr 27 16:38:55.468: INFO: Got endpoints: latency-svc-m8zv4 [749.791781ms]
Apr 27 16:38:55.512: INFO: Created: latency-svc-hxx76
Apr 27 16:38:55.518: INFO: Got endpoints: latency-svc-4cmz4 [749.920393ms]
Apr 27 16:38:55.561: INFO: Created: latency-svc-vqhzd
Apr 27 16:38:55.568: INFO: Got endpoints: latency-svc-8w5xt [750.46116ms]
Apr 27 16:38:55.612: INFO: Created: latency-svc-dwkrx
Apr 27 16:38:55.620: INFO: Got endpoints: latency-svc-rbdw7 [750.354759ms]
Apr 27 16:38:55.662: INFO: Created: latency-svc-pflkp
Apr 27 16:38:55.668: INFO: Got endpoints: latency-svc-pr726 [750.211921ms]
Apr 27 16:38:55.713: INFO: Created: latency-svc-584ks
Apr 27 16:38:55.718: INFO: Got endpoints: latency-svc-sg2b7 [750.204326ms]
Apr 27 16:38:55.762: INFO: Created: latency-svc-4kb6m
Apr 27 16:38:55.768: INFO: Got endpoints: latency-svc-4tnz9 [750.432048ms]
Apr 27 16:38:55.811: INFO: Created: latency-svc-th28z
Apr 27 16:38:55.819: INFO: Got endpoints: latency-svc-xbs82 [751.367442ms]
Apr 27 16:38:55.862: INFO: Created: latency-svc-zrgzl
Apr 27 16:38:55.868: INFO: Got endpoints: latency-svc-99b2x [748.173763ms]
Apr 27 16:38:55.913: INFO: Created: latency-svc-hx68h
Apr 27 16:38:55.917: INFO: Got endpoints: latency-svc-fp6ql [749.107426ms]
Apr 27 16:38:55.961: INFO: Created: latency-svc-ghnf5
Apr 27 16:38:55.968: INFO: Got endpoints: latency-svc-kk4t9 [749.375353ms]
Apr 27 16:38:56.011: INFO: Created: latency-svc-nbbcg
Apr 27 16:38:56.018: INFO: Got endpoints: latency-svc-sg6bj [749.981483ms]
Apr 27 16:38:56.063: INFO: Created: latency-svc-gcf6z
Apr 27 16:38:56.068: INFO: Got endpoints: latency-svc-nrsvk [750.249242ms]
Apr 27 16:38:56.111: INFO: Created: latency-svc-k7f86
Apr 27 16:38:56.118: INFO: Got endpoints: latency-svc-zb57b [749.663928ms]
Apr 27 16:38:56.162: INFO: Created: latency-svc-n9n4w
Apr 27 16:38:56.169: INFO: Got endpoints: latency-svc-hxx76 [751.075066ms]
Apr 27 16:38:56.211: INFO: Created: latency-svc-hjr8p
Apr 27 16:38:56.218: INFO: Got endpoints: latency-svc-vqhzd [749.72297ms]
Apr 27 16:38:56.263: INFO: Created: latency-svc-sjjh4
Apr 27 16:38:56.268: INFO: Got endpoints: latency-svc-dwkrx [749.64466ms]
Apr 27 16:38:56.311: INFO: Created: latency-svc-rhfcd
Apr 27 16:38:56.318: INFO: Got endpoints: latency-svc-pflkp [749.26638ms]
Apr 27 16:38:56.361: INFO: Created: latency-svc-wlb7l
Apr 27 16:38:56.368: INFO: Got endpoints: latency-svc-584ks [747.89014ms]
Apr 27 16:38:56.411: INFO: Created: latency-svc-s7rg4
Apr 27 16:38:56.418: INFO: Got endpoints: latency-svc-4kb6m [749.771067ms]
Apr 27 16:38:56.462: INFO: Created: latency-svc-9zns7
Apr 27 16:38:56.468: INFO: Got endpoints: latency-svc-th28z [749.897903ms]
Apr 27 16:38:56.511: INFO: Created: latency-svc-24zhz
Apr 27 16:38:56.518: INFO: Got endpoints: latency-svc-zrgzl [749.160611ms]
Apr 27 16:38:56.561: INFO: Created: latency-svc-w9msq
Apr 27 16:38:56.568: INFO: Got endpoints: latency-svc-hx68h [748.990897ms]
Apr 27 16:38:56.611: INFO: Created: latency-svc-vxzsb
Apr 27 16:38:56.618: INFO: Got endpoints: latency-svc-ghnf5 [750.10291ms]
Apr 27 16:38:56.662: INFO: Created: latency-svc-8grh2
Apr 27 16:38:56.668: INFO: Got endpoints: latency-svc-nbbcg [750.330518ms]
Apr 27 16:38:56.711: INFO: Created: latency-svc-ncd26
Apr 27 16:38:56.718: INFO: Got endpoints: latency-svc-gcf6z [750.288205ms]
Apr 27 16:38:56.761: INFO: Created: latency-svc-9gc9f
Apr 27 16:38:56.768: INFO: Got endpoints: latency-svc-k7f86 [749.862361ms]
Apr 27 16:38:56.813: INFO: Created: latency-svc-vqn9w
Apr 27 16:38:56.818: INFO: Got endpoints: latency-svc-n9n4w [749.517501ms]
Apr 27 16:38:56.862: INFO: Created: latency-svc-4prmr
Apr 27 16:38:56.868: INFO: Got endpoints: latency-svc-hjr8p [750.309609ms]
Apr 27 16:38:56.918: INFO: Got endpoints: latency-svc-sjjh4 [748.533408ms]
Apr 27 16:38:56.968: INFO: Got endpoints: latency-svc-rhfcd [750.35749ms]
Apr 27 16:38:57.018: INFO: Got endpoints: latency-svc-wlb7l [750.384709ms]
Apr 27 16:38:57.069: INFO: Got endpoints: latency-svc-s7rg4 [750.727798ms]
Apr 27 16:38:57.118: INFO: Got endpoints: latency-svc-9zns7 [750.0565ms]
Apr 27 16:38:57.168: INFO: Got endpoints: latency-svc-24zhz [750.332878ms]
Apr 27 16:38:57.220: INFO: Got endpoints: latency-svc-w9msq [751.912295ms]
Apr 27 16:38:57.268: INFO: Got endpoints: latency-svc-vxzsb [750.528324ms]
Apr 27 16:38:57.320: INFO: Got endpoints: latency-svc-8grh2 [751.112827ms]
Apr 27 16:38:57.369: INFO: Got endpoints: latency-svc-ncd26 [751.553985ms]
Apr 27 16:38:57.419: INFO: Got endpoints: latency-svc-9gc9f [751.218112ms]
Apr 27 16:38:57.468: INFO: Got endpoints: latency-svc-vqn9w [750.039616ms]
Apr 27 16:38:57.518: INFO: Got endpoints: latency-svc-4prmr [750.421133ms]
Apr 27 16:38:57.518: INFO: Latencies: [94.748104ms 97.080234ms 98.902224ms 101.488458ms 101.953699ms 102.346005ms 102.915416ms 103.233104ms 104.36684ms 104.770934ms 107.957495ms 108.853659ms 108.905985ms 116.696394ms 133.674329ms 139.177363ms 140.28526ms 140.839628ms 141.495539ms 142.462927ms 143.305566ms 144.821726ms 146.161736ms 151.010082ms 152.214951ms 182.531983ms 189.28438ms 189.947541ms 194.171371ms 195.406398ms 202.795202ms 204.392617ms 209.092572ms 213.426996ms 220.764826ms 224.143236ms 230.132657ms 233.884072ms 234.561523ms 282.266852ms 327.674462ms 328.365818ms 374.782308ms 422.916942ms 469.014717ms 514.722273ms 560.15318ms 604.858552ms 651.343782ms 658.147134ms 659.835495ms 697.587173ms 707.697358ms 708.930437ms 709.65197ms 746.505188ms 747.278426ms 747.624235ms 747.70675ms 747.89014ms 747.963749ms 748.173763ms 748.216156ms 748.3166ms 748.432207ms 748.457833ms 748.463675ms 748.477139ms 748.533408ms 748.724885ms 748.955526ms 748.990897ms 749.059165ms 749.06728ms 749.107426ms 749.154783ms 749.160611ms 749.193955ms 749.211388ms 749.26638ms 749.288266ms 749.298505ms 749.375353ms 749.392655ms 749.398271ms 749.404348ms 749.424089ms 749.434932ms 749.513206ms 749.514035ms 749.517501ms 749.539934ms 749.584138ms 749.600528ms 749.629073ms 749.633662ms 749.64466ms 749.648445ms 749.663928ms 749.72297ms 749.743201ms 749.771067ms 749.781254ms 749.786839ms 749.791781ms 749.792674ms 749.812437ms 749.821332ms 749.826104ms 749.83415ms 749.840761ms 749.862361ms 749.868642ms 749.87366ms 749.897903ms 749.908294ms 749.920393ms 749.94178ms 749.949499ms 749.954775ms 749.974553ms 749.981483ms 750.005119ms 750.012074ms 750.017161ms 750.033417ms 750.039616ms 750.052336ms 750.0565ms 750.073183ms 750.077126ms 750.099938ms 750.100626ms 750.10291ms 750.104268ms 750.124028ms 750.127239ms 750.146984ms 750.152614ms 750.167062ms 750.177179ms 750.194157ms 750.204326ms 750.211921ms 750.225502ms 750.234542ms 750.249242ms 750.260148ms 750.261574ms 750.288205ms 750.309609ms 750.330518ms 750.332878ms 750.335041ms 750.354759ms 750.35749ms 750.384709ms 750.421133ms 750.427187ms 750.432048ms 750.445797ms 750.447896ms 750.449674ms 750.46116ms 750.462751ms 750.464657ms 750.467976ms 750.510467ms 750.528324ms 750.546305ms 750.552472ms 750.567281ms 750.57647ms 750.677338ms 750.727798ms 750.728175ms 750.803098ms 750.80404ms 750.930412ms 751.033993ms 751.075066ms 751.112827ms 751.218112ms 751.328743ms 751.339028ms 751.367442ms 751.390579ms 751.553985ms 751.567984ms 751.770219ms 751.912295ms 752.004236ms 752.12403ms 752.339548ms 753.00948ms 790.793458ms 791.326392ms 792.370456ms 839.875733ms 841.666794ms]
Apr 27 16:38:57.518: INFO: 50 %ile: 749.743201ms
Apr 27 16:38:57.518: INFO: 90 %ile: 751.075066ms
Apr 27 16:38:57.518: INFO: 99 %ile: 839.875733ms
Apr 27 16:38:57.518: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:57.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-6352" for this suite.
•{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":277,"completed":95,"skipped":1676,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:57.702: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5867
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:38:58.520: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 27 16:39:00.703: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Apr 27 16:39:03.511: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-5867 /apis/apps/v1/namespaces/deployment-5867/deployments/test-cleanup-deployment 51f8bd56-e356-4b59-ac31-234972594fc1 18775 1 2020-04-27 16:39:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 2020-04-27 16:39:00 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 16:39:02 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003bc4ad8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-04-27 16:39:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-b4867b47f" has successfully progressed.,LastUpdateTime:2020-04-27 16:39:02 +0000 UTC,LastTransitionTime:2020-04-27 16:39:00 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 27 16:39:03.609: INFO: New ReplicaSet "test-cleanup-deployment-b4867b47f" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-b4867b47f  deployment-5867 /apis/apps/v1/namespaces/deployment-5867/replicasets/test-cleanup-deployment-b4867b47f ace92c5a-6248-4e1a-b467-bedcca755525 18768 1 2020-04-27 16:39:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 51f8bd56-e356-4b59-ac31-234972594fc1 0xc003bc4f40 0xc003bc4f41}] []  [{kube-controller-manager Update apps/v1 2020-04-27 16:39:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 49 102 56 98 100 53 54 45 101 51 53 54 45 52 98 53 57 45 97 99 51 49 45 50 51 52 57 55 50 53 57 52 102 99 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: b4867b47f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003bc4fb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:39:03.699: INFO: Pod "test-cleanup-deployment-b4867b47f-jnjwg" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-b4867b47f-jnjwg test-cleanup-deployment-b4867b47f- deployment-5867 /api/v1/namespaces/deployment-5867/pods/test-cleanup-deployment-b4867b47f-jnjwg 59bc4977-89e8-4e8d-87b7-040099de2d70 18767 0 2020-04-27 16:39:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[cni.projectcalico.org/podIP:100.64.1.141/32 cni.projectcalico.org/podIPs:100.64.1.141/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-cleanup-deployment-b4867b47f ace92c5a-6248-4e1a-b467-bedcca755525 0xc003bc53e0 0xc003bc53e1}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:00 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 99 101 57 50 99 53 97 45 54 50 52 56 45 52 101 49 97 45 98 52 54 55 45 98 101 100 99 99 97 55 53 53 53 50 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:39:01 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:02 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 49 52 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wm9sg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wm9sg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wm9sg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:100.64.1.141,StartTime:2020-04-27 16:39:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:39:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://302d5d3027e6979f140de5a6d9eef480376c4d161337bdc9d1c39863a3fdb575,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.141,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:39:03.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5867" for this suite.
•{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":277,"completed":96,"skipped":1699,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:39:03.899: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-9389
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:39:04.563: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr 27 16:39:09.085: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9389 create -f -'
Apr 27 16:39:10.390: INFO: stderr: ""
Apr 27 16:39:10.390: INFO: stdout: "e2e-test-crd-publish-openapi-6258-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 27 16:39:10.390: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9389 delete e2e-test-crd-publish-openapi-6258-crds test-cr'
Apr 27 16:39:10.845: INFO: stderr: ""
Apr 27 16:39:10.846: INFO: stdout: "e2e-test-crd-publish-openapi-6258-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Apr 27 16:39:10.846: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9389 apply -f -'
Apr 27 16:39:11.862: INFO: stderr: ""
Apr 27 16:39:11.862: INFO: stdout: "e2e-test-crd-publish-openapi-6258-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 27 16:39:11.862: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9389 delete e2e-test-crd-publish-openapi-6258-crds test-cr'
Apr 27 16:39:12.293: INFO: stderr: ""
Apr 27 16:39:12.293: INFO: stdout: "e2e-test-crd-publish-openapi-6258-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Apr 27 16:39:12.293: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-6258-crds'
Apr 27 16:39:13.047: INFO: stderr: ""
Apr 27 16:39:13.047: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-6258-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:39:17.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9389" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":277,"completed":97,"skipped":1727,"failed":0}
SSSSSSS
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:39:17.377: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename limitrange
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in limitrange-3270
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
Apr 27 16:39:18.196: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
Apr 27 16:39:18.375: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr 27 16:39:18.375: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
Apr 27 16:39:18.557: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr 27 16:39:18.557: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
Apr 27 16:39:18.737: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Apr 27 16:39:18.737: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
Apr 27 16:39:26.460: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:39:26.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-3270" for this suite.
•{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":277,"completed":98,"skipped":1734,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:39:26.734: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-1317
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:39:27.466: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-c4a4fd68-8672-4f9c-b933-a6c393f17b6b" in namespace "security-context-test-1317" to be "Succeeded or Failed"
Apr 27 16:39:27.557: INFO: Pod "busybox-privileged-false-c4a4fd68-8672-4f9c-b933-a6c393f17b6b": Phase="Pending", Reason="", readiness=false. Elapsed: 90.943066ms
Apr 27 16:39:29.648: INFO: Pod "busybox-privileged-false-c4a4fd68-8672-4f9c-b933-a6c393f17b6b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.181819996s
Apr 27 16:39:29.648: INFO: Pod "busybox-privileged-false-c4a4fd68-8672-4f9c-b933-a6c393f17b6b" satisfied condition "Succeeded or Failed"
Apr 27 16:39:29.745: INFO: Got logs for pod "busybox-privileged-false-c4a4fd68-8672-4f9c-b933-a6c393f17b6b": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:39:29.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1317" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":99,"skipped":1754,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:39:29.927: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4449
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:39:30.566: INFO: Creating deployment "webserver-deployment"
Apr 27 16:39:30.656: INFO: Waiting for observed generation 1
Apr 27 16:39:30.746: INFO: Waiting for all required pods to come up
Apr 27 16:39:30.837: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Apr 27 16:39:35.104: INFO: Waiting for deployment "webserver-deployment" to complete
Apr 27 16:39:35.283: INFO: Updating deployment "webserver-deployment" with a non-existent image
Apr 27 16:39:35.464: INFO: Updating deployment webserver-deployment
Apr 27 16:39:35.464: INFO: Waiting for observed generation 2
Apr 27 16:39:35.553: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr 27 16:39:35.643: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr 27 16:39:35.733: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 27 16:39:36.002: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr 27 16:39:36.002: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr 27 16:39:36.092: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 27 16:39:36.271: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Apr 27 16:39:36.271: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Apr 27 16:39:36.452: INFO: Updating deployment webserver-deployment
Apr 27 16:39:36.452: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Apr 27 16:39:36.630: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr 27 16:39:36.720: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Apr 27 16:39:36.900: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-4449 /apis/apps/v1/namespaces/deployment-4449/deployments/webserver-deployment e426b09e-5525-4cc2-8ad6-ab910e242cc8 20056 3 2020-04-27 16:39:30 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005ce8528 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-04-27 16:39:36 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-6676bcd6d4" is progressing.,LastUpdateTime:2020-04-27 16:39:36 +0000 UTC,LastTransitionTime:2020-04-27 16:39:30 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Apr 27 16:39:36.991: INFO: New ReplicaSet "webserver-deployment-6676bcd6d4" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-6676bcd6d4  deployment-4449 /apis/apps/v1/namespaces/deployment-4449/replicasets/webserver-deployment-6676bcd6d4 c4bb459d-0391-4df3-b0ea-f848aa957d90 20055 3 2020-04-27 16:39:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment e426b09e-5525-4cc2-8ad6-ab910e242cc8 0xc005ce8c17 0xc005ce8c18}] []  [{kube-controller-manager Update apps/v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 52 50 54 98 48 57 101 45 53 53 50 53 45 52 99 99 50 45 56 97 100 54 45 97 98 57 49 48 101 50 52 50 99 99 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 6676bcd6d4,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005ce8cd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:39:36.991: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Apr 27 16:39:36.991: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-84855cf797  deployment-4449 /apis/apps/v1/namespaces/deployment-4449/replicasets/webserver-deployment-84855cf797 12c28ea5-cee9-4f97-a889-aa45c9dcd02b 20051 3 2020-04-27 16:39:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment e426b09e-5525-4cc2-8ad6-ab910e242cc8 0xc005ce8d37 0xc005ce8d38}] []  [{kube-controller-manager Update apps/v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 52 50 54 98 48 57 101 45 53 53 50 53 45 52 99 99 50 45 56 97 100 54 45 97 98 57 49 48 101 50 52 50 99 99 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 84855cf797,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005ce8dc8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:39:37.086: INFO: Pod "webserver-deployment-6676bcd6d4-47p54" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-47p54 webserver-deployment-6676bcd6d4- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-6676bcd6d4-47p54 e7e143b8-f0e9-46de-bec0-59f80e23faf5 20065 0 2020-04-27 16:39:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 c4bb459d-0391-4df3-b0ea-f848aa957d90 0xc005ce9787 0xc005ce9788}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 52 98 98 52 53 57 100 45 48 51 57 49 45 52 100 102 51 45 98 48 101 97 45 102 56 52 56 97 97 57 53 55 100 57 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-65.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.8.65,PodIP:,StartTime:2020-04-27 16:39:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.087: INFO: Pod "webserver-deployment-6676bcd6d4-72m7m" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-72m7m webserver-deployment-6676bcd6d4- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-6676bcd6d4-72m7m 02f980ee-10ae-4129-ab2f-8f9feadd7541 20004 0 2020-04-27 16:39:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:100.64.0.28/32 cni.projectcalico.org/podIPs:100.64.0.28/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 c4bb459d-0391-4df3-b0ea-f848aa957d90 0xc005ce9b40 0xc005ce9b41}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:35 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 52 98 98 52 53 57 100 45 48 51 57 49 45 52 100 102 51 45 98 48 101 97 45 102 56 52 56 97 97 57 53 55 100 57 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:35 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-65.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.8.65,PodIP:,StartTime:2020-04-27 16:39:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.087: INFO: Pod "webserver-deployment-6676bcd6d4-77xcb" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-77xcb webserver-deployment-6676bcd6d4- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-6676bcd6d4-77xcb 777b14f5-d6be-4bf7-8c75-b229282b16a7 20003 0 2020-04-27 16:39:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 c4bb459d-0391-4df3-b0ea-f848aa957d90 0xc005ce9e60 0xc005ce9e61}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:35 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 52 98 98 52 53 57 100 45 48 51 57 49 45 52 100 102 51 45 98 48 101 97 45 102 56 52 56 97 97 57 53 55 100 57 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:35 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:,StartTime:2020-04-27 16:39:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.087: INFO: Pod "webserver-deployment-6676bcd6d4-9nng5" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-9nng5 webserver-deployment-6676bcd6d4- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-6676bcd6d4-9nng5 d6d5628d-177d-4a61-9da3-25a0716bad52 20077 0 2020-04-27 16:39:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:100.64.1.152/32 cni.projectcalico.org/podIPs:100.64.1.152/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 c4bb459d-0391-4df3-b0ea-f848aa957d90 0xc005cd00d7 0xc005cd00d8}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:35 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 52 98 98 52 53 57 100 45 48 51 57 49 45 52 100 102 51 45 98 48 101 97 45 102 56 52 56 97 97 57 53 55 100 57 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:35 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:,StartTime:2020-04-27 16:39:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.087: INFO: Pod "webserver-deployment-6676bcd6d4-c6gkl" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-c6gkl webserver-deployment-6676bcd6d4- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-6676bcd6d4-c6gkl cf9cfd91-0c4d-40d9-8cd8-f91af6612ddb 20059 0 2020-04-27 16:39:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 c4bb459d-0391-4df3-b0ea-f848aa957d90 0xc005cd0317 0xc005cd0318}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 52 98 98 52 53 57 100 45 48 51 57 49 45 52 100 102 51 45 98 48 101 97 45 102 56 52 56 97 97 57 53 55 100 57 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-65.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.8.65,PodIP:,StartTime:2020-04-27 16:39:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.088: INFO: Pod "webserver-deployment-6676bcd6d4-f6lpn" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-f6lpn webserver-deployment-6676bcd6d4- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-6676bcd6d4-f6lpn f972373a-3ccd-41fe-b316-9aeedfc1e5c4 20063 0 2020-04-27 16:39:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 c4bb459d-0391-4df3-b0ea-f848aa957d90 0xc005cd04c0 0xc005cd04c1}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 52 98 98 52 53 57 100 45 48 51 57 49 45 52 100 102 51 45 98 48 101 97 45 102 56 52 56 97 97 57 53 55 100 57 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:,StartTime:2020-04-27 16:39:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.088: INFO: Pod "webserver-deployment-6676bcd6d4-g88f9" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-g88f9 webserver-deployment-6676bcd6d4- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-6676bcd6d4-g88f9 654d8bdb-d955-496f-b501-1adf6a9177d9 20081 0 2020-04-27 16:39:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 c4bb459d-0391-4df3-b0ea-f848aa957d90 0xc005cd0677 0xc005cd0678}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 52 98 98 52 53 57 100 45 48 51 57 49 45 52 100 102 51 45 98 48 101 97 45 102 56 52 56 97 97 57 53 55 100 57 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:,StartTime:2020-04-27 16:39:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.088: INFO: Pod "webserver-deployment-6676bcd6d4-gff82" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-gff82 webserver-deployment-6676bcd6d4- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-6676bcd6d4-gff82 acd2c758-5dcb-4851-85d7-0c32fb50e8f3 20001 0 2020-04-27 16:39:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 c4bb459d-0391-4df3-b0ea-f848aa957d90 0xc005cd0897 0xc005cd0898}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:35 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 52 98 98 52 53 57 100 45 48 51 57 49 45 52 100 102 51 45 98 48 101 97 45 102 56 52 56 97 97 57 53 55 100 57 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:35 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:,StartTime:2020-04-27 16:39:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.088: INFO: Pod "webserver-deployment-6676bcd6d4-kqrl7" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-kqrl7 webserver-deployment-6676bcd6d4- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-6676bcd6d4-kqrl7 3f3a2a8c-8a07-46fa-a59f-32f154bf65b7 20068 0 2020-04-27 16:39:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 c4bb459d-0391-4df3-b0ea-f848aa957d90 0xc005cd0b87 0xc005cd0b88}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 52 98 98 52 53 57 100 45 48 51 57 49 45 52 100 102 51 45 98 48 101 97 45 102 56 52 56 97 97 57 53 55 100 57 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:,StartTime:2020-04-27 16:39:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.088: INFO: Pod "webserver-deployment-6676bcd6d4-ltk7w" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-ltk7w webserver-deployment-6676bcd6d4- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-6676bcd6d4-ltk7w 321d4c8e-1fd9-4b86-be16-cd1fac4372f8 20071 0 2020-04-27 16:39:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 c4bb459d-0391-4df3-b0ea-f848aa957d90 0xc005cd0d77 0xc005cd0d78}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 52 98 98 52 53 57 100 45 48 51 57 49 45 52 100 102 51 45 98 48 101 97 45 102 56 52 56 97 97 57 53 55 100 57 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:,StartTime:2020-04-27 16:39:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.089: INFO: Pod "webserver-deployment-6676bcd6d4-nl427" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-nl427 webserver-deployment-6676bcd6d4- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-6676bcd6d4-nl427 546bdf95-711a-4a15-9050-a4cc7c2ef16a 20002 0 2020-04-27 16:39:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 c4bb459d-0391-4df3-b0ea-f848aa957d90 0xc005cd1097 0xc005cd1098}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:35 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 52 98 98 52 53 57 100 45 48 51 57 49 45 52 100 102 51 45 98 48 101 97 45 102 56 52 56 97 97 57 53 55 100 57 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:35 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:,StartTime:2020-04-27 16:39:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.089: INFO: Pod "webserver-deployment-6676bcd6d4-q8sqq" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-q8sqq webserver-deployment-6676bcd6d4- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-6676bcd6d4-q8sqq 1b8f0cdc-fc69-4e6a-8f97-d8b681f7014a 20066 0 2020-04-27 16:39:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 c4bb459d-0391-4df3-b0ea-f848aa957d90 0xc005cd1477 0xc005cd1478}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 52 98 98 52 53 57 100 45 48 51 57 49 45 52 100 102 51 45 98 48 101 97 45 102 56 52 56 97 97 57 53 55 100 57 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-65.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.8.65,PodIP:,StartTime:2020-04-27 16:39:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.089: INFO: Pod "webserver-deployment-6676bcd6d4-ws7pz" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-ws7pz webserver-deployment-6676bcd6d4- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-6676bcd6d4-ws7pz 5b261fba-e4df-44f8-9357-415e147feac9 20070 0 2020-04-27 16:39:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 c4bb459d-0391-4df3-b0ea-f848aa957d90 0xc005cd1860 0xc005cd1861}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 52 98 98 52 53 57 100 45 48 51 57 49 45 52 100 102 51 45 98 48 101 97 45 102 56 52 56 97 97 57 53 55 100 57 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:,StartTime:2020-04-27 16:39:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.089: INFO: Pod "webserver-deployment-84855cf797-48vz4" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-48vz4 webserver-deployment-84855cf797- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-84855cf797-48vz4 c3387c05-5c44-40db-b141-ac1ab34ae9f7 20078 0 2020-04-27 16:39:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 12c28ea5-cee9-4f97-a889-aa45c9dcd02b 0xc005cd1b77 0xc005cd1b78}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 50 99 50 56 101 97 53 45 99 101 101 57 45 52 102 57 55 45 97 56 56 57 45 97 97 52 53 99 57 100 99 100 48 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:,StartTime:2020-04-27 16:39:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.090: INFO: Pod "webserver-deployment-84855cf797-4z9lg" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-4z9lg webserver-deployment-84855cf797- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-84855cf797-4z9lg da53f8b1-499d-4a30-aed0-68958416e190 19928 0 2020-04-27 16:39:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.143/32 cni.projectcalico.org/podIPs:100.64.1.143/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 12c28ea5-cee9-4f97-a889-aa45c9dcd02b 0xc005cd1f37 0xc005cd1f38}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:30 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 50 99 50 56 101 97 53 45 99 101 101 57 45 52 102 57 55 45 97 56 56 57 45 97 97 52 53 99 57 100 99 100 48 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:39:32 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:33 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 49 52 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:100.64.1.143,StartTime:2020-04-27 16:39:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:39:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://03e348ad47ac8875c283d7f9cfbb6d38bf5e92803847fa03ffeda0404e118467,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.143,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.090: INFO: Pod "webserver-deployment-84855cf797-59w4q" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-59w4q webserver-deployment-84855cf797- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-84855cf797-59w4q c59d718d-69df-48bf-b3e3-18da15a3f087 20067 0 2020-04-27 16:39:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 12c28ea5-cee9-4f97-a889-aa45c9dcd02b 0xc005cb81a7 0xc005cb81a8}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 50 99 50 56 101 97 53 45 99 101 101 57 45 52 102 57 55 45 97 56 56 57 45 97 97 52 53 99 57 100 99 100 48 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-65.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.8.65,PodIP:,StartTime:2020-04-27 16:39:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.090: INFO: Pod "webserver-deployment-84855cf797-5rdbc" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-5rdbc webserver-deployment-84855cf797- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-84855cf797-5rdbc fd9828c5-137b-4137-aa73-f59cc98286e6 19937 0 2020-04-27 16:39:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.145/32 cni.projectcalico.org/podIPs:100.64.1.145/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 12c28ea5-cee9-4f97-a889-aa45c9dcd02b 0xc005cb8447 0xc005cb8448}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:30 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 50 99 50 56 101 97 53 45 99 101 101 57 45 52 102 57 55 45 97 56 56 57 45 97 97 52 53 99 57 100 99 100 48 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:39:32 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:33 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 49 52 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:100.64.1.145,StartTime:2020-04-27 16:39:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:39:33 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://809279692a27d426901d7e39f58ab5079d250735178125870e8861d32ee5f745,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.145,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.090: INFO: Pod "webserver-deployment-84855cf797-8c5h9" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-8c5h9 webserver-deployment-84855cf797- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-84855cf797-8c5h9 ea51e727-e3db-40fa-98da-eaffa2a9e8d7 20061 0 2020-04-27 16:39:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 12c28ea5-cee9-4f97-a889-aa45c9dcd02b 0xc005cb86f7 0xc005cb86f8}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 50 99 50 56 101 97 53 45 99 101 101 57 45 52 102 57 55 45 97 56 56 57 45 97 97 52 53 99 57 100 99 100 48 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-65.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.8.65,PodIP:,StartTime:2020-04-27 16:39:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.090: INFO: Pod "webserver-deployment-84855cf797-9k74c" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-9k74c webserver-deployment-84855cf797- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-84855cf797-9k74c c1c45bf9-338a-4b35-aaa9-fd31b5db519f 19925 0 2020-04-27 16:39:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.147/32 cni.projectcalico.org/podIPs:100.64.1.147/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 12c28ea5-cee9-4f97-a889-aa45c9dcd02b 0xc005cb89a7 0xc005cb89a8}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:30 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 50 99 50 56 101 97 53 45 99 101 101 57 45 52 102 57 55 45 97 56 56 57 45 97 97 52 53 99 57 100 99 100 48 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:39:32 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:33 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 49 52 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:100.64.1.147,StartTime:2020-04-27 16:39:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:39:33 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://c2b8eec7d3075eec8673344c27c15eb9281deb4bb027fc8f3476e3f4879dc739,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.147,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.091: INFO: Pod "webserver-deployment-84855cf797-9nv7c" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-9nv7c webserver-deployment-84855cf797- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-84855cf797-9nv7c 01f21b81-d2ef-430c-b064-4e27ce12e1a4 20058 0 2020-04-27 16:39:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 12c28ea5-cee9-4f97-a889-aa45c9dcd02b 0xc005cb8bc7 0xc005cb8bc8}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 50 99 50 56 101 97 53 45 99 101 101 57 45 52 102 57 55 45 97 56 56 57 45 97 97 52 53 99 57 100 99 100 48 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-65.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.8.65,PodIP:,StartTime:2020-04-27 16:39:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.091: INFO: Pod "webserver-deployment-84855cf797-cvlhm" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-cvlhm webserver-deployment-84855cf797- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-84855cf797-cvlhm ee0944d9-eebb-4dfc-81a2-d6dd87e87a86 19934 0 2020-04-27 16:39:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.144/32 cni.projectcalico.org/podIPs:100.64.1.144/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 12c28ea5-cee9-4f97-a889-aa45c9dcd02b 0xc005cb8db7 0xc005cb8db8}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:30 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 50 99 50 56 101 97 53 45 99 101 101 57 45 52 102 57 55 45 97 56 56 57 45 97 97 52 53 99 57 100 99 100 48 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:39:32 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:33 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 49 52 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:100.64.1.144,StartTime:2020-04-27 16:39:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:39:33 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://fdc47e027af664b03b89de5c62adda9c9c66123a655e2ec6ae4e50b085500102,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.144,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.091: INFO: Pod "webserver-deployment-84855cf797-cztgq" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-cztgq webserver-deployment-84855cf797- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-84855cf797-cztgq e4ec877a-ac5c-4636-b487-ef31541c93d8 20064 0 2020-04-27 16:39:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 12c28ea5-cee9-4f97-a889-aa45c9dcd02b 0xc005cb9057 0xc005cb9058}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 50 99 50 56 101 97 53 45 99 101 101 57 45 52 102 57 55 45 97 56 56 57 45 97 97 52 53 99 57 100 99 100 48 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-65.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.8.65,PodIP:,StartTime:2020-04-27 16:39:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.091: INFO: Pod "webserver-deployment-84855cf797-d4pd6" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-d4pd6 webserver-deployment-84855cf797- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-84855cf797-d4pd6 8d2dec3a-4e0b-4239-87e8-1e0e6eddda4a 20053 0 2020-04-27 16:39:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 12c28ea5-cee9-4f97-a889-aa45c9dcd02b 0xc005cb9357 0xc005cb9358}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 50 99 50 56 101 97 53 45 99 101 101 57 45 52 102 57 55 45 97 56 56 57 45 97 97 52 53 99 57 100 99 100 48 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-65.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.8.65,PodIP:,StartTime:2020-04-27 16:39:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.091: INFO: Pod "webserver-deployment-84855cf797-dnlhh" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-dnlhh webserver-deployment-84855cf797- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-84855cf797-dnlhh 098f4e17-e650-4fac-9d0d-4bf7608a5fc6 19906 0 2020-04-27 16:39:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.0.27/32 cni.projectcalico.org/podIPs:100.64.0.27/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 12c28ea5-cee9-4f97-a889-aa45c9dcd02b 0xc005cb9637 0xc005cb9638}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:30 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 50 99 50 56 101 97 53 45 99 101 101 57 45 52 102 57 55 45 97 56 56 57 45 97 97 52 53 99 57 100 99 100 48 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:39:31 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:31 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 48 46 50 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-65.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.8.65,PodIP:100.64.0.27,StartTime:2020-04-27 16:39:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:39:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://6e31836657777eb42d93b4fb247a9fd3d97438c302a47e9c6f14adf3c6681041,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.27,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.092: INFO: Pod "webserver-deployment-84855cf797-dvnmv" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-dvnmv webserver-deployment-84855cf797- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-84855cf797-dvnmv 31a952a2-d8e8-4200-bbcc-972f15a45cae 20057 0 2020-04-27 16:39:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 12c28ea5-cee9-4f97-a889-aa45c9dcd02b 0xc005cb9920 0xc005cb9921}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 50 99 50 56 101 97 53 45 99 101 101 57 45 52 102 57 55 45 97 56 56 57 45 97 97 52 53 99 57 100 99 100 48 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-65.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.8.65,PodIP:,StartTime:2020-04-27 16:39:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.092: INFO: Pod "webserver-deployment-84855cf797-gr8l4" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-gr8l4 webserver-deployment-84855cf797- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-84855cf797-gr8l4 9c7c225d-8f61-4655-983b-e2544f0a9ce6 20062 0 2020-04-27 16:39:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 12c28ea5-cee9-4f97-a889-aa45c9dcd02b 0xc005cb9b37 0xc005cb9b38}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 50 99 50 56 101 97 53 45 99 101 101 57 45 52 102 57 55 45 97 56 56 57 45 97 97 52 53 99 57 100 99 100 48 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-65.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.8.65,PodIP:,StartTime:2020-04-27 16:39:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.092: INFO: Pod "webserver-deployment-84855cf797-lb8d6" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-lb8d6 webserver-deployment-84855cf797- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-84855cf797-lb8d6 e4a6be54-83ee-4357-84a2-f347c0f374c1 20073 0 2020-04-27 16:39:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 12c28ea5-cee9-4f97-a889-aa45c9dcd02b 0xc005cb9d77 0xc005cb9d78}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 50 99 50 56 101 97 53 45 99 101 101 57 45 52 102 57 55 45 97 56 56 57 45 97 97 52 53 99 57 100 99 100 48 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:,StartTime:2020-04-27 16:39:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.092: INFO: Pod "webserver-deployment-84855cf797-n66vt" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-n66vt webserver-deployment-84855cf797- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-84855cf797-n66vt 064d7541-3323-4381-90df-d6557b56fbf4 19931 0 2020-04-27 16:39:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.151/32 cni.projectcalico.org/podIPs:100.64.1.151/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 12c28ea5-cee9-4f97-a889-aa45c9dcd02b 0xc005c9e097 0xc005c9e098}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:30 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 50 99 50 56 101 97 53 45 99 101 101 57 45 52 102 57 55 45 97 56 56 57 45 97 97 52 53 99 57 100 99 100 48 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:39:33 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:33 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 49 53 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:100.64.1.151,StartTime:2020-04-27 16:39:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:39:33 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://6bacfbbd0ac149e3234c0a49c12b752b5972d3ccf18a03d018eba44e5cfc7b1e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.151,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.092: INFO: Pod "webserver-deployment-84855cf797-qftj7" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-qftj7 webserver-deployment-84855cf797- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-84855cf797-qftj7 dd6bdbd6-7a74-4696-b386-21d0280487b7 20072 0 2020-04-27 16:39:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 12c28ea5-cee9-4f97-a889-aa45c9dcd02b 0xc005c9e327 0xc005c9e328}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 50 99 50 56 101 97 53 45 99 101 101 57 45 52 102 57 55 45 97 56 56 57 45 97 97 52 53 99 57 100 99 100 48 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:,StartTime:2020-04-27 16:39:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.093: INFO: Pod "webserver-deployment-84855cf797-qg6jh" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-qg6jh webserver-deployment-84855cf797- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-84855cf797-qg6jh 1e646080-de0d-4a8c-8ef5-eb56deb0d1ea 19940 0 2020-04-27 16:39:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.148/32 cni.projectcalico.org/podIPs:100.64.1.148/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 12c28ea5-cee9-4f97-a889-aa45c9dcd02b 0xc005c9e517 0xc005c9e518}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:30 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 50 99 50 56 101 97 53 45 99 101 101 57 45 52 102 57 55 45 97 56 56 57 45 97 97 52 53 99 57 100 99 100 48 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:39:32 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:33 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 49 52 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:100.64.1.148,StartTime:2020-04-27 16:39:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:39:33 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://f6482eb2a19a3ec90beb5dfa3e81959a6313bf44e8ef466ab5897a88f9aa9a26,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.148,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.093: INFO: Pod "webserver-deployment-84855cf797-r8w8c" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-r8w8c webserver-deployment-84855cf797- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-84855cf797-r8w8c b986da00-cde4-4486-a318-eb34b2c44f2b 19943 0 2020-04-27 16:39:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.146/32 cni.projectcalico.org/podIPs:100.64.1.146/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 12c28ea5-cee9-4f97-a889-aa45c9dcd02b 0xc005c9e867 0xc005c9e868}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:30 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 50 99 50 56 101 97 53 45 99 101 101 57 45 52 102 57 55 45 97 56 56 57 45 97 97 52 53 99 57 100 99 100 48 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:39:32 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:33 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 49 52 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:100.64.1.146,StartTime:2020-04-27 16:39:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:39:33 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://91c95ce2af6aa4e51ac3022d5f919edc8e0f916b36b26635a01f0733a1044a94,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.146,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.093: INFO: Pod "webserver-deployment-84855cf797-wf7gn" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-wf7gn webserver-deployment-84855cf797- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-84855cf797-wf7gn 739a61dc-3a0a-4cbd-87b8-0b492fdea211 20060 0 2020-04-27 16:39:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 12c28ea5-cee9-4f97-a889-aa45c9dcd02b 0xc005c9eac7 0xc005c9eac8}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 50 99 50 56 101 97 53 45 99 101 101 57 45 52 102 57 55 45 97 56 56 57 45 97 97 52 53 99 57 100 99 100 48 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-65.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.8.65,PodIP:,StartTime:2020-04-27 16:39:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:39:37.093: INFO: Pod "webserver-deployment-84855cf797-wxpnt" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-wxpnt webserver-deployment-84855cf797- deployment-4449 /api/v1/namespaces/deployment-4449/pods/webserver-deployment-84855cf797-wxpnt 7649c2e8-47c1-43b9-9e33-de5098ae6531 20069 0 2020-04-27 16:39:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 12c28ea5-cee9-4f97-a889-aa45c9dcd02b 0xc005c9ec77 0xc005c9ec78}] []  [{kube-controller-manager Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 50 99 50 56 101 97 53 45 99 101 101 57 45 52 102 57 55 45 97 56 56 57 45 97 97 52 53 99 57 100 99 100 48 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:39:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c86j8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c86j8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c86j8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:39:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:,StartTime:2020-04-27 16:39:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:39:37.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4449" for this suite.
•{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":277,"completed":100,"skipped":1778,"failed":0}
SSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:39:37.275: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7503
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating pod
Apr 27 16:39:42.364: INFO: Pod pod-hostip-0eb8b64d-cec1-475b-9359-082633a6293f has hostIP: 10.250.8.65
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:39:42.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7503" for this suite.
•{"msg":"PASSED [k8s.io] Pods should get a host IP [NodeConformance] [Conformance]","total":277,"completed":101,"skipped":1783,"failed":0}
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:39:42.545: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8217
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Apr 27 16:39:49.724: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-8217 PodName:pod-sharedvolume-451a6a48-0006-4719-ba49-c066745abaee ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:39:49.725: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:39:50.470: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:39:50.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8217" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":277,"completed":102,"skipped":1790,"failed":0}

------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:39:50.652: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9888
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-9b971de3-03e7-41d2-bd78-d5603f884fa9
STEP: Creating a pod to test consume configMaps
Apr 27 16:39:51.502: INFO: Waiting up to 5m0s for pod "pod-configmaps-7f45199c-340c-4629-8581-0b4dff6cb206" in namespace "configmap-9888" to be "Succeeded or Failed"
Apr 27 16:39:51.592: INFO: Pod "pod-configmaps-7f45199c-340c-4629-8581-0b4dff6cb206": Phase="Pending", Reason="", readiness=false. Elapsed: 89.835485ms
Apr 27 16:39:53.683: INFO: Pod "pod-configmaps-7f45199c-340c-4629-8581-0b4dff6cb206": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180348414s
STEP: Saw pod success
Apr 27 16:39:53.683: INFO: Pod "pod-configmaps-7f45199c-340c-4629-8581-0b4dff6cb206" satisfied condition "Succeeded or Failed"
Apr 27 16:39:53.773: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-configmaps-7f45199c-340c-4629-8581-0b4dff6cb206 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:39:53.963: INFO: Waiting for pod pod-configmaps-7f45199c-340c-4629-8581-0b4dff6cb206 to disappear
Apr 27 16:39:54.052: INFO: Pod pod-configmaps-7f45199c-340c-4629-8581-0b4dff6cb206 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:39:54.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9888" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":103,"skipped":1790,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:39:54.234: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1697
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Apr 27 16:39:54.874: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 27 16:39:55.148: INFO: Waiting for terminating namespaces to be deleted...
Apr 27 16:39:55.237: INFO: 
Logging pods the kubelet thinks is on node ip-10-250-10-186.ec2.internal before test
Apr 27 16:39:55.343: INFO: node-problem-detector-f7dh2 from kube-system started at 2020-04-27 15:54:02 +0000 UTC (1 container statuses recorded)
Apr 27 16:39:55.343: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 16:39:55.343: INFO: kube-proxy-f8lnb from kube-system started at 2020-04-27 15:54:02 +0000 UTC (1 container statuses recorded)
Apr 27 16:39:55.343: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:39:55.343: INFO: csi-driver-node-qjp4d from kube-system started at 2020-04-27 15:54:02 +0000 UTC (3 container statuses recorded)
Apr 27 16:39:55.343: INFO: 	Container csi-driver ready: true, restart count 0
Apr 27 16:39:55.343: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 27 16:39:55.343: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 27 16:39:55.343: INFO: pod-sharedvolume-451a6a48-0006-4719-ba49-c066745abaee from emptydir-8217 started at 2020-04-27 16:39:43 +0000 UTC (2 container statuses recorded)
Apr 27 16:39:55.343: INFO: 	Container busybox-main-container ready: true, restart count 0
Apr 27 16:39:55.343: INFO: 	Container busybox-sub-container ready: false, restart count 0
Apr 27 16:39:55.343: INFO: node-exporter-zggrn from kube-system started at 2020-04-27 15:54:02 +0000 UTC (1 container statuses recorded)
Apr 27 16:39:55.343: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:39:55.343: INFO: calico-node-mvhvc from kube-system started at 2020-04-27 15:57:54 +0000 UTC (1 container statuses recorded)
Apr 27 16:39:55.343: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:39:55.343: INFO: 
Logging pods the kubelet thinks is on node ip-10-250-8-65.ec2.internal before test
Apr 27 16:39:55.520: INFO: kubernetes-dashboard-6b586c4cb4-jw8gc from kubernetes-dashboard started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:39:55.520: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 27 16:39:55.520: INFO: kube-proxy-2tzh4 from kube-system started at 2020-04-27 15:53:59 +0000 UTC (1 container statuses recorded)
Apr 27 16:39:55.520: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:39:55.520: INFO: calico-typha-vertical-autoscaler-5b477c88cf-lq56p from kube-system started at 2020-04-27 15:54:17 +0000 UTC (1 container statuses recorded)
Apr 27 16:39:55.520: INFO: 	Container autoscaler ready: true, restart count 3
Apr 27 16:39:55.520: INFO: csi-driver-node-lqmtr from kube-system started at 2020-04-27 15:53:59 +0000 UTC (3 container statuses recorded)
Apr 27 16:39:55.520: INFO: 	Container csi-driver ready: true, restart count 0
Apr 27 16:39:55.520: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 27 16:39:55.520: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 27 16:39:55.520: INFO: calico-kube-controllers-77dcb8f688-f6jtd from kube-system started at 2020-04-27 15:54:17 +0000 UTC (1 container statuses recorded)
Apr 27 16:39:55.520: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 27 16:39:55.520: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-hqsfl from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:39:55.520: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr 27 16:39:55.520: INFO: calico-node-l4j7q from kube-system started at 2020-04-27 15:57:44 +0000 UTC (1 container statuses recorded)
Apr 27 16:39:55.520: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:39:55.520: INFO: node-exporter-vv796 from kube-system started at 2020-04-27 15:53:59 +0000 UTC (1 container statuses recorded)
Apr 27 16:39:55.520: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:39:55.520: INFO: coredns-5cb857d789-m225g from kube-system started at 2020-04-27 15:54:14 +0000 UTC (1 container statuses recorded)
Apr 27 16:39:55.520: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:39:55.520: INFO: addons-nginx-ingress-controller-6cf77756b5-8sgd9 from kube-system started at 2020-04-27 15:54:17 +0000 UTC (1 container statuses recorded)
Apr 27 16:39:55.520: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 27 16:39:55.520: INFO: coredns-5cb857d789-bn7lm from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:39:55.520: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:39:55.520: INFO: calico-typha-deploy-784665cc66-dtz47 from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:39:55.520: INFO: 	Container calico-typha ready: true, restart count 0
Apr 27 16:39:55.520: INFO: blackbox-exporter-5dc75b79b7-hcrbp from kube-system started at 2020-04-27 15:53:59 +0000 UTC (1 container statuses recorded)
Apr 27 16:39:55.520: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 27 16:39:55.520: INFO: dashboard-metrics-scraper-76c7b697bc-ghctb from kubernetes-dashboard started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:39:55.520: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 27 16:39:55.520: INFO: vpn-shoot-5c755d796f-fvlqt from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:39:55.520: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 27 16:39:55.520: INFO: metrics-server-7dd4d485f9-ff6mk from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:39:55.520: INFO: 	Container metrics-server ready: true, restart count 0
Apr 27 16:39:55.520: INFO: calico-node-vertical-autoscaler-74d4897db8-g7wmv from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:39:55.520: INFO: 	Container autoscaler ready: true, restart count 3
Apr 27 16:39:55.520: INFO: calico-typha-horizontal-autoscaler-6fdd5d8746-vxwg5 from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 16:39:55.520: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 16:39:55.520: INFO: node-problem-detector-frcdg from kube-system started at 2020-04-27 15:53:59 +0000 UTC (1 container statuses recorded)
Apr 27 16:39:55.520: INFO: 	Container node-problem-detector ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1609baad01794946], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1609baad01a7d366], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:39:56.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1697" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":277,"completed":104,"skipped":1806,"failed":0}
SS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:39:57.157: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-5980
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:39:57.889: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-5596782d-890d-48a1-a53c-9bfb66715b64" in namespace "security-context-test-5980" to be "Succeeded or Failed"
Apr 27 16:39:57.978: INFO: Pod "busybox-readonly-false-5596782d-890d-48a1-a53c-9bfb66715b64": Phase="Pending", Reason="", readiness=false. Elapsed: 89.585336ms
Apr 27 16:40:00.069: INFO: Pod "busybox-readonly-false-5596782d-890d-48a1-a53c-9bfb66715b64": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180165935s
Apr 27 16:40:00.069: INFO: Pod "busybox-readonly-false-5596782d-890d-48a1-a53c-9bfb66715b64" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:40:00.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5980" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":277,"completed":105,"skipped":1808,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:40:00.251: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8914
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:40:01.382: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Apr 27 16:40:01.569: INFO: Number of nodes with available pods: 0
Apr 27 16:40:01.569: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Apr 27 16:40:02.053: INFO: Number of nodes with available pods: 0
Apr 27 16:40:02.053: INFO: Node ip-10-250-8-65.ec2.internal is running more than one daemon pod
Apr 27 16:40:03.143: INFO: Number of nodes with available pods: 0
Apr 27 16:40:03.143: INFO: Node ip-10-250-8-65.ec2.internal is running more than one daemon pod
Apr 27 16:40:04.147: INFO: Number of nodes with available pods: 1
Apr 27 16:40:04.147: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Apr 27 16:40:04.597: INFO: Number of nodes with available pods: 0
Apr 27 16:40:04.597: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Apr 27 16:40:04.781: INFO: Number of nodes with available pods: 0
Apr 27 16:40:04.781: INFO: Node ip-10-250-8-65.ec2.internal is running more than one daemon pod
Apr 27 16:40:05.872: INFO: Number of nodes with available pods: 0
Apr 27 16:40:05.872: INFO: Node ip-10-250-8-65.ec2.internal is running more than one daemon pod
Apr 27 16:40:06.872: INFO: Number of nodes with available pods: 0
Apr 27 16:40:06.872: INFO: Node ip-10-250-8-65.ec2.internal is running more than one daemon pod
Apr 27 16:40:07.873: INFO: Number of nodes with available pods: 0
Apr 27 16:40:07.873: INFO: Node ip-10-250-8-65.ec2.internal is running more than one daemon pod
Apr 27 16:40:08.873: INFO: Number of nodes with available pods: 1
Apr 27 16:40:08.873: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8914, will wait for the garbage collector to delete the pods
Apr 27 16:40:09.335: INFO: Deleting DaemonSet.extensions daemon-set took: 91.447112ms
Apr 27 16:40:09.935: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.272479ms
Apr 27 16:40:23.325: INFO: Number of nodes with available pods: 0
Apr 27 16:40:23.325: INFO: Number of running nodes: 0, number of available pods: 0
Apr 27 16:40:23.415: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8914/daemonsets","resourceVersion":"20605"},"items":null}

Apr 27 16:40:23.505: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8914/pods","resourceVersion":"20605"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:40:23.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8914" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":277,"completed":106,"skipped":1829,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:40:24.138: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8283
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl logs
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1288
STEP: creating an pod
Apr 27 16:40:24.777: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run logs-generator --image=us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 --namespace=kubectl-8283 -- logs-generator --log-lines-total 100 --run-duration 20s'
Apr 27 16:40:25.128: INFO: stderr: ""
Apr 27 16:40:25.128: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Waiting for log generator to start.
Apr 27 16:40:25.128: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Apr 27 16:40:25.128: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-8283" to be "running and ready, or succeeded"
Apr 27 16:40:25.218: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 89.784893ms
Apr 27 16:40:27.309: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.180509132s
Apr 27 16:40:27.309: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Apr 27 16:40:27.309: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Apr 27 16:40:27.309: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-8283'
Apr 27 16:40:27.748: INFO: stderr: ""
Apr 27 16:40:27.748: INFO: stdout: "I0427 16:40:25.883377       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/667q 232\nI0427 16:40:26.083500       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/9mgb 410\nI0427 16:40:26.283501       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/mptm 479\nI0427 16:40:26.483489       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/jlt 202\nI0427 16:40:26.683502       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/zv5 383\nI0427 16:40:26.883507       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/njr 272\nI0427 16:40:27.083485       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/n96 356\nI0427 16:40:27.283481       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/ntt 329\nI0427 16:40:27.483499       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/kpm 323\nI0427 16:40:27.683495       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/99m8 502\n"
STEP: limiting log lines
Apr 27 16:40:27.748: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-8283 --tail=1'
Apr 27 16:40:28.179: INFO: stderr: ""
Apr 27 16:40:28.180: INFO: stdout: "I0427 16:40:28.083485       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/4m5n 297\n"
Apr 27 16:40:28.180: INFO: got output "I0427 16:40:28.083485       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/4m5n 297\n"
STEP: limiting log bytes
Apr 27 16:40:28.180: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-8283 --limit-bytes=1'
Apr 27 16:40:28.708: INFO: stderr: ""
Apr 27 16:40:28.708: INFO: stdout: "I"
Apr 27 16:40:28.708: INFO: got output "I"
STEP: exposing timestamps
Apr 27 16:40:28.708: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-8283 --tail=1 --timestamps'
Apr 27 16:40:29.142: INFO: stderr: ""
Apr 27 16:40:29.142: INFO: stdout: "2020-04-27T16:40:29.083577678Z I0427 16:40:29.083487       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/rdx 527\n"
Apr 27 16:40:29.142: INFO: got output "2020-04-27T16:40:29.083577678Z I0427 16:40:29.083487       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/rdx 527\n"
STEP: restricting to a time range
Apr 27 16:40:31.643: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-8283 --since=1s'
Apr 27 16:40:37.073: INFO: stderr: ""
Apr 27 16:40:37.073: INFO: stdout: "I0427 16:40:36.083475       1 logs_generator.go:76] 51 PUT /api/v1/namespaces/ns/pods/zbg5 466\nI0427 16:40:36.283510       1 logs_generator.go:76] 52 GET /api/v1/namespaces/kube-system/pods/5gdj 448\nI0427 16:40:36.483489       1 logs_generator.go:76] 53 PUT /api/v1/namespaces/kube-system/pods/m6n 381\nI0427 16:40:36.683491       1 logs_generator.go:76] 54 PUT /api/v1/namespaces/kube-system/pods/zlc9 334\nI0427 16:40:36.883493       1 logs_generator.go:76] 55 POST /api/v1/namespaces/kube-system/pods/rtx 251\n"
Apr 27 16:40:37.074: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-8283 --since=24h'
Apr 27 16:40:37.516: INFO: stderr: ""
Apr 27 16:40:37.516: INFO: stdout: "I0427 16:40:25.883377       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/667q 232\nI0427 16:40:26.083500       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/9mgb 410\nI0427 16:40:26.283501       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/mptm 479\nI0427 16:40:26.483489       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/jlt 202\nI0427 16:40:26.683502       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/zv5 383\nI0427 16:40:26.883507       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/njr 272\nI0427 16:40:27.083485       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/n96 356\nI0427 16:40:27.283481       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/ntt 329\nI0427 16:40:27.483499       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/kpm 323\nI0427 16:40:27.683495       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/99m8 502\nI0427 16:40:27.883503       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/j6n 453\nI0427 16:40:28.083485       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/4m5n 297\nI0427 16:40:28.283517       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/fs5 587\nI0427 16:40:28.483488       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/2w8 244\nI0427 16:40:28.683488       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/ns/pods/4w8 382\nI0427 16:40:28.883486       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/fpxz 473\nI0427 16:40:29.083487       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/rdx 527\nI0427 16:40:29.283489       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/9gtm 487\nI0427 16:40:29.483488       1 logs_generator.go:76] 18 GET /api/v1/namespaces/ns/pods/xnqh 299\nI0427 16:40:29.683481       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/dln 405\nI0427 16:40:29.883502       1 logs_generator.go:76] 20 GET /api/v1/namespaces/default/pods/vx4 457\nI0427 16:40:30.083491       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/cs8n 420\nI0427 16:40:30.283488       1 logs_generator.go:76] 22 GET /api/v1/namespaces/default/pods/6j5 414\nI0427 16:40:30.483491       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/default/pods/c4sh 554\nI0427 16:40:30.683496       1 logs_generator.go:76] 24 PUT /api/v1/namespaces/default/pods/swtw 573\nI0427 16:40:30.883514       1 logs_generator.go:76] 25 POST /api/v1/namespaces/kube-system/pods/t89f 415\nI0427 16:40:31.083433       1 logs_generator.go:76] 26 GET /api/v1/namespaces/kube-system/pods/8wj 300\nI0427 16:40:31.283514       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/kube-system/pods/7gb 413\nI0427 16:40:31.483509       1 logs_generator.go:76] 28 POST /api/v1/namespaces/ns/pods/cm5c 298\nI0427 16:40:31.683490       1 logs_generator.go:76] 29 PUT /api/v1/namespaces/kube-system/pods/nct 488\nI0427 16:40:31.883490       1 logs_generator.go:76] 30 PUT /api/v1/namespaces/default/pods/v7wl 348\nI0427 16:40:32.083489       1 logs_generator.go:76] 31 POST /api/v1/namespaces/kube-system/pods/89v 376\nI0427 16:40:32.283480       1 logs_generator.go:76] 32 PUT /api/v1/namespaces/kube-system/pods/rcmp 475\nI0427 16:40:32.483500       1 logs_generator.go:76] 33 GET /api/v1/namespaces/default/pods/bdjm 325\nI0427 16:40:32.683501       1 logs_generator.go:76] 34 GET /api/v1/namespaces/default/pods/w4f 473\nI0427 16:40:32.883490       1 logs_generator.go:76] 35 PUT /api/v1/namespaces/ns/pods/jzg 219\nI0427 16:40:33.083502       1 logs_generator.go:76] 36 PUT /api/v1/namespaces/default/pods/8lb 450\nI0427 16:40:33.283488       1 logs_generator.go:76] 37 GET /api/v1/namespaces/ns/pods/7cq 410\nI0427 16:40:33.483490       1 logs_generator.go:76] 38 GET /api/v1/namespaces/default/pods/qw2 508\nI0427 16:40:33.683512       1 logs_generator.go:76] 39 GET /api/v1/namespaces/kube-system/pods/8p2c 289\nI0427 16:40:33.883485       1 logs_generator.go:76] 40 PUT /api/v1/namespaces/kube-system/pods/x69c 248\nI0427 16:40:34.083477       1 logs_generator.go:76] 41 POST /api/v1/namespaces/default/pods/9c7 428\nI0427 16:40:34.283526       1 logs_generator.go:76] 42 PUT /api/v1/namespaces/kube-system/pods/pwm 454\nI0427 16:40:34.483488       1 logs_generator.go:76] 43 PUT /api/v1/namespaces/ns/pods/qpp 301\nI0427 16:40:34.683490       1 logs_generator.go:76] 44 POST /api/v1/namespaces/default/pods/dhhf 455\nI0427 16:40:34.883506       1 logs_generator.go:76] 45 POST /api/v1/namespaces/default/pods/xpxv 551\nI0427 16:40:35.083511       1 logs_generator.go:76] 46 PUT /api/v1/namespaces/ns/pods/c6zs 388\nI0427 16:40:35.283485       1 logs_generator.go:76] 47 GET /api/v1/namespaces/ns/pods/gpf 499\nI0427 16:40:35.483497       1 logs_generator.go:76] 48 GET /api/v1/namespaces/default/pods/bmx 573\nI0427 16:40:35.683492       1 logs_generator.go:76] 49 PUT /api/v1/namespaces/default/pods/wpm 350\nI0427 16:40:35.883488       1 logs_generator.go:76] 50 POST /api/v1/namespaces/kube-system/pods/h78d 249\nI0427 16:40:36.083475       1 logs_generator.go:76] 51 PUT /api/v1/namespaces/ns/pods/zbg5 466\nI0427 16:40:36.283510       1 logs_generator.go:76] 52 GET /api/v1/namespaces/kube-system/pods/5gdj 448\nI0427 16:40:36.483489       1 logs_generator.go:76] 53 PUT /api/v1/namespaces/kube-system/pods/m6n 381\nI0427 16:40:36.683491       1 logs_generator.go:76] 54 PUT /api/v1/namespaces/kube-system/pods/zlc9 334\nI0427 16:40:36.883493       1 logs_generator.go:76] 55 POST /api/v1/namespaces/kube-system/pods/rtx 251\nI0427 16:40:37.083502       1 logs_generator.go:76] 56 GET /api/v1/namespaces/default/pods/x6dr 366\nI0427 16:40:37.283495       1 logs_generator.go:76] 57 POST /api/v1/namespaces/kube-system/pods/rvjp 534\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1294
Apr 27 16:40:37.517: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pod logs-generator --namespace=kubectl-8283'
Apr 27 16:40:39.524: INFO: stderr: ""
Apr 27 16:40:39.524: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:40:39.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8283" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":277,"completed":107,"skipped":1831,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:40:39.706: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9416
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-d0e14d6a-6944-4a0b-853f-7b5fa372f655
STEP: Creating a pod to test consume configMaps
Apr 27 16:40:40.530: INFO: Waiting up to 5m0s for pod "pod-configmaps-9e7fd2bd-835c-47c8-9fd0-d0e91c937b5c" in namespace "configmap-9416" to be "Succeeded or Failed"
Apr 27 16:40:40.620: INFO: Pod "pod-configmaps-9e7fd2bd-835c-47c8-9fd0-d0e91c937b5c": Phase="Pending", Reason="", readiness=false. Elapsed: 90.069592ms
Apr 27 16:40:42.710: INFO: Pod "pod-configmaps-9e7fd2bd-835c-47c8-9fd0-d0e91c937b5c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180425533s
STEP: Saw pod success
Apr 27 16:40:42.710: INFO: Pod "pod-configmaps-9e7fd2bd-835c-47c8-9fd0-d0e91c937b5c" satisfied condition "Succeeded or Failed"
Apr 27 16:40:42.800: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-configmaps-9e7fd2bd-835c-47c8-9fd0-d0e91c937b5c container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:40:42.990: INFO: Waiting for pod pod-configmaps-9e7fd2bd-835c-47c8-9fd0-d0e91c937b5c to disappear
Apr 27 16:40:43.079: INFO: Pod pod-configmaps-9e7fd2bd-835c-47c8-9fd0-d0e91c937b5c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:40:43.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9416" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":108,"skipped":1850,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:40:43.262: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-8910
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:40:50.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8910" for this suite.
•{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":277,"completed":109,"skipped":1883,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:40:50.264: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6864
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-644eeb67-bea0-4877-ade5-6824ece0cf84
STEP: Creating a pod to test consume secrets
Apr 27 16:40:51.088: INFO: Waiting up to 5m0s for pod "pod-secrets-c15ecce8-6165-44c1-a01d-2f99b2b6cf92" in namespace "secrets-6864" to be "Succeeded or Failed"
Apr 27 16:40:51.178: INFO: Pod "pod-secrets-c15ecce8-6165-44c1-a01d-2f99b2b6cf92": Phase="Pending", Reason="", readiness=false. Elapsed: 89.77322ms
Apr 27 16:40:53.268: INFO: Pod "pod-secrets-c15ecce8-6165-44c1-a01d-2f99b2b6cf92": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179834479s
STEP: Saw pod success
Apr 27 16:40:53.268: INFO: Pod "pod-secrets-c15ecce8-6165-44c1-a01d-2f99b2b6cf92" satisfied condition "Succeeded or Failed"
Apr 27 16:40:53.357: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-secrets-c15ecce8-6165-44c1-a01d-2f99b2b6cf92 container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:40:53.548: INFO: Waiting for pod pod-secrets-c15ecce8-6165-44c1-a01d-2f99b2b6cf92 to disappear
Apr 27 16:40:53.637: INFO: Pod pod-secrets-c15ecce8-6165-44c1-a01d-2f99b2b6cf92 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:40:53.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6864" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":110,"skipped":1910,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:40:53.820: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1637
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Apr 27 16:40:54.459: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:40:58.482: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:15.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1637" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":277,"completed":111,"skipped":1919,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:15.432: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8363
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Apr 27 16:41:19.215: INFO: Successfully updated pod "labelsupdatec4f36b79-19ca-4aee-891e-7d49785c8221"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:21.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8363" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":277,"completed":112,"skipped":1959,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:21.589: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8131
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:41:22.227: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr 27 16:41:26.260: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-8131 create -f -'
Apr 27 16:41:27.585: INFO: stderr: ""
Apr 27 16:41:27.585: INFO: stdout: "e2e-test-crd-publish-openapi-9065-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 27 16:41:27.586: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-8131 delete e2e-test-crd-publish-openapi-9065-crds test-cr'
Apr 27 16:41:28.004: INFO: stderr: ""
Apr 27 16:41:28.004: INFO: stdout: "e2e-test-crd-publish-openapi-9065-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Apr 27 16:41:28.004: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-8131 apply -f -'
Apr 27 16:41:29.029: INFO: stderr: ""
Apr 27 16:41:29.029: INFO: stdout: "e2e-test-crd-publish-openapi-9065-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 27 16:41:29.029: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-8131 delete e2e-test-crd-publish-openapi-9065-crds test-cr'
Apr 27 16:41:29.453: INFO: stderr: ""
Apr 27 16:41:29.453: INFO: stdout: "e2e-test-crd-publish-openapi-9065-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Apr 27 16:41:29.453: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-9065-crds'
Apr 27 16:41:30.210: INFO: stderr: ""
Apr 27 16:41:30.210: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9065-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:34.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8131" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":277,"completed":113,"skipped":1978,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:34.514: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1105
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating secret secrets-1105/secret-test-62cd0563-96c2-43d4-8568-b9fb980e5456
STEP: Creating a pod to test consume secrets
Apr 27 16:41:35.334: INFO: Waiting up to 5m0s for pod "pod-configmaps-cc425e1c-41d8-415b-8c82-12c541728523" in namespace "secrets-1105" to be "Succeeded or Failed"
Apr 27 16:41:35.424: INFO: Pod "pod-configmaps-cc425e1c-41d8-415b-8c82-12c541728523": Phase="Pending", Reason="", readiness=false. Elapsed: 89.477396ms
Apr 27 16:41:37.514: INFO: Pod "pod-configmaps-cc425e1c-41d8-415b-8c82-12c541728523": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179612234s
STEP: Saw pod success
Apr 27 16:41:37.514: INFO: Pod "pod-configmaps-cc425e1c-41d8-415b-8c82-12c541728523" satisfied condition "Succeeded or Failed"
Apr 27 16:41:37.604: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-configmaps-cc425e1c-41d8-415b-8c82-12c541728523 container env-test: <nil>
STEP: delete the pod
Apr 27 16:41:37.795: INFO: Waiting for pod pod-configmaps-cc425e1c-41d8-415b-8c82-12c541728523 to disappear
Apr 27 16:41:37.884: INFO: Pod pod-configmaps-cc425e1c-41d8-415b-8c82-12c541728523 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:37.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1105" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":277,"completed":114,"skipped":1992,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:38.067: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6575
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Apr 27 16:41:40.106: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0427 16:41:40.106362    7325 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:40.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6575" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":277,"completed":115,"skipped":2019,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:40.289: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-772
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a Namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nspatchtest-9e3127ec-d1f0-4ff7-bcc6-74e2432feeaf-5367
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:41.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-772" for this suite.
STEP: Destroying namespace "nspatchtest-9e3127ec-d1f0-4ff7-bcc6-74e2432feeaf-5367" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":277,"completed":116,"skipped":2037,"failed":0}
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:41.929: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-4387
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's command
Apr 27 16:41:42.661: INFO: Waiting up to 5m0s for pod "var-expansion-59cfdcdf-11d0-46a2-9f1d-c20d06881a93" in namespace "var-expansion-4387" to be "Succeeded or Failed"
Apr 27 16:41:42.751: INFO: Pod "var-expansion-59cfdcdf-11d0-46a2-9f1d-c20d06881a93": Phase="Pending", Reason="", readiness=false. Elapsed: 89.662352ms
Apr 27 16:41:44.841: INFO: Pod "var-expansion-59cfdcdf-11d0-46a2-9f1d-c20d06881a93": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.17997244s
STEP: Saw pod success
Apr 27 16:41:44.841: INFO: Pod "var-expansion-59cfdcdf-11d0-46a2-9f1d-c20d06881a93" satisfied condition "Succeeded or Failed"
Apr 27 16:41:44.931: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod var-expansion-59cfdcdf-11d0-46a2-9f1d-c20d06881a93 container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:41:45.121: INFO: Waiting for pod var-expansion-59cfdcdf-11d0-46a2-9f1d-c20d06881a93 to disappear
Apr 27 16:41:45.211: INFO: Pod var-expansion-59cfdcdf-11d0-46a2-9f1d-c20d06881a93 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:45.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4387" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":277,"completed":117,"skipped":2040,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:45.392: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5247
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:41:46.122: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bdc0e52c-6b00-44d1-85b5-11095e30096c" in namespace "projected-5247" to be "Succeeded or Failed"
Apr 27 16:41:46.212: INFO: Pod "downwardapi-volume-bdc0e52c-6b00-44d1-85b5-11095e30096c": Phase="Pending", Reason="", readiness=false. Elapsed: 89.824617ms
Apr 27 16:41:48.302: INFO: Pod "downwardapi-volume-bdc0e52c-6b00-44d1-85b5-11095e30096c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180349622s
STEP: Saw pod success
Apr 27 16:41:48.302: INFO: Pod "downwardapi-volume-bdc0e52c-6b00-44d1-85b5-11095e30096c" satisfied condition "Succeeded or Failed"
Apr 27 16:41:48.392: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod downwardapi-volume-bdc0e52c-6b00-44d1-85b5-11095e30096c container client-container: <nil>
STEP: delete the pod
Apr 27 16:41:48.582: INFO: Waiting for pod downwardapi-volume-bdc0e52c-6b00-44d1-85b5-11095e30096c to disappear
Apr 27 16:41:48.671: INFO: Pod downwardapi-volume-bdc0e52c-6b00-44d1-85b5-11095e30096c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:48.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5247" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":277,"completed":118,"skipped":2055,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:48.854: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-2386
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:41:50.535: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602510, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602510, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602510, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602510, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:41:53.719: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:41:53.809: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:55.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-2386" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137
•{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":277,"completed":119,"skipped":2059,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:55.783: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5874
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-19d87675-67d7-4379-b419-e97fc11552e5
STEP: Creating configMap with name cm-test-opt-upd-8bfd8845-b936-47a8-982c-5ee5ed5ff71c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-19d87675-67d7-4379-b419-e97fc11552e5
STEP: Updating configmap cm-test-opt-upd-8bfd8845-b936-47a8-982c-5ee5ed5ff71c
STEP: Creating configMap with name cm-test-opt-create-feedf499-e27c-430f-90e1-7c2b05c8540b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:42:02.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5874" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":120,"skipped":2073,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:42:02.218: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2516
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:42:20.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2516" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":277,"completed":121,"skipped":2086,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:42:20.313: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1306
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:42:21.044: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b5071f4e-6958-46af-8612-8124a9935aee" in namespace "downward-api-1306" to be "Succeeded or Failed"
Apr 27 16:42:21.134: INFO: Pod "downwardapi-volume-b5071f4e-6958-46af-8612-8124a9935aee": Phase="Pending", Reason="", readiness=false. Elapsed: 89.853786ms
Apr 27 16:42:23.224: INFO: Pod "downwardapi-volume-b5071f4e-6958-46af-8612-8124a9935aee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179897075s
STEP: Saw pod success
Apr 27 16:42:23.224: INFO: Pod "downwardapi-volume-b5071f4e-6958-46af-8612-8124a9935aee" satisfied condition "Succeeded or Failed"
Apr 27 16:42:23.314: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod downwardapi-volume-b5071f4e-6958-46af-8612-8124a9935aee container client-container: <nil>
STEP: delete the pod
Apr 27 16:42:23.506: INFO: Waiting for pod downwardapi-volume-b5071f4e-6958-46af-8612-8124a9935aee to disappear
Apr 27 16:42:23.596: INFO: Pod downwardapi-volume-b5071f4e-6958-46af-8612-8124a9935aee no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:42:23.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1306" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":277,"completed":122,"skipped":2087,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:42:23.778: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-21
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:42:25.968: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602545, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602545, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602545, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602545, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:42:29.151: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:42:29.241: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-387-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:42:30.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-21" for this suite.
STEP: Destroying namespace "webhook-21-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":277,"completed":123,"skipped":2094,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:42:31.321: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-664
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Apr 27 16:42:31.959: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:42:36.007: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:42:52.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-664" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":277,"completed":124,"skipped":2126,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:42:53.006: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2343
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-a8d1125d-f82b-418b-b8cd-8985e3245ccb
STEP: Creating a pod to test consume secrets
Apr 27 16:42:53.826: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-db08e5c2-d236-45b3-97e4-c193b0110a80" in namespace "projected-2343" to be "Succeeded or Failed"
Apr 27 16:42:53.916: INFO: Pod "pod-projected-secrets-db08e5c2-d236-45b3-97e4-c193b0110a80": Phase="Pending", Reason="", readiness=false. Elapsed: 89.494635ms
Apr 27 16:42:56.006: INFO: Pod "pod-projected-secrets-db08e5c2-d236-45b3-97e4-c193b0110a80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179660657s
STEP: Saw pod success
Apr 27 16:42:56.006: INFO: Pod "pod-projected-secrets-db08e5c2-d236-45b3-97e4-c193b0110a80" satisfied condition "Succeeded or Failed"
Apr 27 16:42:56.096: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-projected-secrets-db08e5c2-d236-45b3-97e4-c193b0110a80 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:42:56.284: INFO: Waiting for pod pod-projected-secrets-db08e5c2-d236-45b3-97e4-c193b0110a80 to disappear
Apr 27 16:42:56.374: INFO: Pod pod-projected-secrets-db08e5c2-d236-45b3-97e4-c193b0110a80 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:42:56.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2343" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":125,"skipped":2137,"failed":0}
SSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:42:56.556: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7680
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Apr 27 16:42:57.291: INFO: Created pod &Pod{ObjectMeta:{dns-7680  dns-7680 /api/v1/namespaces/dns-7680/pods/dns-7680 e00a088e-0c9a-43f8-ad60-d4badfc57d50 21903 0 2020-04-27 16:42:57 +0000 UTC <nil> <nil> map[] map[kubernetes.io/psp:e2e-test-privileged-psp] [] []  [{e2e.test Update v1 2020-04-27 16:42:57 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 67 111 110 102 105 103 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 115 101 114 118 101 114 115 34 58 123 125 44 34 102 58 115 101 97 114 99 104 101 115 34 58 123 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-chmqr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-chmqr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-chmqr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:42:57.380: INFO: The status of Pod dns-7680 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:42:59.471: INFO: The status of Pod dns-7680 is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
Apr 27 16:42:59.471: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-7680 PodName:dns-7680 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:42:59.471: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Verifying customized DNS server is configured on pod...
Apr 27 16:43:00.328: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-7680 PodName:dns-7680 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:43:00.328: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:43:01.109: INFO: Deleting pod dns-7680...
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:43:01.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7680" for this suite.
•{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":277,"completed":126,"skipped":2142,"failed":0}
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:43:01.385: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8447
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override all
Apr 27 16:43:02.127: INFO: Waiting up to 5m0s for pod "client-containers-9e5a144c-11f4-4699-a55d-d6aabcb7ce70" in namespace "containers-8447" to be "Succeeded or Failed"
Apr 27 16:43:02.224: INFO: Pod "client-containers-9e5a144c-11f4-4699-a55d-d6aabcb7ce70": Phase="Pending", Reason="", readiness=false. Elapsed: 97.018116ms
Apr 27 16:43:04.314: INFO: Pod "client-containers-9e5a144c-11f4-4699-a55d-d6aabcb7ce70": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.18730462s
STEP: Saw pod success
Apr 27 16:43:04.314: INFO: Pod "client-containers-9e5a144c-11f4-4699-a55d-d6aabcb7ce70" satisfied condition "Succeeded or Failed"
Apr 27 16:43:04.404: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod client-containers-9e5a144c-11f4-4699-a55d-d6aabcb7ce70 container test-container: <nil>
STEP: delete the pod
Apr 27 16:43:04.612: INFO: Waiting for pod client-containers-9e5a144c-11f4-4699-a55d-d6aabcb7ce70 to disappear
Apr 27 16:43:04.701: INFO: Pod client-containers-9e5a144c-11f4-4699-a55d-d6aabcb7ce70 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:43:04.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8447" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":277,"completed":127,"skipped":2155,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:43:04.883: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7921
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 27 16:43:05.618: INFO: Waiting up to 5m0s for pod "pod-4993fd8a-58cf-4436-b830-6684ec331685" in namespace "emptydir-7921" to be "Succeeded or Failed"
Apr 27 16:43:05.708: INFO: Pod "pod-4993fd8a-58cf-4436-b830-6684ec331685": Phase="Pending", Reason="", readiness=false. Elapsed: 89.785889ms
Apr 27 16:43:07.798: INFO: Pod "pod-4993fd8a-58cf-4436-b830-6684ec331685": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180146862s
STEP: Saw pod success
Apr 27 16:43:07.798: INFO: Pod "pod-4993fd8a-58cf-4436-b830-6684ec331685" satisfied condition "Succeeded or Failed"
Apr 27 16:43:07.888: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-4993fd8a-58cf-4436-b830-6684ec331685 container test-container: <nil>
STEP: delete the pod
Apr 27 16:43:08.079: INFO: Waiting for pod pod-4993fd8a-58cf-4436-b830-6684ec331685 to disappear
Apr 27 16:43:08.169: INFO: Pod pod-4993fd8a-58cf-4436-b830-6684ec331685 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:43:08.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7921" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":128,"skipped":2157,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:43:08.355: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2740
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 27 16:43:09.086: INFO: Waiting up to 5m0s for pod "pod-adeb373b-57a5-4d6b-b757-7adc849c1be3" in namespace "emptydir-2740" to be "Succeeded or Failed"
Apr 27 16:43:09.175: INFO: Pod "pod-adeb373b-57a5-4d6b-b757-7adc849c1be3": Phase="Pending", Reason="", readiness=false. Elapsed: 89.671535ms
Apr 27 16:43:11.266: INFO: Pod "pod-adeb373b-57a5-4d6b-b757-7adc849c1be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180065484s
STEP: Saw pod success
Apr 27 16:43:11.266: INFO: Pod "pod-adeb373b-57a5-4d6b-b757-7adc849c1be3" satisfied condition "Succeeded or Failed"
Apr 27 16:43:11.356: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-adeb373b-57a5-4d6b-b757-7adc849c1be3 container test-container: <nil>
STEP: delete the pod
Apr 27 16:43:11.550: INFO: Waiting for pod pod-adeb373b-57a5-4d6b-b757-7adc849c1be3 to disappear
Apr 27 16:43:11.640: INFO: Pod pod-adeb373b-57a5-4d6b-b757-7adc849c1be3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:43:11.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2740" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":129,"skipped":2180,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:43:11.822: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6744
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:43:13.422: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602593, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602593, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602593, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602593, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:43:16.607: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:43:18.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6744" for this suite.
STEP: Destroying namespace "webhook-6744-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":277,"completed":130,"skipped":2183,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:43:19.400: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4529
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4529.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-4529.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4529.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-4529.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4529.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4529.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-4529.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4529.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-4529.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4529.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 16:43:22.671: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:22.763: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:22.856: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:22.949: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:23.229: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:23.322: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:23.415: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:23.507: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:23.696: INFO: Lookups using dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4529.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4529.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local jessie_udp@dns-test-service-2.dns-4529.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4529.svc.cluster.local]

Apr 27 16:43:28.788: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:28.881: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:28.973: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:29.066: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:29.347: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:29.439: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:29.532: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:29.624: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:29.812: INFO: Lookups using dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4529.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4529.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local jessie_udp@dns-test-service-2.dns-4529.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4529.svc.cluster.local]

Apr 27 16:43:33.788: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:33.881: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:33.973: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:34.065: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:34.347: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:34.439: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:34.532: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:34.624: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:34.813: INFO: Lookups using dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4529.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4529.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local jessie_udp@dns-test-service-2.dns-4529.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4529.svc.cluster.local]

Apr 27 16:43:38.789: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:38.881: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:38.975: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:39.067: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:39.348: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:39.441: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:39.533: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:39.625: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:39.814: INFO: Lookups using dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4529.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4529.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local jessie_udp@dns-test-service-2.dns-4529.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4529.svc.cluster.local]

Apr 27 16:43:43.789: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:43.881: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:43.973: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:44.066: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:44.349: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:44.442: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:44.535: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:44.638: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:44.827: INFO: Lookups using dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4529.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4529.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local jessie_udp@dns-test-service-2.dns-4529.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4529.svc.cluster.local]

Apr 27 16:43:48.789: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:48.881: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:48.974: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:49.066: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:49.347: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:49.439: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:49.613: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:49.705: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4529.svc.cluster.local from pod dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd: the server could not find the requested resource (get pods dns-test-395283b5-972e-4f01-ab74-6821dcff69bd)
Apr 27 16:43:49.894: INFO: Lookups using dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4529.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4529.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4529.svc.cluster.local jessie_udp@dns-test-service-2.dns-4529.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4529.svc.cluster.local]

Apr 27 16:43:54.827: INFO: DNS probes using dns-4529/dns-test-395283b5-972e-4f01-ab74-6821dcff69bd succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:43:55.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4529" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":277,"completed":131,"skipped":2198,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:43:55.200: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6279
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Apr 27 16:43:55.839: INFO: PodSpec: initContainers in spec.initContainers
Apr 27 16:44:39.886: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-c0bd528d-1b09-40af-9403-142ed84df820", GenerateName:"", Namespace:"init-container-6279", SelfLink:"/api/v1/namespaces/init-container-6279/pods/pod-init-c0bd528d-1b09-40af-9403-142ed84df820", UID:"6c689c5e-46bc-48ca-9d9b-45cf77c167de", ResourceVersion:"22604", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63723602635, loc:(*time.Location)(0x7b501e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"839645004"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.64.1.199/32", "cni.projectcalico.org/podIPs":"100.64.1.199/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc004293560), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042935a0)}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc0042935c0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0042935e0)}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc004293600), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004293620)}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-fgdhn", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0077c49c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fgdhn", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fgdhn", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.2", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fgdhn", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0045ffef8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-250-10-186.ec2.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0032ff490), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0045fffe0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004562000)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc004562008), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00456200c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602635, loc:(*time.Location)(0x7b501e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602635, loc:(*time.Location)(0x7b501e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602635, loc:(*time.Location)(0x7b501e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602635, loc:(*time.Location)(0x7b501e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.10.186", PodIP:"100.64.1.199", PodIPs:[]v1.PodIP{v1.PodIP{IP:"100.64.1.199"}}, StartTime:(*v1.Time)(0xc004293640), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0032ff570)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0032ff5e0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://34447826528cfb27bd70213dc4d0e6435740e66ec6f844a4ff7cd34305528aee", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004293680), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004293660), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.2", ImageID:"", ContainerID:"", Started:(*bool)(0xc00456208f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:39.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6279" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":277,"completed":132,"skipped":2220,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:40.067: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6520
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating cluster-info
Apr 27 16:44:40.705: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config cluster-info'
Apr 27 16:44:41.049: INFO: stderr: ""
Apr 27 16:44:41.049: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:41.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6520" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]","total":277,"completed":133,"skipped":2224,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:41.231: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-75
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-17507bc6-f402-487e-b66f-6bc79a9da96b
STEP: Creating a pod to test consume configMaps
Apr 27 16:44:42.053: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e32d6af2-c4cd-43ed-8fc4-a68385ab8026" in namespace "projected-75" to be "Succeeded or Failed"
Apr 27 16:44:42.143: INFO: Pod "pod-projected-configmaps-e32d6af2-c4cd-43ed-8fc4-a68385ab8026": Phase="Pending", Reason="", readiness=false. Elapsed: 90.071847ms
Apr 27 16:44:44.233: INFO: Pod "pod-projected-configmaps-e32d6af2-c4cd-43ed-8fc4-a68385ab8026": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180181631s
STEP: Saw pod success
Apr 27 16:44:44.233: INFO: Pod "pod-projected-configmaps-e32d6af2-c4cd-43ed-8fc4-a68385ab8026" satisfied condition "Succeeded or Failed"
Apr 27 16:44:44.322: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-projected-configmaps-e32d6af2-c4cd-43ed-8fc4-a68385ab8026 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:44:44.604: INFO: Waiting for pod pod-projected-configmaps-e32d6af2-c4cd-43ed-8fc4-a68385ab8026 to disappear
Apr 27 16:44:44.693: INFO: Pod pod-projected-configmaps-e32d6af2-c4cd-43ed-8fc4-a68385ab8026 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:44.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-75" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":134,"skipped":2235,"failed":0}
SSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:44.875: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-328
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:44:45.513: INFO: Creating ReplicaSet my-hostname-basic-b956cd2c-927d-493f-a4b2-04c0d7024516
Apr 27 16:44:45.693: INFO: Pod name my-hostname-basic-b956cd2c-927d-493f-a4b2-04c0d7024516: Found 1 pods out of 1
Apr 27 16:44:45.693: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-b956cd2c-927d-493f-a4b2-04c0d7024516" is running
Apr 27 16:44:47.873: INFO: Pod "my-hostname-basic-b956cd2c-927d-493f-a4b2-04c0d7024516-zwm2c" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 16:44:45 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 16:44:45 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-b956cd2c-927d-493f-a4b2-04c0d7024516]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 16:44:45 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-b956cd2c-927d-493f-a4b2-04c0d7024516]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 16:44:45 +0000 UTC Reason: Message:}])
Apr 27 16:44:47.874: INFO: Trying to dial the pod
Apr 27 16:44:53.235: INFO: Controller my-hostname-basic-b956cd2c-927d-493f-a4b2-04c0d7024516: Got expected result from replica 1 [my-hostname-basic-b956cd2c-927d-493f-a4b2-04c0d7024516-zwm2c]: "my-hostname-basic-b956cd2c-927d-493f-a4b2-04c0d7024516-zwm2c", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:53.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-328" for this suite.
•{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":277,"completed":135,"skipped":2238,"failed":0}
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:53.418: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5456
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:44:54.149: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cda26310-7a7b-4232-ba28-6b5e2548093d" in namespace "projected-5456" to be "Succeeded or Failed"
Apr 27 16:44:54.239: INFO: Pod "downwardapi-volume-cda26310-7a7b-4232-ba28-6b5e2548093d": Phase="Pending", Reason="", readiness=false. Elapsed: 89.697381ms
Apr 27 16:44:56.328: INFO: Pod "downwardapi-volume-cda26310-7a7b-4232-ba28-6b5e2548093d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179575459s
STEP: Saw pod success
Apr 27 16:44:56.329: INFO: Pod "downwardapi-volume-cda26310-7a7b-4232-ba28-6b5e2548093d" satisfied condition "Succeeded or Failed"
Apr 27 16:44:56.418: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod downwardapi-volume-cda26310-7a7b-4232-ba28-6b5e2548093d container client-container: <nil>
STEP: delete the pod
Apr 27 16:44:56.608: INFO: Waiting for pod downwardapi-volume-cda26310-7a7b-4232-ba28-6b5e2548093d to disappear
Apr 27 16:44:56.698: INFO: Pod downwardapi-volume-cda26310-7a7b-4232-ba28-6b5e2548093d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:56.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5456" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":136,"skipped":2241,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:56.880: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8621
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-c725a36e-550f-415b-899d-a8aeaa20fac3
STEP: Creating secret with name s-test-opt-upd-292fbe2e-da62-4c08-a5c3-7bc455e61538
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-c725a36e-550f-415b-899d-a8aeaa20fac3
STEP: Updating secret s-test-opt-upd-292fbe2e-da62-4c08-a5c3-7bc455e61538
STEP: Creating secret with name s-test-opt-create-3af7be9e-eda1-40d8-b81b-bdbfc7dc8f52
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:22.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8621" for this suite.
•{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":137,"skipped":2250,"failed":0}
S
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:22.991: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1605
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1605.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1605.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 16:46:26.838: INFO: DNS probes using dns-1605/dns-test-a443cefe-bef0-412a-b1bb-31b31c489d18 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:26.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1605" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":277,"completed":138,"skipped":2251,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:27.114: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6526
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:46:27.753: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config version'
Apr 27 16:46:28.097: INFO: stderr: ""
Apr 27 16:46:28.097: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.2\", GitCommit:\"52c56ce7a8272c798dbc29846288d7cd9fbae032\", GitTreeState:\"clean\", BuildDate:\"2020-04-16T11:56:40Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.2\", GitCommit:\"52c56ce7a8272c798dbc29846288d7cd9fbae032\", GitTreeState:\"clean\", BuildDate:\"2020-04-16T11:48:36Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:28.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6526" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":277,"completed":139,"skipped":2269,"failed":0}

------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:28.277: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1538
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-df7f9f74-6b27-4f7f-bfaf-b641f448eccd
STEP: Creating configMap with name cm-test-opt-upd-46bb8bab-19fe-4d0c-b9e3-6efcdfe6fafd
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-df7f9f74-6b27-4f7f-bfaf-b641f448eccd
STEP: Updating configmap cm-test-opt-upd-46bb8bab-19fe-4d0c-b9e3-6efcdfe6fafd
STEP: Creating configMap with name cm-test-opt-create-dfed23b9-50d9-4d79-9988-0cd93b7ae02f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:47:47.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1538" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":140,"skipped":2269,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:47:48.128: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7023
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 27 16:47:48.861: INFO: Waiting up to 5m0s for pod "pod-965dce6a-eac2-4845-96a8-e064a3dbdcd5" in namespace "emptydir-7023" to be "Succeeded or Failed"
Apr 27 16:47:48.951: INFO: Pod "pod-965dce6a-eac2-4845-96a8-e064a3dbdcd5": Phase="Pending", Reason="", readiness=false. Elapsed: 90.046655ms
Apr 27 16:47:51.042: INFO: Pod "pod-965dce6a-eac2-4845-96a8-e064a3dbdcd5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180440584s
STEP: Saw pod success
Apr 27 16:47:51.042: INFO: Pod "pod-965dce6a-eac2-4845-96a8-e064a3dbdcd5" satisfied condition "Succeeded or Failed"
Apr 27 16:47:51.132: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-965dce6a-eac2-4845-96a8-e064a3dbdcd5 container test-container: <nil>
STEP: delete the pod
Apr 27 16:47:51.322: INFO: Waiting for pod pod-965dce6a-eac2-4845-96a8-e064a3dbdcd5 to disappear
Apr 27 16:47:51.413: INFO: Pod pod-965dce6a-eac2-4845-96a8-e064a3dbdcd5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:47:51.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7023" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":141,"skipped":2280,"failed":0}
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:47:51.595: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2013
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-dcad261b-32de-484d-95d2-6dbdea87e703
STEP: Creating a pod to test consume configMaps
Apr 27 16:47:52.418: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a2264974-cb5e-4ecf-88a9-cb6642a13033" in namespace "projected-2013" to be "Succeeded or Failed"
Apr 27 16:47:52.507: INFO: Pod "pod-projected-configmaps-a2264974-cb5e-4ecf-88a9-cb6642a13033": Phase="Pending", Reason="", readiness=false. Elapsed: 89.792585ms
Apr 27 16:47:54.598: INFO: Pod "pod-projected-configmaps-a2264974-cb5e-4ecf-88a9-cb6642a13033": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180157547s
STEP: Saw pod success
Apr 27 16:47:54.598: INFO: Pod "pod-projected-configmaps-a2264974-cb5e-4ecf-88a9-cb6642a13033" satisfied condition "Succeeded or Failed"
Apr 27 16:47:54.688: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-projected-configmaps-a2264974-cb5e-4ecf-88a9-cb6642a13033 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:47:54.878: INFO: Waiting for pod pod-projected-configmaps-a2264974-cb5e-4ecf-88a9-cb6642a13033 to disappear
Apr 27 16:47:54.968: INFO: Pod pod-projected-configmaps-a2264974-cb5e-4ecf-88a9-cb6642a13033 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:47:54.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2013" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":277,"completed":142,"skipped":2283,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:47:55.150: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5586
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Apr 27 16:47:55.881: INFO: Waiting up to 5m0s for pod "downward-api-013bc73b-688d-451d-8fe7-c77064a21eb3" in namespace "downward-api-5586" to be "Succeeded or Failed"
Apr 27 16:47:55.971: INFO: Pod "downward-api-013bc73b-688d-451d-8fe7-c77064a21eb3": Phase="Pending", Reason="", readiness=false. Elapsed: 89.829905ms
Apr 27 16:47:58.061: INFO: Pod "downward-api-013bc73b-688d-451d-8fe7-c77064a21eb3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.1802822s
STEP: Saw pod success
Apr 27 16:47:58.061: INFO: Pod "downward-api-013bc73b-688d-451d-8fe7-c77064a21eb3" satisfied condition "Succeeded or Failed"
Apr 27 16:47:58.151: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod downward-api-013bc73b-688d-451d-8fe7-c77064a21eb3 container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:47:58.367: INFO: Waiting for pod downward-api-013bc73b-688d-451d-8fe7-c77064a21eb3 to disappear
Apr 27 16:47:58.456: INFO: Pod downward-api-013bc73b-688d-451d-8fe7-c77064a21eb3 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:47:58.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5586" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":277,"completed":143,"skipped":2321,"failed":0}
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:47:58.638: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4662
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-4662
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating statefulset ss in namespace statefulset-4662
Apr 27 16:47:59.549: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Apr 27 16:48:09.639: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 16:48:10.089: INFO: Deleting all statefulset in ns statefulset-4662
Apr 27 16:48:10.179: INFO: Scaling statefulset ss to 0
Apr 27 16:48:20.543: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:48:20.633: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:48:20.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4662" for this suite.
•{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":277,"completed":144,"skipped":2324,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:48:21.086: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8250
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:48:39.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8250" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":277,"completed":145,"skipped":2339,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:48:39.182: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7694
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:48:40.290: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"d020c1db-f75a-433f-9705-78953864f3e8", Controller:(*bool)(0xc0030259fa), BlockOwnerDeletion:(*bool)(0xc0030259fb)}}
Apr 27 16:48:40.382: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"65cbfd54-1ab8-4de0-bfc8-173d25166431", Controller:(*bool)(0xc00469aa26), BlockOwnerDeletion:(*bool)(0xc00469aa27)}}
Apr 27 16:48:40.474: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"af906dab-30bc-498a-a075-296e7e3b1939", Controller:(*bool)(0xc00466d81e), BlockOwnerDeletion:(*bool)(0xc00466d81f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:48:45.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7694" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":277,"completed":146,"skipped":2374,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:48:45.838: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1652
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-1652/configmap-test-fdadafbd-c872-4a8a-a608-70bb9b709ee0
STEP: Creating a pod to test consume configMaps
Apr 27 16:48:46.659: INFO: Waiting up to 5m0s for pod "pod-configmaps-0fbaddec-b9d6-4409-ae83-a31f9af6ef69" in namespace "configmap-1652" to be "Succeeded or Failed"
Apr 27 16:48:46.749: INFO: Pod "pod-configmaps-0fbaddec-b9d6-4409-ae83-a31f9af6ef69": Phase="Pending", Reason="", readiness=false. Elapsed: 90.079991ms
Apr 27 16:48:48.839: INFO: Pod "pod-configmaps-0fbaddec-b9d6-4409-ae83-a31f9af6ef69": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180360335s
STEP: Saw pod success
Apr 27 16:48:48.840: INFO: Pod "pod-configmaps-0fbaddec-b9d6-4409-ae83-a31f9af6ef69" satisfied condition "Succeeded or Failed"
Apr 27 16:48:48.930: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-configmaps-0fbaddec-b9d6-4409-ae83-a31f9af6ef69 container env-test: <nil>
STEP: delete the pod
Apr 27 16:48:49.118: INFO: Waiting for pod pod-configmaps-0fbaddec-b9d6-4409-ae83-a31f9af6ef69 to disappear
Apr 27 16:48:49.208: INFO: Pod pod-configmaps-0fbaddec-b9d6-4409-ae83-a31f9af6ef69 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:48:49.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1652" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":277,"completed":147,"skipped":2420,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:48:49.390: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9893
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-9893
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Apr 27 16:48:50.299: INFO: Found 1 stateful pods, waiting for 3
Apr 27 16:49:00.390: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:49:00.390: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:49:00.390: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Apr 27 16:49:00.852: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Apr 27 16:49:01.224: INFO: Updating stateful set ss2
Apr 27 16:49:01.404: INFO: Waiting for Pod statefulset-9893/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 27 16:49:11.585: INFO: Waiting for Pod statefulset-9893/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Apr 27 16:49:21.862: INFO: Found 2 stateful pods, waiting for 3
Apr 27 16:49:31.954: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:49:31.954: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:49:31.954: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Apr 27 16:49:32.324: INFO: Updating stateful set ss2
Apr 27 16:49:32.504: INFO: Waiting for Pod statefulset-9893/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 27 16:49:42.875: INFO: Updating stateful set ss2
Apr 27 16:49:43.056: INFO: Waiting for StatefulSet statefulset-9893/ss2 to complete update
Apr 27 16:49:43.056: INFO: Waiting for Pod statefulset-9893/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 27 16:49:53.236: INFO: Waiting for StatefulSet statefulset-9893/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 16:50:03.237: INFO: Deleting all statefulset in ns statefulset-9893
Apr 27 16:50:03.328: INFO: Scaling statefulset ss2 to 0
Apr 27 16:50:13.690: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:50:13.780: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:50:14.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9893" for this suite.
•{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":277,"completed":148,"skipped":2453,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:50:14.233: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1061
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:50:37.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1061" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":277,"completed":149,"skipped":2474,"failed":0}
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:50:37.947: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3662
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-3b89b63c-ef15-471f-a602-5483d1fda502
STEP: Creating a pod to test consume configMaps
Apr 27 16:50:38.768: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-627fd0da-cce5-49ab-95f7-c1e19091fafe" in namespace "projected-3662" to be "Succeeded or Failed"
Apr 27 16:50:38.858: INFO: Pod "pod-projected-configmaps-627fd0da-cce5-49ab-95f7-c1e19091fafe": Phase="Pending", Reason="", readiness=false. Elapsed: 89.78572ms
Apr 27 16:50:40.948: INFO: Pod "pod-projected-configmaps-627fd0da-cce5-49ab-95f7-c1e19091fafe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180049505s
STEP: Saw pod success
Apr 27 16:50:40.948: INFO: Pod "pod-projected-configmaps-627fd0da-cce5-49ab-95f7-c1e19091fafe" satisfied condition "Succeeded or Failed"
Apr 27 16:50:41.038: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-projected-configmaps-627fd0da-cce5-49ab-95f7-c1e19091fafe container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:50:41.320: INFO: Waiting for pod pod-projected-configmaps-627fd0da-cce5-49ab-95f7-c1e19091fafe to disappear
Apr 27 16:50:41.410: INFO: Pod pod-projected-configmaps-627fd0da-cce5-49ab-95f7-c1e19091fafe no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:50:41.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3662" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":150,"skipped":2475,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:50:41.592: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5352
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Apr 27 16:50:42.231: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-5352'
Apr 27 16:50:43.106: INFO: stderr: ""
Apr 27 16:50:43.106: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 27 16:50:43.106: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5352'
Apr 27 16:50:43.447: INFO: stderr: ""
Apr 27 16:50:43.448: INFO: stdout: "update-demo-nautilus-l87x9 update-demo-nautilus-stx64 "
Apr 27 16:50:43.448: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-l87x9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5352'
Apr 27 16:50:43.785: INFO: stderr: ""
Apr 27 16:50:43.785: INFO: stdout: ""
Apr 27 16:50:43.785: INFO: update-demo-nautilus-l87x9 is created but not running
Apr 27 16:50:48.785: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5352'
Apr 27 16:50:49.127: INFO: stderr: ""
Apr 27 16:50:49.127: INFO: stdout: "update-demo-nautilus-l87x9 update-demo-nautilus-stx64 "
Apr 27 16:50:49.127: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-l87x9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5352'
Apr 27 16:50:49.460: INFO: stderr: ""
Apr 27 16:50:49.461: INFO: stdout: "true"
Apr 27 16:50:49.461: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-l87x9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5352'
Apr 27 16:50:49.805: INFO: stderr: ""
Apr 27 16:50:49.805: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:50:49.805: INFO: validating pod update-demo-nautilus-l87x9
Apr 27 16:50:49.987: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:50:49.987: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:50:49.987: INFO: update-demo-nautilus-l87x9 is verified up and running
Apr 27 16:50:49.987: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-stx64 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5352'
Apr 27 16:50:50.330: INFO: stderr: ""
Apr 27 16:50:50.330: INFO: stdout: "true"
Apr 27 16:50:50.330: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-stx64 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5352'
Apr 27 16:50:50.665: INFO: stderr: ""
Apr 27 16:50:50.665: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:50:50.665: INFO: validating pod update-demo-nautilus-stx64
Apr 27 16:50:50.847: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:50:50.847: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:50:50.847: INFO: update-demo-nautilus-stx64 is verified up and running
STEP: scaling down the replication controller
Apr 27 16:50:50.849: INFO: scanned /root for discovery docs: <nil>
Apr 27 16:50:50.849: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-5352'
Apr 27 16:50:51.369: INFO: stderr: ""
Apr 27 16:50:51.369: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 27 16:50:51.370: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5352'
Apr 27 16:50:51.712: INFO: stderr: ""
Apr 27 16:50:51.712: INFO: stdout: "update-demo-nautilus-l87x9 update-demo-nautilus-stx64 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr 27 16:50:56.712: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5352'
Apr 27 16:50:57.056: INFO: stderr: ""
Apr 27 16:50:57.057: INFO: stdout: "update-demo-nautilus-stx64 "
Apr 27 16:50:57.057: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-stx64 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5352'
Apr 27 16:50:57.401: INFO: stderr: ""
Apr 27 16:50:57.401: INFO: stdout: "true"
Apr 27 16:50:57.401: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-stx64 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5352'
Apr 27 16:50:57.732: INFO: stderr: ""
Apr 27 16:50:57.732: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:50:57.732: INFO: validating pod update-demo-nautilus-stx64
Apr 27 16:50:57.827: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:50:57.827: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:50:57.827: INFO: update-demo-nautilus-stx64 is verified up and running
STEP: scaling up the replication controller
Apr 27 16:50:57.830: INFO: scanned /root for discovery docs: <nil>
Apr 27 16:50:57.830: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-5352'
Apr 27 16:50:58.348: INFO: stderr: ""
Apr 27 16:50:58.348: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 27 16:50:58.348: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5352'
Apr 27 16:50:58.688: INFO: stderr: ""
Apr 27 16:50:58.688: INFO: stdout: "update-demo-nautilus-stx64 update-demo-nautilus-vhqt4 "
Apr 27 16:50:58.688: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-stx64 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5352'
Apr 27 16:50:59.020: INFO: stderr: ""
Apr 27 16:50:59.021: INFO: stdout: "true"
Apr 27 16:50:59.021: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-stx64 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5352'
Apr 27 16:50:59.354: INFO: stderr: ""
Apr 27 16:50:59.354: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:50:59.354: INFO: validating pod update-demo-nautilus-stx64
Apr 27 16:50:59.448: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:50:59.448: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:50:59.448: INFO: update-demo-nautilus-stx64 is verified up and running
Apr 27 16:50:59.448: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-vhqt4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5352'
Apr 27 16:50:59.789: INFO: stderr: ""
Apr 27 16:50:59.789: INFO: stdout: ""
Apr 27 16:50:59.789: INFO: update-demo-nautilus-vhqt4 is created but not running
Apr 27 16:51:04.789: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5352'
Apr 27 16:51:05.128: INFO: stderr: ""
Apr 27 16:51:05.128: INFO: stdout: "update-demo-nautilus-stx64 update-demo-nautilus-vhqt4 "
Apr 27 16:51:05.128: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-stx64 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5352'
Apr 27 16:51:05.470: INFO: stderr: ""
Apr 27 16:51:05.470: INFO: stdout: "true"
Apr 27 16:51:05.470: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-stx64 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5352'
Apr 27 16:51:05.814: INFO: stderr: ""
Apr 27 16:51:05.814: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:51:05.814: INFO: validating pod update-demo-nautilus-stx64
Apr 27 16:51:05.912: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:51:05.912: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:51:05.912: INFO: update-demo-nautilus-stx64 is verified up and running
Apr 27 16:51:05.912: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-vhqt4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5352'
Apr 27 16:51:11.256: INFO: stderr: ""
Apr 27 16:51:11.256: INFO: stdout: "true"
Apr 27 16:51:11.256: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-vhqt4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5352'
Apr 27 16:51:11.592: INFO: stderr: ""
Apr 27 16:51:11.592: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:51:11.592: INFO: validating pod update-demo-nautilus-vhqt4
Apr 27 16:51:11.807: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:51:11.807: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:51:11.807: INFO: update-demo-nautilus-vhqt4 is verified up and running
STEP: using delete to clean up resources
Apr 27 16:51:11.807: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-5352'
Apr 27 16:51:12.228: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 16:51:12.228: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 27 16:51:12.228: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5352'
Apr 27 16:51:12.651: INFO: stderr: "No resources found in kubectl-5352 namespace.\n"
Apr 27 16:51:12.651: INFO: stdout: ""
Apr 27 16:51:12.651: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-5352 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 27 16:51:12.985: INFO: stderr: ""
Apr 27 16:51:12.985: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:51:12.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5352" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":277,"completed":151,"skipped":2496,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:51:13.169: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1969
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-downwardapi-sjz7
STEP: Creating a pod to test atomic-volume-subpath
Apr 27 16:51:14.081: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-sjz7" in namespace "subpath-1969" to be "Succeeded or Failed"
Apr 27 16:51:14.171: INFO: Pod "pod-subpath-test-downwardapi-sjz7": Phase="Pending", Reason="", readiness=false. Elapsed: 89.97677ms
Apr 27 16:51:16.262: INFO: Pod "pod-subpath-test-downwardapi-sjz7": Phase="Running", Reason="", readiness=true. Elapsed: 2.180520439s
Apr 27 16:51:18.352: INFO: Pod "pod-subpath-test-downwardapi-sjz7": Phase="Running", Reason="", readiness=true. Elapsed: 4.270681519s
Apr 27 16:51:20.442: INFO: Pod "pod-subpath-test-downwardapi-sjz7": Phase="Running", Reason="", readiness=true. Elapsed: 6.36103665s
Apr 27 16:51:22.533: INFO: Pod "pod-subpath-test-downwardapi-sjz7": Phase="Running", Reason="", readiness=true. Elapsed: 8.451494639s
Apr 27 16:51:24.623: INFO: Pod "pod-subpath-test-downwardapi-sjz7": Phase="Running", Reason="", readiness=true. Elapsed: 10.542091849s
Apr 27 16:51:26.714: INFO: Pod "pod-subpath-test-downwardapi-sjz7": Phase="Running", Reason="", readiness=true. Elapsed: 12.632812225s
Apr 27 16:51:28.805: INFO: Pod "pod-subpath-test-downwardapi-sjz7": Phase="Running", Reason="", readiness=true. Elapsed: 14.723360093s
Apr 27 16:51:30.895: INFO: Pod "pod-subpath-test-downwardapi-sjz7": Phase="Running", Reason="", readiness=true. Elapsed: 16.813742173s
Apr 27 16:51:32.986: INFO: Pod "pod-subpath-test-downwardapi-sjz7": Phase="Running", Reason="", readiness=true. Elapsed: 18.904406645s
Apr 27 16:51:35.076: INFO: Pod "pod-subpath-test-downwardapi-sjz7": Phase="Running", Reason="", readiness=true. Elapsed: 20.994835314s
Apr 27 16:51:37.167: INFO: Pod "pod-subpath-test-downwardapi-sjz7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 23.085213973s
STEP: Saw pod success
Apr 27 16:51:37.167: INFO: Pod "pod-subpath-test-downwardapi-sjz7" satisfied condition "Succeeded or Failed"
Apr 27 16:51:37.257: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-subpath-test-downwardapi-sjz7 container test-container-subpath-downwardapi-sjz7: <nil>
STEP: delete the pod
Apr 27 16:51:37.449: INFO: Waiting for pod pod-subpath-test-downwardapi-sjz7 to disappear
Apr 27 16:51:37.539: INFO: Pod pod-subpath-test-downwardapi-sjz7 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-sjz7
Apr 27 16:51:37.539: INFO: Deleting pod "pod-subpath-test-downwardapi-sjz7" in namespace "subpath-1969"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:51:37.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1969" for this suite.
•{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [LinuxOnly] [Conformance]","total":277,"completed":152,"skipped":2504,"failed":0}
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:51:37.811: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6957
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:51:45.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6957" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":277,"completed":153,"skipped":2508,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:51:45.903: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9855
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on node default medium
Apr 27 16:51:46.634: INFO: Waiting up to 5m0s for pod "pod-f46ee2a2-b407-4790-b387-f66733ad3eb4" in namespace "emptydir-9855" to be "Succeeded or Failed"
Apr 27 16:51:46.724: INFO: Pod "pod-f46ee2a2-b407-4790-b387-f66733ad3eb4": Phase="Pending", Reason="", readiness=false. Elapsed: 89.88605ms
Apr 27 16:51:48.814: INFO: Pod "pod-f46ee2a2-b407-4790-b387-f66733ad3eb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180595319s
STEP: Saw pod success
Apr 27 16:51:48.814: INFO: Pod "pod-f46ee2a2-b407-4790-b387-f66733ad3eb4" satisfied condition "Succeeded or Failed"
Apr 27 16:51:48.904: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-f46ee2a2-b407-4790-b387-f66733ad3eb4 container test-container: <nil>
STEP: delete the pod
Apr 27 16:51:49.095: INFO: Waiting for pod pod-f46ee2a2-b407-4790-b387-f66733ad3eb4 to disappear
Apr 27 16:51:49.185: INFO: Pod pod-f46ee2a2-b407-4790-b387-f66733ad3eb4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:51:49.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9855" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":154,"skipped":2561,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:51:49.367: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-7263
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:51:50.006: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating first CR 
Apr 27 16:51:50.751: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T16:51:50Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T16:51:50Z]] name:name1 resourceVersion:25433 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:428a7e1c-80bc-4e0c-a1e1-2047005e1bac] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Apr 27 16:52:00.843: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T16:52:00Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T16:52:00Z]] name:name2 resourceVersion:25496 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:174deac4-d259-41e1-8f99-65914738de67] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Apr 27 16:52:10.934: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T16:51:50Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T16:52:10Z]] name:name1 resourceVersion:25556 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:428a7e1c-80bc-4e0c-a1e1-2047005e1bac] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Apr 27 16:52:21.026: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T16:52:00Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T16:52:20Z]] name:name2 resourceVersion:25606 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:174deac4-d259-41e1-8f99-65914738de67] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Apr 27 16:52:31.119: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T16:51:50Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T16:52:10Z]] name:name1 resourceVersion:25651 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:428a7e1c-80bc-4e0c-a1e1-2047005e1bac] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Apr 27 16:52:41.211: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T16:52:00Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T16:52:20Z]] name:name2 resourceVersion:25695 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:174deac4-d259-41e1-8f99-65914738de67] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:52:51.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-7263" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":277,"completed":155,"skipped":2567,"failed":0}
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:52:51.575: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8518
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-988fb892-a9fc-4c3e-94a5-51a4742427bc in namespace container-probe-8518
Apr 27 16:52:54.571: INFO: Started pod busybox-988fb892-a9fc-4c3e-94a5-51a4742427bc in namespace container-probe-8518
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 16:52:54.661: INFO: Initial restart count of pod busybox-988fb892-a9fc-4c3e-94a5-51a4742427bc is 0
Apr 27 16:53:47.016: INFO: Restart count of pod container-probe-8518/busybox-988fb892-a9fc-4c3e-94a5-51a4742427bc is now 1 (52.354735058s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:47.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8518" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":277,"completed":156,"skipped":2571,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:47.291: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9482
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:53:47.930: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Apr 27 16:53:48.471: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:48.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9482" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":277,"completed":157,"skipped":2596,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:48.743: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9955
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 27 16:53:52.521: INFO: Successfully updated pod "pod-update-activedeadlineseconds-be3650f2-fa40-4d8c-a2b5-95c898e7f23b"
Apr 27 16:53:52.521: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-be3650f2-fa40-4d8c-a2b5-95c898e7f23b" in namespace "pods-9955" to be "terminated due to deadline exceeded"
Apr 27 16:53:52.611: INFO: Pod "pod-update-activedeadlineseconds-be3650f2-fa40-4d8c-a2b5-95c898e7f23b": Phase="Running", Reason="", readiness=true. Elapsed: 89.775801ms
Apr 27 16:53:54.701: INFO: Pod "pod-update-activedeadlineseconds-be3650f2-fa40-4d8c-a2b5-95c898e7f23b": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.179819158s
Apr 27 16:53:54.701: INFO: Pod "pod-update-activedeadlineseconds-be3650f2-fa40-4d8c-a2b5-95c898e7f23b" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:54.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9955" for this suite.
•{"msg":"PASSED [k8s.io] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":277,"completed":158,"skipped":2617,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:54.883: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3364
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod test-webserver-46594153-2a93-4f5c-82d1-a963b9474033 in namespace container-probe-3364
Apr 27 16:53:57.794: INFO: Started pod test-webserver-46594153-2a93-4f5c-82d1-a963b9474033 in namespace container-probe-3364
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 16:53:57.885: INFO: Initial restart count of pod test-webserver-46594153-2a93-4f5c-82d1-a963b9474033 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:57:58.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3364" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":277,"completed":159,"skipped":2669,"failed":0}

------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:57:58.577: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-4063
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:58:00.259: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603479, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603479, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603479, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603479, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:58:03.444: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:58:03.533: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:58:05.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-4063" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137
•{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":277,"completed":160,"skipped":2669,"failed":0}
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:58:06.435: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5491
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-5491
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 27 16:58:07.109: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 27 16:58:07.589: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:58:09.679: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:58:11.680: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:58:13.679: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:58:15.679: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:58:17.680: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:58:19.679: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:58:21.680: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:58:23.680: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:58:25.679: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr 27 16:58:25.859: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Apr 27 16:58:28.400: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.238:8080/dial?request=hostname&protocol=http&host=100.64.1.237&port=8080&tries=1'] Namespace:pod-network-test-5491 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:58:28.400: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:58:34.199: INFO: Waiting for responses: map[]
Apr 27 16:58:34.289: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.238:8080/dial?request=hostname&protocol=http&host=100.64.0.43&port=8080&tries=1'] Namespace:pod-network-test-5491 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:58:34.289: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:58:35.019: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:58:35.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5491" for this suite.
•{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":277,"completed":161,"skipped":2673,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:58:35.201: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1430
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-02dbb13a-ce70-4a28-be54-b80de75bd87a
STEP: Creating a pod to test consume secrets
Apr 27 16:58:36.022: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e2d314e1-1f3a-4ad9-882c-cda872d82972" in namespace "projected-1430" to be "Succeeded or Failed"
Apr 27 16:58:36.112: INFO: Pod "pod-projected-secrets-e2d314e1-1f3a-4ad9-882c-cda872d82972": Phase="Pending", Reason="", readiness=false. Elapsed: 89.872709ms
Apr 27 16:58:38.203: INFO: Pod "pod-projected-secrets-e2d314e1-1f3a-4ad9-882c-cda872d82972": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180301808s
STEP: Saw pod success
Apr 27 16:58:38.203: INFO: Pod "pod-projected-secrets-e2d314e1-1f3a-4ad9-882c-cda872d82972" satisfied condition "Succeeded or Failed"
Apr 27 16:58:38.293: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-projected-secrets-e2d314e1-1f3a-4ad9-882c-cda872d82972 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:58:38.580: INFO: Waiting for pod pod-projected-secrets-e2d314e1-1f3a-4ad9-882c-cda872d82972 to disappear
Apr 27 16:58:38.670: INFO: Pod pod-projected-secrets-e2d314e1-1f3a-4ad9-882c-cda872d82972 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:58:38.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1430" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":162,"skipped":2680,"failed":0}
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:58:38.852: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7864
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-8a86fe3d-be20-45dc-8493-5e72e541b032
STEP: Creating a pod to test consume configMaps
Apr 27 16:58:39.673: INFO: Waiting up to 5m0s for pod "pod-configmaps-1007a2ce-ecbc-4afa-b7d2-e5144301c24c" in namespace "configmap-7864" to be "Succeeded or Failed"
Apr 27 16:58:39.763: INFO: Pod "pod-configmaps-1007a2ce-ecbc-4afa-b7d2-e5144301c24c": Phase="Pending", Reason="", readiness=false. Elapsed: 89.442221ms
Apr 27 16:58:41.853: INFO: Pod "pod-configmaps-1007a2ce-ecbc-4afa-b7d2-e5144301c24c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179714874s
STEP: Saw pod success
Apr 27 16:58:41.853: INFO: Pod "pod-configmaps-1007a2ce-ecbc-4afa-b7d2-e5144301c24c" satisfied condition "Succeeded or Failed"
Apr 27 16:58:41.943: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-configmaps-1007a2ce-ecbc-4afa-b7d2-e5144301c24c container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:58:42.133: INFO: Waiting for pod pod-configmaps-1007a2ce-ecbc-4afa-b7d2-e5144301c24c to disappear
Apr 27 16:58:42.222: INFO: Pod pod-configmaps-1007a2ce-ecbc-4afa-b7d2-e5144301c24c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:58:42.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7864" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":277,"completed":163,"skipped":2681,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:58:42.405: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-3787
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:58:43.043: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:58:43.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3787" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":277,"completed":164,"skipped":2685,"failed":0}
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:58:43.909: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9717
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:58:48.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9717" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":277,"completed":165,"skipped":2690,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:58:49.040: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5229
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:58:49.859: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 27 16:58:52.040: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr 27 16:58:54.130: INFO: Creating deployment "test-rollover-deployment"
Apr 27 16:58:54.309: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr 27 16:58:54.399: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr 27 16:58:54.579: INFO: Ensure that both replica sets have 1 created replica
Apr 27 16:58:54.759: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr 27 16:58:54.940: INFO: Updating deployment test-rollover-deployment
Apr 27 16:58:54.940: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr 27 16:58:55.030: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr 27 16:58:55.210: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr 27 16:58:55.389: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 16:58:55.390: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603534, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603534, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603534, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603534, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:58:57.570: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 16:58:57.571: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603534, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603534, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603535, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603534, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:58:59.571: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 16:58:59.571: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603534, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603534, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603535, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603534, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:59:01.570: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 16:59:01.571: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603534, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603534, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603535, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603534, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:59:03.570: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 16:59:03.571: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603534, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603534, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603535, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603534, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:59:05.570: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 16:59:05.570: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603534, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603534, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603535, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603534, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:59:07.570: INFO: 
Apr 27 16:59:07.570: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Apr 27 16:59:07.840: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-5229 /apis/apps/v1/namespaces/deployment-5229/deployments/test-rollover-deployment a5d74bd0-0fbc-4bde-85e4-8c0701f19106 27892 2 2020-04-27 16:58:54 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-04-27 16:58:54 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 16:59:05 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005ebd548 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-04-27 16:58:54 +0000 UTC,LastTransitionTime:2020-04-27 16:58:54 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-84f7f6f64b" has successfully progressed.,LastUpdateTime:2020-04-27 16:59:05 +0000 UTC,LastTransitionTime:2020-04-27 16:58:54 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 27 16:59:07.932: INFO: New ReplicaSet "test-rollover-deployment-84f7f6f64b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-84f7f6f64b  deployment-5229 /apis/apps/v1/namespaces/deployment-5229/replicasets/test-rollover-deployment-84f7f6f64b bf5944c5-891f-408d-bb71-47b26edbd3be 27885 2 2020-04-27 16:58:54 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment a5d74bd0-0fbc-4bde-85e4-8c0701f19106 0xc004824617 0xc004824618}] []  [{kube-controller-manager Update apps/v1 2020-04-27 16:59:05 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 53 100 55 52 98 100 48 45 48 102 98 99 45 52 98 100 101 45 56 53 101 52 45 56 99 48 55 48 49 102 49 57 49 48 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 84f7f6f64b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0048246b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:59:07.932: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr 27 16:59:07.932: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-5229 /apis/apps/v1/namespaces/deployment-5229/replicasets/test-rollover-controller c88a82a1-4231-4133-bb40-8ae64997fd88 27891 2 2020-04-27 16:58:49 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment a5d74bd0-0fbc-4bde-85e4-8c0701f19106 0xc0048243d7 0xc0048243d8}] []  [{e2e.test Update apps/v1 2020-04-27 16:58:49 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 16:59:05 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 53 100 55 52 98 100 48 45 48 102 98 99 45 52 98 100 101 45 56 53 101 52 45 56 99 48 55 48 49 102 49 57 49 48 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004824478 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:59:07.932: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-5686c4cfd5  deployment-5229 /apis/apps/v1/namespaces/deployment-5229/replicasets/test-rollover-deployment-5686c4cfd5 1b218db1-0b0f-4a79-996c-313cce0b9e07 27819 2 2020-04-27 16:58:54 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment a5d74bd0-0fbc-4bde-85e4-8c0701f19106 0xc004824507 0xc004824508}] []  [{kube-controller-manager Update apps/v1 2020-04-27 16:58:54 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 53 100 55 52 98 100 48 45 48 102 98 99 45 52 98 100 101 45 56 53 101 52 45 56 99 48 55 48 49 102 49 57 49 48 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 114 101 100 105 115 45 115 108 97 118 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5686c4cfd5,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0048245a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:59:08.023: INFO: Pod "test-rollover-deployment-84f7f6f64b-r9zjg" is available:
&Pod{ObjectMeta:{test-rollover-deployment-84f7f6f64b-r9zjg test-rollover-deployment-84f7f6f64b- deployment-5229 /api/v1/namespaces/deployment-5229/pods/test-rollover-deployment-84f7f6f64b-r9zjg 537df857-860c-4867-a8b6-9629ee3bad84 27836 0 2020-04-27 16:58:54 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[cni.projectcalico.org/podIP:100.64.1.244/32 cni.projectcalico.org/podIPs:100.64.1.244/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rollover-deployment-84f7f6f64b bf5944c5-891f-408d-bb71-47b26edbd3be 0xc003024a17 0xc003024a18}] []  [{kube-controller-manager Update v1 2020-04-27 16:58:54 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 98 102 53 57 52 52 99 53 45 56 57 49 102 45 52 48 56 100 45 98 98 55 49 45 52 55 98 50 54 101 100 98 100 51 98 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:58:55 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:58:55 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 50 52 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-68ppr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-68ppr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-68ppr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:58:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:58:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:58:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:58:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:100.64.1.244,StartTime:2020-04-27 16:58:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:58:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://48ec587eec496995c0d93bc8ab39415effdedbfe9750dc730ceb9a4ce682e8e9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.244,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:59:08.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5229" for this suite.
•{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":277,"completed":166,"skipped":2766,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:59:08.205: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-9165
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test env composition
Apr 27 16:59:08.937: INFO: Waiting up to 5m0s for pod "var-expansion-762fb17e-7ce8-4908-b9f6-dc84da1d4b51" in namespace "var-expansion-9165" to be "Succeeded or Failed"
Apr 27 16:59:09.027: INFO: Pod "var-expansion-762fb17e-7ce8-4908-b9f6-dc84da1d4b51": Phase="Pending", Reason="", readiness=false. Elapsed: 89.715354ms
Apr 27 16:59:11.117: INFO: Pod "var-expansion-762fb17e-7ce8-4908-b9f6-dc84da1d4b51": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179906213s
STEP: Saw pod success
Apr 27 16:59:11.117: INFO: Pod "var-expansion-762fb17e-7ce8-4908-b9f6-dc84da1d4b51" satisfied condition "Succeeded or Failed"
Apr 27 16:59:11.207: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod var-expansion-762fb17e-7ce8-4908-b9f6-dc84da1d4b51 container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:59:11.397: INFO: Waiting for pod var-expansion-762fb17e-7ce8-4908-b9f6-dc84da1d4b51 to disappear
Apr 27 16:59:11.487: INFO: Pod var-expansion-762fb17e-7ce8-4908-b9f6-dc84da1d4b51 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:59:11.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9165" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":277,"completed":167,"skipped":2800,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:59:11.669: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-1014
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
STEP: reading a file in the container
Apr 27 16:59:15.349: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-1014 pod-service-account-37cb3058-c8ac-429a-9dcb-0bee65921e11 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Apr 27 16:59:16.971: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-1014 pod-service-account-37cb3058-c8ac-429a-9dcb-0bee65921e11 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Apr 27 16:59:18.052: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-1014 pod-service-account-37cb3058-c8ac-429a-9dcb-0bee65921e11 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:59:19.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1014" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":277,"completed":168,"skipped":2818,"failed":0}
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:59:19.410: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1250
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1418
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Apr 27 16:59:20.048: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-pod --restart=Never --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-1250'
Apr 27 16:59:20.391: INFO: stderr: ""
Apr 27 16:59:20.392: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1423
Apr 27 16:59:20.481: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pods e2e-test-httpd-pod --namespace=kubectl-1250'
Apr 27 16:59:23.162: INFO: stderr: ""
Apr 27 16:59:23.162: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:59:23.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1250" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":277,"completed":169,"skipped":2827,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:59:23.344: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4884
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:59:23.983: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:59:26.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4884" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":277,"completed":170,"skipped":2860,"failed":0}
SSSS
------------------------------
[k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:59:26.960: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-5763
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:345
Apr 27 16:59:27.599: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 27 17:00:28.151: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:00:28.241: INFO: Starting informer...
STEP: Starting pods...
Apr 27 17:00:28.513: INFO: Pod1 is running on ip-10-250-10-186.ec2.internal. Tainting Node
Apr 27 17:00:30.965: INFO: Pod2 is running on ip-10-250-10-186.ec2.internal. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Apr 27 17:00:42.654: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Apr 27 17:01:02.653: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:01:02.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-5763" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":277,"completed":171,"skipped":2864,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:01:03.111: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3847
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Apr 27 17:01:04.109: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3847 /api/v1/namespaces/watch-3847/configmaps/e2e-watch-test-configmap-a 8031a92b-ba41-4fe7-ab6e-15c63f06d844 28586 0 2020-04-27 17:01:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 17:01:04 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 17:01:04.109: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3847 /api/v1/namespaces/watch-3847/configmaps/e2e-watch-test-configmap-a 8031a92b-ba41-4fe7-ab6e-15c63f06d844 28586 0 2020-04-27 17:01:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 17:01:04 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Apr 27 17:01:14.293: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3847 /api/v1/namespaces/watch-3847/configmaps/e2e-watch-test-configmap-a 8031a92b-ba41-4fe7-ab6e-15c63f06d844 28653 0 2020-04-27 17:01:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 17:01:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 17:01:14.294: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3847 /api/v1/namespaces/watch-3847/configmaps/e2e-watch-test-configmap-a 8031a92b-ba41-4fe7-ab6e-15c63f06d844 28653 0 2020-04-27 17:01:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 17:01:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Apr 27 17:01:24.474: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3847 /api/v1/namespaces/watch-3847/configmaps/e2e-watch-test-configmap-a 8031a92b-ba41-4fe7-ab6e-15c63f06d844 28705 0 2020-04-27 17:01:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 17:01:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 17:01:24.474: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3847 /api/v1/namespaces/watch-3847/configmaps/e2e-watch-test-configmap-a 8031a92b-ba41-4fe7-ab6e-15c63f06d844 28705 0 2020-04-27 17:01:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 17:01:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Apr 27 17:01:34.566: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3847 /api/v1/namespaces/watch-3847/configmaps/e2e-watch-test-configmap-a 8031a92b-ba41-4fe7-ab6e-15c63f06d844 28750 0 2020-04-27 17:01:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 17:01:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 17:01:34.566: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3847 /api/v1/namespaces/watch-3847/configmaps/e2e-watch-test-configmap-a 8031a92b-ba41-4fe7-ab6e-15c63f06d844 28750 0 2020-04-27 17:01:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 17:01:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Apr 27 17:01:44.658: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3847 /api/v1/namespaces/watch-3847/configmaps/e2e-watch-test-configmap-b 76a69148-d164-4f29-b6c8-db9516ff1972 28794 0 2020-04-27 17:01:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-04-27 17:01:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 17:01:44.658: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3847 /api/v1/namespaces/watch-3847/configmaps/e2e-watch-test-configmap-b 76a69148-d164-4f29-b6c8-db9516ff1972 28794 0 2020-04-27 17:01:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-04-27 17:01:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Apr 27 17:01:54.750: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3847 /api/v1/namespaces/watch-3847/configmaps/e2e-watch-test-configmap-b 76a69148-d164-4f29-b6c8-db9516ff1972 28841 0 2020-04-27 17:01:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-04-27 17:01:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 17:01:54.750: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3847 /api/v1/namespaces/watch-3847/configmaps/e2e-watch-test-configmap-b 76a69148-d164-4f29-b6c8-db9516ff1972 28841 0 2020-04-27 17:01:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-04-27 17:01:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:02:04.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3847" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":277,"completed":172,"skipped":2882,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:02:04.934: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1642
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:02:05.668: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9c12e750-f609-4179-8094-9055814a4517" in namespace "downward-api-1642" to be "Succeeded or Failed"
Apr 27 17:02:05.758: INFO: Pod "downwardapi-volume-9c12e750-f609-4179-8094-9055814a4517": Phase="Pending", Reason="", readiness=false. Elapsed: 90.392672ms
Apr 27 17:02:07.849: INFO: Pod "downwardapi-volume-9c12e750-f609-4179-8094-9055814a4517": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.181103391s
STEP: Saw pod success
Apr 27 17:02:07.849: INFO: Pod "downwardapi-volume-9c12e750-f609-4179-8094-9055814a4517" satisfied condition "Succeeded or Failed"
Apr 27 17:02:07.939: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod downwardapi-volume-9c12e750-f609-4179-8094-9055814a4517 container client-container: <nil>
STEP: delete the pod
Apr 27 17:02:08.221: INFO: Waiting for pod downwardapi-volume-9c12e750-f609-4179-8094-9055814a4517 to disappear
Apr 27 17:02:08.311: INFO: Pod downwardapi-volume-9c12e750-f609-4179-8094-9055814a4517 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:02:08.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1642" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":277,"completed":173,"skipped":2901,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:02:08.495: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3743
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:02:09.134: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Apr 27 17:02:13.194: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3743 create -f -'
Apr 27 17:02:14.569: INFO: stderr: ""
Apr 27 17:02:14.569: INFO: stdout: "e2e-test-crd-publish-openapi-9052-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 27 17:02:14.569: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3743 delete e2e-test-crd-publish-openapi-9052-crds test-foo'
Apr 27 17:02:15.053: INFO: stderr: ""
Apr 27 17:02:15.054: INFO: stdout: "e2e-test-crd-publish-openapi-9052-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Apr 27 17:02:15.054: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3743 apply -f -'
Apr 27 17:02:16.128: INFO: stderr: ""
Apr 27 17:02:16.128: INFO: stdout: "e2e-test-crd-publish-openapi-9052-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 27 17:02:16.128: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3743 delete e2e-test-crd-publish-openapi-9052-crds test-foo'
Apr 27 17:02:16.566: INFO: stderr: ""
Apr 27 17:02:16.566: INFO: stdout: "e2e-test-crd-publish-openapi-9052-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Apr 27 17:02:16.566: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3743 create -f -'
Apr 27 17:02:16.999: INFO: rc: 1
Apr 27 17:02:16.999: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3743 apply -f -'
Apr 27 17:02:17.453: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Apr 27 17:02:17.453: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3743 create -f -'
Apr 27 17:02:18.119: INFO: rc: 1
Apr 27 17:02:18.119: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3743 apply -f -'
Apr 27 17:02:18.554: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Apr 27 17:02:18.554: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-9052-crds'
Apr 27 17:02:18.987: INFO: stderr: ""
Apr 27 17:02:18.987: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9052-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Apr 27 17:02:18.988: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-9052-crds.metadata'
Apr 27 17:02:19.433: INFO: stderr: ""
Apr 27 17:02:19.433: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9052-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Apr 27 17:02:19.433: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-9052-crds.spec'
Apr 27 17:02:19.947: INFO: stderr: ""
Apr 27 17:02:19.947: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9052-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Apr 27 17:02:19.947: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-9052-crds.spec.bars'
Apr 27 17:02:20.794: INFO: stderr: ""
Apr 27 17:02:20.794: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9052-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Apr 27 17:02:20.795: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-9052-crds.spec.bars2'
Apr 27 17:02:21.618: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:02:26.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3743" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":277,"completed":174,"skipped":2990,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:02:26.384: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-288
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:02:27.477: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Apr 27 17:02:27.750: INFO: Number of nodes with available pods: 0
Apr 27 17:02:27.750: INFO: Node ip-10-250-10-186.ec2.internal is running more than one daemon pod
Apr 27 17:02:28.932: INFO: Number of nodes with available pods: 1
Apr 27 17:02:28.932: INFO: Node ip-10-250-10-186.ec2.internal is running more than one daemon pod
Apr 27 17:02:29.935: INFO: Number of nodes with available pods: 2
Apr 27 17:02:29.935: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Apr 27 17:02:30.569: INFO: Wrong image for pod: daemon-set-2wtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:02:30.569: INFO: Wrong image for pod: daemon-set-6sccm. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:02:31.751: INFO: Wrong image for pod: daemon-set-2wtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:02:31.751: INFO: Wrong image for pod: daemon-set-6sccm. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:02:32.751: INFO: Wrong image for pod: daemon-set-2wtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:02:32.751: INFO: Pod daemon-set-2wtq6 is not available
Apr 27 17:02:32.751: INFO: Wrong image for pod: daemon-set-6sccm. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:02:33.751: INFO: Wrong image for pod: daemon-set-6sccm. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:02:33.751: INFO: Pod daemon-set-zgps4 is not available
Apr 27 17:02:34.751: INFO: Wrong image for pod: daemon-set-6sccm. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:02:35.751: INFO: Wrong image for pod: daemon-set-6sccm. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:02:35.751: INFO: Pod daemon-set-6sccm is not available
Apr 27 17:02:36.751: INFO: Pod daemon-set-2z5g7 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Apr 27 17:02:37.024: INFO: Number of nodes with available pods: 1
Apr 27 17:02:37.024: INFO: Node ip-10-250-8-65.ec2.internal is running more than one daemon pod
Apr 27 17:02:38.206: INFO: Number of nodes with available pods: 2
Apr 27 17:02:38.206: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-288, will wait for the garbage collector to delete the pods
Apr 27 17:02:38.938: INFO: Deleting DaemonSet.extensions daemon-set took: 91.230599ms
Apr 27 17:02:39.539: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.378091ms
Apr 27 17:02:52.829: INFO: Number of nodes with available pods: 0
Apr 27 17:02:52.829: INFO: Number of running nodes: 0, number of available pods: 0
Apr 27 17:02:52.919: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-288/daemonsets","resourceVersion":"29230"},"items":null}

Apr 27 17:02:53.009: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-288/pods","resourceVersion":"29230"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:02:53.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-288" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":277,"completed":175,"skipped":3003,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:02:53.464: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4483
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 27 17:02:54.198: INFO: Waiting up to 5m0s for pod "pod-4b8d4a8f-80da-4fb7-92a1-5ef7724c13e2" in namespace "emptydir-4483" to be "Succeeded or Failed"
Apr 27 17:02:54.288: INFO: Pod "pod-4b8d4a8f-80da-4fb7-92a1-5ef7724c13e2": Phase="Pending", Reason="", readiness=false. Elapsed: 89.85896ms
Apr 27 17:02:56.379: INFO: Pod "pod-4b8d4a8f-80da-4fb7-92a1-5ef7724c13e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180505197s
STEP: Saw pod success
Apr 27 17:02:56.379: INFO: Pod "pod-4b8d4a8f-80da-4fb7-92a1-5ef7724c13e2" satisfied condition "Succeeded or Failed"
Apr 27 17:02:56.469: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-4b8d4a8f-80da-4fb7-92a1-5ef7724c13e2 container test-container: <nil>
STEP: delete the pod
Apr 27 17:02:56.660: INFO: Waiting for pod pod-4b8d4a8f-80da-4fb7-92a1-5ef7724c13e2 to disappear
Apr 27 17:02:56.750: INFO: Pod pod-4b8d4a8f-80da-4fb7-92a1-5ef7724c13e2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:02:56.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4483" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":176,"skipped":3064,"failed":0}
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:02:56.933: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9436
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override command
Apr 27 17:02:57.667: INFO: Waiting up to 5m0s for pod "client-containers-fcd3d112-dfd5-4d96-862c-32f23583b6a9" in namespace "containers-9436" to be "Succeeded or Failed"
Apr 27 17:02:57.757: INFO: Pod "client-containers-fcd3d112-dfd5-4d96-862c-32f23583b6a9": Phase="Pending", Reason="", readiness=false. Elapsed: 89.99743ms
Apr 27 17:02:59.847: INFO: Pod "client-containers-fcd3d112-dfd5-4d96-862c-32f23583b6a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180316905s
STEP: Saw pod success
Apr 27 17:02:59.847: INFO: Pod "client-containers-fcd3d112-dfd5-4d96-862c-32f23583b6a9" satisfied condition "Succeeded or Failed"
Apr 27 17:02:59.937: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod client-containers-fcd3d112-dfd5-4d96-862c-32f23583b6a9 container test-container: <nil>
STEP: delete the pod
Apr 27 17:03:00.129: INFO: Waiting for pod client-containers-fcd3d112-dfd5-4d96-862c-32f23583b6a9 to disappear
Apr 27 17:03:00.219: INFO: Pod client-containers-fcd3d112-dfd5-4d96-862c-32f23583b6a9 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:00.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9436" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":277,"completed":177,"skipped":3067,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:00.402: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-3400
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Apr 27 17:03:01.042: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:04.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3400" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":277,"completed":178,"skipped":3099,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:05.050: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5802
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Apr 27 17:03:08.924: INFO: Successfully updated pod "annotationupdate42ca3278-61c1-45ec-92c1-fe4cff7604b0"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:11.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5802" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":277,"completed":179,"skipped":3128,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:11.302: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2780
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-a95dd59d-a15b-4c6b-a3cc-6b75472316f9
STEP: Creating a pod to test consume secrets
Apr 27 17:03:12.127: INFO: Waiting up to 5m0s for pod "pod-secrets-022c57ee-51a0-4f0b-9ae4-673efaeec3fd" in namespace "secrets-2780" to be "Succeeded or Failed"
Apr 27 17:03:12.217: INFO: Pod "pod-secrets-022c57ee-51a0-4f0b-9ae4-673efaeec3fd": Phase="Pending", Reason="", readiness=false. Elapsed: 89.875579ms
Apr 27 17:03:14.307: INFO: Pod "pod-secrets-022c57ee-51a0-4f0b-9ae4-673efaeec3fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180246756s
STEP: Saw pod success
Apr 27 17:03:14.307: INFO: Pod "pod-secrets-022c57ee-51a0-4f0b-9ae4-673efaeec3fd" satisfied condition "Succeeded or Failed"
Apr 27 17:03:14.397: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-secrets-022c57ee-51a0-4f0b-9ae4-673efaeec3fd container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:03:14.589: INFO: Waiting for pod pod-secrets-022c57ee-51a0-4f0b-9ae4-673efaeec3fd to disappear
Apr 27 17:03:14.679: INFO: Pod pod-secrets-022c57ee-51a0-4f0b-9ae4-673efaeec3fd no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:14.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2780" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":180,"skipped":3171,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:14.862: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1629
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-3178
STEP: Creating secret with name secret-test-0202de9b-39b8-487e-b193-1fbc39b936dc
STEP: Creating a pod to test consume secrets
Apr 27 17:03:16.360: INFO: Waiting up to 5m0s for pod "pod-secrets-fd4f311b-0ca7-40af-b11b-766b5a1a5007" in namespace "secrets-1629" to be "Succeeded or Failed"
Apr 27 17:03:16.450: INFO: Pod "pod-secrets-fd4f311b-0ca7-40af-b11b-766b5a1a5007": Phase="Pending", Reason="", readiness=false. Elapsed: 89.965834ms
Apr 27 17:03:18.541: INFO: Pod "pod-secrets-fd4f311b-0ca7-40af-b11b-766b5a1a5007": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180460946s
STEP: Saw pod success
Apr 27 17:03:18.541: INFO: Pod "pod-secrets-fd4f311b-0ca7-40af-b11b-766b5a1a5007" satisfied condition "Succeeded or Failed"
Apr 27 17:03:18.631: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-secrets-fd4f311b-0ca7-40af-b11b-766b5a1a5007 container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:03:18.821: INFO: Waiting for pod pod-secrets-fd4f311b-0ca7-40af-b11b-766b5a1a5007 to disappear
Apr 27 17:03:18.911: INFO: Pod pod-secrets-fd4f311b-0ca7-40af-b11b-766b5a1a5007 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:18.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1629" for this suite.
STEP: Destroying namespace "secret-namespace-3178" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":277,"completed":181,"skipped":3194,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:19.185: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4573
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Apr 27 17:03:20.456: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4573 /api/v1/namespaces/watch-4573/configmaps/e2e-watch-test-resource-version a6dee4b7-5fe4-473a-abce-c716f720e75e 29505 0 2020-04-27 17:03:19 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-04-27 17:03:20 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 17:03:20.456: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4573 /api/v1/namespaces/watch-4573/configmaps/e2e-watch-test-resource-version a6dee4b7-5fe4-473a-abce-c716f720e75e 29506 0 2020-04-27 17:03:19 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-04-27 17:03:20 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:20.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4573" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":277,"completed":182,"skipped":3208,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:20.639: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5934
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:03:21.279: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:23.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5934" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":277,"completed":183,"skipped":3219,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:24.152: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8040
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name secret-emptykey-test-f1c3dca4-effd-4ff5-8442-5c91e0bb60e5
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:24.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8040" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should fail to create secret due to empty secret key [Conformance]","total":277,"completed":184,"skipped":3225,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:25.063: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3920
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Apr 27 17:03:27.106: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:27.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0427 17:03:27.106408    7325 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-3920" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":277,"completed":185,"skipped":3249,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:27.287: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4915
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap that has name configmap-test-emptyKey-d2971fc3-1f12-4778-b494-cc8bdc21e9c5
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:28.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4915" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":277,"completed":186,"skipped":3276,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:28.201: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6391
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:03:30.046: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603809, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603809, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603809, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603809, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:03:33.231: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:03:33.321: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2627-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:34.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6391" for this suite.
STEP: Destroying namespace "webhook-6391-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":277,"completed":187,"skipped":3279,"failed":0}
SSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:34.900: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2600
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2600.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-2600.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2600.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2600.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-2600.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2600.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 17:03:38.780: INFO: DNS probes using dns-2600/dns-test-fa57cc9a-563d-4820-bda8-c8cac039fadc succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:38.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2600" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":277,"completed":188,"skipped":3283,"failed":0}
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:39.056: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2636
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:03:39.788: INFO: Waiting up to 5m0s for pod "downwardapi-volume-195044e0-f6d3-44d2-8f70-191c3787489a" in namespace "downward-api-2636" to be "Succeeded or Failed"
Apr 27 17:03:39.878: INFO: Pod "downwardapi-volume-195044e0-f6d3-44d2-8f70-191c3787489a": Phase="Pending", Reason="", readiness=false. Elapsed: 90.101729ms
Apr 27 17:03:41.968: INFO: Pod "downwardapi-volume-195044e0-f6d3-44d2-8f70-191c3787489a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180423016s
STEP: Saw pod success
Apr 27 17:03:41.968: INFO: Pod "downwardapi-volume-195044e0-f6d3-44d2-8f70-191c3787489a" satisfied condition "Succeeded or Failed"
Apr 27 17:03:42.059: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod downwardapi-volume-195044e0-f6d3-44d2-8f70-191c3787489a container client-container: <nil>
STEP: delete the pod
Apr 27 17:03:42.252: INFO: Waiting for pod downwardapi-volume-195044e0-f6d3-44d2-8f70-191c3787489a to disappear
Apr 27 17:03:42.342: INFO: Pod downwardapi-volume-195044e0-f6d3-44d2-8f70-191c3787489a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:42.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2636" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":189,"skipped":3289,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:42.526: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-6099
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:43.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6099" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":277,"completed":190,"skipped":3301,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:43.617: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5751
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:59.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5751" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":277,"completed":191,"skipped":3332,"failed":0}

------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:59.991: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5050
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 27 17:04:00.724: INFO: Waiting up to 5m0s for pod "pod-fdfcb0c4-e5c7-4e67-863b-24d60dd1855d" in namespace "emptydir-5050" to be "Succeeded or Failed"
Apr 27 17:04:00.814: INFO: Pod "pod-fdfcb0c4-e5c7-4e67-863b-24d60dd1855d": Phase="Pending", Reason="", readiness=false. Elapsed: 89.887722ms
Apr 27 17:04:02.905: INFO: Pod "pod-fdfcb0c4-e5c7-4e67-863b-24d60dd1855d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180501778s
STEP: Saw pod success
Apr 27 17:04:02.905: INFO: Pod "pod-fdfcb0c4-e5c7-4e67-863b-24d60dd1855d" satisfied condition "Succeeded or Failed"
Apr 27 17:04:02.995: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-fdfcb0c4-e5c7-4e67-863b-24d60dd1855d container test-container: <nil>
STEP: delete the pod
Apr 27 17:04:03.185: INFO: Waiting for pod pod-fdfcb0c4-e5c7-4e67-863b-24d60dd1855d to disappear
Apr 27 17:04:03.275: INFO: Pod pod-fdfcb0c4-e5c7-4e67-863b-24d60dd1855d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:04:03.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5050" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":192,"skipped":3332,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:04:03.457: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1568
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-ppkd
STEP: Creating a pod to test atomic-volume-subpath
Apr 27 17:04:04.370: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ppkd" in namespace "subpath-1568" to be "Succeeded or Failed"
Apr 27 17:04:04.459: INFO: Pod "pod-subpath-test-configmap-ppkd": Phase="Pending", Reason="", readiness=false. Elapsed: 89.719235ms
Apr 27 17:04:06.550: INFO: Pod "pod-subpath-test-configmap-ppkd": Phase="Running", Reason="", readiness=true. Elapsed: 2.180436434s
Apr 27 17:04:08.641: INFO: Pod "pod-subpath-test-configmap-ppkd": Phase="Running", Reason="", readiness=true. Elapsed: 4.271276369s
Apr 27 17:04:10.731: INFO: Pod "pod-subpath-test-configmap-ppkd": Phase="Running", Reason="", readiness=true. Elapsed: 6.361666604s
Apr 27 17:04:12.822: INFO: Pod "pod-subpath-test-configmap-ppkd": Phase="Running", Reason="", readiness=true. Elapsed: 8.451982255s
Apr 27 17:04:14.912: INFO: Pod "pod-subpath-test-configmap-ppkd": Phase="Running", Reason="", readiness=true. Elapsed: 10.542584211s
Apr 27 17:04:17.003: INFO: Pod "pod-subpath-test-configmap-ppkd": Phase="Running", Reason="", readiness=true. Elapsed: 12.633018531s
Apr 27 17:04:19.093: INFO: Pod "pod-subpath-test-configmap-ppkd": Phase="Running", Reason="", readiness=true. Elapsed: 14.723560982s
Apr 27 17:04:21.184: INFO: Pod "pod-subpath-test-configmap-ppkd": Phase="Running", Reason="", readiness=true. Elapsed: 16.814017473s
Apr 27 17:04:23.274: INFO: Pod "pod-subpath-test-configmap-ppkd": Phase="Running", Reason="", readiness=true. Elapsed: 18.904158557s
Apr 27 17:04:25.364: INFO: Pod "pod-subpath-test-configmap-ppkd": Phase="Running", Reason="", readiness=true. Elapsed: 20.994684708s
Apr 27 17:04:27.455: INFO: Pod "pod-subpath-test-configmap-ppkd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 23.085510031s
STEP: Saw pod success
Apr 27 17:04:27.455: INFO: Pod "pod-subpath-test-configmap-ppkd" satisfied condition "Succeeded or Failed"
Apr 27 17:04:27.545: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-subpath-test-configmap-ppkd container test-container-subpath-configmap-ppkd: <nil>
STEP: delete the pod
Apr 27 17:04:27.736: INFO: Waiting for pod pod-subpath-test-configmap-ppkd to disappear
Apr 27 17:04:27.826: INFO: Pod pod-subpath-test-configmap-ppkd no longer exists
STEP: Deleting pod pod-subpath-test-configmap-ppkd
Apr 27 17:04:27.826: INFO: Deleting pod "pod-subpath-test-configmap-ppkd" in namespace "subpath-1568"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:04:27.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1568" for this suite.
•{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [LinuxOnly] [Conformance]","total":277,"completed":193,"skipped":3347,"failed":0}
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:04:28.098: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3550
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:04:30.415: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603870, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603870, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603870, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603870, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:04:33.599: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:04:45.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3550" for this suite.
STEP: Destroying namespace "webhook-3550-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":277,"completed":194,"skipped":3348,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:04:46.036: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2432
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:04:46.676: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-2432'
Apr 27 17:04:47.553: INFO: stderr: ""
Apr 27 17:04:47.553: INFO: stdout: "replicationcontroller/agnhost-master created\n"
Apr 27 17:04:47.554: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-2432'
Apr 27 17:04:48.083: INFO: stderr: ""
Apr 27 17:04:48.083: INFO: stdout: "service/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Apr 27 17:04:49.175: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:04:49.175: INFO: Found 0 / 1
Apr 27 17:04:50.174: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:04:50.174: INFO: Found 1 / 1
Apr 27 17:04:50.174: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 27 17:04:50.264: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:04:50.264: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 27 17:04:50.264: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe pod agnhost-master-wvzpz --namespace=kubectl-2432'
Apr 27 17:04:50.803: INFO: stderr: ""
Apr 27 17:04:50.803: INFO: stdout: "Name:         agnhost-master-wvzpz\nNamespace:    kubectl-2432\nPriority:     0\nNode:         ip-10-250-10-186.ec2.internal/10.250.10.186\nStart Time:   Mon, 27 Apr 2020 17:04:47 +0000\nLabels:       app=agnhost\n              role=master\nAnnotations:  cni.projectcalico.org/podIP: 100.64.1.17/32\n              cni.projectcalico.org/podIPs: 100.64.1.17/32\n              kubernetes.io/psp: e2e-test-privileged-psp\nStatus:       Running\nIP:           100.64.1.17\nIPs:\n  IP:           100.64.1.17\nControlled By:  ReplicationController/agnhost-master\nContainers:\n  agnhost-master:\n    Container ID:   docker://20af98b5ea38f38aa714f8b27ff6722c0f3e73f8429d811e66a84183ccb029a4\n    Image:          us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Image ID:       docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 27 Apr 2020 17:04:48 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-hsq2v (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-hsq2v:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-hsq2v\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                                    Message\n  ----    ------     ----       ----                                    -------\n  Normal  Scheduled  <unknown>  default-scheduler                       Successfully assigned kubectl-2432/agnhost-master-wvzpz to ip-10-250-10-186.ec2.internal\n  Normal  Pulled     2s         kubelet, ip-10-250-10-186.ec2.internal  Container image \"us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\" already present on machine\n  Normal  Created    2s         kubelet, ip-10-250-10-186.ec2.internal  Created container agnhost-master\n  Normal  Started    2s         kubelet, ip-10-250-10-186.ec2.internal  Started container agnhost-master\n"
Apr 27 17:04:50.803: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe rc agnhost-master --namespace=kubectl-2432'
Apr 27 17:04:51.418: INFO: stderr: ""
Apr 27 17:04:51.418: INFO: stdout: "Name:         agnhost-master\nNamespace:    kubectl-2432\nSelector:     app=agnhost,role=master\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=master\n  Containers:\n   agnhost-master:\n    Image:        us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: agnhost-master-wvzpz\n"
Apr 27 17:04:51.418: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe service agnhost-master --namespace=kubectl-2432'
Apr 27 17:04:52.038: INFO: stderr: ""
Apr 27 17:04:52.038: INFO: stdout: "Name:              agnhost-master\nNamespace:         kubectl-2432\nLabels:            app=agnhost\n                   role=master\nAnnotations:       <none>\nSelector:          app=agnhost,role=master\nType:              ClusterIP\nIP:                100.107.82.219\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         100.64.1.17:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr 27 17:04:52.130: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe node ip-10-250-10-186.ec2.internal'
Apr 27 17:04:53.023: INFO: stderr: ""
Apr 27 17:04:53.023: INFO: stdout: "Name:               ip-10-250-10-186.ec2.internal\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=m5.large\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-east-1\n                    failure-domain.beta.kubernetes.io/zone=us-east-1c\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-10-250-10-186.ec2.internal\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/instance-type=m5.large\n                    node.kubernetes.io/role=node\n                    topology.ebs.csi.aws.com/zone=us-east-1c\n                    topology.kubernetes.io/region=us-east-1\n                    topology.kubernetes.io/zone=us-east-1c\n                    worker.garden.sapcloud.io/group=worker-1\n                    worker.gardener.cloud/pool=worker-1\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"ebs.csi.aws.com\":\"i-0f4b44cb3f9defc50\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    node.machine.sapcloud.io/last-applied-anno-labels-taints:\n                      {\"metadata\":{\"creationTimestamp\":null,\"labels\":{\"node.kubernetes.io/role\":\"node\",\"worker.garden.sapcloud.io/group\":\"worker-1\",\"worker.gard...\n                    projectcalico.org/IPv4Address: 10.250.10.186/19\n                    projectcalico.org/IPv4IPIPTunnelAddr: 100.64.1.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 27 Apr 2020 15:54:02 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-10-250-10-186.ec2.internal\n  AcquireTime:     <unset>\n  RenewTime:       Mon, 27 Apr 2020 17:04:44 +0000\nConditions:\n  Type                          Status  LastHeartbeatTime                 LastTransitionTime                Reason                          Message\n  ----                          ------  -----------------                 ------------------                ------                          -------\n  FrequentContainerdRestart     False   Mon, 27 Apr 2020 17:03:57 +0000   Mon, 27 Apr 2020 15:55:14 +0000   NoFrequentContainerdRestart     containerd is functioning properly\n  KernelDeadlock                False   Mon, 27 Apr 2020 17:03:57 +0000   Mon, 27 Apr 2020 15:55:14 +0000   KernelHasNoDeadlock             kernel has no deadlock\n  ReadonlyFilesystem            False   Mon, 27 Apr 2020 17:03:57 +0000   Mon, 27 Apr 2020 15:55:14 +0000   FilesystemIsNotReadOnly         Filesystem is not read-only\n  CorruptDockerOverlay2         False   Mon, 27 Apr 2020 17:03:57 +0000   Mon, 27 Apr 2020 15:55:14 +0000   NoCorruptDockerOverlay2         docker overlay2 is functioning properly\n  FrequentUnregisterNetDevice   False   Mon, 27 Apr 2020 17:03:57 +0000   Mon, 27 Apr 2020 15:55:14 +0000   NoFrequentUnregisterNetDevice   node is functioning properly\n  FrequentKubeletRestart        False   Mon, 27 Apr 2020 17:03:57 +0000   Mon, 27 Apr 2020 15:55:14 +0000   NoFrequentKubeletRestart        kubelet is functioning properly\n  FrequentDockerRestart         False   Mon, 27 Apr 2020 17:03:57 +0000   Mon, 27 Apr 2020 15:55:14 +0000   NoFrequentDockerRestart         docker is functioning properly\n  NetworkUnavailable            False   Mon, 27 Apr 2020 15:57:57 +0000   Mon, 27 Apr 2020 15:57:57 +0000   CalicoIsUp                      Calico is running on this node\n  MemoryPressure                False   Mon, 27 Apr 2020 17:04:49 +0000   Mon, 27 Apr 2020 15:54:02 +0000   KubeletHasSufficientMemory      kubelet has sufficient memory available\n  DiskPressure                  False   Mon, 27 Apr 2020 17:04:49 +0000   Mon, 27 Apr 2020 15:54:02 +0000   KubeletHasNoDiskPressure        kubelet has no disk pressure\n  PIDPressure                   False   Mon, 27 Apr 2020 17:04:49 +0000   Mon, 27 Apr 2020 15:54:02 +0000   KubeletHasSufficientPID         kubelet has sufficient PID available\n  Ready                         True    Mon, 27 Apr 2020 17:04:49 +0000   Mon, 27 Apr 2020 15:54:22 +0000   KubeletReady                    kubelet is posting ready status\nAddresses:\n  InternalIP:   10.250.10.186\n  InternalDNS:  ip-10-250-10-186.ec2.internal\n  Hostname:     ip-10-250-10-186.ec2.internal\nCapacity:\n  cpu:                2\n  ephemeral-storage:  28056816Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7951512Ki\n  pods:               110\nAllocatable:\n  cpu:                1920m\n  ephemeral-storage:  27293670584\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             6661489044\n  pods:               110\nSystem Info:\n  Machine ID:                 ec2a5f08f19cc19c7f3c119b00efa7d7\n  System UUID:                ec2a5f08-f19c-c19c-7f3c-119b00efa7d7\n  Boot ID:                    a278cabd-2f6c-4632-820d-9d5bf62886af\n  Kernel Version:             4.19.86-coreos\n  OS Image:                   Container Linux by CoreOS 2303.3.0 (Rhyolite)\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://18.6.3\n  Kubelet Version:            v1.18.2\n  Kube-Proxy Version:         v1.18.2\nPodCIDR:                      100.64.1.0/24\nPodCIDRs:                     100.64.1.0/24\nProviderID:                   aws:///us-east-1c/i-0f4b44cb3f9defc50\nNon-terminated Pods:          (6 in total)\n  Namespace                   Name                           CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                   ----                           ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-node-mvhvc              250m (13%)    800m (41%)  100Mi (1%)       700Mi (11%)    66m\n  kube-system                 csi-driver-node-qjp4d          20m (1%)      50m (2%)    50Mi (0%)        80Mi (1%)      70m\n  kube-system                 kube-proxy-f8lnb               20m (1%)      0 (0%)      64Mi (1%)        0 (0%)         70m\n  kube-system                 node-exporter-zggrn            5m (0%)       25m (1%)    10Mi (0%)        100Mi (1%)     70m\n  kube-system                 node-problem-detector-f7dh2    20m (1%)      200m (10%)  20Mi (0%)        100Mi (1%)     70m\n  kubectl-2432                agnhost-master-wvzpz           0 (0%)        0 (0%)      0 (0%)           0 (0%)         6s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                315m (16%)  1075m (55%)\n  memory             244Mi (3%)  980Mi (15%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
Apr 27 17:04:53.024: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe namespace kubectl-2432'
Apr 27 17:04:53.635: INFO: stderr: ""
Apr 27 17:04:53.635: INFO: stdout: "Name:         kubectl-2432\nLabels:       e2e-framework=kubectl\n              e2e-run=198d53a1-1549-45b7-8c2a-22ba5d8e39af\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:04:53.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2432" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":277,"completed":195,"skipped":3424,"failed":0}
SSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:04:53.817: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5544
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:04:57.004: INFO: Waiting up to 5m0s for pod "client-envvars-9813279c-b82f-4ab4-b0ae-c014f494e49d" in namespace "pods-5544" to be "Succeeded or Failed"
Apr 27 17:04:57.094: INFO: Pod "client-envvars-9813279c-b82f-4ab4-b0ae-c014f494e49d": Phase="Pending", Reason="", readiness=false. Elapsed: 89.940479ms
Apr 27 17:04:59.184: INFO: Pod "client-envvars-9813279c-b82f-4ab4-b0ae-c014f494e49d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180319315s
STEP: Saw pod success
Apr 27 17:04:59.185: INFO: Pod "client-envvars-9813279c-b82f-4ab4-b0ae-c014f494e49d" satisfied condition "Succeeded or Failed"
Apr 27 17:04:59.274: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod client-envvars-9813279c-b82f-4ab4-b0ae-c014f494e49d container env3cont: <nil>
STEP: delete the pod
Apr 27 17:04:59.463: INFO: Waiting for pod client-envvars-9813279c-b82f-4ab4-b0ae-c014f494e49d to disappear
Apr 27 17:04:59.553: INFO: Pod client-envvars-9813279c-b82f-4ab4-b0ae-c014f494e49d no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:04:59.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5544" for this suite.
•{"msg":"PASSED [k8s.io] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":277,"completed":196,"skipped":3427,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:04:59.736: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2664
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-dd34acd7-b9bf-45e6-ac2e-2399bea7650f
STEP: Creating a pod to test consume secrets
Apr 27 17:05:00.559: INFO: Waiting up to 5m0s for pod "pod-secrets-a3c61ef7-a9f2-444d-8b1a-55652ea33144" in namespace "secrets-2664" to be "Succeeded or Failed"
Apr 27 17:05:00.649: INFO: Pod "pod-secrets-a3c61ef7-a9f2-444d-8b1a-55652ea33144": Phase="Pending", Reason="", readiness=false. Elapsed: 89.692654ms
Apr 27 17:05:02.740: INFO: Pod "pod-secrets-a3c61ef7-a9f2-444d-8b1a-55652ea33144": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180247883s
STEP: Saw pod success
Apr 27 17:05:02.740: INFO: Pod "pod-secrets-a3c61ef7-a9f2-444d-8b1a-55652ea33144" satisfied condition "Succeeded or Failed"
Apr 27 17:05:02.831: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-secrets-a3c61ef7-a9f2-444d-8b1a-55652ea33144 container secret-env-test: <nil>
STEP: delete the pod
Apr 27 17:05:03.023: INFO: Waiting for pod pod-secrets-a3c61ef7-a9f2-444d-8b1a-55652ea33144 to disappear
Apr 27 17:05:03.113: INFO: Pod pod-secrets-a3c61ef7-a9f2-444d-8b1a-55652ea33144 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:03.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2664" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":277,"completed":197,"skipped":3436,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:03.296: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7887
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:05:04.030: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d8cef1d3-90b1-4cd1-bd34-33bd679f613c" in namespace "downward-api-7887" to be "Succeeded or Failed"
Apr 27 17:05:04.120: INFO: Pod "downwardapi-volume-d8cef1d3-90b1-4cd1-bd34-33bd679f613c": Phase="Pending", Reason="", readiness=false. Elapsed: 89.856342ms
Apr 27 17:05:06.210: INFO: Pod "downwardapi-volume-d8cef1d3-90b1-4cd1-bd34-33bd679f613c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180452494s
STEP: Saw pod success
Apr 27 17:05:06.211: INFO: Pod "downwardapi-volume-d8cef1d3-90b1-4cd1-bd34-33bd679f613c" satisfied condition "Succeeded or Failed"
Apr 27 17:05:06.301: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod downwardapi-volume-d8cef1d3-90b1-4cd1-bd34-33bd679f613c container client-container: <nil>
STEP: delete the pod
Apr 27 17:05:06.491: INFO: Waiting for pod downwardapi-volume-d8cef1d3-90b1-4cd1-bd34-33bd679f613c to disappear
Apr 27 17:05:06.581: INFO: Pod downwardapi-volume-d8cef1d3-90b1-4cd1-bd34-33bd679f613c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:06.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7887" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":198,"skipped":3437,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:06.764: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-281
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:05:07.404: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr 27 17:05:11.465: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-281 create -f -'
Apr 27 17:05:17.797: INFO: stderr: ""
Apr 27 17:05:17.797: INFO: stdout: "e2e-test-crd-publish-openapi-9369-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 27 17:05:17.798: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-281 delete e2e-test-crd-publish-openapi-9369-crds test-cr'
Apr 27 17:05:18.228: INFO: stderr: ""
Apr 27 17:05:18.228: INFO: stdout: "e2e-test-crd-publish-openapi-9369-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Apr 27 17:05:18.228: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-281 apply -f -'
Apr 27 17:05:19.271: INFO: stderr: ""
Apr 27 17:05:19.271: INFO: stdout: "e2e-test-crd-publish-openapi-9369-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 27 17:05:19.271: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-281 delete e2e-test-crd-publish-openapi-9369-crds test-cr'
Apr 27 17:05:19.701: INFO: stderr: ""
Apr 27 17:05:19.701: INFO: stdout: "e2e-test-crd-publish-openapi-9369-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Apr 27 17:05:19.701: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-9369-crds'
Apr 27 17:05:20.126: INFO: stderr: ""
Apr 27 17:05:20.126: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9369-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:24.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-281" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":277,"completed":199,"skipped":3438,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:24.326: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1706
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name projected-secret-test-0a160ea5-8f5c-4088-8d56-1d9e32876970
STEP: Creating a pod to test consume secrets
Apr 27 17:05:25.149: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8b9ef077-a4cc-45c6-ab30-8758de8cb47b" in namespace "projected-1706" to be "Succeeded or Failed"
Apr 27 17:05:25.239: INFO: Pod "pod-projected-secrets-8b9ef077-a4cc-45c6-ab30-8758de8cb47b": Phase="Pending", Reason="", readiness=false. Elapsed: 89.931634ms
Apr 27 17:05:27.409: INFO: Pod "pod-projected-secrets-8b9ef077-a4cc-45c6-ab30-8758de8cb47b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.259213711s
STEP: Saw pod success
Apr 27 17:05:27.409: INFO: Pod "pod-projected-secrets-8b9ef077-a4cc-45c6-ab30-8758de8cb47b" satisfied condition "Succeeded or Failed"
Apr 27 17:05:27.510: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-projected-secrets-8b9ef077-a4cc-45c6-ab30-8758de8cb47b container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:05:27.700: INFO: Waiting for pod pod-projected-secrets-8b9ef077-a4cc-45c6-ab30-8758de8cb47b to disappear
Apr 27 17:05:27.789: INFO: Pod pod-projected-secrets-8b9ef077-a4cc-45c6-ab30-8758de8cb47b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:27.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1706" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":277,"completed":200,"skipped":3445,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:27.972: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-355
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 27 17:05:28.705: INFO: Waiting up to 5m0s for pod "pod-78ff137d-4fd6-4835-83fc-9041a7dc7e87" in namespace "emptydir-355" to be "Succeeded or Failed"
Apr 27 17:05:28.795: INFO: Pod "pod-78ff137d-4fd6-4835-83fc-9041a7dc7e87": Phase="Pending", Reason="", readiness=false. Elapsed: 90.16416ms
Apr 27 17:05:30.886: INFO: Pod "pod-78ff137d-4fd6-4835-83fc-9041a7dc7e87": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.181054971s
STEP: Saw pod success
Apr 27 17:05:30.886: INFO: Pod "pod-78ff137d-4fd6-4835-83fc-9041a7dc7e87" satisfied condition "Succeeded or Failed"
Apr 27 17:05:30.976: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-78ff137d-4fd6-4835-83fc-9041a7dc7e87 container test-container: <nil>
STEP: delete the pod
Apr 27 17:05:31.167: INFO: Waiting for pod pod-78ff137d-4fd6-4835-83fc-9041a7dc7e87 to disappear
Apr 27 17:05:31.257: INFO: Pod pod-78ff137d-4fd6-4835-83fc-9041a7dc7e87 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:31.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-355" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":201,"skipped":3454,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:31.440: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1853
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:05:32.175: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a1aeb237-fb0f-4f76-88b3-7699c6a0b929" in namespace "projected-1853" to be "Succeeded or Failed"
Apr 27 17:05:32.265: INFO: Pod "downwardapi-volume-a1aeb237-fb0f-4f76-88b3-7699c6a0b929": Phase="Pending", Reason="", readiness=false. Elapsed: 90.080006ms
Apr 27 17:05:34.356: INFO: Pod "downwardapi-volume-a1aeb237-fb0f-4f76-88b3-7699c6a0b929": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180540592s
STEP: Saw pod success
Apr 27 17:05:34.356: INFO: Pod "downwardapi-volume-a1aeb237-fb0f-4f76-88b3-7699c6a0b929" satisfied condition "Succeeded or Failed"
Apr 27 17:05:34.446: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod downwardapi-volume-a1aeb237-fb0f-4f76-88b3-7699c6a0b929 container client-container: <nil>
STEP: delete the pod
Apr 27 17:05:34.637: INFO: Waiting for pod downwardapi-volume-a1aeb237-fb0f-4f76-88b3-7699c6a0b929 to disappear
Apr 27 17:05:34.727: INFO: Pod downwardapi-volume-a1aeb237-fb0f-4f76-88b3-7699c6a0b929 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:34.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1853" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":277,"completed":202,"skipped":3482,"failed":0}
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:34.910: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4769
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Apr 27 17:05:35.642: INFO: Waiting up to 5m0s for pod "downward-api-0741ecbf-bba9-4a0d-b6b3-a7a107344439" in namespace "downward-api-4769" to be "Succeeded or Failed"
Apr 27 17:05:35.731: INFO: Pod "downward-api-0741ecbf-bba9-4a0d-b6b3-a7a107344439": Phase="Pending", Reason="", readiness=false. Elapsed: 89.780301ms
Apr 27 17:05:37.822: INFO: Pod "downward-api-0741ecbf-bba9-4a0d-b6b3-a7a107344439": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180224844s
STEP: Saw pod success
Apr 27 17:05:37.822: INFO: Pod "downward-api-0741ecbf-bba9-4a0d-b6b3-a7a107344439" satisfied condition "Succeeded or Failed"
Apr 27 17:05:37.912: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod downward-api-0741ecbf-bba9-4a0d-b6b3-a7a107344439 container dapi-container: <nil>
STEP: delete the pod
Apr 27 17:05:38.104: INFO: Waiting for pod downward-api-0741ecbf-bba9-4a0d-b6b3-a7a107344439 to disappear
Apr 27 17:05:38.193: INFO: Pod downward-api-0741ecbf-bba9-4a0d-b6b3-a7a107344439 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:38.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4769" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":277,"completed":203,"skipped":3489,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should patch a secret [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:38.375: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5855
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a secret [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:39.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5855" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should patch a secret [Conformance]","total":277,"completed":204,"skipped":3512,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:39.745: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5817
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 27 17:05:42.839: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:43.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5817" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":205,"skipped":3527,"failed":0}
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:43.205: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9386
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:05:45.206: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603944, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603944, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603944, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603944, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:05:48.391: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:05:48.482: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:50.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9386" for this suite.
STEP: Destroying namespace "webhook-9386-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":277,"completed":206,"skipped":3529,"failed":0}
SS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:50.912: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-3969
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Apr 27 17:05:51.551: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the sample API server.
Apr 27 17:05:53.174: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603952, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603952, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603952, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603952, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:05:55.265: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603952, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603952, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603952, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603952, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:05:57.265: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603952, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603952, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603952, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603952, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:05:59.265: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603952, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603952, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603952, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603952, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:06:01.265: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603952, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603952, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603952, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603952, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:06:05.375: INFO: Waited 2.018358717s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:06:08.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-3969" for this suite.
•{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":277,"completed":207,"skipped":3531,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:06:08.761: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8247
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching services
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:06:09.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8247" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":277,"completed":208,"skipped":3547,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:06:09.674: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7600
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 27 17:06:10.410: INFO: Waiting up to 5m0s for pod "pod-ea2ebeef-30ad-4632-a186-298bc1bedb4e" in namespace "emptydir-7600" to be "Succeeded or Failed"
Apr 27 17:06:10.500: INFO: Pod "pod-ea2ebeef-30ad-4632-a186-298bc1bedb4e": Phase="Pending", Reason="", readiness=false. Elapsed: 90.107228ms
Apr 27 17:06:12.591: INFO: Pod "pod-ea2ebeef-30ad-4632-a186-298bc1bedb4e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.181236459s
STEP: Saw pod success
Apr 27 17:06:12.591: INFO: Pod "pod-ea2ebeef-30ad-4632-a186-298bc1bedb4e" satisfied condition "Succeeded or Failed"
Apr 27 17:06:12.681: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-ea2ebeef-30ad-4632-a186-298bc1bedb4e container test-container: <nil>
STEP: delete the pod
Apr 27 17:06:12.872: INFO: Waiting for pod pod-ea2ebeef-30ad-4632-a186-298bc1bedb4e to disappear
Apr 27 17:06:12.962: INFO: Pod pod-ea2ebeef-30ad-4632-a186-298bc1bedb4e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:06:12.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7600" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":209,"skipped":3561,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:06:13.146: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5798
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 27 17:06:13.879: INFO: Waiting up to 5m0s for pod "pod-0093c1a0-c670-4637-bbfc-6b05104fa350" in namespace "emptydir-5798" to be "Succeeded or Failed"
Apr 27 17:06:13.970: INFO: Pod "pod-0093c1a0-c670-4637-bbfc-6b05104fa350": Phase="Pending", Reason="", readiness=false. Elapsed: 90.799653ms
Apr 27 17:06:16.060: INFO: Pod "pod-0093c1a0-c670-4637-bbfc-6b05104fa350": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.181506704s
STEP: Saw pod success
Apr 27 17:06:16.060: INFO: Pod "pod-0093c1a0-c670-4637-bbfc-6b05104fa350" satisfied condition "Succeeded or Failed"
Apr 27 17:06:16.151: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-0093c1a0-c670-4637-bbfc-6b05104fa350 container test-container: <nil>
STEP: delete the pod
Apr 27 17:06:16.342: INFO: Waiting for pod pod-0093c1a0-c670-4637-bbfc-6b05104fa350 to disappear
Apr 27 17:06:16.432: INFO: Pod pod-0093c1a0-c670-4637-bbfc-6b05104fa350 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:06:16.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5798" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":210,"skipped":3590,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:06:16.614: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7757
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:06:33.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7757" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":277,"completed":211,"skipped":3595,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:06:34.164: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7858
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-hgcw
STEP: Creating a pod to test atomic-volume-subpath
Apr 27 17:06:35.076: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-hgcw" in namespace "subpath-7858" to be "Succeeded or Failed"
Apr 27 17:06:35.166: INFO: Pod "pod-subpath-test-configmap-hgcw": Phase="Pending", Reason="", readiness=false. Elapsed: 89.775099ms
Apr 27 17:06:37.256: INFO: Pod "pod-subpath-test-configmap-hgcw": Phase="Running", Reason="", readiness=true. Elapsed: 2.180230815s
Apr 27 17:06:39.346: INFO: Pod "pod-subpath-test-configmap-hgcw": Phase="Running", Reason="", readiness=true. Elapsed: 4.270532223s
Apr 27 17:06:41.437: INFO: Pod "pod-subpath-test-configmap-hgcw": Phase="Running", Reason="", readiness=true. Elapsed: 6.361502904s
Apr 27 17:06:43.528: INFO: Pod "pod-subpath-test-configmap-hgcw": Phase="Running", Reason="", readiness=true. Elapsed: 8.452253248s
Apr 27 17:06:45.619: INFO: Pod "pod-subpath-test-configmap-hgcw": Phase="Running", Reason="", readiness=true. Elapsed: 10.542761319s
Apr 27 17:06:47.709: INFO: Pod "pod-subpath-test-configmap-hgcw": Phase="Running", Reason="", readiness=true. Elapsed: 12.633077981s
Apr 27 17:06:49.799: INFO: Pod "pod-subpath-test-configmap-hgcw": Phase="Running", Reason="", readiness=true. Elapsed: 14.723360725s
Apr 27 17:06:51.890: INFO: Pod "pod-subpath-test-configmap-hgcw": Phase="Running", Reason="", readiness=true. Elapsed: 16.81420455s
Apr 27 17:06:53.980: INFO: Pod "pod-subpath-test-configmap-hgcw": Phase="Running", Reason="", readiness=true. Elapsed: 18.904549864s
Apr 27 17:06:56.071: INFO: Pod "pod-subpath-test-configmap-hgcw": Phase="Running", Reason="", readiness=true. Elapsed: 20.994814637s
Apr 27 17:06:58.161: INFO: Pod "pod-subpath-test-configmap-hgcw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 23.085489026s
STEP: Saw pod success
Apr 27 17:06:58.161: INFO: Pod "pod-subpath-test-configmap-hgcw" satisfied condition "Succeeded or Failed"
Apr 27 17:06:58.252: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-subpath-test-configmap-hgcw container test-container-subpath-configmap-hgcw: <nil>
STEP: delete the pod
Apr 27 17:06:58.442: INFO: Waiting for pod pod-subpath-test-configmap-hgcw to disappear
Apr 27 17:06:58.532: INFO: Pod pod-subpath-test-configmap-hgcw no longer exists
STEP: Deleting pod pod-subpath-test-configmap-hgcw
Apr 27 17:06:58.532: INFO: Deleting pod "pod-subpath-test-configmap-hgcw" in namespace "subpath-7858"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:06:58.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7858" for this suite.
•{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]","total":277,"completed":212,"skipped":3644,"failed":0}
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:06:58.804: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1811
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1811.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1811.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1811.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1811.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1811.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1811.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1811.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1811.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1811.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1811.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1811.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 191.228.104.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.104.228.191_udp@PTR;check="$$(dig +tcp +noall +answer +search 191.228.104.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.104.228.191_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1811.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1811.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1811.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1811.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1811.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1811.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1811.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1811.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1811.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1811.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1811.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 191.228.104.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.104.228.191_udp@PTR;check="$$(dig +tcp +noall +answer +search 191.228.104.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.104.228.191_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 17:07:02.187: INFO: Unable to read wheezy_udp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:02.280: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:02.373: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:02.466: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:03.132: INFO: Unable to read jessie_udp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:03.224: INFO: Unable to read jessie_tcp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:03.317: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:03.410: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:03.980: INFO: Lookups using dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500 failed for: [wheezy_udp@dns-test-service.dns-1811.svc.cluster.local wheezy_tcp@dns-test-service.dns-1811.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local jessie_udp@dns-test-service.dns-1811.svc.cluster.local jessie_tcp@dns-test-service.dns-1811.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local]

Apr 27 17:07:09.074: INFO: Unable to read wheezy_udp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:09.166: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:09.260: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:09.353: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:10.013: INFO: Unable to read jessie_udp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:10.106: INFO: Unable to read jessie_tcp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:10.199: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:10.292: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:10.860: INFO: Lookups using dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500 failed for: [wheezy_udp@dns-test-service.dns-1811.svc.cluster.local wheezy_tcp@dns-test-service.dns-1811.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local jessie_udp@dns-test-service.dns-1811.svc.cluster.local jessie_tcp@dns-test-service.dns-1811.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local]

Apr 27 17:07:14.074: INFO: Unable to read wheezy_udp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:14.167: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:14.260: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:14.358: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:15.017: INFO: Unable to read jessie_udp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:15.110: INFO: Unable to read jessie_tcp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:15.244: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:15.337: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:15.905: INFO: Lookups using dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500 failed for: [wheezy_udp@dns-test-service.dns-1811.svc.cluster.local wheezy_tcp@dns-test-service.dns-1811.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local jessie_udp@dns-test-service.dns-1811.svc.cluster.local jessie_tcp@dns-test-service.dns-1811.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local]

Apr 27 17:07:19.074: INFO: Unable to read wheezy_udp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:19.166: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:19.259: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:19.352: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:20.020: INFO: Unable to read jessie_udp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:20.112: INFO: Unable to read jessie_tcp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:20.205: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:20.298: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:20.867: INFO: Lookups using dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500 failed for: [wheezy_udp@dns-test-service.dns-1811.svc.cluster.local wheezy_tcp@dns-test-service.dns-1811.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local jessie_udp@dns-test-service.dns-1811.svc.cluster.local jessie_tcp@dns-test-service.dns-1811.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local]

Apr 27 17:07:24.074: INFO: Unable to read wheezy_udp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:24.166: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:24.259: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:24.352: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:25.010: INFO: Unable to read jessie_udp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:25.103: INFO: Unable to read jessie_tcp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:25.196: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:25.289: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:25.904: INFO: Lookups using dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500 failed for: [wheezy_udp@dns-test-service.dns-1811.svc.cluster.local wheezy_tcp@dns-test-service.dns-1811.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local jessie_udp@dns-test-service.dns-1811.svc.cluster.local jessie_tcp@dns-test-service.dns-1811.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local]

Apr 27 17:07:29.074: INFO: Unable to read wheezy_udp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:29.166: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:29.259: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:29.352: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:30.022: INFO: Unable to read jessie_udp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:30.115: INFO: Unable to read jessie_tcp@dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:30.208: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:30.301: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local from pod dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500: the server could not find the requested resource (get pods dns-test-11c38a15-337d-48b5-9d44-5883dd022500)
Apr 27 17:07:30.873: INFO: Lookups using dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500 failed for: [wheezy_udp@dns-test-service.dns-1811.svc.cluster.local wheezy_tcp@dns-test-service.dns-1811.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local jessie_udp@dns-test-service.dns-1811.svc.cluster.local jessie_tcp@dns-test-service.dns-1811.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1811.svc.cluster.local]

Apr 27 17:07:36.058: INFO: DNS probes using dns-1811/dns-test-11c38a15-337d-48b5-9d44-5883dd022500 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:07:36.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1811" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":277,"completed":213,"skipped":3649,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:07:36.525: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1114
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:07:37.347: INFO: The status of Pod test-webserver-e40979ba-e314-49ef-9323-c14e99b4a714 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 17:07:39.438: INFO: The status of Pod test-webserver-e40979ba-e314-49ef-9323-c14e99b4a714 is Running (Ready = false)
Apr 27 17:07:41.438: INFO: The status of Pod test-webserver-e40979ba-e314-49ef-9323-c14e99b4a714 is Running (Ready = false)
Apr 27 17:07:43.438: INFO: The status of Pod test-webserver-e40979ba-e314-49ef-9323-c14e99b4a714 is Running (Ready = false)
Apr 27 17:07:45.438: INFO: The status of Pod test-webserver-e40979ba-e314-49ef-9323-c14e99b4a714 is Running (Ready = false)
Apr 27 17:07:47.438: INFO: The status of Pod test-webserver-e40979ba-e314-49ef-9323-c14e99b4a714 is Running (Ready = false)
Apr 27 17:07:49.438: INFO: The status of Pod test-webserver-e40979ba-e314-49ef-9323-c14e99b4a714 is Running (Ready = false)
Apr 27 17:07:51.438: INFO: The status of Pod test-webserver-e40979ba-e314-49ef-9323-c14e99b4a714 is Running (Ready = false)
Apr 27 17:07:53.438: INFO: The status of Pod test-webserver-e40979ba-e314-49ef-9323-c14e99b4a714 is Running (Ready = false)
Apr 27 17:07:55.438: INFO: The status of Pod test-webserver-e40979ba-e314-49ef-9323-c14e99b4a714 is Running (Ready = false)
Apr 27 17:07:57.438: INFO: The status of Pod test-webserver-e40979ba-e314-49ef-9323-c14e99b4a714 is Running (Ready = true)
Apr 27 17:07:57.528: INFO: Container started at 2020-04-27 17:07:38 +0000 UTC, pod became ready at 2020-04-27 17:07:57 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:07:57.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1114" for this suite.
•{"msg":"PASSED [k8s.io] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":277,"completed":214,"skipped":3678,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:07:57.710: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2480
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:07:59.810: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604079, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604079, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604079, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604079, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:08:01.901: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604079, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604079, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604079, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604079, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:08:04.996: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:08:06.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2480" for this suite.
STEP: Destroying namespace "webhook-2480-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":277,"completed":215,"skipped":3708,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:08:06.790: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8768
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:08:09.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8768" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":216,"skipped":3741,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:08:10.076: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6977
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 27 17:08:13.168: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:08:13.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6977" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":217,"skipped":3831,"failed":0}
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:08:13.534: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6561
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:08:14.720: INFO: Create a RollingUpdate DaemonSet
Apr 27 17:08:14.811: INFO: Check that daemon pods launch on every node of the cluster
Apr 27 17:08:14.993: INFO: Number of nodes with available pods: 0
Apr 27 17:08:14.993: INFO: Node ip-10-250-10-186.ec2.internal is running more than one daemon pod
Apr 27 17:08:16.176: INFO: Number of nodes with available pods: 1
Apr 27 17:08:16.176: INFO: Node ip-10-250-10-186.ec2.internal is running more than one daemon pod
Apr 27 17:08:17.175: INFO: Number of nodes with available pods: 2
Apr 27 17:08:17.176: INFO: Number of running nodes: 2, number of available pods: 2
Apr 27 17:08:17.176: INFO: Update the DaemonSet to trigger a rollout
Apr 27 17:08:17.357: INFO: Updating DaemonSet daemon-set
Apr 27 17:08:21.720: INFO: Roll back the DaemonSet before rollout is complete
Apr 27 17:08:21.901: INFO: Updating DaemonSet daemon-set
Apr 27 17:08:21.901: INFO: Make sure DaemonSet rollback is complete
Apr 27 17:08:21.992: INFO: Wrong image for pod: daemon-set-gvqg5. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Apr 27 17:08:21.992: INFO: Pod daemon-set-gvqg5 is not available
Apr 27 17:08:23.174: INFO: Wrong image for pod: daemon-set-gvqg5. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Apr 27 17:08:23.174: INFO: Pod daemon-set-gvqg5 is not available
Apr 27 17:08:24.174: INFO: Pod daemon-set-qdq88 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6561, will wait for the garbage collector to delete the pods
Apr 27 17:08:24.726: INFO: Deleting DaemonSet.extensions daemon-set took: 91.513324ms
Apr 27 17:08:24.827: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.386081ms
Apr 27 17:08:33.317: INFO: Number of nodes with available pods: 0
Apr 27 17:08:33.317: INFO: Number of running nodes: 0, number of available pods: 0
Apr 27 17:08:33.406: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6561/daemonsets","resourceVersion":"32151"},"items":null}

Apr 27 17:08:33.496: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6561/pods","resourceVersion":"32151"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:08:33.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6561" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":277,"completed":218,"skipped":3836,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:08:33.953: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-5564
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:164
Apr 27 17:08:34.593: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 27 17:09:35.147: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:09:35.237: INFO: Starting informer...
STEP: Starting pod...
Apr 27 17:09:35.419: INFO: Pod is running on ip-10-250-10-186.ec2.internal. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Apr 27 17:09:35.693: INFO: Pod wasn't evicted. Proceeding
Apr 27 17:09:35.694: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Apr 27 17:10:50.968: INFO: Pod wasn't evicted. Test successful
[AfterEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:10:50.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-5564" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":277,"completed":219,"skipped":3852,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:10:51.150: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-5408
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Apr 27 17:10:56.614: INFO: Pod name wrapped-volume-race-d5f63ec1-e2a2-490c-9117-80d9ef21d1d4: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d5f63ec1-e2a2-490c-9117-80d9ef21d1d4 in namespace emptydir-wrapper-5408, will wait for the garbage collector to delete the pods
Apr 27 17:11:01.521: INFO: Deleting ReplicationController wrapped-volume-race-d5f63ec1-e2a2-490c-9117-80d9ef21d1d4 took: 168.903425ms
Apr 27 17:11:01.621: INFO: Terminating ReplicationController wrapped-volume-race-d5f63ec1-e2a2-490c-9117-80d9ef21d1d4 pods took: 100.388499ms
STEP: Creating RC which spawns configmap-volume pods
Apr 27 17:11:13.117: INFO: Pod name wrapped-volume-race-cc9823ba-33e1-4943-9dfc-8aa210d96e0a: Found 3 pods out of 5
Apr 27 17:11:18.212: INFO: Pod name wrapped-volume-race-cc9823ba-33e1-4943-9dfc-8aa210d96e0a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-cc9823ba-33e1-4943-9dfc-8aa210d96e0a in namespace emptydir-wrapper-5408, will wait for the garbage collector to delete the pods
Apr 27 17:11:18.951: INFO: Deleting ReplicationController wrapped-volume-race-cc9823ba-33e1-4943-9dfc-8aa210d96e0a took: 91.021238ms
Apr 27 17:11:19.052: INFO: Terminating ReplicationController wrapped-volume-race-cc9823ba-33e1-4943-9dfc-8aa210d96e0a pods took: 100.383842ms
STEP: Creating RC which spawns configmap-volume pods
Apr 27 17:11:33.134: INFO: Pod name wrapped-volume-race-f2b0f402-d5a7-4035-826d-ec74ee8e3d22: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f2b0f402-d5a7-4035-826d-ec74ee8e3d22 in namespace emptydir-wrapper-5408, will wait for the garbage collector to delete the pods
Apr 27 17:11:38.039: INFO: Deleting ReplicationController wrapped-volume-race-f2b0f402-d5a7-4035-826d-ec74ee8e3d22 took: 169.459645ms
Apr 27 17:11:38.139: INFO: Terminating ReplicationController wrapped-volume-race-f2b0f402-d5a7-4035-826d-ec74ee8e3d22 pods took: 100.336151ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:11:47.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5408" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":277,"completed":220,"skipped":3854,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:11:47.474: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6293
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-cb50c283-8929-465e-a4d9-c645d9b3301b
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-cb50c283-8929-465e-a4d9-c645d9b3301b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:13:14.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6293" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":221,"skipped":3869,"failed":0}
SS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:13:15.171: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8611
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:13:15.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8611" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":277,"completed":222,"skipped":3871,"failed":0}

------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:13:16.082: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8019
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Apr 27 17:13:16.722: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-8019'
Apr 27 17:13:17.647: INFO: stderr: ""
Apr 27 17:13:17.647: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Apr 27 17:13:18.738: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:13:18.738: INFO: Found 0 / 1
Apr 27 17:13:19.738: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:13:19.738: INFO: Found 1 / 1
Apr 27 17:13:19.738: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Apr 27 17:13:19.828: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:13:19.828: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 27 17:13:19.828: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config patch pod agnhost-master-ldx2b --namespace=kubectl-8019 -p {"metadata":{"annotations":{"x":"y"}}}'
Apr 27 17:13:20.255: INFO: stderr: ""
Apr 27 17:13:20.255: INFO: stdout: "pod/agnhost-master-ldx2b patched\n"
STEP: checking annotations
Apr 27 17:13:20.345: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:13:20.345: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:13:20.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8019" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":277,"completed":223,"skipped":3871,"failed":0}
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:13:20.527: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8996
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:13:21.257: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1bfb4d6f-e05e-4ee2-b1a8-7a423e4e0ca1" in namespace "projected-8996" to be "Succeeded or Failed"
Apr 27 17:13:21.347: INFO: Pod "downwardapi-volume-1bfb4d6f-e05e-4ee2-b1a8-7a423e4e0ca1": Phase="Pending", Reason="", readiness=false. Elapsed: 89.930005ms
Apr 27 17:13:23.438: INFO: Pod "downwardapi-volume-1bfb4d6f-e05e-4ee2-b1a8-7a423e4e0ca1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180888213s
STEP: Saw pod success
Apr 27 17:13:23.438: INFO: Pod "downwardapi-volume-1bfb4d6f-e05e-4ee2-b1a8-7a423e4e0ca1" satisfied condition "Succeeded or Failed"
Apr 27 17:13:23.528: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod downwardapi-volume-1bfb4d6f-e05e-4ee2-b1a8-7a423e4e0ca1 container client-container: <nil>
STEP: delete the pod
Apr 27 17:13:23.719: INFO: Waiting for pod downwardapi-volume-1bfb4d6f-e05e-4ee2-b1a8-7a423e4e0ca1 to disappear
Apr 27 17:13:23.809: INFO: Pod downwardapi-volume-1bfb4d6f-e05e-4ee2-b1a8-7a423e4e0ca1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:13:23.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8996" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":277,"completed":224,"skipped":3873,"failed":0}

------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:13:23.991: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-254
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-a544514e-50f7-4975-9aee-98ccb7e993a2
STEP: Creating a pod to test consume secrets
Apr 27 17:13:24.814: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1a43ed35-fd61-4d9b-9167-c1bf8559f396" in namespace "projected-254" to be "Succeeded or Failed"
Apr 27 17:13:24.904: INFO: Pod "pod-projected-secrets-1a43ed35-fd61-4d9b-9167-c1bf8559f396": Phase="Pending", Reason="", readiness=false. Elapsed: 90.036823ms
Apr 27 17:13:26.994: INFO: Pod "pod-projected-secrets-1a43ed35-fd61-4d9b-9167-c1bf8559f396": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180362833s
STEP: Saw pod success
Apr 27 17:13:26.994: INFO: Pod "pod-projected-secrets-1a43ed35-fd61-4d9b-9167-c1bf8559f396" satisfied condition "Succeeded or Failed"
Apr 27 17:13:27.084: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-projected-secrets-1a43ed35-fd61-4d9b-9167-c1bf8559f396 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:13:27.274: INFO: Waiting for pod pod-projected-secrets-1a43ed35-fd61-4d9b-9167-c1bf8559f396 to disappear
Apr 27 17:13:27.365: INFO: Pod pod-projected-secrets-1a43ed35-fd61-4d9b-9167-c1bf8559f396 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:13:27.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-254" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":225,"skipped":3873,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:13:27.547: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9653
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Apr 27 17:13:28.366: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:13:42.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9653" for this suite.
•{"msg":"PASSED [k8s.io] Pods should be submitted and removed [NodeConformance] [Conformance]","total":277,"completed":226,"skipped":3881,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:13:42.932: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-5706
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-h6kj9 in namespace proxy-5706
I0427 17:13:43.757853    7325 runners.go:190] Created replication controller with name: proxy-service-h6kj9, namespace: proxy-5706, replica count: 1
I0427 17:13:44.858526    7325 runners.go:190] proxy-service-h6kj9 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0427 17:13:45.858814    7325 runners.go:190] proxy-service-h6kj9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 17:13:46.859128    7325 runners.go:190] proxy-service-h6kj9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 17:13:47.859541    7325 runners.go:190] proxy-service-h6kj9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 17:13:48.859866    7325 runners.go:190] proxy-service-h6kj9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 17:13:49.860197    7325 runners.go:190] proxy-service-h6kj9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 17:13:50.860516    7325 runners.go:190] proxy-service-h6kj9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 17:13:51.860812    7325 runners.go:190] proxy-service-h6kj9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 17:13:52.861115    7325 runners.go:190] proxy-service-h6kj9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 17:13:53.861390    7325 runners.go:190] proxy-service-h6kj9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 17:13:54.861666    7325 runners.go:190] proxy-service-h6kj9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 17:13:55.861958    7325 runners.go:190] proxy-service-h6kj9 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 27 17:13:55.951: INFO: setup took 12.378861535s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Apr 27 17:13:56.059: INFO: (0) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname2/proxy/: bar (200; 106.991695ms)
Apr 27 17:13:56.059: INFO: (0) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname2/proxy/: bar (200; 107.036681ms)
Apr 27 17:13:56.059: INFO: (0) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/rewriteme">test</a> (200; 107.09407ms)
Apr 27 17:13:56.059: INFO: (0) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">... (200; 106.980165ms)
Apr 27 17:13:56.059: INFO: (0) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">test<... (200; 106.976236ms)
Apr 27 17:13:56.059: INFO: (0) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname1/proxy/: foo (200; 107.047664ms)
Apr 27 17:13:56.063: INFO: (0) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname1/proxy/: tls baz (200; 111.021491ms)
Apr 27 17:13:56.063: INFO: (0) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:462/proxy/: tls qux (200; 111.122147ms)
Apr 27 17:13:56.063: INFO: (0) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname2/proxy/: tls qux (200; 111.155842ms)
Apr 27 17:13:56.068: INFO: (0) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/tlsrewritem... (200; 116.70208ms)
Apr 27 17:13:56.132: INFO: (0) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 179.816538ms)
Apr 27 17:13:56.134: INFO: (0) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 181.906738ms)
Apr 27 17:13:56.135: INFO: (0) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 183.69287ms)
Apr 27 17:13:56.135: INFO: (0) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:460/proxy/: tls baz (200; 183.708736ms)
Apr 27 17:13:56.137: INFO: (0) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 185.605617ms)
Apr 27 17:13:56.178: INFO: (0) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname1/proxy/: foo (200; 226.60247ms)
Apr 27 17:13:56.272: INFO: (1) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 93.328755ms)
Apr 27 17:13:56.272: INFO: (1) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:460/proxy/: tls baz (200; 93.802815ms)
Apr 27 17:13:56.273: INFO: (1) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">test<... (200; 94.097698ms)
Apr 27 17:13:56.273: INFO: (1) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname2/proxy/: tls qux (200; 94.005313ms)
Apr 27 17:13:56.273: INFO: (1) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/tlsrewritem... (200; 94.109433ms)
Apr 27 17:13:56.273: INFO: (1) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname1/proxy/: foo (200; 94.245433ms)
Apr 27 17:13:56.273: INFO: (1) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname1/proxy/: tls baz (200; 94.094888ms)
Apr 27 17:13:56.273: INFO: (1) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname2/proxy/: bar (200; 94.09712ms)
Apr 27 17:13:56.273: INFO: (1) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname1/proxy/: foo (200; 94.087593ms)
Apr 27 17:13:56.273: INFO: (1) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">... (200; 94.542617ms)
Apr 27 17:13:56.273: INFO: (1) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:462/proxy/: tls qux (200; 94.525779ms)
Apr 27 17:13:56.273: INFO: (1) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/rewriteme">test</a> (200; 94.564998ms)
Apr 27 17:13:56.275: INFO: (1) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname2/proxy/: bar (200; 96.052334ms)
Apr 27 17:13:56.276: INFO: (1) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 97.215844ms)
Apr 27 17:13:56.276: INFO: (1) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 97.355353ms)
Apr 27 17:13:56.276: INFO: (1) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 97.465953ms)
Apr 27 17:13:56.369: INFO: (2) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 92.832868ms)
Apr 27 17:13:56.369: INFO: (2) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/rewriteme">test</a> (200; 93.198274ms)
Apr 27 17:13:56.370: INFO: (2) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">test<... (200; 93.252027ms)
Apr 27 17:13:56.370: INFO: (2) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:460/proxy/: tls baz (200; 93.217192ms)
Apr 27 17:13:56.370: INFO: (2) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname1/proxy/: tls baz (200; 93.470105ms)
Apr 27 17:13:56.370: INFO: (2) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/tlsrewritem... (200; 93.395925ms)
Apr 27 17:13:56.370: INFO: (2) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:462/proxy/: tls qux (200; 93.294562ms)
Apr 27 17:13:56.370: INFO: (2) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 93.585772ms)
Apr 27 17:13:56.370: INFO: (2) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname2/proxy/: tls qux (200; 93.577206ms)
Apr 27 17:13:56.370: INFO: (2) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">... (200; 93.559994ms)
Apr 27 17:13:56.370: INFO: (2) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname2/proxy/: bar (200; 94.081487ms)
Apr 27 17:13:56.370: INFO: (2) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname2/proxy/: bar (200; 94.222908ms)
Apr 27 17:13:56.371: INFO: (2) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname1/proxy/: foo (200; 95.077793ms)
Apr 27 17:13:56.373: INFO: (2) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname1/proxy/: foo (200; 96.370746ms)
Apr 27 17:13:56.374: INFO: (2) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 98.254253ms)
Apr 27 17:13:56.374: INFO: (2) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 98.327319ms)
Apr 27 17:13:56.467: INFO: (3) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 92.522782ms)
Apr 27 17:13:56.468: INFO: (3) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/tlsrewritem... (200; 93.419286ms)
Apr 27 17:13:56.468: INFO: (3) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname1/proxy/: tls baz (200; 93.558587ms)
Apr 27 17:13:56.468: INFO: (3) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 93.546801ms)
Apr 27 17:13:56.468: INFO: (3) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">... (200; 93.668977ms)
Apr 27 17:13:56.468: INFO: (3) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname1/proxy/: foo (200; 93.556765ms)
Apr 27 17:13:56.468: INFO: (3) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 93.622805ms)
Apr 27 17:13:56.469: INFO: (3) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:460/proxy/: tls baz (200; 94.006162ms)
Apr 27 17:13:56.469: INFO: (3) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">test<... (200; 94.158727ms)
Apr 27 17:13:56.469: INFO: (3) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/rewriteme">test</a> (200; 94.227459ms)
Apr 27 17:13:56.469: INFO: (3) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:462/proxy/: tls qux (200; 94.204683ms)
Apr 27 17:13:56.469: INFO: (3) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname2/proxy/: tls qux (200; 94.344898ms)
Apr 27 17:13:56.470: INFO: (3) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname2/proxy/: bar (200; 95.525291ms)
Apr 27 17:13:56.471: INFO: (3) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname2/proxy/: bar (200; 96.558047ms)
Apr 27 17:13:56.473: INFO: (3) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname1/proxy/: foo (200; 98.113775ms)
Apr 27 17:13:56.473: INFO: (3) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 98.069346ms)
Apr 27 17:13:56.566: INFO: (4) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">... (200; 92.580554ms)
Apr 27 17:13:56.567: INFO: (4) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:460/proxy/: tls baz (200; 93.5617ms)
Apr 27 17:13:56.567: INFO: (4) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/tlsrewritem... (200; 93.677832ms)
Apr 27 17:13:56.567: INFO: (4) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 93.619834ms)
Apr 27 17:13:56.567: INFO: (4) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname2/proxy/: tls qux (200; 93.736222ms)
Apr 27 17:13:56.567: INFO: (4) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname1/proxy/: foo (200; 93.640955ms)
Apr 27 17:13:56.567: INFO: (4) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname2/proxy/: bar (200; 93.630408ms)
Apr 27 17:13:56.567: INFO: (4) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname1/proxy/: foo (200; 93.627729ms)
Apr 27 17:13:56.567: INFO: (4) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname1/proxy/: tls baz (200; 94.119903ms)
Apr 27 17:13:56.567: INFO: (4) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/rewriteme">test</a> (200; 94.24755ms)
Apr 27 17:13:56.567: INFO: (4) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">test<... (200; 94.13784ms)
Apr 27 17:13:56.567: INFO: (4) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:462/proxy/: tls qux (200; 94.341749ms)
Apr 27 17:13:56.569: INFO: (4) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 95.867577ms)
Apr 27 17:13:56.570: INFO: (4) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname2/proxy/: bar (200; 96.882964ms)
Apr 27 17:13:56.570: INFO: (4) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 97.004589ms)
Apr 27 17:13:56.570: INFO: (4) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 97.000766ms)
Apr 27 17:13:56.663: INFO: (5) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 92.887281ms)
Apr 27 17:13:56.663: INFO: (5) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 92.889243ms)
Apr 27 17:13:56.663: INFO: (5) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">test<... (200; 93.003908ms)
Apr 27 17:13:56.663: INFO: (5) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 92.959854ms)
Apr 27 17:13:56.663: INFO: (5) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/rewriteme">test</a> (200; 93.028423ms)
Apr 27 17:13:56.664: INFO: (5) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:462/proxy/: tls qux (200; 94.196611ms)
Apr 27 17:13:56.664: INFO: (5) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/tlsrewritem... (200; 94.152395ms)
Apr 27 17:13:56.664: INFO: (5) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname2/proxy/: bar (200; 94.205807ms)
Apr 27 17:13:56.664: INFO: (5) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname2/proxy/: tls qux (200; 94.218149ms)
Apr 27 17:13:56.664: INFO: (5) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:460/proxy/: tls baz (200; 94.262042ms)
Apr 27 17:13:56.664: INFO: (5) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">... (200; 94.395427ms)
Apr 27 17:13:56.665: INFO: (5) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname1/proxy/: tls baz (200; 94.322833ms)
Apr 27 17:13:56.666: INFO: (5) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname1/proxy/: foo (200; 95.676656ms)
Apr 27 17:13:56.666: INFO: (5) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname1/proxy/: foo (200; 95.6662ms)
Apr 27 17:13:56.667: INFO: (5) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 96.964841ms)
Apr 27 17:13:56.669: INFO: (5) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname2/proxy/: bar (200; 98.725626ms)
Apr 27 17:13:56.762: INFO: (6) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/tlsrewritem... (200; 92.9067ms)
Apr 27 17:13:56.762: INFO: (6) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname1/proxy/: foo (200; 93.327308ms)
Apr 27 17:13:56.762: INFO: (6) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/rewriteme">test</a> (200; 93.429739ms)
Apr 27 17:13:56.762: INFO: (6) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname1/proxy/: foo (200; 93.315265ms)
Apr 27 17:13:56.762: INFO: (6) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 93.485687ms)
Apr 27 17:13:56.763: INFO: (6) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">... (200; 94.055965ms)
Apr 27 17:13:56.763: INFO: (6) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">test<... (200; 93.961365ms)
Apr 27 17:13:56.763: INFO: (6) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname2/proxy/: tls qux (200; 93.971225ms)
Apr 27 17:13:56.763: INFO: (6) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:462/proxy/: tls qux (200; 94.029473ms)
Apr 27 17:13:56.763: INFO: (6) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname1/proxy/: tls baz (200; 93.87727ms)
Apr 27 17:13:56.763: INFO: (6) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname2/proxy/: bar (200; 94.049036ms)
Apr 27 17:13:56.763: INFO: (6) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:460/proxy/: tls baz (200; 93.993774ms)
Apr 27 17:13:56.766: INFO: (6) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 96.791876ms)
Apr 27 17:13:56.766: INFO: (6) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 96.825067ms)
Apr 27 17:13:56.766: INFO: (6) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname2/proxy/: bar (200; 96.932081ms)
Apr 27 17:13:56.766: INFO: (6) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 96.838433ms)
Apr 27 17:13:56.858: INFO: (7) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:462/proxy/: tls qux (200; 92.451123ms)
Apr 27 17:13:56.859: INFO: (7) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:460/proxy/: tls baz (200; 92.807575ms)
Apr 27 17:13:56.859: INFO: (7) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">... (200; 92.800575ms)
Apr 27 17:13:56.859: INFO: (7) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">test<... (200; 92.749082ms)
Apr 27 17:13:56.859: INFO: (7) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 92.907313ms)
Apr 27 17:13:56.859: INFO: (7) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 92.952143ms)
Apr 27 17:13:56.859: INFO: (7) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 93.259041ms)
Apr 27 17:13:56.859: INFO: (7) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/tlsrewritem... (200; 93.474715ms)
Apr 27 17:13:56.859: INFO: (7) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/rewriteme">test</a> (200; 93.423748ms)
Apr 27 17:13:56.859: INFO: (7) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname1/proxy/: tls baz (200; 93.486053ms)
Apr 27 17:13:56.859: INFO: (7) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 93.426111ms)
Apr 27 17:13:56.860: INFO: (7) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname2/proxy/: tls qux (200; 94.421594ms)
Apr 27 17:13:56.862: INFO: (7) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname2/proxy/: bar (200; 96.114143ms)
Apr 27 17:13:56.863: INFO: (7) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname1/proxy/: foo (200; 97.320945ms)
Apr 27 17:13:56.863: INFO: (7) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname2/proxy/: bar (200; 97.234783ms)
Apr 27 17:13:56.863: INFO: (7) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname1/proxy/: foo (200; 97.301163ms)
Apr 27 17:13:56.956: INFO: (8) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 93.019697ms)
Apr 27 17:13:56.957: INFO: (8) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname1/proxy/: foo (200; 93.621963ms)
Apr 27 17:13:56.957: INFO: (8) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname2/proxy/: bar (200; 93.738289ms)
Apr 27 17:13:56.957: INFO: (8) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">test<... (200; 93.621746ms)
Apr 27 17:13:56.957: INFO: (8) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname2/proxy/: tls qux (200; 93.754058ms)
Apr 27 17:13:56.957: INFO: (8) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:462/proxy/: tls qux (200; 93.635519ms)
Apr 27 17:13:56.957: INFO: (8) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 93.679398ms)
Apr 27 17:13:56.957: INFO: (8) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">... (200; 93.907468ms)
Apr 27 17:13:56.957: INFO: (8) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/tlsrewritem... (200; 93.90923ms)
Apr 27 17:13:56.957: INFO: (8) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname1/proxy/: tls baz (200; 93.998547ms)
Apr 27 17:13:56.958: INFO: (8) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/rewriteme">test</a> (200; 94.280816ms)
Apr 27 17:13:56.958: INFO: (8) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:460/proxy/: tls baz (200; 94.299681ms)
Apr 27 17:13:56.959: INFO: (8) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 95.33486ms)
Apr 27 17:13:56.960: INFO: (8) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname1/proxy/: foo (200; 96.326051ms)
Apr 27 17:13:56.962: INFO: (8) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname2/proxy/: bar (200; 98.22837ms)
Apr 27 17:13:56.962: INFO: (8) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 98.177224ms)
Apr 27 17:13:57.054: INFO: (9) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 92.268135ms)
Apr 27 17:13:57.055: INFO: (9) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 92.980083ms)
Apr 27 17:13:57.055: INFO: (9) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">test<... (200; 92.990806ms)
Apr 27 17:13:57.055: INFO: (9) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">... (200; 93.088683ms)
Apr 27 17:13:57.055: INFO: (9) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 93.145955ms)
Apr 27 17:13:57.055: INFO: (9) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/rewriteme">test</a> (200; 93.058894ms)
Apr 27 17:13:57.055: INFO: (9) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:462/proxy/: tls qux (200; 93.14344ms)
Apr 27 17:13:57.056: INFO: (9) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname1/proxy/: foo (200; 93.773795ms)
Apr 27 17:13:57.057: INFO: (9) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname2/proxy/: tls qux (200; 94.632798ms)
Apr 27 17:13:57.057: INFO: (9) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/tlsrewritem... (200; 94.595121ms)
Apr 27 17:13:57.057: INFO: (9) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:460/proxy/: tls baz (200; 94.736822ms)
Apr 27 17:13:57.057: INFO: (9) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname1/proxy/: tls baz (200; 94.773447ms)
Apr 27 17:13:57.058: INFO: (9) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname2/proxy/: bar (200; 95.873429ms)
Apr 27 17:13:57.058: INFO: (9) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 95.796204ms)
Apr 27 17:13:57.059: INFO: (9) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname1/proxy/: foo (200; 97.61826ms)
Apr 27 17:13:57.059: INFO: (9) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname2/proxy/: bar (200; 97.576ms)
Apr 27 17:13:57.152: INFO: (10) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">test<... (200; 91.95605ms)
Apr 27 17:13:57.153: INFO: (10) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/rewriteme">test</a> (200; 93.828454ms)
Apr 27 17:13:57.154: INFO: (10) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 93.619863ms)
Apr 27 17:13:57.154: INFO: (10) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname1/proxy/: foo (200; 93.707996ms)
Apr 27 17:13:57.154: INFO: (10) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname1/proxy/: tls baz (200; 93.722802ms)
Apr 27 17:13:57.154: INFO: (10) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname2/proxy/: bar (200; 93.762734ms)
Apr 27 17:13:57.154: INFO: (10) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname2/proxy/: tls qux (200; 93.773948ms)
Apr 27 17:13:57.154: INFO: (10) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">... (200; 93.895403ms)
Apr 27 17:13:57.155: INFO: (10) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 95.133619ms)
Apr 27 17:13:57.155: INFO: (10) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:462/proxy/: tls qux (200; 95.500078ms)
Apr 27 17:13:57.155: INFO: (10) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:460/proxy/: tls baz (200; 95.467233ms)
Apr 27 17:13:57.155: INFO: (10) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/tlsrewritem... (200; 95.679784ms)
Apr 27 17:13:57.156: INFO: (10) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname2/proxy/: bar (200; 96.376643ms)
Apr 27 17:13:57.158: INFO: (10) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 98.224721ms)
Apr 27 17:13:57.158: INFO: (10) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 98.29425ms)
Apr 27 17:13:57.160: INFO: (10) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname1/proxy/: foo (200; 100.061939ms)
Apr 27 17:13:57.254: INFO: (11) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">test<... (200; 93.839749ms)
Apr 27 17:13:57.254: INFO: (11) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname1/proxy/: foo (200; 94.019153ms)
Apr 27 17:13:57.254: INFO: (11) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname1/proxy/: tls baz (200; 93.990175ms)
Apr 27 17:13:57.254: INFO: (11) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname2/proxy/: bar (200; 93.98528ms)
Apr 27 17:13:57.254: INFO: (11) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/rewriteme">test</a> (200; 93.890888ms)
Apr 27 17:13:57.254: INFO: (11) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:460/proxy/: tls baz (200; 93.829584ms)
Apr 27 17:13:57.254: INFO: (11) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname2/proxy/: tls qux (200; 93.98693ms)
Apr 27 17:13:57.254: INFO: (11) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 93.997786ms)
Apr 27 17:13:57.254: INFO: (11) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname1/proxy/: foo (200; 94.082181ms)
Apr 27 17:13:57.254: INFO: (11) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:462/proxy/: tls qux (200; 94.013616ms)
Apr 27 17:13:57.255: INFO: (11) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/tlsrewritem... (200; 95.285539ms)
Apr 27 17:13:57.255: INFO: (11) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">... (200; 95.377018ms)
Apr 27 17:13:57.256: INFO: (11) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname2/proxy/: bar (200; 96.367703ms)
Apr 27 17:13:57.258: INFO: (11) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 98.268874ms)
Apr 27 17:13:57.258: INFO: (11) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 98.537813ms)
Apr 27 17:13:57.258: INFO: (11) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 98.54742ms)
Apr 27 17:13:57.352: INFO: (12) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:462/proxy/: tls qux (200; 93.553469ms)
Apr 27 17:13:57.352: INFO: (12) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">... (200; 93.509729ms)
Apr 27 17:13:57.352: INFO: (12) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">test<... (200; 93.62644ms)
Apr 27 17:13:57.352: INFO: (12) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 93.550642ms)
Apr 27 17:13:57.352: INFO: (12) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 93.656731ms)
Apr 27 17:13:57.352: INFO: (12) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:460/proxy/: tls baz (200; 93.770225ms)
Apr 27 17:13:57.352: INFO: (12) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname2/proxy/: bar (200; 93.788009ms)
Apr 27 17:13:57.352: INFO: (12) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname2/proxy/: bar (200; 93.754469ms)
Apr 27 17:13:57.352: INFO: (12) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/rewriteme">test</a> (200; 93.828434ms)
Apr 27 17:13:57.352: INFO: (12) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/tlsrewritem... (200; 93.793871ms)
Apr 27 17:13:57.352: INFO: (12) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname1/proxy/: tls baz (200; 93.93913ms)
Apr 27 17:13:57.353: INFO: (12) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname2/proxy/: tls qux (200; 94.133596ms)
Apr 27 17:13:57.355: INFO: (12) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname1/proxy/: foo (200; 96.193745ms)
Apr 27 17:13:57.356: INFO: (12) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 97.080118ms)
Apr 27 17:13:57.356: INFO: (12) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname1/proxy/: foo (200; 97.079887ms)
Apr 27 17:13:57.357: INFO: (12) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 98.117677ms)
Apr 27 17:13:57.451: INFO: (13) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:462/proxy/: tls qux (200; 93.525319ms)
Apr 27 17:13:57.451: INFO: (13) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 93.714636ms)
Apr 27 17:13:57.451: INFO: (13) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname1/proxy/: foo (200; 93.554991ms)
Apr 27 17:13:57.451: INFO: (13) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 93.514967ms)
Apr 27 17:13:57.451: INFO: (13) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/tlsrewritem... (200; 93.702006ms)
Apr 27 17:13:57.451: INFO: (13) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:460/proxy/: tls baz (200; 93.977846ms)
Apr 27 17:13:57.451: INFO: (13) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">... (200; 94.040021ms)
Apr 27 17:13:57.451: INFO: (13) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname2/proxy/: tls qux (200; 93.867945ms)
Apr 27 17:13:57.451: INFO: (13) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/rewriteme">test</a> (200; 93.90495ms)
Apr 27 17:13:57.451: INFO: (13) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 93.950544ms)
Apr 27 17:13:57.451: INFO: (13) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname1/proxy/: tls baz (200; 93.88574ms)
Apr 27 17:13:57.451: INFO: (13) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">test<... (200; 94.005161ms)
Apr 27 17:13:57.493: INFO: (13) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname1/proxy/: foo (200; 136.476184ms)
Apr 27 17:13:57.493: INFO: (13) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 136.50272ms)
Apr 27 17:13:57.494: INFO: (13) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname2/proxy/: bar (200; 136.59573ms)
Apr 27 17:13:57.493: INFO: (13) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname2/proxy/: bar (200; 136.627294ms)
Apr 27 17:13:57.587: INFO: (14) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">test<... (200; 92.958258ms)
Apr 27 17:13:57.587: INFO: (14) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/rewriteme">test</a> (200; 93.319155ms)
Apr 27 17:13:57.587: INFO: (14) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname1/proxy/: foo (200; 93.364391ms)
Apr 27 17:13:57.587: INFO: (14) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname2/proxy/: bar (200; 93.25673ms)
Apr 27 17:13:57.587: INFO: (14) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname2/proxy/: tls qux (200; 93.377938ms)
Apr 27 17:13:57.587: INFO: (14) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname2/proxy/: bar (200; 93.322192ms)
Apr 27 17:13:57.588: INFO: (14) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:462/proxy/: tls qux (200; 93.847235ms)
Apr 27 17:13:57.588: INFO: (14) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname1/proxy/: foo (200; 94.035212ms)
Apr 27 17:13:57.588: INFO: (14) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:460/proxy/: tls baz (200; 94.059402ms)
Apr 27 17:13:57.588: INFO: (14) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname1/proxy/: tls baz (200; 93.952521ms)
Apr 27 17:13:57.588: INFO: (14) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/tlsrewritem... (200; 93.939694ms)
Apr 27 17:13:57.588: INFO: (14) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">... (200; 93.894473ms)
Apr 27 17:13:57.590: INFO: (14) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 96.397593ms)
Apr 27 17:13:57.590: INFO: (14) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 96.370633ms)
Apr 27 17:13:57.590: INFO: (14) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 96.372401ms)
Apr 27 17:13:57.590: INFO: (14) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 96.342187ms)
Apr 27 17:13:57.683: INFO: (15) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 92.937447ms)
Apr 27 17:13:57.683: INFO: (15) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 93.105791ms)
Apr 27 17:13:57.683: INFO: (15) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/rewriteme">test</a> (200; 92.948031ms)
Apr 27 17:13:57.683: INFO: (15) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">... (200; 92.94259ms)
Apr 27 17:13:57.683: INFO: (15) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:462/proxy/: tls qux (200; 92.936178ms)
Apr 27 17:13:57.683: INFO: (15) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:460/proxy/: tls baz (200; 92.988581ms)
Apr 27 17:13:57.684: INFO: (15) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname2/proxy/: bar (200; 93.415127ms)
Apr 27 17:13:57.684: INFO: (15) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">test<... (200; 93.425788ms)
Apr 27 17:13:57.684: INFO: (15) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname1/proxy/: foo (200; 93.52962ms)
Apr 27 17:13:57.684: INFO: (15) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/tlsrewritem... (200; 93.576084ms)
Apr 27 17:13:57.684: INFO: (15) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname2/proxy/: tls qux (200; 93.618234ms)
Apr 27 17:13:57.684: INFO: (15) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname1/proxy/: tls baz (200; 93.555206ms)
Apr 27 17:13:57.686: INFO: (15) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname1/proxy/: foo (200; 95.774219ms)
Apr 27 17:13:57.688: INFO: (15) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 97.972159ms)
Apr 27 17:13:57.688: INFO: (15) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname2/proxy/: bar (200; 97.894173ms)
Apr 27 17:13:57.688: INFO: (15) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 97.926004ms)
Apr 27 17:13:57.784: INFO: (16) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname1/proxy/: foo (200; 95.633871ms)
Apr 27 17:13:57.784: INFO: (16) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">... (200; 95.624041ms)
Apr 27 17:13:57.784: INFO: (16) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname2/proxy/: bar (200; 95.710987ms)
Apr 27 17:13:57.784: INFO: (16) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname2/proxy/: tls qux (200; 95.745058ms)
Apr 27 17:13:57.784: INFO: (16) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname2/proxy/: bar (200; 95.578874ms)
Apr 27 17:13:57.784: INFO: (16) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:462/proxy/: tls qux (200; 95.596988ms)
Apr 27 17:13:57.784: INFO: (16) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 95.649658ms)
Apr 27 17:13:57.784: INFO: (16) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname1/proxy/: tls baz (200; 95.680337ms)
Apr 27 17:13:57.785: INFO: (16) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/rewriteme">test</a> (200; 96.274731ms)
Apr 27 17:13:57.785: INFO: (16) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/tlsrewritem... (200; 96.252578ms)
Apr 27 17:13:57.785: INFO: (16) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">test<... (200; 96.285231ms)
Apr 27 17:13:57.785: INFO: (16) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:460/proxy/: tls baz (200; 96.333492ms)
Apr 27 17:13:57.787: INFO: (16) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 98.794906ms)
Apr 27 17:13:57.787: INFO: (16) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 98.712473ms)
Apr 27 17:13:57.787: INFO: (16) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname1/proxy/: foo (200; 98.851877ms)
Apr 27 17:13:57.787: INFO: (16) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 98.80216ms)
Apr 27 17:13:57.881: INFO: (17) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 93.252439ms)
Apr 27 17:13:57.881: INFO: (17) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:462/proxy/: tls qux (200; 93.365145ms)
Apr 27 17:13:57.881: INFO: (17) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/tlsrewritem... (200; 93.245265ms)
Apr 27 17:13:57.881: INFO: (17) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 93.373808ms)
Apr 27 17:13:57.881: INFO: (17) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:460/proxy/: tls baz (200; 93.307132ms)
Apr 27 17:13:57.882: INFO: (17) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 94.906611ms)
Apr 27 17:13:57.881: INFO: (17) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 93.343178ms)
Apr 27 17:13:57.881: INFO: (17) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">test<... (200; 93.300233ms)
Apr 27 17:13:57.881: INFO: (17) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">... (200; 93.336945ms)
Apr 27 17:13:57.883: INFO: (17) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname2/proxy/: tls qux (200; 95.455193ms)
Apr 27 17:13:57.883: INFO: (17) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname1/proxy/: tls baz (200; 95.430249ms)
Apr 27 17:13:57.883: INFO: (17) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/rewriteme">test</a> (200; 95.546585ms)
Apr 27 17:13:57.885: INFO: (17) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname1/proxy/: foo (200; 97.173159ms)
Apr 27 17:13:57.885: INFO: (17) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname2/proxy/: bar (200; 97.127869ms)
Apr 27 17:13:57.885: INFO: (17) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname2/proxy/: bar (200; 97.165889ms)
Apr 27 17:13:57.885: INFO: (17) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname1/proxy/: foo (200; 97.074217ms)
Apr 27 17:13:57.977: INFO: (18) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:460/proxy/: tls baz (200; 92.571696ms)
Apr 27 17:13:57.978: INFO: (18) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname2/proxy/: bar (200; 93.649659ms)
Apr 27 17:13:57.978: INFO: (18) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">test<... (200; 93.557184ms)
Apr 27 17:13:57.978: INFO: (18) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 93.561407ms)
Apr 27 17:13:57.978: INFO: (18) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/rewriteme">test</a> (200; 93.640949ms)
Apr 27 17:13:57.979: INFO: (18) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname1/proxy/: foo (200; 94.024831ms)
Apr 27 17:13:57.979: INFO: (18) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname1/proxy/: tls baz (200; 94.041859ms)
Apr 27 17:13:57.979: INFO: (18) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 94.07038ms)
Apr 27 17:13:57.979: INFO: (18) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">... (200; 94.042985ms)
Apr 27 17:13:57.979: INFO: (18) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname2/proxy/: tls qux (200; 94.277896ms)
Apr 27 17:13:57.979: INFO: (18) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:462/proxy/: tls qux (200; 94.257777ms)
Apr 27 17:13:57.979: INFO: (18) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/tlsrewritem... (200; 94.261953ms)
Apr 27 17:13:57.982: INFO: (18) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname2/proxy/: bar (200; 97.4538ms)
Apr 27 17:13:57.982: INFO: (18) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname1/proxy/: foo (200; 97.429378ms)
Apr 27 17:13:57.985: INFO: (18) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 100.209584ms)
Apr 27 17:13:57.985: INFO: (18) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 100.183922ms)
Apr 27 17:13:58.113: INFO: (19) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt/proxy/rewriteme">test</a> (200; 127.873268ms)
Apr 27 17:13:58.114: INFO: (19) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:460/proxy/: tls baz (200; 128.86597ms)
Apr 27 17:13:58.114: INFO: (19) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">test<... (200; 128.798104ms)
Apr 27 17:13:58.114: INFO: (19) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 128.72867ms)
Apr 27 17:13:58.115: INFO: (19) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname1/proxy/: foo (200; 129.342065ms)
Apr 27 17:13:58.115: INFO: (19) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:1080/proxy/rewriteme">... (200; 129.62628ms)
Apr 27 17:13:58.115: INFO: (19) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname1/proxy/: foo (200; 129.822929ms)
Apr 27 17:13:58.115: INFO: (19) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:162/proxy/: bar (200; 129.689812ms)
Apr 27 17:13:58.115: INFO: (19) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/: <a href="/api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:443/proxy/tlsrewritem... (200; 129.990877ms)
Apr 27 17:13:58.115: INFO: (19) /api/v1/namespaces/proxy-5706/pods/https:proxy-service-h6kj9-t9cjt:462/proxy/: tls qux (200; 130.083064ms)
Apr 27 17:13:58.115: INFO: (19) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname1/proxy/: tls baz (200; 130.158954ms)
Apr 27 17:13:58.115: INFO: (19) /api/v1/namespaces/proxy-5706/services/https:proxy-service-h6kj9:tlsportname2/proxy/: tls qux (200; 130.151833ms)
Apr 27 17:13:58.119: INFO: (19) /api/v1/namespaces/proxy-5706/pods/proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 133.495434ms)
Apr 27 17:13:58.119: INFO: (19) /api/v1/namespaces/proxy-5706/services/http:proxy-service-h6kj9:portname2/proxy/: bar (200; 133.581237ms)
Apr 27 17:13:58.119: INFO: (19) /api/v1/namespaces/proxy-5706/pods/http:proxy-service-h6kj9-t9cjt:160/proxy/: foo (200; 133.625694ms)
Apr 27 17:13:58.119: INFO: (19) /api/v1/namespaces/proxy-5706/services/proxy-service-h6kj9:portname2/proxy/: bar (200; 133.78409ms)
STEP: deleting ReplicationController proxy-service-h6kj9 in namespace proxy-5706, will wait for the garbage collector to delete the pods
Apr 27 17:13:58.402: INFO: Deleting ReplicationController proxy-service-h6kj9 took: 91.152043ms
Apr 27 17:13:59.002: INFO: Terminating ReplicationController proxy-service-h6kj9 pods took: 600.367255ms
[AfterEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:02.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5706" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":277,"completed":227,"skipped":3901,"failed":0}
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:02.885: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2055
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating all guestbook components
Apr 27 17:14:03.525: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-slave
  labels:
    app: agnhost
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: slave
    tier: backend

Apr 27 17:14:03.525: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-2055'
Apr 27 17:14:04.396: INFO: stderr: ""
Apr 27 17:14:04.396: INFO: stdout: "service/agnhost-slave created\n"
Apr 27 17:14:04.397: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-master
  labels:
    app: agnhost
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: master
    tier: backend

Apr 27 17:14:04.397: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-2055'
Apr 27 17:14:05.313: INFO: stderr: ""
Apr 27 17:14:05.313: INFO: stdout: "service/agnhost-master created\n"
Apr 27 17:14:05.314: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr 27 17:14:05.314: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-2055'
Apr 27 17:14:05.838: INFO: stderr: ""
Apr 27 17:14:05.838: INFO: stdout: "service/frontend created\n"
Apr 27 17:14:05.839: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Apr 27 17:14:05.839: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-2055'
Apr 27 17:14:06.366: INFO: stderr: ""
Apr 27 17:14:06.366: INFO: stdout: "deployment.apps/frontend created\n"
Apr 27 17:14:06.366: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 27 17:14:06.366: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-2055'
Apr 27 17:14:07.245: INFO: stderr: ""
Apr 27 17:14:07.245: INFO: stdout: "deployment.apps/agnhost-master created\n"
Apr 27 17:14:07.245: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--slaveof", "agnhost-master", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 27 17:14:07.245: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-2055'
Apr 27 17:14:08.103: INFO: stderr: ""
Apr 27 17:14:08.103: INFO: stdout: "deployment.apps/agnhost-slave created\n"
STEP: validating guestbook app
Apr 27 17:14:08.103: INFO: Waiting for all frontend pods to be Running.
Apr 27 17:14:13.204: INFO: Waiting for frontend to serve content.
Apr 27 17:14:13.387: INFO: Trying to add a new entry to the guestbook.
Apr 27 17:14:13.567: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Apr 27 17:14:13.747: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2055'
Apr 27 17:14:14.183: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 17:14:14.183: INFO: stdout: "service \"agnhost-slave\" force deleted\n"
STEP: using delete to clean up resources
Apr 27 17:14:14.183: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2055'
Apr 27 17:14:14.621: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 17:14:14.621: INFO: stdout: "service \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 27 17:14:14.621: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2055'
Apr 27 17:14:15.064: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 17:14:15.064: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 27 17:14:15.064: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2055'
Apr 27 17:14:15.520: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 17:14:15.520: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 27 17:14:15.520: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2055'
Apr 27 17:14:15.948: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 17:14:15.948: INFO: stdout: "deployment.apps \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 27 17:14:15.948: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2055'
Apr 27 17:14:16.369: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 17:14:16.369: INFO: stdout: "deployment.apps \"agnhost-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:16.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2055" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":277,"completed":228,"skipped":3911,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:16.551: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7200
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0427 17:14:28.466716    7325 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 27 17:14:28.466: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:28.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7200" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":277,"completed":229,"skipped":3916,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:28.649: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2954
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-2954
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-2954
I0427 17:14:29.655027    7325 runners.go:190] Created replication controller with name: externalname-service, namespace: services-2954, replica count: 2
Apr 27 17:14:32.755: INFO: Creating new exec pod
I0427 17:14:32.755666    7325 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 27 17:14:36.027: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-2954 execpodtd7qk -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Apr 27 17:14:37.123: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 27 17:14:37.124: INFO: stdout: ""
Apr 27 17:14:37.124: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-2954 execpodtd7qk -- /bin/sh -x -c nc -zv -t -w 2 100.104.116.228 80'
Apr 27 17:14:38.197: INFO: stderr: "+ nc -zv -t -w 2 100.104.116.228 80\nConnection to 100.104.116.228 80 port [tcp/http] succeeded!\n"
Apr 27 17:14:38.197: INFO: stdout: ""
Apr 27 17:14:38.197: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:38.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2954" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":277,"completed":230,"skipped":3975,"failed":0}
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:38.475: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8522
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting the proxy server
Apr 27 17:14:39.117: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:39.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8522" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":277,"completed":231,"skipped":3984,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:39.623: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1762
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Apr 27 17:14:40.263: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Apr 27 17:14:58.516: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 17:15:02.626: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:15:19.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1762" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":277,"completed":232,"skipped":3992,"failed":0}
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:15:19.863: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2038
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 27 17:15:25.510: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 17:15:25.600: INFO: Pod pod-with-poststart-http-hook still exists
Apr 27 17:15:27.600: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 17:15:27.691: INFO: Pod pod-with-poststart-http-hook still exists
Apr 27 17:15:29.600: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 17:15:29.691: INFO: Pod pod-with-poststart-http-hook still exists
Apr 27 17:15:31.600: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 17:15:31.690: INFO: Pod pod-with-poststart-http-hook still exists
Apr 27 17:15:33.600: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 17:15:33.691: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:15:33.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2038" for this suite.
•{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":277,"completed":233,"skipped":3995,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:15:33.875: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-6117
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:15:34.607: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-e050cc8a-b20b-4603-abb3-042e05315add" in namespace "security-context-test-6117" to be "Succeeded or Failed"
Apr 27 17:15:34.697: INFO: Pod "alpine-nnp-false-e050cc8a-b20b-4603-abb3-042e05315add": Phase="Pending", Reason="", readiness=false. Elapsed: 89.76491ms
Apr 27 17:15:36.787: INFO: Pod "alpine-nnp-false-e050cc8a-b20b-4603-abb3-042e05315add": Phase="Pending", Reason="", readiness=false. Elapsed: 2.179692299s
Apr 27 17:15:38.877: INFO: Pod "alpine-nnp-false-e050cc8a-b20b-4603-abb3-042e05315add": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.269790659s
Apr 27 17:15:38.877: INFO: Pod "alpine-nnp-false-e050cc8a-b20b-4603-abb3-042e05315add" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:15:38.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6117" for this suite.
•{"msg":"PASSED [k8s.io] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":234,"skipped":4046,"failed":0}
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:15:39.155: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-301
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-301.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-301.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-301.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-301.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 17:15:42.526: INFO: DNS probes using dns-test-e3fdef1e-8f44-42a9-8746-1c84fff1cbaf succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-301.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-301.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-301.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-301.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 17:15:45.343: INFO: File wheezy_udp@dns-test-service-3.dns-301.svc.cluster.local from pod  dns-301/dns-test-fd6a5a98-496a-4e7b-9e83-a55826502a16 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 17:15:45.437: INFO: File jessie_udp@dns-test-service-3.dns-301.svc.cluster.local from pod  dns-301/dns-test-fd6a5a98-496a-4e7b-9e83-a55826502a16 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 17:15:45.437: INFO: Lookups using dns-301/dns-test-fd6a5a98-496a-4e7b-9e83-a55826502a16 failed for: [wheezy_udp@dns-test-service-3.dns-301.svc.cluster.local jessie_udp@dns-test-service-3.dns-301.svc.cluster.local]

Apr 27 17:15:50.532: INFO: File wheezy_udp@dns-test-service-3.dns-301.svc.cluster.local from pod  dns-301/dns-test-fd6a5a98-496a-4e7b-9e83-a55826502a16 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 17:15:50.627: INFO: File jessie_udp@dns-test-service-3.dns-301.svc.cluster.local from pod  dns-301/dns-test-fd6a5a98-496a-4e7b-9e83-a55826502a16 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 17:15:50.627: INFO: Lookups using dns-301/dns-test-fd6a5a98-496a-4e7b-9e83-a55826502a16 failed for: [wheezy_udp@dns-test-service-3.dns-301.svc.cluster.local jessie_udp@dns-test-service-3.dns-301.svc.cluster.local]

Apr 27 17:15:55.535: INFO: File wheezy_udp@dns-test-service-3.dns-301.svc.cluster.local from pod  dns-301/dns-test-fd6a5a98-496a-4e7b-9e83-a55826502a16 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 17:15:55.629: INFO: File jessie_udp@dns-test-service-3.dns-301.svc.cluster.local from pod  dns-301/dns-test-fd6a5a98-496a-4e7b-9e83-a55826502a16 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 17:15:55.630: INFO: Lookups using dns-301/dns-test-fd6a5a98-496a-4e7b-9e83-a55826502a16 failed for: [wheezy_udp@dns-test-service-3.dns-301.svc.cluster.local jessie_udp@dns-test-service-3.dns-301.svc.cluster.local]

Apr 27 17:16:00.532: INFO: File wheezy_udp@dns-test-service-3.dns-301.svc.cluster.local from pod  dns-301/dns-test-fd6a5a98-496a-4e7b-9e83-a55826502a16 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 17:16:00.627: INFO: File jessie_udp@dns-test-service-3.dns-301.svc.cluster.local from pod  dns-301/dns-test-fd6a5a98-496a-4e7b-9e83-a55826502a16 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 17:16:00.627: INFO: Lookups using dns-301/dns-test-fd6a5a98-496a-4e7b-9e83-a55826502a16 failed for: [wheezy_udp@dns-test-service-3.dns-301.svc.cluster.local jessie_udp@dns-test-service-3.dns-301.svc.cluster.local]

Apr 27 17:16:05.532: INFO: File wheezy_udp@dns-test-service-3.dns-301.svc.cluster.local from pod  dns-301/dns-test-fd6a5a98-496a-4e7b-9e83-a55826502a16 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 17:16:05.627: INFO: File jessie_udp@dns-test-service-3.dns-301.svc.cluster.local from pod  dns-301/dns-test-fd6a5a98-496a-4e7b-9e83-a55826502a16 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 17:16:05.627: INFO: Lookups using dns-301/dns-test-fd6a5a98-496a-4e7b-9e83-a55826502a16 failed for: [wheezy_udp@dns-test-service-3.dns-301.svc.cluster.local jessie_udp@dns-test-service-3.dns-301.svc.cluster.local]

Apr 27 17:16:10.532: INFO: File wheezy_udp@dns-test-service-3.dns-301.svc.cluster.local from pod  dns-301/dns-test-fd6a5a98-496a-4e7b-9e83-a55826502a16 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 17:16:10.629: INFO: File jessie_udp@dns-test-service-3.dns-301.svc.cluster.local from pod  dns-301/dns-test-fd6a5a98-496a-4e7b-9e83-a55826502a16 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 17:16:10.629: INFO: Lookups using dns-301/dns-test-fd6a5a98-496a-4e7b-9e83-a55826502a16 failed for: [wheezy_udp@dns-test-service-3.dns-301.svc.cluster.local jessie_udp@dns-test-service-3.dns-301.svc.cluster.local]

Apr 27 17:16:15.626: INFO: DNS probes using dns-test-fd6a5a98-496a-4e7b-9e83-a55826502a16 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-301.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-301.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-301.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-301.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 17:16:18.700: INFO: DNS probes using dns-test-16d8ffe7-8b2c-4368-9599-c94187139aa8 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:16:18.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-301" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":277,"completed":235,"skipped":4053,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:16:19.070: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3648
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-3183979d-349b-47d7-9421-63c0e790f458
STEP: Creating a pod to test consume secrets
Apr 27 17:16:19.892: INFO: Waiting up to 5m0s for pod "pod-secrets-60f9e240-bbaa-4f67-8cb5-66fa18db5ab3" in namespace "secrets-3648" to be "Succeeded or Failed"
Apr 27 17:16:19.983: INFO: Pod "pod-secrets-60f9e240-bbaa-4f67-8cb5-66fa18db5ab3": Phase="Pending", Reason="", readiness=false. Elapsed: 90.238397ms
Apr 27 17:16:22.073: INFO: Pod "pod-secrets-60f9e240-bbaa-4f67-8cb5-66fa18db5ab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180700195s
STEP: Saw pod success
Apr 27 17:16:22.073: INFO: Pod "pod-secrets-60f9e240-bbaa-4f67-8cb5-66fa18db5ab3" satisfied condition "Succeeded or Failed"
Apr 27 17:16:22.163: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-secrets-60f9e240-bbaa-4f67-8cb5-66fa18db5ab3 container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:16:22.354: INFO: Waiting for pod pod-secrets-60f9e240-bbaa-4f67-8cb5-66fa18db5ab3 to disappear
Apr 27 17:16:22.443: INFO: Pod pod-secrets-60f9e240-bbaa-4f67-8cb5-66fa18db5ab3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:16:22.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3648" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":236,"skipped":4079,"failed":0}
SSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:16:22.626: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9588
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-9588
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-9588
STEP: creating replication controller externalsvc in namespace services-9588
I0427 17:16:23.542725    7325 runners.go:190] Created replication controller with name: externalsvc, namespace: services-9588, replica count: 2
I0427 17:16:26.643305    7325 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Apr 27 17:16:26.918: INFO: Creating new exec pod
Apr 27 17:16:29.189: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-9588 execpodknj86 -- /bin/sh -x -c nslookup clusterip-service'
Apr 27 17:16:30.802: INFO: stderr: "+ nslookup clusterip-service\n"
Apr 27 17:16:30.802: INFO: stdout: "Server:\t\t100.104.0.10\nAddress:\t100.104.0.10#53\n\nclusterip-service.services-9588.svc.cluster.local\tcanonical name = externalsvc.services-9588.svc.cluster.local.\nName:\texternalsvc.services-9588.svc.cluster.local\nAddress: 100.107.42.152\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-9588, will wait for the garbage collector to delete the pods
Apr 27 17:16:31.084: INFO: Deleting ReplicationController externalsvc took: 91.384787ms
Apr 27 17:16:31.684: INFO: Terminating ReplicationController externalsvc pods took: 600.408787ms
Apr 27 17:16:42.780: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:16:42.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9588" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":277,"completed":237,"skipped":4083,"failed":0}
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:16:43.054: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-4189
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's args
Apr 27 17:16:43.786: INFO: Waiting up to 5m0s for pod "var-expansion-842bc050-398a-47b5-93d8-eed50fe7b21b" in namespace "var-expansion-4189" to be "Succeeded or Failed"
Apr 27 17:16:43.876: INFO: Pod "var-expansion-842bc050-398a-47b5-93d8-eed50fe7b21b": Phase="Pending", Reason="", readiness=false. Elapsed: 89.963137ms
Apr 27 17:16:45.966: INFO: Pod "var-expansion-842bc050-398a-47b5-93d8-eed50fe7b21b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180421239s
STEP: Saw pod success
Apr 27 17:16:45.967: INFO: Pod "var-expansion-842bc050-398a-47b5-93d8-eed50fe7b21b" satisfied condition "Succeeded or Failed"
Apr 27 17:16:46.056: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod var-expansion-842bc050-398a-47b5-93d8-eed50fe7b21b container dapi-container: <nil>
STEP: delete the pod
Apr 27 17:16:46.247: INFO: Waiting for pod var-expansion-842bc050-398a-47b5-93d8-eed50fe7b21b to disappear
Apr 27 17:16:46.337: INFO: Pod var-expansion-842bc050-398a-47b5-93d8-eed50fe7b21b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:16:46.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4189" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":277,"completed":238,"skipped":4087,"failed":0}
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:16:46.519: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5760
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-4b219a7c-8de1-4770-9389-4af84e474164
STEP: Creating a pod to test consume configMaps
Apr 27 17:16:47.341: INFO: Waiting up to 5m0s for pod "pod-configmaps-44f2f5cb-f7f7-44fd-82dd-365bda6844b4" in namespace "configmap-5760" to be "Succeeded or Failed"
Apr 27 17:16:47.432: INFO: Pod "pod-configmaps-44f2f5cb-f7f7-44fd-82dd-365bda6844b4": Phase="Pending", Reason="", readiness=false. Elapsed: 90.020988ms
Apr 27 17:16:49.522: INFO: Pod "pod-configmaps-44f2f5cb-f7f7-44fd-82dd-365bda6844b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180438585s
STEP: Saw pod success
Apr 27 17:16:49.522: INFO: Pod "pod-configmaps-44f2f5cb-f7f7-44fd-82dd-365bda6844b4" satisfied condition "Succeeded or Failed"
Apr 27 17:16:49.612: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-configmaps-44f2f5cb-f7f7-44fd-82dd-365bda6844b4 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 17:16:49.801: INFO: Waiting for pod pod-configmaps-44f2f5cb-f7f7-44fd-82dd-365bda6844b4 to disappear
Apr 27 17:16:49.891: INFO: Pod pod-configmaps-44f2f5cb-f7f7-44fd-82dd-365bda6844b4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:16:49.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5760" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":239,"skipped":4092,"failed":0}
SSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:16:50.073: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2075
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 27 17:16:53.848: INFO: Successfully updated pod "pod-update-7864605b-b06d-4aee-83e6-fc0a58bf9085"
STEP: verifying the updated pod is in kubernetes
Apr 27 17:16:54.028: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:16:54.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2075" for this suite.
•{"msg":"PASSED [k8s.io] Pods should be updated [NodeConformance] [Conformance]","total":277,"completed":240,"skipped":4097,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:16:54.214: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4416
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Apr 27 17:16:54.853: INFO: namespace kubectl-4416
Apr 27 17:16:54.853: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-4416'
Apr 27 17:16:55.727: INFO: stderr: ""
Apr 27 17:16:55.728: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Apr 27 17:16:56.818: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:16:56.818: INFO: Found 0 / 1
Apr 27 17:16:57.818: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:16:57.818: INFO: Found 1 / 1
Apr 27 17:16:57.818: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 27 17:16:57.909: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:16:57.909: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 27 17:16:57.909: INFO: wait on agnhost-master startup in kubectl-4416 
Apr 27 17:16:57.909: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs agnhost-master-97jsn agnhost-master --namespace=kubectl-4416'
Apr 27 17:16:58.444: INFO: stderr: ""
Apr 27 17:16:58.444: INFO: stdout: "Paused\n"
STEP: exposing RC
Apr 27 17:16:58.444: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config expose rc agnhost-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-4416'
Apr 27 17:16:58.907: INFO: stderr: ""
Apr 27 17:16:58.907: INFO: stdout: "service/rm2 exposed\n"
Apr 27 17:16:58.997: INFO: Service rm2 in namespace kubectl-4416 found.
STEP: exposing service
Apr 27 17:17:01.177: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-4416'
Apr 27 17:17:01.627: INFO: stderr: ""
Apr 27 17:17:01.627: INFO: stdout: "service/rm3 exposed\n"
Apr 27 17:17:01.720: INFO: Service rm3 in namespace kubectl-4416 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:17:03.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4416" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":277,"completed":241,"skipped":4098,"failed":0}
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:17:04.084: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8049
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Apr 27 17:17:04.723: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:17:07.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8049" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":277,"completed":242,"skipped":4099,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:17:07.337: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1799
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:17:07.977: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:17:13.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1799" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":277,"completed":243,"skipped":4112,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:17:13.208: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1873
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-secret-sd2q
STEP: Creating a pod to test atomic-volume-subpath
Apr 27 17:17:14.262: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-sd2q" in namespace "subpath-1873" to be "Succeeded or Failed"
Apr 27 17:17:14.353: INFO: Pod "pod-subpath-test-secret-sd2q": Phase="Pending", Reason="", readiness=false. Elapsed: 90.288579ms
Apr 27 17:17:16.444: INFO: Pod "pod-subpath-test-secret-sd2q": Phase="Running", Reason="", readiness=true. Elapsed: 2.181307529s
Apr 27 17:17:18.534: INFO: Pod "pod-subpath-test-secret-sd2q": Phase="Running", Reason="", readiness=true. Elapsed: 4.271576529s
Apr 27 17:17:20.625: INFO: Pod "pod-subpath-test-secret-sd2q": Phase="Running", Reason="", readiness=true. Elapsed: 6.362662261s
Apr 27 17:17:22.716: INFO: Pod "pod-subpath-test-secret-sd2q": Phase="Running", Reason="", readiness=true. Elapsed: 8.45341771s
Apr 27 17:17:24.807: INFO: Pod "pod-subpath-test-secret-sd2q": Phase="Running", Reason="", readiness=true. Elapsed: 10.544153078s
Apr 27 17:17:26.897: INFO: Pod "pod-subpath-test-secret-sd2q": Phase="Running", Reason="", readiness=true. Elapsed: 12.634460036s
Apr 27 17:17:28.987: INFO: Pod "pod-subpath-test-secret-sd2q": Phase="Running", Reason="", readiness=true. Elapsed: 14.724875159s
Apr 27 17:17:31.078: INFO: Pod "pod-subpath-test-secret-sd2q": Phase="Running", Reason="", readiness=true. Elapsed: 16.81540859s
Apr 27 17:17:33.169: INFO: Pod "pod-subpath-test-secret-sd2q": Phase="Running", Reason="", readiness=true. Elapsed: 18.906158286s
Apr 27 17:17:35.259: INFO: Pod "pod-subpath-test-secret-sd2q": Phase="Running", Reason="", readiness=true. Elapsed: 20.996805071s
Apr 27 17:17:37.350: INFO: Pod "pod-subpath-test-secret-sd2q": Phase="Succeeded", Reason="", readiness=false. Elapsed: 23.087654984s
STEP: Saw pod success
Apr 27 17:17:37.350: INFO: Pod "pod-subpath-test-secret-sd2q" satisfied condition "Succeeded or Failed"
Apr 27 17:17:37.440: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-subpath-test-secret-sd2q container test-container-subpath-secret-sd2q: <nil>
STEP: delete the pod
Apr 27 17:17:37.630: INFO: Waiting for pod pod-subpath-test-secret-sd2q to disappear
Apr 27 17:17:37.720: INFO: Pod pod-subpath-test-secret-sd2q no longer exists
STEP: Deleting pod pod-subpath-test-secret-sd2q
Apr 27 17:17:37.720: INFO: Deleting pod "pod-subpath-test-secret-sd2q" in namespace "subpath-1873"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:17:37.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1873" for this suite.
•{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [LinuxOnly] [Conformance]","total":277,"completed":244,"skipped":4129,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:17:37.993: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-204
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on tmpfs
Apr 27 17:17:38.727: INFO: Waiting up to 5m0s for pod "pod-af7fee21-3e16-4873-ae59-e92fbe624663" in namespace "emptydir-204" to be "Succeeded or Failed"
Apr 27 17:17:38.817: INFO: Pod "pod-af7fee21-3e16-4873-ae59-e92fbe624663": Phase="Pending", Reason="", readiness=false. Elapsed: 89.962454ms
Apr 27 17:17:40.907: INFO: Pod "pod-af7fee21-3e16-4873-ae59-e92fbe624663": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180365306s
STEP: Saw pod success
Apr 27 17:17:40.907: INFO: Pod "pod-af7fee21-3e16-4873-ae59-e92fbe624663" satisfied condition "Succeeded or Failed"
Apr 27 17:17:40.997: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-af7fee21-3e16-4873-ae59-e92fbe624663 container test-container: <nil>
STEP: delete the pod
Apr 27 17:17:41.186: INFO: Waiting for pod pod-af7fee21-3e16-4873-ae59-e92fbe624663 to disappear
Apr 27 17:17:41.275: INFO: Pod pod-af7fee21-3e16-4873-ae59-e92fbe624663 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:17:41.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-204" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":245,"skipped":4144,"failed":0}
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:17:41.458: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8856
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl replace
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Apr 27 17:17:42.100: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-pod --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-8856'
Apr 27 17:17:42.458: INFO: stderr: ""
Apr 27 17:17:42.458: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Apr 27 17:17:47.559: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod e2e-test-httpd-pod --namespace=kubectl-8856 -o json'
Apr 27 17:17:47.918: INFO: stderr: ""
Apr 27 17:17:47.918: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"100.64.1.93/32\",\n            \"cni.projectcalico.org/podIPs\": \"100.64.1.93/32\",\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2020-04-27T17:17:42Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"managedFields\": [\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:labels\": {\n                            \".\": {},\n                            \"f:run\": {}\n                        }\n                    },\n                    \"f:spec\": {\n                        \"f:containers\": {\n                            \"k:{\\\"name\\\":\\\"e2e-test-httpd-pod\\\"}\": {\n                                \".\": {},\n                                \"f:image\": {},\n                                \"f:imagePullPolicy\": {},\n                                \"f:name\": {},\n                                \"f:resources\": {},\n                                \"f:terminationMessagePath\": {},\n                                \"f:terminationMessagePolicy\": {}\n                            }\n                        },\n                        \"f:dnsPolicy\": {},\n                        \"f:enableServiceLinks\": {},\n                        \"f:restartPolicy\": {},\n                        \"f:schedulerName\": {},\n                        \"f:securityContext\": {},\n                        \"f:terminationGracePeriodSeconds\": {}\n                    }\n                },\n                \"manager\": \"kubectl\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-04-27T17:17:42Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:annotations\": {\n                            \"f:cni.projectcalico.org/podIP\": {},\n                            \"f:cni.projectcalico.org/podIPs\": {}\n                        }\n                    }\n                },\n                \"manager\": \"calico\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-04-27T17:17:43Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:status\": {\n                        \"f:conditions\": {\n                            \"k:{\\\"type\\\":\\\"ContainersReady\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Initialized\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Ready\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            }\n                        },\n                        \"f:containerStatuses\": {},\n                        \"f:hostIP\": {},\n                        \"f:phase\": {},\n                        \"f:podIP\": {},\n                        \"f:podIPs\": {\n                            \".\": {},\n                            \"k:{\\\"ip\\\":\\\"100.64.1.93\\\"}\": {\n                                \".\": {},\n                                \"f:ip\": {}\n                            }\n                        },\n                        \"f:startTime\": {}\n                    }\n                },\n                \"manager\": \"kubelet\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-04-27T17:17:43Z\"\n            }\n        ],\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-8856\",\n        \"resourceVersion\": \"36057\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-8856/pods/e2e-test-httpd-pod\",\n        \"uid\": \"f73b1d03-75ac-4656-8bed-78e7f8a4cdcc\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-npn5g\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-250-10-186.ec2.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-npn5g\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-npn5g\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-27T17:17:42Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-27T17:17:43Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-27T17:17:43Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-27T17:17:42Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://17fb678ab39af575b5ff873067bc01bb45d211c2d84c153f0866267a59d15910\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-04-27T17:17:43Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.10.186\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.64.1.93\",\n        \"podIPs\": [\n            {\n                \"ip\": \"100.64.1.93\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-04-27T17:17:42Z\"\n    }\n}\n"
STEP: replace the image in the pod
Apr 27 17:17:47.919: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config replace -f - --namespace=kubectl-8856'
Apr 27 17:17:48.826: INFO: stderr: ""
Apr 27 17:17:48.826: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Apr 27 17:17:48.917: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmlf4-s1n.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pods e2e-test-httpd-pod --namespace=kubectl-8856'
Apr 27 17:17:52.663: INFO: stderr: ""
Apr 27 17:17:52.663: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:17:52.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8856" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":277,"completed":246,"skipped":4153,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:17:52.848: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5005
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Apr 27 17:17:56.720: INFO: Successfully updated pod "annotationupdatefbbb4e1d-2d01-4876-9bf0-02d4ef0b2b18"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:17:58.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5005" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":277,"completed":247,"skipped":4171,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:17:59.099: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4264
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:18:01.106: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604680, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604680, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604680, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604680, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:18:03.196: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604680, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604680, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604680, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604680, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:18:06.290: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Apr 27 17:18:06.663: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:18:06.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4264" for this suite.
STEP: Destroying namespace "webhook-4264-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":277,"completed":248,"skipped":4190,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:18:07.532: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2278
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:18:08.262: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eff82c4e-83a9-461f-84c5-f8f46038cadd" in namespace "downward-api-2278" to be "Succeeded or Failed"
Apr 27 17:18:08.352: INFO: Pod "downwardapi-volume-eff82c4e-83a9-461f-84c5-f8f46038cadd": Phase="Pending", Reason="", readiness=false. Elapsed: 89.782978ms
Apr 27 17:18:10.443: INFO: Pod "downwardapi-volume-eff82c4e-83a9-461f-84c5-f8f46038cadd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180211417s
STEP: Saw pod success
Apr 27 17:18:10.443: INFO: Pod "downwardapi-volume-eff82c4e-83a9-461f-84c5-f8f46038cadd" satisfied condition "Succeeded or Failed"
Apr 27 17:18:10.533: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod downwardapi-volume-eff82c4e-83a9-461f-84c5-f8f46038cadd container client-container: <nil>
STEP: delete the pod
Apr 27 17:18:10.751: INFO: Waiting for pod downwardapi-volume-eff82c4e-83a9-461f-84c5-f8f46038cadd to disappear
Apr 27 17:18:10.840: INFO: Pod downwardapi-volume-eff82c4e-83a9-461f-84c5-f8f46038cadd no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:18:10.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2278" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":277,"completed":249,"skipped":4191,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:18:11.023: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7673
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:18:11.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7673" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":277,"completed":250,"skipped":4199,"failed":0}
SSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:18:12.025: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-3419
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Apr 27 17:18:15.113: INFO: &Pod{ObjectMeta:{send-events-c5537c7a-814c-48bd-abca-6acad29fd28d  events-3419 /api/v1/namespaces/events-3419/pods/send-events-c5537c7a-814c-48bd-abca-6acad29fd28d d5aa0445-d51b-4c22-a99b-b2019a6fad18 36323 0 2020-04-27 17:18:12 +0000 UTC <nil> <nil> map[name:foo time:661974078] map[cni.projectcalico.org/podIP:100.64.1.97/32 cni.projectcalico.org/podIPs:100.64.1.97/32 kubernetes.io/psp:e2e-test-privileged-psp] [] []  [{e2e.test Update v1 2020-04-27 17:18:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 116 105 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 112 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 114 116 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 99 111 110 116 97 105 110 101 114 80 111 114 116 92 34 58 56 48 44 92 34 112 114 111 116 111 99 111 108 92 34 58 92 34 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 99 111 110 116 97 105 110 101 114 80 111 114 116 34 58 123 125 44 34 102 58 112 114 111 116 111 99 111 108 34 58 123 125 125 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:18:13 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:18:13 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 57 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-xfxdd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-xfxdd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-xfxdd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:18:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:18:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:18:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:18:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:100.64.1.97,StartTime:2020-04-27 17:18:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:18:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://99782b467920f4b3f6350fe9d75ed423d2a01c2a1d07b1826e2c3ad91bc09ffd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.97,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Apr 27 17:18:17.204: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Apr 27 17:18:19.295: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:18:19.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-3419" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]","total":277,"completed":251,"skipped":4212,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:18:19.568: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1049
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-1049
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 27 17:18:20.206: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 27 17:18:20.661: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 17:18:22.751: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:18:24.751: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:18:26.751: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:18:28.751: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:18:30.751: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:18:32.751: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:18:34.751: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:18:36.751: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:18:38.751: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:18:40.751: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr 27 17:18:40.931: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Apr 27 17:18:43.741: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.1.98:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1049 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 17:18:43.741: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 17:18:44.519: INFO: Found all expected endpoints: [netserver-0]
Apr 27 17:18:44.608: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.0.52:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1049 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 17:18:44.609: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 17:18:45.362: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:18:45.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1049" for this suite.
•{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":252,"skipped":4253,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:18:45.544: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5388
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-69bdbdf7-513b-44e2-a0a4-5766cc776bd0
STEP: Creating a pod to test consume configMaps
Apr 27 17:18:46.427: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b2088501-8aa8-4e9a-94fd-663e1198be8b" in namespace "projected-5388" to be "Succeeded or Failed"
Apr 27 17:18:46.526: INFO: Pod "pod-projected-configmaps-b2088501-8aa8-4e9a-94fd-663e1198be8b": Phase="Pending", Reason="", readiness=false. Elapsed: 98.448927ms
Apr 27 17:18:48.616: INFO: Pod "pod-projected-configmaps-b2088501-8aa8-4e9a-94fd-663e1198be8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.188576396s
STEP: Saw pod success
Apr 27 17:18:48.616: INFO: Pod "pod-projected-configmaps-b2088501-8aa8-4e9a-94fd-663e1198be8b" satisfied condition "Succeeded or Failed"
Apr 27 17:18:48.706: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-projected-configmaps-b2088501-8aa8-4e9a-94fd-663e1198be8b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 17:18:48.897: INFO: Waiting for pod pod-projected-configmaps-b2088501-8aa8-4e9a-94fd-663e1198be8b to disappear
Apr 27 17:18:48.986: INFO: Pod pod-projected-configmaps-b2088501-8aa8-4e9a-94fd-663e1198be8b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:18:48.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5388" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":253,"skipped":4281,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:18:49.169: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6216
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Apr 27 17:18:49.807: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 27 17:18:50.079: INFO: Waiting for terminating namespaces to be deleted...
Apr 27 17:18:50.169: INFO: 
Logging pods the kubelet thinks is on node ip-10-250-10-186.ec2.internal before test
Apr 27 17:18:50.271: INFO: node-problem-detector-f7dh2 from kube-system started at 2020-04-27 15:54:02 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.271: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 17:18:50.271: INFO: netserver-0 from pod-network-test-1049 started at 2020-04-27 17:18:20 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.271: INFO: 	Container webserver ready: true, restart count 0
Apr 27 17:18:50.271: INFO: send-events-c5537c7a-814c-48bd-abca-6acad29fd28d from events-3419 started at 2020-04-27 17:18:12 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.271: INFO: 	Container p ready: false, restart count 0
Apr 27 17:18:50.271: INFO: kube-proxy-f8lnb from kube-system started at 2020-04-27 15:54:02 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.271: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 17:18:50.271: INFO: csi-driver-node-qjp4d from kube-system started at 2020-04-27 15:54:02 +0000 UTC (3 container statuses recorded)
Apr 27 17:18:50.271: INFO: 	Container csi-driver ready: true, restart count 0
Apr 27 17:18:50.271: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 27 17:18:50.271: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 27 17:18:50.271: INFO: test-container-pod from pod-network-test-1049 started at 2020-04-27 17:18:41 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.271: INFO: 	Container webserver ready: true, restart count 0
Apr 27 17:18:50.271: INFO: host-test-container-pod from pod-network-test-1049 started at 2020-04-27 17:18:41 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.271: INFO: 	Container agnhost ready: true, restart count 0
Apr 27 17:18:50.271: INFO: node-exporter-zggrn from kube-system started at 2020-04-27 15:54:02 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.271: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 17:18:50.271: INFO: calico-node-mvhvc from kube-system started at 2020-04-27 15:57:54 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.271: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 17:18:50.271: INFO: 
Logging pods the kubelet thinks is on node ip-10-250-8-65.ec2.internal before test
Apr 27 17:18:50.398: INFO: node-problem-detector-frcdg from kube-system started at 2020-04-27 15:53:59 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.398: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 17:18:50.398: INFO: kube-proxy-2tzh4 from kube-system started at 2020-04-27 15:53:59 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.398: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 17:18:50.398: INFO: kubernetes-dashboard-6b586c4cb4-jw8gc from kubernetes-dashboard started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.398: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 27 17:18:50.398: INFO: netserver-1 from pod-network-test-1049 started at 2020-04-27 17:18:20 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.398: INFO: 	Container webserver ready: true, restart count 0
Apr 27 17:18:50.398: INFO: csi-driver-node-lqmtr from kube-system started at 2020-04-27 15:53:59 +0000 UTC (3 container statuses recorded)
Apr 27 17:18:50.398: INFO: 	Container csi-driver ready: true, restart count 0
Apr 27 17:18:50.398: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 27 17:18:50.398: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 27 17:18:50.398: INFO: calico-typha-vertical-autoscaler-5b477c88cf-lq56p from kube-system started at 2020-04-27 15:54:17 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.398: INFO: 	Container autoscaler ready: true, restart count 3
Apr 27 17:18:50.398: INFO: node-exporter-vv796 from kube-system started at 2020-04-27 15:53:59 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.398: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 17:18:50.398: INFO: calico-kube-controllers-77dcb8f688-f6jtd from kube-system started at 2020-04-27 15:54:17 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.398: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 27 17:18:50.398: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-hqsfl from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.398: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr 27 17:18:50.398: INFO: calico-node-l4j7q from kube-system started at 2020-04-27 15:57:44 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.398: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 17:18:50.398: INFO: calico-typha-deploy-784665cc66-dtz47 from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.398: INFO: 	Container calico-typha ready: true, restart count 0
Apr 27 17:18:50.398: INFO: blackbox-exporter-5dc75b79b7-hcrbp from kube-system started at 2020-04-27 15:53:59 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.398: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 27 17:18:50.398: INFO: coredns-5cb857d789-m225g from kube-system started at 2020-04-27 15:54:14 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.398: INFO: 	Container coredns ready: true, restart count 0
Apr 27 17:18:50.398: INFO: addons-nginx-ingress-controller-6cf77756b5-8sgd9 from kube-system started at 2020-04-27 15:54:17 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.398: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 27 17:18:50.398: INFO: coredns-5cb857d789-bn7lm from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.398: INFO: 	Container coredns ready: true, restart count 0
Apr 27 17:18:50.398: INFO: dashboard-metrics-scraper-76c7b697bc-ghctb from kubernetes-dashboard started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.398: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 27 17:18:50.398: INFO: vpn-shoot-5c755d796f-fvlqt from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.398: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 27 17:18:50.398: INFO: calico-typha-horizontal-autoscaler-6fdd5d8746-vxwg5 from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.398: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 17:18:50.398: INFO: metrics-server-7dd4d485f9-ff6mk from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.398: INFO: 	Container metrics-server ready: true, restart count 0
Apr 27 17:18:50.398: INFO: calico-node-vertical-autoscaler-74d4897db8-g7wmv from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 17:18:50.398: INFO: 	Container autoscaler ready: true, restart count 3
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-fd57ab49-a0bc-4ef3-a368-bb8d05c6f846 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-fd57ab49-a0bc-4ef3-a368-bb8d05c6f846 off the node ip-10-250-10-186.ec2.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-fd57ab49-a0bc-4ef3-a368-bb8d05c6f846
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:18:55.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6216" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":277,"completed":254,"skipped":4325,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:18:55.936: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-676
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:18:56.665: INFO: Waiting up to 5m0s for pod "downwardapi-volume-00cc668b-ca6d-4b63-b83f-e9db5f2839fb" in namespace "projected-676" to be "Succeeded or Failed"
Apr 27 17:18:56.755: INFO: Pod "downwardapi-volume-00cc668b-ca6d-4b63-b83f-e9db5f2839fb": Phase="Pending", Reason="", readiness=false. Elapsed: 89.589249ms
Apr 27 17:18:58.845: INFO: Pod "downwardapi-volume-00cc668b-ca6d-4b63-b83f-e9db5f2839fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179753653s
STEP: Saw pod success
Apr 27 17:18:58.845: INFO: Pod "downwardapi-volume-00cc668b-ca6d-4b63-b83f-e9db5f2839fb" satisfied condition "Succeeded or Failed"
Apr 27 17:18:58.935: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod downwardapi-volume-00cc668b-ca6d-4b63-b83f-e9db5f2839fb container client-container: <nil>
STEP: delete the pod
Apr 27 17:18:59.125: INFO: Waiting for pod downwardapi-volume-00cc668b-ca6d-4b63-b83f-e9db5f2839fb to disappear
Apr 27 17:18:59.214: INFO: Pod downwardapi-volume-00cc668b-ca6d-4b63-b83f-e9db5f2839fb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:18:59.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-676" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":255,"skipped":4330,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:18:59.397: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9026
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Apr 27 17:19:00.038: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 27 17:19:00.311: INFO: Waiting for terminating namespaces to be deleted...
Apr 27 17:19:00.401: INFO: 
Logging pods the kubelet thinks is on node ip-10-250-10-186.ec2.internal before test
Apr 27 17:19:00.501: INFO: kube-proxy-f8lnb from kube-system started at 2020-04-27 15:54:02 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.501: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 17:19:00.501: INFO: csi-driver-node-qjp4d from kube-system started at 2020-04-27 15:54:02 +0000 UTC (3 container statuses recorded)
Apr 27 17:19:00.501: INFO: 	Container csi-driver ready: true, restart count 0
Apr 27 17:19:00.501: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 27 17:19:00.501: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 27 17:19:00.501: INFO: with-labels from sched-pred-6216 started at 2020-04-27 17:18:53 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.502: INFO: 	Container with-labels ready: true, restart count 0
Apr 27 17:19:00.502: INFO: node-exporter-zggrn from kube-system started at 2020-04-27 15:54:02 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.502: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 17:19:00.502: INFO: calico-node-mvhvc from kube-system started at 2020-04-27 15:57:54 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.502: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 17:19:00.502: INFO: node-problem-detector-f7dh2 from kube-system started at 2020-04-27 15:54:02 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.502: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 17:19:00.502: INFO: 
Logging pods the kubelet thinks is on node ip-10-250-8-65.ec2.internal before test
Apr 27 17:19:00.618: INFO: node-problem-detector-frcdg from kube-system started at 2020-04-27 15:53:59 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.618: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 17:19:00.618: INFO: kube-proxy-2tzh4 from kube-system started at 2020-04-27 15:53:59 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.618: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 17:19:00.618: INFO: kubernetes-dashboard-6b586c4cb4-jw8gc from kubernetes-dashboard started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.618: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 27 17:19:00.618: INFO: csi-driver-node-lqmtr from kube-system started at 2020-04-27 15:53:59 +0000 UTC (3 container statuses recorded)
Apr 27 17:19:00.618: INFO: 	Container csi-driver ready: true, restart count 0
Apr 27 17:19:00.618: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 27 17:19:00.618: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 27 17:19:00.618: INFO: calico-typha-vertical-autoscaler-5b477c88cf-lq56p from kube-system started at 2020-04-27 15:54:17 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.618: INFO: 	Container autoscaler ready: true, restart count 3
Apr 27 17:19:00.618: INFO: node-exporter-vv796 from kube-system started at 2020-04-27 15:53:59 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.618: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 17:19:00.618: INFO: calico-kube-controllers-77dcb8f688-f6jtd from kube-system started at 2020-04-27 15:54:17 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.618: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 27 17:19:00.618: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-hqsfl from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.618: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr 27 17:19:00.618: INFO: calico-node-l4j7q from kube-system started at 2020-04-27 15:57:44 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.618: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 17:19:00.618: INFO: blackbox-exporter-5dc75b79b7-hcrbp from kube-system started at 2020-04-27 15:53:59 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.618: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 27 17:19:00.618: INFO: coredns-5cb857d789-m225g from kube-system started at 2020-04-27 15:54:14 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.618: INFO: 	Container coredns ready: true, restart count 0
Apr 27 17:19:00.618: INFO: addons-nginx-ingress-controller-6cf77756b5-8sgd9 from kube-system started at 2020-04-27 15:54:17 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.618: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 27 17:19:00.618: INFO: coredns-5cb857d789-bn7lm from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.618: INFO: 	Container coredns ready: true, restart count 0
Apr 27 17:19:00.618: INFO: calico-typha-deploy-784665cc66-dtz47 from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.618: INFO: 	Container calico-typha ready: true, restart count 0
Apr 27 17:19:00.618: INFO: dashboard-metrics-scraper-76c7b697bc-ghctb from kubernetes-dashboard started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.618: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 27 17:19:00.618: INFO: vpn-shoot-5c755d796f-fvlqt from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.618: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 27 17:19:00.618: INFO: calico-typha-horizontal-autoscaler-6fdd5d8746-vxwg5 from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.618: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 17:19:00.618: INFO: metrics-server-7dd4d485f9-ff6mk from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.618: INFO: 	Container metrics-server ready: true, restart count 0
Apr 27 17:19:00.618: INFO: calico-node-vertical-autoscaler-74d4897db8-g7wmv from kube-system started at 2020-04-27 15:54:21 +0000 UTC (1 container statuses recorded)
Apr 27 17:19:00.618: INFO: 	Container autoscaler ready: true, restart count 3
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-5ac281fe-5a9c-4f68-8230-715209aac9cd 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-5ac281fe-5a9c-4f68-8230-715209aac9cd off the node ip-10-250-10-186.ec2.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-5ac281fe-5a9c-4f68-8230-715209aac9cd
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:24:06.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9026" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:307.105 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":277,"completed":256,"skipped":4393,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:24:06.502: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8941
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-projected-pm6p
STEP: Creating a pod to test atomic-volume-subpath
Apr 27 17:24:07.413: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-pm6p" in namespace "subpath-8941" to be "Succeeded or Failed"
Apr 27 17:24:07.503: INFO: Pod "pod-subpath-test-projected-pm6p": Phase="Pending", Reason="", readiness=false. Elapsed: 89.488645ms
Apr 27 17:24:09.593: INFO: Pod "pod-subpath-test-projected-pm6p": Phase="Running", Reason="", readiness=true. Elapsed: 2.179740521s
Apr 27 17:24:11.683: INFO: Pod "pod-subpath-test-projected-pm6p": Phase="Running", Reason="", readiness=true. Elapsed: 4.269979315s
Apr 27 17:24:13.774: INFO: Pod "pod-subpath-test-projected-pm6p": Phase="Running", Reason="", readiness=true. Elapsed: 6.360274391s
Apr 27 17:24:15.863: INFO: Pod "pod-subpath-test-projected-pm6p": Phase="Running", Reason="", readiness=true. Elapsed: 8.450097445s
Apr 27 17:24:17.953: INFO: Pod "pod-subpath-test-projected-pm6p": Phase="Running", Reason="", readiness=true. Elapsed: 10.540226461s
Apr 27 17:24:20.044: INFO: Pod "pod-subpath-test-projected-pm6p": Phase="Running", Reason="", readiness=true. Elapsed: 12.630394811s
Apr 27 17:24:22.134: INFO: Pod "pod-subpath-test-projected-pm6p": Phase="Running", Reason="", readiness=true. Elapsed: 14.720399561s
Apr 27 17:24:24.223: INFO: Pod "pod-subpath-test-projected-pm6p": Phase="Running", Reason="", readiness=true. Elapsed: 16.810251947s
Apr 27 17:24:26.314: INFO: Pod "pod-subpath-test-projected-pm6p": Phase="Running", Reason="", readiness=true. Elapsed: 18.90039249s
Apr 27 17:24:28.404: INFO: Pod "pod-subpath-test-projected-pm6p": Phase="Running", Reason="", readiness=true. Elapsed: 20.990599111s
Apr 27 17:24:30.494: INFO: Pod "pod-subpath-test-projected-pm6p": Phase="Succeeded", Reason="", readiness=false. Elapsed: 23.081145198s
STEP: Saw pod success
Apr 27 17:24:30.494: INFO: Pod "pod-subpath-test-projected-pm6p" satisfied condition "Succeeded or Failed"
Apr 27 17:24:30.584: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-subpath-test-projected-pm6p container test-container-subpath-projected-pm6p: <nil>
STEP: delete the pod
Apr 27 17:24:30.842: INFO: Waiting for pod pod-subpath-test-projected-pm6p to disappear
Apr 27 17:24:30.931: INFO: Pod pod-subpath-test-projected-pm6p no longer exists
STEP: Deleting pod pod-subpath-test-projected-pm6p
Apr 27 17:24:30.931: INFO: Deleting pod "pod-subpath-test-projected-pm6p" in namespace "subpath-8941"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:24:31.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8941" for this suite.
•{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [LinuxOnly] [Conformance]","total":277,"completed":257,"skipped":4402,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:24:31.203: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8210
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service endpoint-test2 in namespace services-8210
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8210 to expose endpoints map[]
Apr 27 17:24:32.025: INFO: successfully validated that service endpoint-test2 in namespace services-8210 exposes endpoints map[] (89.514571ms elapsed)
STEP: Creating pod pod1 in namespace services-8210
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8210 to expose endpoints map[pod1:[80]]
Apr 27 17:24:34.656: INFO: successfully validated that service endpoint-test2 in namespace services-8210 exposes endpoints map[pod1:[80]] (2.538631982s elapsed)
STEP: Creating pod pod2 in namespace services-8210
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8210 to expose endpoints map[pod1:[80] pod2:[80]]
Apr 27 17:24:36.286: INFO: successfully validated that service endpoint-test2 in namespace services-8210 exposes endpoints map[pod1:[80] pod2:[80]] (1.538527342s elapsed)
STEP: Deleting pod pod1 in namespace services-8210
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8210 to expose endpoints map[pod2:[80]]
Apr 27 17:24:36.556: INFO: successfully validated that service endpoint-test2 in namespace services-8210 exposes endpoints map[pod2:[80]] (178.890921ms elapsed)
STEP: Deleting pod pod2 in namespace services-8210
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8210 to expose endpoints map[]
Apr 27 17:24:36.736: INFO: successfully validated that service endpoint-test2 in namespace services-8210 exposes endpoints map[] (89.609742ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:24:36.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8210" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":277,"completed":258,"skipped":4413,"failed":0}
SSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:24:37.013: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-2192
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-2192, will wait for the garbage collector to delete the pods
Apr 27 17:24:40.115: INFO: Deleting Job.batch foo took: 91.033626ms
Apr 27 17:24:40.215: INFO: Terminating Job.batch foo pods took: 100.28262ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:25:22.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2192" for this suite.
•{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":277,"completed":259,"skipped":4418,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:25:22.987: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-6953
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Apr 27 17:25:23.625: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:25:49.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6953" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":277,"completed":260,"skipped":4443,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:25:49.496: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-392
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-392
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-392
STEP: Creating statefulset with conflicting port in namespace statefulset-392
STEP: Waiting until pod test-pod will start running in namespace statefulset-392
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-392
Apr 27 17:25:52.805: INFO: Observed stateful pod in namespace: statefulset-392, name: ss-0, uid: 20dbec9c-7fad-4747-8be5-55f9da46ab49, status phase: Pending. Waiting for statefulset controller to delete.
Apr 27 17:25:52.815: INFO: Observed stateful pod in namespace: statefulset-392, name: ss-0, uid: 20dbec9c-7fad-4747-8be5-55f9da46ab49, status phase: Failed. Waiting for statefulset controller to delete.
Apr 27 17:25:52.854: INFO: Observed stateful pod in namespace: statefulset-392, name: ss-0, uid: 20dbec9c-7fad-4747-8be5-55f9da46ab49, status phase: Failed. Waiting for statefulset controller to delete.
Apr 27 17:25:52.856: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-392
STEP: Removing pod with conflicting port in namespace statefulset-392
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-392 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 17:25:55.130: INFO: Deleting all statefulset in ns statefulset-392
Apr 27 17:25:55.220: INFO: Scaling statefulset ss to 0
Apr 27 17:26:05.582: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 17:26:05.673: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:26:05.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-392" for this suite.
•{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":277,"completed":261,"skipped":4471,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Lease 
  lease API should be available [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Lease
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:26:06.127: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename lease-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in lease-test-4774
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Lease
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:26:07.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-4774" for this suite.
•{"msg":"PASSED [k8s.io] Lease lease API should be available [Conformance]","total":277,"completed":262,"skipped":4495,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:26:08.034: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-6789
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7036
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3700
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:26:23.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6789" for this suite.
STEP: Destroying namespace "nsdeletetest-7036" for this suite.
Apr 27 17:26:23.677: INFO: Namespace nsdeletetest-7036 was already deleted
STEP: Destroying namespace "nsdeletetest-3700" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":277,"completed":263,"skipped":4514,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:26:23.768: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1800
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-0b1ab097-2099-4f35-a243-34aa87becfff
STEP: Creating a pod to test consume secrets
Apr 27 17:26:24.591: INFO: Waiting up to 5m0s for pod "pod-secrets-ebddc57c-a09e-43ee-8472-f39097a1bd53" in namespace "secrets-1800" to be "Succeeded or Failed"
Apr 27 17:26:24.680: INFO: Pod "pod-secrets-ebddc57c-a09e-43ee-8472-f39097a1bd53": Phase="Pending", Reason="", readiness=false. Elapsed: 89.594477ms
Apr 27 17:26:26.771: INFO: Pod "pod-secrets-ebddc57c-a09e-43ee-8472-f39097a1bd53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179985282s
STEP: Saw pod success
Apr 27 17:26:26.771: INFO: Pod "pod-secrets-ebddc57c-a09e-43ee-8472-f39097a1bd53" satisfied condition "Succeeded or Failed"
Apr 27 17:26:26.861: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-secrets-ebddc57c-a09e-43ee-8472-f39097a1bd53 container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:26:27.145: INFO: Waiting for pod pod-secrets-ebddc57c-a09e-43ee-8472-f39097a1bd53 to disappear
Apr 27 17:26:27.235: INFO: Pod pod-secrets-ebddc57c-a09e-43ee-8472-f39097a1bd53 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:26:27.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1800" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":264,"skipped":4522,"failed":0}
S
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:26:27.416: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-7117
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:171
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating server pod server in namespace prestop-7117
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-7117
STEP: Deleting pre-stop pod
Apr 27 17:26:37.959: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:26:38.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-7117" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":277,"completed":265,"skipped":4523,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:26:38.231: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6166
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Apr 27 17:26:38.962: INFO: Waiting up to 5m0s for pod "downward-api-9ac8e339-b3ce-483b-bad1-4b5c4d49491e" in namespace "downward-api-6166" to be "Succeeded or Failed"
Apr 27 17:26:39.052: INFO: Pod "downward-api-9ac8e339-b3ce-483b-bad1-4b5c4d49491e": Phase="Pending", Reason="", readiness=false. Elapsed: 89.514712ms
Apr 27 17:26:41.142: INFO: Pod "downward-api-9ac8e339-b3ce-483b-bad1-4b5c4d49491e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179956221s
STEP: Saw pod success
Apr 27 17:26:41.142: INFO: Pod "downward-api-9ac8e339-b3ce-483b-bad1-4b5c4d49491e" satisfied condition "Succeeded or Failed"
Apr 27 17:26:41.232: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod downward-api-9ac8e339-b3ce-483b-bad1-4b5c4d49491e container dapi-container: <nil>
STEP: delete the pod
Apr 27 17:26:41.422: INFO: Waiting for pod downward-api-9ac8e339-b3ce-483b-bad1-4b5c4d49491e to disappear
Apr 27 17:26:41.512: INFO: Pod downward-api-9ac8e339-b3ce-483b-bad1-4b5c4d49491e no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:26:41.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6166" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":277,"completed":266,"skipped":4534,"failed":0}
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:26:41.694: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6923
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-1dc89a78-9a8c-44c3-9226-d75d8562ba7d
STEP: Creating a pod to test consume secrets
Apr 27 17:26:42.515: INFO: Waiting up to 5m0s for pod "pod-secrets-d332d1d2-d603-4e66-98dc-82d4906022dd" in namespace "secrets-6923" to be "Succeeded or Failed"
Apr 27 17:26:42.604: INFO: Pod "pod-secrets-d332d1d2-d603-4e66-98dc-82d4906022dd": Phase="Pending", Reason="", readiness=false. Elapsed: 89.572109ms
Apr 27 17:26:44.695: INFO: Pod "pod-secrets-d332d1d2-d603-4e66-98dc-82d4906022dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179968507s
STEP: Saw pod success
Apr 27 17:26:44.695: INFO: Pod "pod-secrets-d332d1d2-d603-4e66-98dc-82d4906022dd" satisfied condition "Succeeded or Failed"
Apr 27 17:26:44.785: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-secrets-d332d1d2-d603-4e66-98dc-82d4906022dd container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:26:44.974: INFO: Waiting for pod pod-secrets-d332d1d2-d603-4e66-98dc-82d4906022dd to disappear
Apr 27 17:26:45.065: INFO: Pod pod-secrets-d332d1d2-d603-4e66-98dc-82d4906022dd no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:26:45.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6923" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":277,"completed":267,"skipped":4538,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:26:45.247: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6069
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:26:45.977: INFO: Waiting up to 5m0s for pod "downwardapi-volume-af484bb9-0d02-42d4-adc6-6175b9b7abb1" in namespace "projected-6069" to be "Succeeded or Failed"
Apr 27 17:26:46.067: INFO: Pod "downwardapi-volume-af484bb9-0d02-42d4-adc6-6175b9b7abb1": Phase="Pending", Reason="", readiness=false. Elapsed: 90.067848ms
Apr 27 17:26:48.157: INFO: Pod "downwardapi-volume-af484bb9-0d02-42d4-adc6-6175b9b7abb1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180209952s
STEP: Saw pod success
Apr 27 17:26:48.157: INFO: Pod "downwardapi-volume-af484bb9-0d02-42d4-adc6-6175b9b7abb1" satisfied condition "Succeeded or Failed"
Apr 27 17:26:48.247: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod downwardapi-volume-af484bb9-0d02-42d4-adc6-6175b9b7abb1 container client-container: <nil>
STEP: delete the pod
Apr 27 17:26:48.434: INFO: Waiting for pod downwardapi-volume-af484bb9-0d02-42d4-adc6-6175b9b7abb1 to disappear
Apr 27 17:26:48.524: INFO: Pod downwardapi-volume-af484bb9-0d02-42d4-adc6-6175b9b7abb1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:26:48.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6069" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":277,"completed":268,"skipped":4546,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:26:48.707: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5643
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:26:51.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5643" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":277,"completed":269,"skipped":4554,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:26:51.899: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2950
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-951c76c6-6dbf-46ab-b1d4-a29f9e80dbe8
STEP: Creating a pod to test consume configMaps
Apr 27 17:26:52.721: INFO: Waiting up to 5m0s for pod "pod-configmaps-5939c9f5-c143-48e3-9ecc-df3d1a883824" in namespace "configmap-2950" to be "Succeeded or Failed"
Apr 27 17:26:52.811: INFO: Pod "pod-configmaps-5939c9f5-c143-48e3-9ecc-df3d1a883824": Phase="Pending", Reason="", readiness=false. Elapsed: 89.50017ms
Apr 27 17:26:54.901: INFO: Pod "pod-configmaps-5939c9f5-c143-48e3-9ecc-df3d1a883824": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179603208s
STEP: Saw pod success
Apr 27 17:26:54.901: INFO: Pod "pod-configmaps-5939c9f5-c143-48e3-9ecc-df3d1a883824" satisfied condition "Succeeded or Failed"
Apr 27 17:26:54.991: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-configmaps-5939c9f5-c143-48e3-9ecc-df3d1a883824 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 17:26:55.182: INFO: Waiting for pod pod-configmaps-5939c9f5-c143-48e3-9ecc-df3d1a883824 to disappear
Apr 27 17:26:55.272: INFO: Pod pod-configmaps-5939c9f5-c143-48e3-9ecc-df3d1a883824 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:26:55.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2950" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":270,"skipped":4575,"failed":0}
SSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:26:55.458: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3701
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:26:56.096: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr 27 17:26:56.276: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 27 17:26:58.457: INFO: Creating deployment "test-rolling-update-deployment"
Apr 27 17:26:58.547: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr 27 17:26:58.727: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr 27 17:26:58.817: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605218, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605218, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605218, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605218, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-59d5cb45c7\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:27:00.908: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Apr 27 17:27:01.178: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-3701 /apis/apps/v1/namespaces/deployment-3701/deployments/test-rolling-update-deployment 6c5c362f-b251-4a94-b05e-44587b55977a 39542 1 2020-04-27 17:26:58 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2020-04-27 17:26:58 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 17:27:00 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005d68558 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-04-27 17:26:58 +0000 UTC,LastTransitionTime:2020-04-27 17:26:58 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-59d5cb45c7" has successfully progressed.,LastUpdateTime:2020-04-27 17:27:00 +0000 UTC,LastTransitionTime:2020-04-27 17:26:58 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 27 17:27:01.268: INFO: New ReplicaSet "test-rolling-update-deployment-59d5cb45c7" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7  deployment-3701 /apis/apps/v1/namespaces/deployment-3701/replicasets/test-rolling-update-deployment-59d5cb45c7 f13c294a-0d48-46c7-962c-b3315a3279ae 39535 1 2020-04-27 17:26:58 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 6c5c362f-b251-4a94-b05e-44587b55977a 0xc005d68cc7 0xc005d68cc8}] []  [{kube-controller-manager Update apps/v1 2020-04-27 17:27:00 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 54 99 53 99 51 54 50 102 45 98 50 53 49 45 52 97 57 52 45 98 48 53 101 45 52 52 53 56 55 98 53 53 57 55 55 97 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 59d5cb45c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005d68de8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 27 17:27:01.268: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr 27 17:27:01.268: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-3701 /apis/apps/v1/namespaces/deployment-3701/replicasets/test-rolling-update-controller 516bda62-7b8d-4ff9-87b9-ce49bca2dbb0 39541 2 2020-04-27 17:26:56 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 6c5c362f-b251-4a94-b05e-44587b55977a 0xc005d68b27 0xc005d68b28}] []  [{e2e.test Update apps/v1 2020-04-27 17:26:56 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 17:27:00 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 54 99 53 99 51 54 50 102 45 98 50 53 49 45 52 97 57 52 45 98 48 53 101 45 52 52 53 56 55 98 53 53 57 55 55 97 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005d68c48 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 17:27:01.359: INFO: Pod "test-rolling-update-deployment-59d5cb45c7-r5zzn" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7-r5zzn test-rolling-update-deployment-59d5cb45c7- deployment-3701 /api/v1/namespaces/deployment-3701/pods/test-rolling-update-deployment-59d5cb45c7-r5zzn 902100c8-000b-41ec-8c57-dda44399bcb6 39534 0 2020-04-27 17:26:58 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[cni.projectcalico.org/podIP:100.64.1.123/32 cni.projectcalico.org/podIPs:100.64.1.123/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rolling-update-deployment-59d5cb45c7 f13c294a-0d48-46c7-962c-b3315a3279ae 0xc005d695d7 0xc005d695d8}] []  [{kube-controller-manager Update v1 2020-04-27 17:26:58 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 49 51 99 50 57 52 97 45 48 100 52 56 45 52 54 99 55 45 57 54 50 99 45 98 51 51 49 53 97 51 50 55 57 97 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:26:59 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:27:00 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 49 50 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6hxsx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6hxsx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6hxsx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:26:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:27:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:27:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:26:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:100.64.1.123,StartTime:2020-04-27 17:26:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:26:59 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://f1a01f8d8d9233e6b08a9e03b33220beda59f84a5ebd62c4d9168ec797151403,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.123,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:27:01.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3701" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":277,"completed":271,"skipped":4579,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:27:01.541: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4491
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:27:03.372: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605223, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605223, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605223, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605223, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:27:06.556: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:27:07.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4491" for this suite.
STEP: Destroying namespace "webhook-4491-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":277,"completed":272,"skipped":4598,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:27:07.805: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5320
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:27:10.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5320" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":277,"completed":273,"skipped":4644,"failed":0}
S
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:27:11.170: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8686
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:28:12.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8686" for this suite.
•{"msg":"PASSED [k8s.io] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":277,"completed":274,"skipped":4645,"failed":0}
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:28:12.233: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7964
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:28:26.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7964" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":277,"completed":275,"skipped":4647,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:28:27.065: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4135
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:28:27.706: INFO: Creating deployment "test-recreate-deployment"
Apr 27 17:28:27.798: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr 27 17:28:27.980: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr 27 17:28:28.070: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605307, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605307, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605307, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605307, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:28:30.160: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr 27 17:28:30.341: INFO: Updating deployment test-recreate-deployment
Apr 27 17:28:30.341: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Apr 27 17:28:30.521: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-4135 /apis/apps/v1/namespaces/deployment-4135/deployments/test-recreate-deployment 22682b82-3bd4-44d4-bf16-79bf81f2c4dd 40166 2 2020-04-27 17:28:27 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-04-27 17:28:30 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 17:28:30 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003025ae8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-04-27 17:28:30 +0000 UTC,LastTransitionTime:2020-04-27 17:28:30 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-d5667d9c7" is progressing.,LastUpdateTime:2020-04-27 17:28:30 +0000 UTC,LastTransitionTime:2020-04-27 17:28:27 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Apr 27 17:28:30.611: INFO: New ReplicaSet "test-recreate-deployment-d5667d9c7" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-d5667d9c7  deployment-4135 /apis/apps/v1/namespaces/deployment-4135/replicasets/test-recreate-deployment-d5667d9c7 7e7cfe69-e9ac-4650-a332-e8b787cc0e82 40165 1 2020-04-27 17:28:30 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 22682b82-3bd4-44d4-bf16-79bf81f2c4dd 0xc0043167e0 0xc0043167e1}] []  [{kube-controller-manager Update apps/v1 2020-04-27 17:28:30 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 50 54 56 50 98 56 50 45 51 98 100 52 45 52 52 100 52 45 98 102 49 54 45 55 57 98 102 56 49 102 50 99 52 100 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: d5667d9c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004316858 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 17:28:30.611: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr 27 17:28:30.611: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-74d98b5f7c  deployment-4135 /apis/apps/v1/namespaces/deployment-4135/replicasets/test-recreate-deployment-74d98b5f7c e329229b-fdc1-4713-8ab8-dd59288efa72 40158 2 2020-04-27 17:28:27 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 22682b82-3bd4-44d4-bf16-79bf81f2c4dd 0xc0043166e7 0xc0043166e8}] []  [{kube-controller-manager Update apps/v1 2020-04-27 17:28:30 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 50 54 56 50 98 56 50 45 51 98 100 52 45 52 52 100 52 45 98 102 49 54 45 55 57 98 102 56 49 102 50 99 52 100 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 74d98b5f7c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004316778 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 17:28:30.702: INFO: Pod "test-recreate-deployment-d5667d9c7-css4l" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-d5667d9c7-css4l test-recreate-deployment-d5667d9c7- deployment-4135 /api/v1/namespaces/deployment-4135/pods/test-recreate-deployment-d5667d9c7-css4l 9fa39181-7fae-4650-81cb-97fbfb825cef 40167 0 2020-04-27 17:28:30 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-recreate-deployment-d5667d9c7 7e7cfe69-e9ac-4650-a332-e8b787cc0e82 0xc004316d30 0xc004316d31}] []  [{kube-controller-manager Update v1 2020-04-27 17:28:30 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 55 101 55 99 102 101 54 57 45 101 57 97 99 45 52 54 53 48 45 97 51 51 50 45 101 56 98 55 56 55 99 99 48 101 56 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:28:30 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ts54v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ts54v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ts54v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-10-186.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:28:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:28:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:28:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:28:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.10.186,PodIP:,StartTime:2020-04-27 17:28:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:28:30.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4135" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":277,"completed":276,"skipped":4687,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:28:30.884: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5308
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 27 17:28:31.615: INFO: Waiting up to 5m0s for pod "pod-2b752868-4b9a-49eb-8517-8a0417aa6a5e" in namespace "emptydir-5308" to be "Succeeded or Failed"
Apr 27 17:28:31.705: INFO: Pod "pod-2b752868-4b9a-49eb-8517-8a0417aa6a5e": Phase="Pending", Reason="", readiness=false. Elapsed: 89.862824ms
Apr 27 17:28:33.795: INFO: Pod "pod-2b752868-4b9a-49eb-8517-8a0417aa6a5e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180169955s
STEP: Saw pod success
Apr 27 17:28:33.795: INFO: Pod "pod-2b752868-4b9a-49eb-8517-8a0417aa6a5e" satisfied condition "Succeeded or Failed"
Apr 27 17:28:33.885: INFO: Trying to get logs from node ip-10-250-10-186.ec2.internal pod pod-2b752868-4b9a-49eb-8517-8a0417aa6a5e container test-container: <nil>
STEP: delete the pod
Apr 27 17:28:34.175: INFO: Waiting for pod pod-2b752868-4b9a-49eb-8517-8a0417aa6a5e to disappear
Apr 27 17:28:34.264: INFO: Pod pod-2b752868-4b9a-49eb-8517-8a0417aa6a5e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:28:34.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5308" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":277,"skipped":4713,"failed":0}
SSApr 27 17:28:34.446: INFO: Running AfterSuite actions on all nodes
Apr 27 17:28:34.446: INFO: Running AfterSuite actions on node 1
Apr 27 17:28:34.446: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/e2e/artifacts/1588003526/junit_01.xml
{"msg":"Test Suite completed","total":277,"completed":277,"skipped":4715,"failed":0}

Ran 277 of 4992 Specs in 4984.224 seconds
SUCCESS! -- 277 Passed | 0 Failed | 0 Flaked | 0 Pending | 4715 Skipped
PASS

Ginkgo ran 1 suite in 1h23m6.510389699s
Test Suite Passed
