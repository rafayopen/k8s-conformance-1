Conformance test: not doing test setup.
I0427 16:06:30.007550    7292 test_context.go:423] Tolerating taints "node-role.kubernetes.io/master" when considering if nodes are ready
I0427 16:06:30.007685    7292 e2e.go:124] Starting e2e run "cb249f49-815c-4512-beef-dd3a6acd2447" on Ginkgo node 1
{"msg":"Test Suite starting","total":277,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1588003588 - Will randomize all specs
Will run 277 of 4992 specs

Apr 27 16:06:30.246: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:06:30.248: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr 27 16:06:30.305: INFO: Waiting up to 10m0s for all pods (need at least 1) in namespace 'kube-system' to be running and ready
Apr 27 16:06:30.370: INFO: 19 / 19 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr 27 16:06:30.370: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
Apr 27 16:06:30.370: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr 27 16:06:30.389: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Apr 27 16:06:30.389: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Apr 27 16:06:30.389: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Apr 27 16:06:30.389: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-problem-detector' (0 seconds elapsed)
Apr 27 16:06:30.389: INFO: e2e test version: v1.18.2
Apr 27 16:06:30.399: INFO: kube-apiserver version: v1.18.2
Apr 27 16:06:30.399: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:06:30.411: INFO: Cluster IP family: ipv4
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:06:30.411: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
Apr 27 16:06:30.474: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Apr 27 16:06:30.510: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9959
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 27 16:06:30.666: INFO: Waiting up to 5m0s for pod "pod-c1a416b7-47d1-4483-9239-dd31c0263204" in namespace "emptydir-9959" to be "Succeeded or Failed"
Apr 27 16:06:30.676: INFO: Pod "pod-c1a416b7-47d1-4483-9239-dd31c0263204": Phase="Pending", Reason="", readiness=false. Elapsed: 9.996004ms
Apr 27 16:06:32.688: INFO: Pod "pod-c1a416b7-47d1-4483-9239-dd31c0263204": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021588164s
Apr 27 16:06:34.699: INFO: Pod "pod-c1a416b7-47d1-4483-9239-dd31c0263204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032923691s
STEP: Saw pod success
Apr 27 16:06:34.700: INFO: Pod "pod-c1a416b7-47d1-4483-9239-dd31c0263204" satisfied condition "Succeeded or Failed"
Apr 27 16:06:34.710: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-c1a416b7-47d1-4483-9239-dd31c0263204 container test-container: <nil>
STEP: delete the pod
Apr 27 16:06:34.840: INFO: Waiting for pod pod-c1a416b7-47d1-4483-9239-dd31c0263204 to disappear
Apr 27 16:06:34.850: INFO: Pod pod-c1a416b7-47d1-4483-9239-dd31c0263204 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:06:34.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9959" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":1,"skipped":1,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:06:34.883: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4948
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-87dc9792-c34f-4bda-8222-d1c82a63fe6c
STEP: Creating a pod to test consume configMaps
Apr 27 16:06:35.093: INFO: Waiting up to 5m0s for pod "pod-configmaps-b464431f-ea11-4de9-9153-939eeb4a2850" in namespace "configmap-4948" to be "Succeeded or Failed"
Apr 27 16:06:35.103: INFO: Pod "pod-configmaps-b464431f-ea11-4de9-9153-939eeb4a2850": Phase="Pending", Reason="", readiness=false. Elapsed: 9.72506ms
Apr 27 16:06:37.114: INFO: Pod "pod-configmaps-b464431f-ea11-4de9-9153-939eeb4a2850": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021228837s
Apr 27 16:06:39.125: INFO: Pod "pod-configmaps-b464431f-ea11-4de9-9153-939eeb4a2850": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031889551s
STEP: Saw pod success
Apr 27 16:06:39.125: INFO: Pod "pod-configmaps-b464431f-ea11-4de9-9153-939eeb4a2850" satisfied condition "Succeeded or Failed"
Apr 27 16:06:39.135: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-configmaps-b464431f-ea11-4de9-9153-939eeb4a2850 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:06:39.168: INFO: Waiting for pod pod-configmaps-b464431f-ea11-4de9-9153-939eeb4a2850 to disappear
Apr 27 16:06:39.178: INFO: Pod pod-configmaps-b464431f-ea11-4de9-9153-939eeb4a2850 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:06:39.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4948" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":277,"completed":2,"skipped":46,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:06:39.208: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-7105
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
STEP: reading a file in the container
Apr 27 16:06:45.961: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-7105 pod-service-account-740ebe93-2ee9-4e4b-a1a8-c0486fc6f078 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Apr 27 16:06:46.560: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-7105 pod-service-account-740ebe93-2ee9-4e4b-a1a8-c0486fc6f078 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Apr 27 16:06:47.049: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-7105 pod-service-account-740ebe93-2ee9-4e4b-a1a8-c0486fc6f078 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:06:47.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7105" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":277,"completed":3,"skipped":57,"failed":0}
S
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:06:47.613: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-2482
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:06:47.814: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-9ee001db-d429-4800-b90a-e079c792c9f4" in namespace "security-context-test-2482" to be "Succeeded or Failed"
Apr 27 16:06:47.825: INFO: Pod "alpine-nnp-false-9ee001db-d429-4800-b90a-e079c792c9f4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.288972ms
Apr 27 16:06:49.836: INFO: Pod "alpine-nnp-false-9ee001db-d429-4800-b90a-e079c792c9f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021579391s
Apr 27 16:06:51.846: INFO: Pod "alpine-nnp-false-9ee001db-d429-4800-b90a-e079c792c9f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031872316s
Apr 27 16:06:53.857: INFO: Pod "alpine-nnp-false-9ee001db-d429-4800-b90a-e079c792c9f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.042342354s
Apr 27 16:06:53.857: INFO: Pod "alpine-nnp-false-9ee001db-d429-4800-b90a-e079c792c9f4" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:06:53.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2482" for this suite.
•{"msg":"PASSED [k8s.io] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":4,"skipped":58,"failed":0}
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:06:53.906: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8108
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override arguments
Apr 27 16:06:54.103: INFO: Waiting up to 5m0s for pod "client-containers-7490c955-d832-411f-ba25-c381ae48872b" in namespace "containers-8108" to be "Succeeded or Failed"
Apr 27 16:06:54.114: INFO: Pod "client-containers-7490c955-d832-411f-ba25-c381ae48872b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.5728ms
Apr 27 16:06:56.152: INFO: Pod "client-containers-7490c955-d832-411f-ba25-c381ae48872b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048569743s
Apr 27 16:06:58.163: INFO: Pod "client-containers-7490c955-d832-411f-ba25-c381ae48872b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05970619s
Apr 27 16:07:00.174: INFO: Pod "client-containers-7490c955-d832-411f-ba25-c381ae48872b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.070821943s
Apr 27 16:07:02.185: INFO: Pod "client-containers-7490c955-d832-411f-ba25-c381ae48872b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.082401584s
Apr 27 16:07:04.197: INFO: Pod "client-containers-7490c955-d832-411f-ba25-c381ae48872b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.094191989s
Apr 27 16:07:06.209: INFO: Pod "client-containers-7490c955-d832-411f-ba25-c381ae48872b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.105538666s
STEP: Saw pod success
Apr 27 16:07:06.209: INFO: Pod "client-containers-7490c955-d832-411f-ba25-c381ae48872b" satisfied condition "Succeeded or Failed"
Apr 27 16:07:06.219: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod client-containers-7490c955-d832-411f-ba25-c381ae48872b container test-container: <nil>
STEP: delete the pod
Apr 27 16:07:06.253: INFO: Waiting for pod client-containers-7490c955-d832-411f-ba25-c381ae48872b to disappear
Apr 27 16:07:06.263: INFO: Pod client-containers-7490c955-d832-411f-ba25-c381ae48872b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:07:06.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8108" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":277,"completed":5,"skipped":60,"failed":0}

------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:07:06.293: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-982
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:07:11.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-982" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":277,"completed":6,"skipped":60,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:07:11.468: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6875
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-6875
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-6875
STEP: creating replication controller externalsvc in namespace services-6875
I0427 16:07:11.709276    7292 runners.go:190] Created replication controller with name: externalsvc, namespace: services-6875, replica count: 2
I0427 16:07:14.760259    7292 runners.go:190] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0427 16:07:17.760448    7292 runners.go:190] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0427 16:07:20.760874    7292 runners.go:190] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0427 16:07:23.761127    7292 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Apr 27 16:07:23.804: INFO: Creating new exec pod
Apr 27 16:07:27.839: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-6875 execpodfjgjv -- /bin/sh -x -c nslookup clusterip-service'
Apr 27 16:07:28.442: INFO: stderr: "+ nslookup clusterip-service\n"
Apr 27 16:07:28.442: INFO: stdout: "Server:\t\t100.104.0.10\nAddress:\t100.104.0.10#53\n\nclusterip-service.services-6875.svc.cluster.local\tcanonical name = externalsvc.services-6875.svc.cluster.local.\nName:\texternalsvc.services-6875.svc.cluster.local\nAddress: 100.107.103.25\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-6875, will wait for the garbage collector to delete the pods
Apr 27 16:07:28.515: INFO: Deleting ReplicationController externalsvc took: 12.254611ms
Apr 27 16:07:29.016: INFO: Terminating ReplicationController externalsvc pods took: 500.363495ms
Apr 27 16:07:37.340: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:07:37.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6875" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":277,"completed":7,"skipped":73,"failed":0}

------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:07:37.386: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3163
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Apr 27 16:07:37.584: INFO: Waiting up to 5m0s for pod "downward-api-16d1035b-62d3-45ad-ad82-8a3e937bcef0" in namespace "downward-api-3163" to be "Succeeded or Failed"
Apr 27 16:07:37.595: INFO: Pod "downward-api-16d1035b-62d3-45ad-ad82-8a3e937bcef0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.588633ms
Apr 27 16:07:39.607: INFO: Pod "downward-api-16d1035b-62d3-45ad-ad82-8a3e937bcef0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022521391s
Apr 27 16:07:41.618: INFO: Pod "downward-api-16d1035b-62d3-45ad-ad82-8a3e937bcef0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033295081s
STEP: Saw pod success
Apr 27 16:07:41.618: INFO: Pod "downward-api-16d1035b-62d3-45ad-ad82-8a3e937bcef0" satisfied condition "Succeeded or Failed"
Apr 27 16:07:41.628: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod downward-api-16d1035b-62d3-45ad-ad82-8a3e937bcef0 container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:07:41.664: INFO: Waiting for pod downward-api-16d1035b-62d3-45ad-ad82-8a3e937bcef0 to disappear
Apr 27 16:07:41.674: INFO: Pod downward-api-16d1035b-62d3-45ad-ad82-8a3e937bcef0 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:07:41.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3163" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":277,"completed":8,"skipped":73,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:07:41.706: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2711
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-cf32a74a-739d-43a5-9a13-48ab9b1d3204
STEP: Creating a pod to test consume configMaps
Apr 27 16:07:41.914: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-211354c6-53e1-419b-b0fc-d20b38ccb2b4" in namespace "projected-2711" to be "Succeeded or Failed"
Apr 27 16:07:41.927: INFO: Pod "pod-projected-configmaps-211354c6-53e1-419b-b0fc-d20b38ccb2b4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.67171ms
Apr 27 16:07:43.938: INFO: Pod "pod-projected-configmaps-211354c6-53e1-419b-b0fc-d20b38ccb2b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023821356s
Apr 27 16:07:45.950: INFO: Pod "pod-projected-configmaps-211354c6-53e1-419b-b0fc-d20b38ccb2b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035246505s
STEP: Saw pod success
Apr 27 16:07:45.950: INFO: Pod "pod-projected-configmaps-211354c6-53e1-419b-b0fc-d20b38ccb2b4" satisfied condition "Succeeded or Failed"
Apr 27 16:07:45.972: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-projected-configmaps-211354c6-53e1-419b-b0fc-d20b38ccb2b4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:07:46.007: INFO: Waiting for pod pod-projected-configmaps-211354c6-53e1-419b-b0fc-d20b38ccb2b4 to disappear
Apr 27 16:07:46.017: INFO: Pod pod-projected-configmaps-211354c6-53e1-419b-b0fc-d20b38ccb2b4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:07:46.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2711" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":277,"completed":9,"skipped":83,"failed":0}
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:07:46.049: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2216
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 27 16:07:46.266: INFO: Waiting up to 5m0s for pod "pod-44875391-6dd4-4cfb-9179-f59efe3179bc" in namespace "emptydir-2216" to be "Succeeded or Failed"
Apr 27 16:07:46.276: INFO: Pod "pod-44875391-6dd4-4cfb-9179-f59efe3179bc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.275222ms
Apr 27 16:07:48.287: INFO: Pod "pod-44875391-6dd4-4cfb-9179-f59efe3179bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021185589s
Apr 27 16:07:50.298: INFO: Pod "pod-44875391-6dd4-4cfb-9179-f59efe3179bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032265335s
STEP: Saw pod success
Apr 27 16:07:50.298: INFO: Pod "pod-44875391-6dd4-4cfb-9179-f59efe3179bc" satisfied condition "Succeeded or Failed"
Apr 27 16:07:50.309: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-44875391-6dd4-4cfb-9179-f59efe3179bc container test-container: <nil>
STEP: delete the pod
Apr 27 16:07:50.344: INFO: Waiting for pod pod-44875391-6dd4-4cfb-9179-f59efe3179bc to disappear
Apr 27 16:07:50.354: INFO: Pod pod-44875391-6dd4-4cfb-9179-f59efe3179bc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:07:50.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2216" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":10,"skipped":90,"failed":0}
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:07:50.385: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7984
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-71338df2-9bbe-46d2-9b83-a3d485bce79d
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-71338df2-9bbe-46d2-9b83-a3d485bce79d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:09:07.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7984" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":11,"skipped":96,"failed":0}
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:09:07.686: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8820
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override all
Apr 27 16:09:07.884: INFO: Waiting up to 5m0s for pod "client-containers-3f520e89-631f-4265-ad47-9493ee1aceb2" in namespace "containers-8820" to be "Succeeded or Failed"
Apr 27 16:09:07.894: INFO: Pod "client-containers-3f520e89-631f-4265-ad47-9493ee1aceb2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.959134ms
Apr 27 16:09:09.905: INFO: Pod "client-containers-3f520e89-631f-4265-ad47-9493ee1aceb2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021238196s
Apr 27 16:09:11.917: INFO: Pod "client-containers-3f520e89-631f-4265-ad47-9493ee1aceb2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032689511s
STEP: Saw pod success
Apr 27 16:09:11.917: INFO: Pod "client-containers-3f520e89-631f-4265-ad47-9493ee1aceb2" satisfied condition "Succeeded or Failed"
Apr 27 16:09:11.927: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod client-containers-3f520e89-631f-4265-ad47-9493ee1aceb2 container test-container: <nil>
STEP: delete the pod
Apr 27 16:09:11.961: INFO: Waiting for pod client-containers-3f520e89-631f-4265-ad47-9493ee1aceb2 to disappear
Apr 27 16:09:11.971: INFO: Pod client-containers-3f520e89-631f-4265-ad47-9493ee1aceb2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:09:11.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8820" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":277,"completed":12,"skipped":98,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:09:12.003: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-136
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 27 16:09:12.197: INFO: Waiting up to 5m0s for pod "pod-5119c4a2-f5bb-44fe-b9c0-f91593fcd2a1" in namespace "emptydir-136" to be "Succeeded or Failed"
Apr 27 16:09:12.210: INFO: Pod "pod-5119c4a2-f5bb-44fe-b9c0-f91593fcd2a1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.891636ms
Apr 27 16:09:14.222: INFO: Pod "pod-5119c4a2-f5bb-44fe-b9c0-f91593fcd2a1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024425764s
Apr 27 16:09:16.232: INFO: Pod "pod-5119c4a2-f5bb-44fe-b9c0-f91593fcd2a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035120136s
STEP: Saw pod success
Apr 27 16:09:16.232: INFO: Pod "pod-5119c4a2-f5bb-44fe-b9c0-f91593fcd2a1" satisfied condition "Succeeded or Failed"
Apr 27 16:09:16.243: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-5119c4a2-f5bb-44fe-b9c0-f91593fcd2a1 container test-container: <nil>
STEP: delete the pod
Apr 27 16:09:16.275: INFO: Waiting for pod pod-5119c4a2-f5bb-44fe-b9c0-f91593fcd2a1 to disappear
Apr 27 16:09:16.285: INFO: Pod pod-5119c4a2-f5bb-44fe-b9c0-f91593fcd2a1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:09:16.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-136" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":13,"skipped":99,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:09:16.322: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-1444
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:09:16.929: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600556, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600556, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600556, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600556, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:09:18.939: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600556, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600556, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600556, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600556, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:09:21.961: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:09:21.972: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:09:22.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-1444" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137
•{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":277,"completed":14,"skipped":108,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:09:22.991: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8873
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:09:23.811: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600563, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600563, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600563, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600563, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:09:25.822: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600563, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600563, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600563, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600563, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:09:28.843: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:09:28.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8873" for this suite.
STEP: Destroying namespace "webhook-8873-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":277,"completed":15,"skipped":116,"failed":0}

------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:09:28.987: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2799
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-275d988a-cd6f-4d91-a404-9714aaa7c9e5
STEP: Creating a pod to test consume secrets
Apr 27 16:09:29.193: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ecb3a602-a54a-4dee-b8f7-0b35f6cbe4cc" in namespace "projected-2799" to be "Succeeded or Failed"
Apr 27 16:09:29.203: INFO: Pod "pod-projected-secrets-ecb3a602-a54a-4dee-b8f7-0b35f6cbe4cc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.054985ms
Apr 27 16:09:31.215: INFO: Pod "pod-projected-secrets-ecb3a602-a54a-4dee-b8f7-0b35f6cbe4cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021917214s
Apr 27 16:09:33.226: INFO: Pod "pod-projected-secrets-ecb3a602-a54a-4dee-b8f7-0b35f6cbe4cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032463361s
STEP: Saw pod success
Apr 27 16:09:33.226: INFO: Pod "pod-projected-secrets-ecb3a602-a54a-4dee-b8f7-0b35f6cbe4cc" satisfied condition "Succeeded or Failed"
Apr 27 16:09:33.236: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-projected-secrets-ecb3a602-a54a-4dee-b8f7-0b35f6cbe4cc container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:09:33.320: INFO: Waiting for pod pod-projected-secrets-ecb3a602-a54a-4dee-b8f7-0b35f6cbe4cc to disappear
Apr 27 16:09:33.330: INFO: Pod pod-projected-secrets-ecb3a602-a54a-4dee-b8f7-0b35f6cbe4cc no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:09:33.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2799" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":16,"skipped":116,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:09:33.362: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-368
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:09:49.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-368" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":277,"completed":17,"skipped":185,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:09:49.751: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-305
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:09:49.955: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f6321f9a-d125-4ec3-87ec-098960b0e94d" in namespace "downward-api-305" to be "Succeeded or Failed"
Apr 27 16:09:49.965: INFO: Pod "downwardapi-volume-f6321f9a-d125-4ec3-87ec-098960b0e94d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.057745ms
Apr 27 16:09:51.976: INFO: Pod "downwardapi-volume-f6321f9a-d125-4ec3-87ec-098960b0e94d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021768619s
Apr 27 16:09:53.988: INFO: Pod "downwardapi-volume-f6321f9a-d125-4ec3-87ec-098960b0e94d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033191193s
STEP: Saw pod success
Apr 27 16:09:53.988: INFO: Pod "downwardapi-volume-f6321f9a-d125-4ec3-87ec-098960b0e94d" satisfied condition "Succeeded or Failed"
Apr 27 16:09:53.999: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod downwardapi-volume-f6321f9a-d125-4ec3-87ec-098960b0e94d container client-container: <nil>
STEP: delete the pod
Apr 27 16:09:54.035: INFO: Waiting for pod downwardapi-volume-f6321f9a-d125-4ec3-87ec-098960b0e94d to disappear
Apr 27 16:09:54.045: INFO: Pod downwardapi-volume-f6321f9a-d125-4ec3-87ec-098960b0e94d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:09:54.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-305" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":18,"skipped":216,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:09:54.076: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2601
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Apr 27 16:09:54.259: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-2601'
Apr 27 16:09:54.538: INFO: stderr: ""
Apr 27 16:09:54.538: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 27 16:09:54.538: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2601'
Apr 27 16:09:59.661: INFO: stderr: ""
Apr 27 16:09:59.661: INFO: stdout: "update-demo-nautilus-dmq4x update-demo-nautilus-q8tng "
Apr 27 16:09:59.661: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-dmq4x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2601'
Apr 27 16:09:59.777: INFO: stderr: ""
Apr 27 16:09:59.777: INFO: stdout: "true"
Apr 27 16:09:59.777: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-dmq4x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2601'
Apr 27 16:09:59.894: INFO: stderr: ""
Apr 27 16:09:59.894: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:09:59.894: INFO: validating pod update-demo-nautilus-dmq4x
Apr 27 16:09:59.990: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:09:59.990: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:09:59.990: INFO: update-demo-nautilus-dmq4x is verified up and running
Apr 27 16:09:59.990: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-q8tng -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2601'
Apr 27 16:10:00.115: INFO: stderr: ""
Apr 27 16:10:00.115: INFO: stdout: "true"
Apr 27 16:10:00.115: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-q8tng -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2601'
Apr 27 16:10:00.224: INFO: stderr: ""
Apr 27 16:10:00.224: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:10:00.224: INFO: validating pod update-demo-nautilus-q8tng
Apr 27 16:10:00.325: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:10:00.325: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:10:00.325: INFO: update-demo-nautilus-q8tng is verified up and running
STEP: scaling down the replication controller
Apr 27 16:10:00.328: INFO: scanned /root for discovery docs: <nil>
Apr 27 16:10:00.328: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-2601'
Apr 27 16:10:00.473: INFO: stderr: ""
Apr 27 16:10:00.473: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 27 16:10:00.473: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2601'
Apr 27 16:10:00.593: INFO: stderr: ""
Apr 27 16:10:00.593: INFO: stdout: "update-demo-nautilus-dmq4x update-demo-nautilus-q8tng "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr 27 16:10:05.593: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2601'
Apr 27 16:10:05.708: INFO: stderr: ""
Apr 27 16:10:05.708: INFO: stdout: "update-demo-nautilus-dmq4x "
Apr 27 16:10:05.708: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-dmq4x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2601'
Apr 27 16:10:05.813: INFO: stderr: ""
Apr 27 16:10:05.813: INFO: stdout: "true"
Apr 27 16:10:05.813: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-dmq4x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2601'
Apr 27 16:10:05.914: INFO: stderr: ""
Apr 27 16:10:05.914: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:10:05.914: INFO: validating pod update-demo-nautilus-dmq4x
Apr 27 16:10:05.927: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:10:05.927: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:10:05.927: INFO: update-demo-nautilus-dmq4x is verified up and running
STEP: scaling up the replication controller
Apr 27 16:10:05.929: INFO: scanned /root for discovery docs: <nil>
Apr 27 16:10:05.929: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-2601'
Apr 27 16:10:06.057: INFO: stderr: ""
Apr 27 16:10:06.058: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 27 16:10:06.058: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2601'
Apr 27 16:10:06.173: INFO: stderr: ""
Apr 27 16:10:06.173: INFO: stdout: "update-demo-nautilus-dmq4x update-demo-nautilus-ttnbh "
Apr 27 16:10:06.173: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-dmq4x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2601'
Apr 27 16:10:06.276: INFO: stderr: ""
Apr 27 16:10:06.276: INFO: stdout: "true"
Apr 27 16:10:06.276: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-dmq4x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2601'
Apr 27 16:10:06.383: INFO: stderr: ""
Apr 27 16:10:06.383: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:10:06.383: INFO: validating pod update-demo-nautilus-dmq4x
Apr 27 16:10:06.395: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:10:06.395: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:10:06.395: INFO: update-demo-nautilus-dmq4x is verified up and running
Apr 27 16:10:06.395: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-ttnbh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2601'
Apr 27 16:10:06.502: INFO: stderr: ""
Apr 27 16:10:06.502: INFO: stdout: ""
Apr 27 16:10:06.502: INFO: update-demo-nautilus-ttnbh is created but not running
Apr 27 16:10:11.502: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2601'
Apr 27 16:10:11.615: INFO: stderr: ""
Apr 27 16:10:11.615: INFO: stdout: "update-demo-nautilus-dmq4x update-demo-nautilus-ttnbh "
Apr 27 16:10:11.615: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-dmq4x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2601'
Apr 27 16:10:11.717: INFO: stderr: ""
Apr 27 16:10:11.717: INFO: stdout: "true"
Apr 27 16:10:11.717: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-dmq4x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2601'
Apr 27 16:10:11.817: INFO: stderr: ""
Apr 27 16:10:11.817: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:10:11.817: INFO: validating pod update-demo-nautilus-dmq4x
Apr 27 16:10:11.829: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:10:11.830: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:10:11.830: INFO: update-demo-nautilus-dmq4x is verified up and running
Apr 27 16:10:11.830: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-ttnbh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2601'
Apr 27 16:10:11.930: INFO: stderr: ""
Apr 27 16:10:11.930: INFO: stdout: "true"
Apr 27 16:10:11.930: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-ttnbh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2601'
Apr 27 16:10:12.032: INFO: stderr: ""
Apr 27 16:10:12.032: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:10:12.032: INFO: validating pod update-demo-nautilus-ttnbh
Apr 27 16:10:12.128: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:10:12.128: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:10:12.128: INFO: update-demo-nautilus-ttnbh is verified up and running
STEP: using delete to clean up resources
Apr 27 16:10:12.128: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2601'
Apr 27 16:10:12.242: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 16:10:12.242: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 27 16:10:12.242: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2601'
Apr 27 16:10:12.356: INFO: stderr: "No resources found in kubectl-2601 namespace.\n"
Apr 27 16:10:12.356: INFO: stdout: ""
Apr 27 16:10:12.356: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-2601 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 27 16:10:12.474: INFO: stderr: ""
Apr 27 16:10:12.474: INFO: stdout: "update-demo-nautilus-dmq4x\nupdate-demo-nautilus-ttnbh\n"
Apr 27 16:10:12.975: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2601'
Apr 27 16:10:13.089: INFO: stderr: "No resources found in kubectl-2601 namespace.\n"
Apr 27 16:10:13.089: INFO: stdout: ""
Apr 27 16:10:13.090: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-2601 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 27 16:10:13.203: INFO: stderr: ""
Apr 27 16:10:13.203: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:10:13.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2601" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":277,"completed":19,"skipped":220,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:10:13.233: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9861
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:10:29.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9861" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":277,"completed":20,"skipped":226,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:10:29.636: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2401
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-2b462cef-9f99-4299-88e2-d5bc60ca52c9 in namespace container-probe-2401
Apr 27 16:10:31.854: INFO: Started pod busybox-2b462cef-9f99-4299-88e2-d5bc60ca52c9 in namespace container-probe-2401
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 16:10:31.864: INFO: Initial restart count of pod busybox-2b462cef-9f99-4299-88e2-d5bc60ca52c9 is 0
Apr 27 16:11:26.171: INFO: Restart count of pod container-probe-2401/busybox-2b462cef-9f99-4299-88e2-d5bc60ca52c9 is now 1 (54.307215337s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:11:26.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2401" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":277,"completed":21,"skipped":261,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:11:26.220: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6473
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6473 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6473;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6473 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6473;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6473.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6473.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6473.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6473.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6473.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6473.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6473.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6473.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6473.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6473.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6473.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6473.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6473.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 183.19.104.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.104.19.183_udp@PTR;check="$$(dig +tcp +noall +answer +search 183.19.104.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.104.19.183_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6473 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6473;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6473 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6473;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6473.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6473.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6473.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6473.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6473.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6473.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6473.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6473.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6473.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6473.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6473.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6473.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6473.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 183.19.104.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.104.19.183_udp@PTR;check="$$(dig +tcp +noall +answer +search 183.19.104.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.104.19.183_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 16:11:46.577: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:46.621: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:46.634: INFO: Unable to read wheezy_udp@dns-test-service.dns-6473 from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:46.646: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6473 from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:46.659: INFO: Unable to read wheezy_udp@dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:46.671: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:46.684: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:46.696: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:47.089: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:47.105: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:47.118: INFO: Unable to read jessie_udp@dns-test-service.dns-6473 from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:47.130: INFO: Unable to read jessie_tcp@dns-test-service.dns-6473 from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:47.143: INFO: Unable to read jessie_udp@dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:47.155: INFO: Unable to read jessie_tcp@dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:47.167: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:47.179: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:47.532: INFO: Lookups using dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6473 wheezy_tcp@dns-test-service.dns-6473 wheezy_udp@dns-test-service.dns-6473.svc wheezy_tcp@dns-test-service.dns-6473.svc wheezy_udp@_http._tcp.dns-test-service.dns-6473.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6473.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6473 jessie_tcp@dns-test-service.dns-6473 jessie_udp@dns-test-service.dns-6473.svc jessie_tcp@dns-test-service.dns-6473.svc jessie_udp@_http._tcp.dns-test-service.dns-6473.svc jessie_tcp@_http._tcp.dns-test-service.dns-6473.svc]

Apr 27 16:11:52.546: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:52.559: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:52.571: INFO: Unable to read wheezy_udp@dns-test-service.dns-6473 from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:52.585: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6473 from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:52.596: INFO: Unable to read wheezy_udp@dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:52.609: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:52.621: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:52.633: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:53.062: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:53.075: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:53.087: INFO: Unable to read jessie_udp@dns-test-service.dns-6473 from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:53.099: INFO: Unable to read jessie_tcp@dns-test-service.dns-6473 from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:53.111: INFO: Unable to read jessie_udp@dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:53.123: INFO: Unable to read jessie_tcp@dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:53.136: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:53.148: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:53.537: INFO: Lookups using dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6473 wheezy_tcp@dns-test-service.dns-6473 wheezy_udp@dns-test-service.dns-6473.svc wheezy_tcp@dns-test-service.dns-6473.svc wheezy_udp@_http._tcp.dns-test-service.dns-6473.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6473.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6473 jessie_tcp@dns-test-service.dns-6473 jessie_udp@dns-test-service.dns-6473.svc jessie_tcp@dns-test-service.dns-6473.svc jessie_udp@_http._tcp.dns-test-service.dns-6473.svc jessie_tcp@_http._tcp.dns-test-service.dns-6473.svc]

Apr 27 16:11:57.544: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:57.557: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:57.569: INFO: Unable to read wheezy_udp@dns-test-service.dns-6473 from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:57.582: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6473 from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:57.593: INFO: Unable to read wheezy_udp@dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:57.606: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:57.618: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:57.631: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:58.061: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:58.073: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:58.085: INFO: Unable to read jessie_udp@dns-test-service.dns-6473 from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:58.097: INFO: Unable to read jessie_tcp@dns-test-service.dns-6473 from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:58.109: INFO: Unable to read jessie_udp@dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:58.120: INFO: Unable to read jessie_tcp@dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:58.132: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:58.144: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6473.svc from pod dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952: the server could not find the requested resource (get pods dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952)
Apr 27 16:11:58.532: INFO: Lookups using dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6473 wheezy_tcp@dns-test-service.dns-6473 wheezy_udp@dns-test-service.dns-6473.svc wheezy_tcp@dns-test-service.dns-6473.svc wheezy_udp@_http._tcp.dns-test-service.dns-6473.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6473.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6473 jessie_tcp@dns-test-service.dns-6473 jessie_udp@dns-test-service.dns-6473.svc jessie_tcp@dns-test-service.dns-6473.svc jessie_udp@_http._tcp.dns-test-service.dns-6473.svc jessie_tcp@_http._tcp.dns-test-service.dns-6473.svc]

Apr 27 16:12:04.351: INFO: DNS probes using dns-6473/dns-test-1a36694b-0db4-4cbf-93cf-4dfa12ca0952 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:12:04.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6473" for this suite.
•{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":277,"completed":22,"skipped":293,"failed":0}

------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:12:04.441: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-2460
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Apr 27 16:12:14.718: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2460 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:12:14.718: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:12:15.074: INFO: Exec stderr: ""
Apr 27 16:12:15.074: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2460 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:12:15.074: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:12:15.468: INFO: Exec stderr: ""
Apr 27 16:12:15.468: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2460 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:12:15.468: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:12:15.857: INFO: Exec stderr: ""
Apr 27 16:12:15.857: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2460 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:12:15.857: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:12:16.332: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Apr 27 16:12:16.332: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2460 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:12:16.332: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:12:16.770: INFO: Exec stderr: ""
Apr 27 16:12:16.770: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2460 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:12:16.770: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:12:17.205: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Apr 27 16:12:17.205: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2460 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:12:17.205: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:12:17.673: INFO: Exec stderr: ""
Apr 27 16:12:17.673: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2460 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:12:17.673: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:12:18.053: INFO: Exec stderr: ""
Apr 27 16:12:18.053: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2460 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:12:18.053: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:12:18.455: INFO: Exec stderr: ""
Apr 27 16:12:18.455: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2460 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:12:18.455: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:12:18.909: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:12:18.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-2460" for this suite.
•{"msg":"PASSED [k8s.io] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":23,"skipped":293,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:12:18.941: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1164
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:12:19.124: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Apr 27 16:12:22.199: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-1164 create -f -'
Apr 27 16:12:22.883: INFO: stderr: ""
Apr 27 16:12:22.883: INFO: stdout: "e2e-test-crd-publish-openapi-6640-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 27 16:12:22.883: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-1164 delete e2e-test-crd-publish-openapi-6640-crds test-foo'
Apr 27 16:12:23.043: INFO: stderr: ""
Apr 27 16:12:23.043: INFO: stdout: "e2e-test-crd-publish-openapi-6640-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Apr 27 16:12:23.043: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-1164 apply -f -'
Apr 27 16:12:23.276: INFO: stderr: ""
Apr 27 16:12:23.276: INFO: stdout: "e2e-test-crd-publish-openapi-6640-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 27 16:12:23.276: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-1164 delete e2e-test-crd-publish-openapi-6640-crds test-foo'
Apr 27 16:12:23.403: INFO: stderr: ""
Apr 27 16:12:23.403: INFO: stdout: "e2e-test-crd-publish-openapi-6640-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Apr 27 16:12:23.403: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-1164 create -f -'
Apr 27 16:12:23.607: INFO: rc: 1
Apr 27 16:12:23.607: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-1164 apply -f -'
Apr 27 16:12:23.853: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Apr 27 16:12:23.853: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-1164 create -f -'
Apr 27 16:12:24.044: INFO: rc: 1
Apr 27 16:12:24.044: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-1164 apply -f -'
Apr 27 16:12:24.298: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Apr 27 16:12:24.299: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-6640-crds'
Apr 27 16:12:24.571: INFO: stderr: ""
Apr 27 16:12:24.572: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-6640-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Apr 27 16:12:24.572: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-6640-crds.metadata'
Apr 27 16:12:24.774: INFO: stderr: ""
Apr 27 16:12:24.774: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-6640-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Apr 27 16:12:24.774: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-6640-crds.spec'
Apr 27 16:12:24.972: INFO: stderr: ""
Apr 27 16:12:24.972: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-6640-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Apr 27 16:12:24.972: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-6640-crds.spec.bars'
Apr 27 16:12:25.165: INFO: stderr: ""
Apr 27 16:12:25.165: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-6640-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Apr 27 16:12:25.166: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-6640-crds.spec.bars2'
Apr 27 16:12:25.415: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:12:29.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1164" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":277,"completed":24,"skipped":300,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:12:29.264: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-709
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl label
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1206
STEP: creating the pod
Apr 27 16:12:29.447: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-709'
Apr 27 16:12:29.757: INFO: stderr: ""
Apr 27 16:12:29.757: INFO: stdout: "pod/pause created\n"
Apr 27 16:12:29.757: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr 27 16:12:29.757: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-709" to be "running and ready"
Apr 27 16:12:29.768: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 10.929586ms
Apr 27 16:12:31.780: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023009006s
Apr 27 16:12:33.791: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.034175426s
Apr 27 16:12:33.791: INFO: Pod "pause" satisfied condition "running and ready"
Apr 27 16:12:33.791: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: adding the label testing-label with value testing-label-value to a pod
Apr 27 16:12:33.791: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config label pods pause testing-label=testing-label-value --namespace=kubectl-709'
Apr 27 16:12:33.935: INFO: stderr: ""
Apr 27 16:12:33.935: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Apr 27 16:12:33.935: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod pause -L testing-label --namespace=kubectl-709'
Apr 27 16:12:34.050: INFO: stderr: ""
Apr 27 16:12:34.050: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Apr 27 16:12:34.050: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config label pods pause testing-label- --namespace=kubectl-709'
Apr 27 16:12:34.175: INFO: stderr: ""
Apr 27 16:12:34.175: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Apr 27 16:12:34.175: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod pause -L testing-label --namespace=kubectl-709'
Apr 27 16:12:34.285: INFO: stderr: ""
Apr 27 16:12:34.285: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1213
STEP: using delete to clean up resources
Apr 27 16:12:34.285: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-709'
Apr 27 16:12:34.412: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 16:12:34.412: INFO: stdout: "pod \"pause\" force deleted\n"
Apr 27 16:12:34.412: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=pause --no-headers --namespace=kubectl-709'
Apr 27 16:12:34.548: INFO: stderr: "No resources found in kubectl-709 namespace.\n"
Apr 27 16:12:34.548: INFO: stdout: ""
Apr 27 16:12:34.548: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=pause --namespace=kubectl-709 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 27 16:12:34.664: INFO: stderr: ""
Apr 27 16:12:34.664: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:12:34.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-709" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":277,"completed":25,"skipped":303,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:12:34.698: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3063
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 27 16:12:37.960: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:12:37.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3063" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":26,"skipped":322,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:12:38.019: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9007
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-1b535391-0bec-4102-bdaa-d5466e708ac1 in namespace container-probe-9007
Apr 27 16:12:42.246: INFO: Started pod liveness-1b535391-0bec-4102-bdaa-d5466e708ac1 in namespace container-probe-9007
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 16:12:42.257: INFO: Initial restart count of pod liveness-1b535391-0bec-4102-bdaa-d5466e708ac1 is 0
Apr 27 16:12:54.341: INFO: Restart count of pod container-probe-9007/liveness-1b535391-0bec-4102-bdaa-d5466e708ac1 is now 1 (12.08416646s elapsed)
Apr 27 16:13:14.461: INFO: Restart count of pod container-probe-9007/liveness-1b535391-0bec-4102-bdaa-d5466e708ac1 is now 2 (32.204324927s elapsed)
Apr 27 16:13:34.579: INFO: Restart count of pod container-probe-9007/liveness-1b535391-0bec-4102-bdaa-d5466e708ac1 is now 3 (52.321780422s elapsed)
Apr 27 16:13:54.702: INFO: Restart count of pod container-probe-9007/liveness-1b535391-0bec-4102-bdaa-d5466e708ac1 is now 4 (1m12.445584112s elapsed)
Apr 27 16:15:03.101: INFO: Restart count of pod container-probe-9007/liveness-1b535391-0bec-4102-bdaa-d5466e708ac1 is now 5 (2m20.843984524s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:15:03.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9007" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":277,"completed":27,"skipped":384,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:15:03.147: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7377
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:15:03.346: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4e56a4cf-2113-453f-8517-4ec089ce3ad3" in namespace "projected-7377" to be "Succeeded or Failed"
Apr 27 16:15:03.356: INFO: Pod "downwardapi-volume-4e56a4cf-2113-453f-8517-4ec089ce3ad3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.252056ms
Apr 27 16:15:05.367: INFO: Pod "downwardapi-volume-4e56a4cf-2113-453f-8517-4ec089ce3ad3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0212736s
Apr 27 16:15:07.380: INFO: Pod "downwardapi-volume-4e56a4cf-2113-453f-8517-4ec089ce3ad3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033384334s
STEP: Saw pod success
Apr 27 16:15:07.380: INFO: Pod "downwardapi-volume-4e56a4cf-2113-453f-8517-4ec089ce3ad3" satisfied condition "Succeeded or Failed"
Apr 27 16:15:07.390: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod downwardapi-volume-4e56a4cf-2113-453f-8517-4ec089ce3ad3 container client-container: <nil>
STEP: delete the pod
Apr 27 16:15:07.518: INFO: Waiting for pod downwardapi-volume-4e56a4cf-2113-453f-8517-4ec089ce3ad3 to disappear
Apr 27 16:15:07.528: INFO: Pod downwardapi-volume-4e56a4cf-2113-453f-8517-4ec089ce3ad3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:15:07.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7377" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":28,"skipped":396,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:15:07.562: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7222
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service endpoint-test2 in namespace services-7222
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7222 to expose endpoints map[]
Apr 27 16:15:07.783: INFO: successfully validated that service endpoint-test2 in namespace services-7222 exposes endpoints map[] (12.648556ms elapsed)
STEP: Creating pod pod1 in namespace services-7222
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7222 to expose endpoints map[pod1:[80]]
Apr 27 16:15:10.889: INFO: successfully validated that service endpoint-test2 in namespace services-7222 exposes endpoints map[pod1:[80]] (3.087022485s elapsed)
STEP: Creating pod pod2 in namespace services-7222
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7222 to expose endpoints map[pod1:[80] pod2:[80]]
Apr 27 16:15:14.035: INFO: successfully validated that service endpoint-test2 in namespace services-7222 exposes endpoints map[pod1:[80] pod2:[80]] (3.13445214s elapsed)
STEP: Deleting pod pod1 in namespace services-7222
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7222 to expose endpoints map[pod2:[80]]
Apr 27 16:15:14.073: INFO: successfully validated that service endpoint-test2 in namespace services-7222 exposes endpoints map[pod2:[80]] (25.404708ms elapsed)
STEP: Deleting pod pod2 in namespace services-7222
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7222 to expose endpoints map[]
Apr 27 16:15:14.098: INFO: successfully validated that service endpoint-test2 in namespace services-7222 exposes endpoints map[] (13.287274ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:15:14.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7222" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":277,"completed":29,"skipped":429,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:15:14.161: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9172
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:15:14.856: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600914, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600914, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600914, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600914, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:15:16.868: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600914, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600914, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600914, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600914, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:15:19.892: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:15:32.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9172" for this suite.
STEP: Destroying namespace "webhook-9172-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":277,"completed":30,"skipped":502,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:15:32.508: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6292
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:15:32.752: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4f4dc9fe-0ee9-4072-b909-cf92a376496a" in namespace "projected-6292" to be "Succeeded or Failed"
Apr 27 16:15:32.763: INFO: Pod "downwardapi-volume-4f4dc9fe-0ee9-4072-b909-cf92a376496a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.530961ms
Apr 27 16:15:34.775: INFO: Pod "downwardapi-volume-4f4dc9fe-0ee9-4072-b909-cf92a376496a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022223223s
Apr 27 16:15:36.790: INFO: Pod "downwardapi-volume-4f4dc9fe-0ee9-4072-b909-cf92a376496a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037974012s
STEP: Saw pod success
Apr 27 16:15:36.791: INFO: Pod "downwardapi-volume-4f4dc9fe-0ee9-4072-b909-cf92a376496a" satisfied condition "Succeeded or Failed"
Apr 27 16:15:36.804: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod downwardapi-volume-4f4dc9fe-0ee9-4072-b909-cf92a376496a container client-container: <nil>
STEP: delete the pod
Apr 27 16:15:36.840: INFO: Waiting for pod downwardapi-volume-4f4dc9fe-0ee9-4072-b909-cf92a376496a to disappear
Apr 27 16:15:36.851: INFO: Pod downwardapi-volume-4f4dc9fe-0ee9-4072-b909-cf92a376496a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:15:36.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6292" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":277,"completed":31,"skipped":554,"failed":0}
SSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:15:36.885: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8066
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 27 16:15:40.158: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:15:40.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8066" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":32,"skipped":557,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:15:40.215: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6214
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Apr 27 16:15:44.994: INFO: Successfully updated pod "labelsupdate8abffcca-160b-402a-8c72-471e555b14b9"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:15:47.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6214" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":277,"completed":33,"skipped":584,"failed":0}
SS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:15:47.061: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9476
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:15:47.319: INFO: Creating deployment "test-recreate-deployment"
Apr 27 16:15:47.331: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr 27 16:15:47.356: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr 27 16:15:47.367: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600947, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600947, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600947, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600947, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:15:49.379: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600947, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600947, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600947, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600947, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:15:51.378: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr 27 16:15:51.401: INFO: Updating deployment test-recreate-deployment
Apr 27 16:15:51.401: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Apr 27 16:15:51.459: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-9476 /apis/apps/v1/namespaces/deployment-9476/deployments/test-recreate-deployment 7ff33849-a928-4698-bb4a-c4b189c100c9 8024 2 2020-04-27 16:15:47 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-04-27 16:15:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 16:15:51 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002722b48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-04-27 16:15:51 +0000 UTC,LastTransitionTime:2020-04-27 16:15:51 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-d5667d9c7" is progressing.,LastUpdateTime:2020-04-27 16:15:51 +0000 UTC,LastTransitionTime:2020-04-27 16:15:47 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Apr 27 16:15:51.470: INFO: New ReplicaSet "test-recreate-deployment-d5667d9c7" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-d5667d9c7  deployment-9476 /apis/apps/v1/namespaces/deployment-9476/replicasets/test-recreate-deployment-d5667d9c7 2814967e-e1bf-4ac4-806a-3f410c0a070c 8022 1 2020-04-27 16:15:51 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 7ff33849-a928-4698-bb4a-c4b189c100c9 0xc002723080 0xc002723081}] []  [{kube-controller-manager Update apps/v1 2020-04-27 16:15:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 55 102 102 51 51 56 52 57 45 97 57 50 56 45 52 54 57 56 45 98 98 52 97 45 99 52 98 49 56 57 99 49 48 48 99 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: d5667d9c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0027230f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:15:51.470: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr 27 16:15:51.471: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-74d98b5f7c  deployment-9476 /apis/apps/v1/namespaces/deployment-9476/replicasets/test-recreate-deployment-74d98b5f7c 78064188-d916-43ff-be9b-8fb0d9446837 8016 2 2020-04-27 16:15:47 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 7ff33849-a928-4698-bb4a-c4b189c100c9 0xc002722f97 0xc002722f98}] []  [{kube-controller-manager Update apps/v1 2020-04-27 16:15:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 55 102 102 51 51 56 52 57 45 97 57 50 56 45 52 54 57 56 45 98 98 52 97 45 99 52 98 49 56 57 99 49 48 48 99 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 74d98b5f7c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002723028 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:15:51.481: INFO: Pod "test-recreate-deployment-d5667d9c7-tkpwp" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-d5667d9c7-tkpwp test-recreate-deployment-d5667d9c7- deployment-9476 /api/v1/namespaces/deployment-9476/pods/test-recreate-deployment-d5667d9c7-tkpwp b5db9e28-6207-4dc3-b6b6-407211e46cd5 8025 0 2020-04-27 16:15:51 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-recreate-deployment-d5667d9c7 2814967e-e1bf-4ac4-806a-3f410c0a070c 0xc0027235c0 0xc0027235c1}] []  [{kube-controller-manager Update v1 2020-04-27 16:15:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 56 49 52 57 54 55 101 45 101 49 98 102 45 52 97 99 52 45 56 48 54 97 45 51 102 52 49 48 99 48 97 48 55 48 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:15:51 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-k7w6c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-k7w6c,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-k7w6c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:15:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:15:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:15:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:15:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2020-04-27 16:15:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:15:51.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9476" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":277,"completed":34,"skipped":586,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:15:51.515: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1993
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:16:08.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1993" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":277,"completed":35,"skipped":593,"failed":0}

------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:16:08.839: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9428
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:16:09.593: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600969, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600969, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600969, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600969, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:16:11.605: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600969, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600969, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600969, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600969, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:16:13.610: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600969, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600969, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600969, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600969, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:16:16.627: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:16:16.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9428" for this suite.
STEP: Destroying namespace "webhook-9428-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":277,"completed":36,"skipped":593,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:16:16.924: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-773
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:16:21.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-773" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":277,"completed":37,"skipped":610,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:16:21.213: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-6396
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:16:21.405: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating first CR 
Apr 27 16:16:21.554: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T16:16:21Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T16:16:21Z]] name:name1 resourceVersion:8273 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:9a19be85-bfd2-4c2d-bfb7-f6f5d4f363ce] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Apr 27 16:16:31.567: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T16:16:31Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T16:16:31Z]] name:name2 resourceVersion:8331 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:888a4c6c-3715-479d-afa1-2331f8998b02] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Apr 27 16:16:41.580: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T16:16:21Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T16:16:41Z]] name:name1 resourceVersion:8371 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:9a19be85-bfd2-4c2d-bfb7-f6f5d4f363ce] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Apr 27 16:16:51.594: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T16:16:31Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T16:16:51Z]] name:name2 resourceVersion:8411 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:888a4c6c-3715-479d-afa1-2331f8998b02] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Apr 27 16:17:01.609: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T16:16:21Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T16:16:41Z]] name:name1 resourceVersion:8452 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:9a19be85-bfd2-4c2d-bfb7-f6f5d4f363ce] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Apr 27 16:17:11.624: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T16:16:31Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T16:16:51Z]] name:name2 resourceVersion:8490 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:888a4c6c-3715-479d-afa1-2331f8998b02] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:17:22.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-6396" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":277,"completed":38,"skipped":635,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:17:22.191: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5479
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 27 16:17:22.669: INFO: Waiting up to 5m0s for pod "pod-f13e444d-db2c-46d4-8f40-1adfc2a4a770" in namespace "emptydir-5479" to be "Succeeded or Failed"
Apr 27 16:17:22.680: INFO: Pod "pod-f13e444d-db2c-46d4-8f40-1adfc2a4a770": Phase="Pending", Reason="", readiness=false. Elapsed: 10.629999ms
Apr 27 16:17:24.692: INFO: Pod "pod-f13e444d-db2c-46d4-8f40-1adfc2a4a770": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022395811s
Apr 27 16:17:26.703: INFO: Pod "pod-f13e444d-db2c-46d4-8f40-1adfc2a4a770": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033969121s
STEP: Saw pod success
Apr 27 16:17:26.703: INFO: Pod "pod-f13e444d-db2c-46d4-8f40-1adfc2a4a770" satisfied condition "Succeeded or Failed"
Apr 27 16:17:26.714: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-f13e444d-db2c-46d4-8f40-1adfc2a4a770 container test-container: <nil>
STEP: delete the pod
Apr 27 16:17:26.753: INFO: Waiting for pod pod-f13e444d-db2c-46d4-8f40-1adfc2a4a770 to disappear
Apr 27 16:17:26.764: INFO: Pod pod-f13e444d-db2c-46d4-8f40-1adfc2a4a770 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:17:26.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5479" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":39,"skipped":643,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:17:26.796: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4629
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:17:26.995: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7926751d-bef5-458a-b59b-d5a2b384df29" in namespace "projected-4629" to be "Succeeded or Failed"
Apr 27 16:17:27.006: INFO: Pod "downwardapi-volume-7926751d-bef5-458a-b59b-d5a2b384df29": Phase="Pending", Reason="", readiness=false. Elapsed: 10.624666ms
Apr 27 16:17:29.017: INFO: Pod "downwardapi-volume-7926751d-bef5-458a-b59b-d5a2b384df29": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022339385s
Apr 27 16:17:31.029: INFO: Pod "downwardapi-volume-7926751d-bef5-458a-b59b-d5a2b384df29": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033848762s
STEP: Saw pod success
Apr 27 16:17:31.029: INFO: Pod "downwardapi-volume-7926751d-bef5-458a-b59b-d5a2b384df29" satisfied condition "Succeeded or Failed"
Apr 27 16:17:31.040: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod downwardapi-volume-7926751d-bef5-458a-b59b-d5a2b384df29 container client-container: <nil>
STEP: delete the pod
Apr 27 16:17:31.103: INFO: Waiting for pod downwardapi-volume-7926751d-bef5-458a-b59b-d5a2b384df29 to disappear
Apr 27 16:17:31.113: INFO: Pod downwardapi-volume-7926751d-bef5-458a-b59b-d5a2b384df29 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:17:31.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4629" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":40,"skipped":658,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:17:31.151: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5590
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:17:31.379: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a88295a9-285d-4656-835d-f2dd0c278bd6" in namespace "projected-5590" to be "Succeeded or Failed"
Apr 27 16:17:31.390: INFO: Pod "downwardapi-volume-a88295a9-285d-4656-835d-f2dd0c278bd6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.469709ms
Apr 27 16:17:33.402: INFO: Pod "downwardapi-volume-a88295a9-285d-4656-835d-f2dd0c278bd6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022120424s
Apr 27 16:17:35.414: INFO: Pod "downwardapi-volume-a88295a9-285d-4656-835d-f2dd0c278bd6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034369351s
STEP: Saw pod success
Apr 27 16:17:35.414: INFO: Pod "downwardapi-volume-a88295a9-285d-4656-835d-f2dd0c278bd6" satisfied condition "Succeeded or Failed"
Apr 27 16:17:35.425: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod downwardapi-volume-a88295a9-285d-4656-835d-f2dd0c278bd6 container client-container: <nil>
STEP: delete the pod
Apr 27 16:17:35.471: INFO: Waiting for pod downwardapi-volume-a88295a9-285d-4656-835d-f2dd0c278bd6 to disappear
Apr 27 16:17:35.482: INFO: Pod downwardapi-volume-a88295a9-285d-4656-835d-f2dd0c278bd6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:17:35.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5590" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":41,"skipped":667,"failed":0}

------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:17:35.514: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3812
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Apr 27 16:17:41.794: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
W0427 16:17:41.794084    7292 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 27 16:17:41.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3812" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":277,"completed":42,"skipped":667,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:17:41.827: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8963
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-09c6694f-fd57-4261-857d-5a7ab70be251
STEP: Creating a pod to test consume configMaps
Apr 27 16:17:42.036: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-924531a4-ae45-458b-a950-7b90f40d89e8" in namespace "projected-8963" to be "Succeeded or Failed"
Apr 27 16:17:42.046: INFO: Pod "pod-projected-configmaps-924531a4-ae45-458b-a950-7b90f40d89e8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.536495ms
Apr 27 16:17:44.059: INFO: Pod "pod-projected-configmaps-924531a4-ae45-458b-a950-7b90f40d89e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022793421s
Apr 27 16:17:46.071: INFO: Pod "pod-projected-configmaps-924531a4-ae45-458b-a950-7b90f40d89e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034917901s
Apr 27 16:17:48.085: INFO: Pod "pod-projected-configmaps-924531a4-ae45-458b-a950-7b90f40d89e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.04953512s
STEP: Saw pod success
Apr 27 16:17:48.085: INFO: Pod "pod-projected-configmaps-924531a4-ae45-458b-a950-7b90f40d89e8" satisfied condition "Succeeded or Failed"
Apr 27 16:17:48.096: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-projected-configmaps-924531a4-ae45-458b-a950-7b90f40d89e8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:17:48.130: INFO: Waiting for pod pod-projected-configmaps-924531a4-ae45-458b-a950-7b90f40d89e8 to disappear
Apr 27 16:17:48.140: INFO: Pod pod-projected-configmaps-924531a4-ae45-458b-a950-7b90f40d89e8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:17:48.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8963" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":43,"skipped":698,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:17:48.173: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3318
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:17:48.364: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:17:52.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3318" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":277,"completed":44,"skipped":737,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:17:52.649: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-9986
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-9986, will wait for the garbage collector to delete the pods
Apr 27 16:17:56.933: INFO: Deleting Job.batch foo took: 13.423436ms
Apr 27 16:17:57.433: INFO: Terminating Job.batch foo pods took: 500.444369ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:18:38.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9986" for this suite.
•{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":277,"completed":45,"skipped":766,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:18:38.678: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8865
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:18:39.630: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601119, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601119, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601119, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601119, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:18:41.642: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601119, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601119, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601119, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601119, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:18:44.662: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Apr 27 16:18:44.788: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:18:44.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8865" for this suite.
STEP: Destroying namespace "webhook-8865-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":277,"completed":46,"skipped":774,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:18:44.965: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-5588
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:18:45.733: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601125, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601125, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601125, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601125, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:18:47.745: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601125, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601125, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601125, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601125, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:18:50.763: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:18:50.775: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:18:52.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-5588" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137
•{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":277,"completed":47,"skipped":779,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:18:52.452: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5583
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service nodeport-test with type=NodePort in namespace services-5583
STEP: creating replication controller nodeport-test in namespace services-5583
I0427 16:18:52.922565    7292 runners.go:190] Created replication controller with name: nodeport-test, namespace: services-5583, replica count: 2
Apr 27 16:18:55.973: INFO: Creating new exec pod
I0427 16:18:55.973294    7292 runners.go:190] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 27 16:19:01.028: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-5583 execpoddwrkc -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Apr 27 16:19:01.597: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Apr 27 16:19:01.597: INFO: stdout: ""
Apr 27 16:19:01.598: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-5583 execpoddwrkc -- /bin/sh -x -c nc -zv -t -w 2 100.110.155.129 80'
Apr 27 16:19:02.138: INFO: stderr: "+ nc -zv -t -w 2 100.110.155.129 80\nConnection to 100.110.155.129 80 port [tcp/http] succeeded!\n"
Apr 27 16:19:02.138: INFO: stdout: ""
Apr 27 16:19:02.138: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-5583 execpoddwrkc -- /bin/sh -x -c nc -zv -t -w 2 10.250.0.4 32617'
Apr 27 16:19:02.663: INFO: stderr: "+ nc -zv -t -w 2 10.250.0.4 32617\nConnection to 10.250.0.4 32617 port [tcp/32617] succeeded!\n"
Apr 27 16:19:02.663: INFO: stdout: ""
Apr 27 16:19:02.663: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-5583 execpoddwrkc -- /bin/sh -x -c nc -zv -t -w 2 10.250.0.5 32617'
Apr 27 16:19:03.231: INFO: stderr: "+ nc -zv -t -w 2 10.250.0.5 32617\nConnection to 10.250.0.5 32617 port [tcp/32617] succeeded!\n"
Apr 27 16:19:03.231: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:19:03.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5583" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":277,"completed":48,"skipped":799,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:19:03.264: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3235
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:19:03.476: INFO: (0) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 16.080718ms)
Apr 27 16:19:03.518: INFO: (1) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 41.091705ms)
Apr 27 16:19:03.530: INFO: (2) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 12.07593ms)
Apr 27 16:19:03.541: INFO: (3) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 11.555292ms)
Apr 27 16:19:03.553: INFO: (4) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 11.79ms)
Apr 27 16:19:03.565: INFO: (5) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 11.761726ms)
Apr 27 16:19:03.577: INFO: (6) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 11.772152ms)
Apr 27 16:19:03.589: INFO: (7) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 11.832968ms)
Apr 27 16:19:03.601: INFO: (8) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 12.046608ms)
Apr 27 16:19:03.613: INFO: (9) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 12.139054ms)
Apr 27 16:19:03.625: INFO: (10) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 11.474464ms)
Apr 27 16:19:03.636: INFO: (11) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 11.612951ms)
Apr 27 16:19:03.648: INFO: (12) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 11.802861ms)
Apr 27 16:19:03.660: INFO: (13) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 11.908474ms)
Apr 27 16:19:03.672: INFO: (14) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 11.807957ms)
Apr 27 16:19:03.685: INFO: (15) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 12.575053ms)
Apr 27 16:19:03.697: INFO: (16) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 11.77012ms)
Apr 27 16:19:03.708: INFO: (17) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 11.52441ms)
Apr 27 16:19:03.720: INFO: (18) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 11.747396ms)
Apr 27 16:19:03.732: INFO: (19) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 11.411186ms)
[AfterEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:19:03.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3235" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]","total":277,"completed":49,"skipped":813,"failed":0}
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:19:03.754: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2241
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:19:03.953: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ed4189c3-eaa2-4106-84ef-289ab51f88ac" in namespace "projected-2241" to be "Succeeded or Failed"
Apr 27 16:19:03.963: INFO: Pod "downwardapi-volume-ed4189c3-eaa2-4106-84ef-289ab51f88ac": Phase="Pending", Reason="", readiness=false. Elapsed: 10.048895ms
Apr 27 16:19:05.975: INFO: Pod "downwardapi-volume-ed4189c3-eaa2-4106-84ef-289ab51f88ac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02196541s
Apr 27 16:19:07.987: INFO: Pod "downwardapi-volume-ed4189c3-eaa2-4106-84ef-289ab51f88ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033527242s
STEP: Saw pod success
Apr 27 16:19:07.987: INFO: Pod "downwardapi-volume-ed4189c3-eaa2-4106-84ef-289ab51f88ac" satisfied condition "Succeeded or Failed"
Apr 27 16:19:07.997: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod downwardapi-volume-ed4189c3-eaa2-4106-84ef-289ab51f88ac container client-container: <nil>
STEP: delete the pod
Apr 27 16:19:08.028: INFO: Waiting for pod downwardapi-volume-ed4189c3-eaa2-4106-84ef-289ab51f88ac to disappear
Apr 27 16:19:08.038: INFO: Pod downwardapi-volume-ed4189c3-eaa2-4106-84ef-289ab51f88ac no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:19:08.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2241" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":50,"skipped":817,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:19:08.072: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2499
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Apr 27 16:19:08.271: INFO: Waiting up to 5m0s for pod "downward-api-16552d72-d0d9-4ff8-a883-fe686354cd46" in namespace "downward-api-2499" to be "Succeeded or Failed"
Apr 27 16:19:08.281: INFO: Pod "downward-api-16552d72-d0d9-4ff8-a883-fe686354cd46": Phase="Pending", Reason="", readiness=false. Elapsed: 10.364567ms
Apr 27 16:19:10.293: INFO: Pod "downward-api-16552d72-d0d9-4ff8-a883-fe686354cd46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022256977s
Apr 27 16:19:12.305: INFO: Pod "downward-api-16552d72-d0d9-4ff8-a883-fe686354cd46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034151439s
STEP: Saw pod success
Apr 27 16:19:12.305: INFO: Pod "downward-api-16552d72-d0d9-4ff8-a883-fe686354cd46" satisfied condition "Succeeded or Failed"
Apr 27 16:19:12.316: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod downward-api-16552d72-d0d9-4ff8-a883-fe686354cd46 container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:19:12.355: INFO: Waiting for pod downward-api-16552d72-d0d9-4ff8-a883-fe686354cd46 to disappear
Apr 27 16:19:12.365: INFO: Pod downward-api-16552d72-d0d9-4ff8-a883-fe686354cd46 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:19:12.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2499" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":277,"completed":51,"skipped":841,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:19:12.399: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3376
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:19:12.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3376" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":277,"completed":52,"skipped":914,"failed":0}
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:19:12.643: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5673
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Apr 27 16:19:12.911: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5673 /api/v1/namespaces/watch-5673/configmaps/e2e-watch-test-resource-version 05b54039-1944-45fa-bde1-562ad72faabd 9437 0 2020-04-27 16:19:12 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-04-27 16:19:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:19:12.911: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5673 /api/v1/namespaces/watch-5673/configmaps/e2e-watch-test-resource-version 05b54039-1944-45fa-bde1-562ad72faabd 9438 0 2020-04-27 16:19:12 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-04-27 16:19:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:19:12.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5673" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":277,"completed":53,"skipped":917,"failed":0}
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:19:12.936: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5571
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:19:29.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5571" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":277,"completed":54,"skipped":920,"failed":0}
SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:19:29.252: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2816
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's args
Apr 27 16:19:29.451: INFO: Waiting up to 5m0s for pod "var-expansion-65953183-e0f9-42ee-8dc6-7402c0834ee0" in namespace "var-expansion-2816" to be "Succeeded or Failed"
Apr 27 16:19:29.461: INFO: Pod "var-expansion-65953183-e0f9-42ee-8dc6-7402c0834ee0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.133108ms
Apr 27 16:19:31.473: INFO: Pod "var-expansion-65953183-e0f9-42ee-8dc6-7402c0834ee0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02191739s
Apr 27 16:19:33.485: INFO: Pod "var-expansion-65953183-e0f9-42ee-8dc6-7402c0834ee0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034183773s
STEP: Saw pod success
Apr 27 16:19:33.485: INFO: Pod "var-expansion-65953183-e0f9-42ee-8dc6-7402c0834ee0" satisfied condition "Succeeded or Failed"
Apr 27 16:19:33.495: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod var-expansion-65953183-e0f9-42ee-8dc6-7402c0834ee0 container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:19:33.532: INFO: Waiting for pod var-expansion-65953183-e0f9-42ee-8dc6-7402c0834ee0 to disappear
Apr 27 16:19:33.543: INFO: Pod var-expansion-65953183-e0f9-42ee-8dc6-7402c0834ee0 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:19:33.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2816" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":277,"completed":55,"skipped":930,"failed":0}
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:19:33.579: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7252
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-f929ae7e-5018-4980-ba8d-2ca7e3884aef in namespace container-probe-7252
Apr 27 16:19:37.798: INFO: Started pod liveness-f929ae7e-5018-4980-ba8d-2ca7e3884aef in namespace container-probe-7252
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 16:19:37.809: INFO: Initial restart count of pod liveness-f929ae7e-5018-4980-ba8d-2ca7e3884aef is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:23:39.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7252" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":277,"completed":56,"skipped":931,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:23:39.551: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-6669
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:23:40.193: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:23:41.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6669" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":277,"completed":57,"skipped":943,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:23:41.201: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4479
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Apr 27 16:23:41.431: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4479 /api/v1/namespaces/watch-4479/configmaps/e2e-watch-test-watch-closed a0a5a0f8-2590-4488-b581-5bc796166397 10667 0 2020-04-27 16:23:41 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-04-27 16:23:41 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:23:41.431: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4479 /api/v1/namespaces/watch-4479/configmaps/e2e-watch-test-watch-closed a0a5a0f8-2590-4488-b581-5bc796166397 10668 0 2020-04-27 16:23:41 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-04-27 16:23:41 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Apr 27 16:23:41.511: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4479 /api/v1/namespaces/watch-4479/configmaps/e2e-watch-test-watch-closed a0a5a0f8-2590-4488-b581-5bc796166397 10669 0 2020-04-27 16:23:41 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-04-27 16:23:41 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:23:41.512: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4479 /api/v1/namespaces/watch-4479/configmaps/e2e-watch-test-watch-closed a0a5a0f8-2590-4488-b581-5bc796166397 10670 0 2020-04-27 16:23:41 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-04-27 16:23:41 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:23:41.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4479" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":277,"completed":58,"skipped":974,"failed":0}
SSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:23:41.543: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2060
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:23:41.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2060" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":277,"completed":59,"skipped":978,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:23:41.762: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8443
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:23:43.201: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 27 16:23:45.238: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601423, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601423, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601423, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601423, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:23:48.269: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Apr 27 16:23:52.443: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config attach --namespace=webhook-8443 to-be-attached-pod -i -c=container1'
Apr 27 16:23:53.108: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:23:53.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8443" for this suite.
STEP: Destroying namespace "webhook-8443-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":277,"completed":60,"skipped":985,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:23:53.226: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1766
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-1766
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Apr 27 16:23:53.451: INFO: Found 0 stateful pods, waiting for 3
Apr 27 16:24:03.464: INFO: Found 2 stateful pods, waiting for 3
Apr 27 16:24:13.463: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:24:13.463: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:24:13.464: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Apr 27 16:24:13.530: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Apr 27 16:24:23.607: INFO: Updating stateful set ss2
Apr 27 16:24:23.633: INFO: Waiting for Pod statefulset-1766/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Apr 27 16:24:33.709: INFO: Found 2 stateful pods, waiting for 3
Apr 27 16:24:43.721: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:24:43.721: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:24:43.721: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Apr 27 16:24:53.721: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:24:53.721: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:24:53.721: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Apr 27 16:24:53.779: INFO: Updating stateful set ss2
Apr 27 16:24:53.801: INFO: Waiting for Pod statefulset-1766/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 27 16:25:03.858: INFO: Updating stateful set ss2
Apr 27 16:25:03.879: INFO: Waiting for StatefulSet statefulset-1766/ss2 to complete update
Apr 27 16:25:03.879: INFO: Waiting for Pod statefulset-1766/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 27 16:25:13.906: INFO: Waiting for StatefulSet statefulset-1766/ss2 to complete update
Apr 27 16:25:13.906: INFO: Waiting for Pod statefulset-1766/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 16:25:23.902: INFO: Deleting all statefulset in ns statefulset-1766
Apr 27 16:25:23.913: INFO: Scaling statefulset ss2 to 0
Apr 27 16:25:53.969: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:25:53.980: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:25:54.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1766" for this suite.
•{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":277,"completed":61,"skipped":1002,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:25:54.051: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4112
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service multi-endpoint-test in namespace services-4112
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4112 to expose endpoints map[]
Apr 27 16:25:54.270: INFO: successfully validated that service multi-endpoint-test in namespace services-4112 exposes endpoints map[] (9.882504ms elapsed)
STEP: Creating pod pod1 in namespace services-4112
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4112 to expose endpoints map[pod1:[100]]
Apr 27 16:25:56.359: INFO: successfully validated that service multi-endpoint-test in namespace services-4112 exposes endpoints map[pod1:[100]] (2.075861099s elapsed)
STEP: Creating pod pod2 in namespace services-4112
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4112 to expose endpoints map[pod1:[100] pod2:[101]]
Apr 27 16:25:59.498: INFO: successfully validated that service multi-endpoint-test in namespace services-4112 exposes endpoints map[pod1:[100] pod2:[101]] (3.126651759s elapsed)
STEP: Deleting pod pod1 in namespace services-4112
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4112 to expose endpoints map[pod2:[101]]
Apr 27 16:25:59.538: INFO: successfully validated that service multi-endpoint-test in namespace services-4112 exposes endpoints map[pod2:[101]] (21.356548ms elapsed)
STEP: Deleting pod pod2 in namespace services-4112
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4112 to expose endpoints map[]
Apr 27 16:25:59.562: INFO: successfully validated that service multi-endpoint-test in namespace services-4112 exposes endpoints map[] (11.168004ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:25:59.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4112" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":277,"completed":62,"skipped":1016,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:25:59.614: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6401
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6401.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6401.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6401.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6401.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6401.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6401.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 16:26:06.377: INFO: DNS probes using dns-6401/dns-test-1f759e12-108e-4ab4-8990-bed7a67caf59 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:26:06.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6401" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":277,"completed":63,"skipped":1044,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:26:06.427: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2017
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting the proxy server
Apr 27 16:26:06.614: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:26:06.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2017" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":277,"completed":64,"skipped":1065,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:26:06.746: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2297
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2297.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-2297.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2297.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2297.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-2297.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2297.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 16:26:13.549: INFO: DNS probes using dns-2297/dns-test-316e4cee-0afb-426d-9313-0762e45387dd succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:26:13.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2297" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":277,"completed":65,"skipped":1086,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:26:13.620: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7066
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:157
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:26:13.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7066" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":277,"completed":66,"skipped":1106,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:26:13.853: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1965
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-1965
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 27 16:26:14.034: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 27 16:26:14.092: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:26:16.102: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:26:18.103: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:26:20.104: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:26:22.103: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:26:24.103: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:26:26.103: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:26:28.107: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:26:30.103: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:26:32.104: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr 27 16:26:32.124: INFO: The status of Pod netserver-1 is Running (Ready = false)
Apr 27 16:26:34.136: INFO: The status of Pod netserver-1 is Running (Ready = false)
Apr 27 16:26:36.136: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Apr 27 16:26:40.230: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.0.22 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1965 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:26:40.230: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:26:41.676: INFO: Found all expected endpoints: [netserver-0]
Apr 27 16:26:41.687: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.1.78 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1965 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:26:41.687: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:26:43.102: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:26:43.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1965" for this suite.
•{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":67,"skipped":1127,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:26:43.133: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3353
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:26:43.341: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f70d258d-39d4-4fc8-8e5f-f458558cd2b1" in namespace "downward-api-3353" to be "Succeeded or Failed"
Apr 27 16:26:43.352: INFO: Pod "downwardapi-volume-f70d258d-39d4-4fc8-8e5f-f458558cd2b1": Phase="Pending", Reason="", readiness=false. Elapsed: 11.175909ms
Apr 27 16:26:45.364: INFO: Pod "downwardapi-volume-f70d258d-39d4-4fc8-8e5f-f458558cd2b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023050244s
Apr 27 16:26:47.376: INFO: Pod "downwardapi-volume-f70d258d-39d4-4fc8-8e5f-f458558cd2b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035644021s
STEP: Saw pod success
Apr 27 16:26:47.376: INFO: Pod "downwardapi-volume-f70d258d-39d4-4fc8-8e5f-f458558cd2b1" satisfied condition "Succeeded or Failed"
Apr 27 16:26:47.388: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod downwardapi-volume-f70d258d-39d4-4fc8-8e5f-f458558cd2b1 container client-container: <nil>
STEP: delete the pod
Apr 27 16:26:47.515: INFO: Waiting for pod downwardapi-volume-f70d258d-39d4-4fc8-8e5f-f458558cd2b1 to disappear
Apr 27 16:26:47.526: INFO: Pod downwardapi-volume-f70d258d-39d4-4fc8-8e5f-f458558cd2b1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:26:47.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3353" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":68,"skipped":1148,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:26:47.558: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5598
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-473c6459-77a8-4260-bb77-42aa8ab5b2b2
STEP: Creating a pod to test consume configMaps
Apr 27 16:26:47.768: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-355b7b2a-18e4-48f4-bd79-2a7c9a33df57" in namespace "projected-5598" to be "Succeeded or Failed"
Apr 27 16:26:47.778: INFO: Pod "pod-projected-configmaps-355b7b2a-18e4-48f4-bd79-2a7c9a33df57": Phase="Pending", Reason="", readiness=false. Elapsed: 10.279406ms
Apr 27 16:26:49.790: INFO: Pod "pod-projected-configmaps-355b7b2a-18e4-48f4-bd79-2a7c9a33df57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021630389s
Apr 27 16:26:51.801: INFO: Pod "pod-projected-configmaps-355b7b2a-18e4-48f4-bd79-2a7c9a33df57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033338066s
STEP: Saw pod success
Apr 27 16:26:51.802: INFO: Pod "pod-projected-configmaps-355b7b2a-18e4-48f4-bd79-2a7c9a33df57" satisfied condition "Succeeded or Failed"
Apr 27 16:26:51.812: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-projected-configmaps-355b7b2a-18e4-48f4-bd79-2a7c9a33df57 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:26:51.849: INFO: Waiting for pod pod-projected-configmaps-355b7b2a-18e4-48f4-bd79-2a7c9a33df57 to disappear
Apr 27 16:26:51.860: INFO: Pod pod-projected-configmaps-355b7b2a-18e4-48f4-bd79-2a7c9a33df57 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:26:51.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5598" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":69,"skipped":1153,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:26:51.892: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2372
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:03.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2372" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":277,"completed":70,"skipped":1159,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:03.203: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-1048
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
Apr 27 16:27:03.948: INFO: created pod pod-service-account-defaultsa
Apr 27 16:27:03.948: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr 27 16:27:03.960: INFO: created pod pod-service-account-mountsa
Apr 27 16:27:03.960: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr 27 16:27:03.971: INFO: created pod pod-service-account-nomountsa
Apr 27 16:27:03.971: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr 27 16:27:03.983: INFO: created pod pod-service-account-defaultsa-mountspec
Apr 27 16:27:03.983: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr 27 16:27:03.994: INFO: created pod pod-service-account-mountsa-mountspec
Apr 27 16:27:03.994: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr 27 16:27:04.010: INFO: created pod pod-service-account-nomountsa-mountspec
Apr 27 16:27:04.010: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr 27 16:27:04.021: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr 27 16:27:04.022: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr 27 16:27:04.033: INFO: created pod pod-service-account-mountsa-nomountspec
Apr 27 16:27:04.033: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr 27 16:27:04.044: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr 27 16:27:04.044: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:04.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1048" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":277,"completed":71,"skipped":1174,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:04.079: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7513
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Apr 27 16:27:04.900: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:04.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0427 16:27:04.900396    7292 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-7513" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":277,"completed":72,"skipped":1192,"failed":0}
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:04.923: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1561
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 27 16:27:05.120: INFO: Waiting up to 5m0s for pod "pod-ffa3d36c-2cab-4c2f-ab59-43dce8103f54" in namespace "emptydir-1561" to be "Succeeded or Failed"
Apr 27 16:27:05.130: INFO: Pod "pod-ffa3d36c-2cab-4c2f-ab59-43dce8103f54": Phase="Pending", Reason="", readiness=false. Elapsed: 10.141036ms
Apr 27 16:27:07.141: INFO: Pod "pod-ffa3d36c-2cab-4c2f-ab59-43dce8103f54": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021332472s
Apr 27 16:27:09.153: INFO: Pod "pod-ffa3d36c-2cab-4c2f-ab59-43dce8103f54": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03293642s
STEP: Saw pod success
Apr 27 16:27:09.153: INFO: Pod "pod-ffa3d36c-2cab-4c2f-ab59-43dce8103f54" satisfied condition "Succeeded or Failed"
Apr 27 16:27:09.164: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 pod pod-ffa3d36c-2cab-4c2f-ab59-43dce8103f54 container test-container: <nil>
STEP: delete the pod
Apr 27 16:27:09.287: INFO: Waiting for pod pod-ffa3d36c-2cab-4c2f-ab59-43dce8103f54 to disappear
Apr 27 16:27:09.297: INFO: Pod pod-ffa3d36c-2cab-4c2f-ab59-43dce8103f54 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:09.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1561" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":73,"skipped":1197,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:09.336: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7409
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:27:09.552: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5431f249-6518-48e2-a2b7-f4214f5a4369" in namespace "downward-api-7409" to be "Succeeded or Failed"
Apr 27 16:27:09.562: INFO: Pod "downwardapi-volume-5431f249-6518-48e2-a2b7-f4214f5a4369": Phase="Pending", Reason="", readiness=false. Elapsed: 10.348069ms
Apr 27 16:27:11.574: INFO: Pod "downwardapi-volume-5431f249-6518-48e2-a2b7-f4214f5a4369": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022015877s
Apr 27 16:27:13.586: INFO: Pod "downwardapi-volume-5431f249-6518-48e2-a2b7-f4214f5a4369": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034032547s
Apr 27 16:27:15.597: INFO: Pod "downwardapi-volume-5431f249-6518-48e2-a2b7-f4214f5a4369": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.045493124s
STEP: Saw pod success
Apr 27 16:27:15.597: INFO: Pod "downwardapi-volume-5431f249-6518-48e2-a2b7-f4214f5a4369" satisfied condition "Succeeded or Failed"
Apr 27 16:27:15.608: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 pod downwardapi-volume-5431f249-6518-48e2-a2b7-f4214f5a4369 container client-container: <nil>
STEP: delete the pod
Apr 27 16:27:15.643: INFO: Waiting for pod downwardapi-volume-5431f249-6518-48e2-a2b7-f4214f5a4369 to disappear
Apr 27 16:27:15.653: INFO: Pod downwardapi-volume-5431f249-6518-48e2-a2b7-f4214f5a4369 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:15.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7409" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":74,"skipped":1199,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:15.685: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5583
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Apr 27 16:27:15.868: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:35.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5583" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":277,"completed":75,"skipped":1200,"failed":0}

------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:35.054: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9869
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:46.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9869" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":277,"completed":76,"skipped":1200,"failed":0}

------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:46.376: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5157
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-5157
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-5157
I0427 16:27:46.618178    7292 runners.go:190] Created replication controller with name: externalname-service, namespace: services-5157, replica count: 2
Apr 27 16:27:49.668: INFO: Creating new exec pod
I0427 16:27:49.668922    7292 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 27 16:27:54.703: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-5157 execpodfngkd -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Apr 27 16:27:55.256: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 27 16:27:55.256: INFO: stdout: ""
Apr 27 16:27:55.257: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-5157 execpodfngkd -- /bin/sh -x -c nc -zv -t -w 2 100.105.211.85 80'
Apr 27 16:27:55.787: INFO: stderr: "+ nc -zv -t -w 2 100.105.211.85 80\nConnection to 100.105.211.85 80 port [tcp/http] succeeded!\n"
Apr 27 16:27:55.787: INFO: stdout: ""
Apr 27 16:27:55.787: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:55.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5157" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":277,"completed":77,"skipped":1200,"failed":0}
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:55.839: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-5096
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Apr 27 16:28:01.119: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:28:01.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5096" for this suite.
•{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":277,"completed":78,"skipped":1204,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:28:01.193: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5933
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:28:01.398: INFO: Waiting up to 5m0s for pod "downwardapi-volume-885a57de-a582-4d9e-a3b0-c45de6be0975" in namespace "downward-api-5933" to be "Succeeded or Failed"
Apr 27 16:28:01.409: INFO: Pod "downwardapi-volume-885a57de-a582-4d9e-a3b0-c45de6be0975": Phase="Pending", Reason="", readiness=false. Elapsed: 10.616594ms
Apr 27 16:28:03.421: INFO: Pod "downwardapi-volume-885a57de-a582-4d9e-a3b0-c45de6be0975": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02292612s
Apr 27 16:28:05.434: INFO: Pod "downwardapi-volume-885a57de-a582-4d9e-a3b0-c45de6be0975": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03551469s
STEP: Saw pod success
Apr 27 16:28:05.434: INFO: Pod "downwardapi-volume-885a57de-a582-4d9e-a3b0-c45de6be0975" satisfied condition "Succeeded or Failed"
Apr 27 16:28:05.445: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod downwardapi-volume-885a57de-a582-4d9e-a3b0-c45de6be0975 container client-container: <nil>
STEP: delete the pod
Apr 27 16:28:05.481: INFO: Waiting for pod downwardapi-volume-885a57de-a582-4d9e-a3b0-c45de6be0975 to disappear
Apr 27 16:28:05.502: INFO: Pod downwardapi-volume-885a57de-a582-4d9e-a3b0-c45de6be0975 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:28:05.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5933" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":277,"completed":79,"skipped":1211,"failed":0}
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:28:05.561: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5284
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 27 16:28:05.760: INFO: Waiting up to 5m0s for pod "pod-236f20da-1b5e-4452-a2b6-bbf1a013d1fc" in namespace "emptydir-5284" to be "Succeeded or Failed"
Apr 27 16:28:05.771: INFO: Pod "pod-236f20da-1b5e-4452-a2b6-bbf1a013d1fc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.579756ms
Apr 27 16:28:07.783: INFO: Pod "pod-236f20da-1b5e-4452-a2b6-bbf1a013d1fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022327884s
Apr 27 16:28:09.794: INFO: Pod "pod-236f20da-1b5e-4452-a2b6-bbf1a013d1fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033993698s
STEP: Saw pod success
Apr 27 16:28:09.794: INFO: Pod "pod-236f20da-1b5e-4452-a2b6-bbf1a013d1fc" satisfied condition "Succeeded or Failed"
Apr 27 16:28:09.805: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-236f20da-1b5e-4452-a2b6-bbf1a013d1fc container test-container: <nil>
STEP: delete the pod
Apr 27 16:28:09.842: INFO: Waiting for pod pod-236f20da-1b5e-4452-a2b6-bbf1a013d1fc to disappear
Apr 27 16:28:09.853: INFO: Pod pod-236f20da-1b5e-4452-a2b6-bbf1a013d1fc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:28:09.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5284" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":80,"skipped":1217,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:28:09.886: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7635
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:28:10.145: INFO: Create a RollingUpdate DaemonSet
Apr 27 16:28:10.157: INFO: Check that daemon pods launch on every node of the cluster
Apr 27 16:28:10.178: INFO: Number of nodes with available pods: 0
Apr 27 16:28:10.178: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 16:28:11.211: INFO: Number of nodes with available pods: 0
Apr 27 16:28:11.211: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 16:28:12.211: INFO: Number of nodes with available pods: 0
Apr 27 16:28:12.211: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 16:28:13.211: INFO: Number of nodes with available pods: 2
Apr 27 16:28:13.211: INFO: Number of running nodes: 2, number of available pods: 2
Apr 27 16:28:13.211: INFO: Update the DaemonSet to trigger a rollout
Apr 27 16:28:13.233: INFO: Updating DaemonSet daemon-set
Apr 27 16:28:17.293: INFO: Roll back the DaemonSet before rollout is complete
Apr 27 16:28:17.320: INFO: Updating DaemonSet daemon-set
Apr 27 16:28:17.320: INFO: Make sure DaemonSet rollback is complete
Apr 27 16:28:17.335: INFO: Wrong image for pod: daemon-set-sg8n8. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Apr 27 16:28:17.335: INFO: Pod daemon-set-sg8n8 is not available
Apr 27 16:28:18.358: INFO: Wrong image for pod: daemon-set-sg8n8. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Apr 27 16:28:18.358: INFO: Pod daemon-set-sg8n8 is not available
Apr 27 16:28:19.358: INFO: Pod daemon-set-f9rnh is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7635, will wait for the garbage collector to delete the pods
Apr 27 16:28:19.475: INFO: Deleting DaemonSet.extensions daemon-set took: 13.582259ms
Apr 27 16:28:19.575: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.347969ms
Apr 27 16:28:21.686: INFO: Number of nodes with available pods: 0
Apr 27 16:28:21.686: INFO: Number of running nodes: 0, number of available pods: 0
Apr 27 16:28:21.700: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7635/daemonsets","resourceVersion":"12743"},"items":null}

Apr 27 16:28:21.711: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7635/pods","resourceVersion":"12743"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:28:21.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7635" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":277,"completed":81,"skipped":1226,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:28:21.780: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1237
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Apr 27 16:28:21.972: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:28:26.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1237" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":277,"completed":82,"skipped":1293,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:28:26.381: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5614
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl replace
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Apr 27 16:28:26.562: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-pod --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-5614'
Apr 27 16:28:26.700: INFO: stderr: ""
Apr 27 16:28:26.700: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Apr 27 16:28:31.751: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod e2e-test-httpd-pod --namespace=kubectl-5614 -o json'
Apr 27 16:28:31.862: INFO: stderr: ""
Apr 27 16:28:31.862: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"100.64.1.102/32\",\n            \"cni.projectcalico.org/podIPs\": \"100.64.1.102/32\",\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2020-04-27T16:28:26Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"managedFields\": [\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:labels\": {\n                            \".\": {},\n                            \"f:run\": {}\n                        }\n                    },\n                    \"f:spec\": {\n                        \"f:containers\": {\n                            \"k:{\\\"name\\\":\\\"e2e-test-httpd-pod\\\"}\": {\n                                \".\": {},\n                                \"f:image\": {},\n                                \"f:imagePullPolicy\": {},\n                                \"f:name\": {},\n                                \"f:resources\": {},\n                                \"f:terminationMessagePath\": {},\n                                \"f:terminationMessagePolicy\": {}\n                            }\n                        },\n                        \"f:dnsPolicy\": {},\n                        \"f:enableServiceLinks\": {},\n                        \"f:restartPolicy\": {},\n                        \"f:schedulerName\": {},\n                        \"f:securityContext\": {},\n                        \"f:terminationGracePeriodSeconds\": {}\n                    }\n                },\n                \"manager\": \"kubectl\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-04-27T16:28:26Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:annotations\": {\n                            \"f:cni.projectcalico.org/podIP\": {},\n                            \"f:cni.projectcalico.org/podIPs\": {}\n                        }\n                    }\n                },\n                \"manager\": \"calico\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-04-27T16:28:27Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:status\": {\n                        \"f:conditions\": {\n                            \"k:{\\\"type\\\":\\\"ContainersReady\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Initialized\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Ready\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            }\n                        },\n                        \"f:containerStatuses\": {},\n                        \"f:hostIP\": {},\n                        \"f:phase\": {},\n                        \"f:podIP\": {},\n                        \"f:podIPs\": {\n                            \".\": {},\n                            \"k:{\\\"ip\\\":\\\"100.64.1.102\\\"}\": {\n                                \".\": {},\n                                \"f:ip\": {}\n                            }\n                        },\n                        \"f:startTime\": {}\n                    }\n                },\n                \"manager\": \"kubelet\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-04-27T16:28:28Z\"\n            }\n        ],\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-5614\",\n        \"resourceVersion\": \"12800\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-5614/pods/e2e-test-httpd-pod\",\n        \"uid\": \"c096c8bf-cb13-4901-ac0c-00f6b90d2682\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-j7s5l\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-j7s5l\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-j7s5l\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-27T16:28:26Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-27T16:28:28Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-27T16:28:28Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-27T16:28:26Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://984e0636a2c675ba3f511a29fa64fd064b4b3b17a764658bd18ff7245c2846a8\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-04-27T16:28:28Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.0.5\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.64.1.102\",\n        \"podIPs\": [\n            {\n                \"ip\": \"100.64.1.102\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-04-27T16:28:26Z\"\n    }\n}\n"
STEP: replace the image in the pod
Apr 27 16:28:31.862: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config replace -f - --namespace=kubectl-5614'
Apr 27 16:28:32.127: INFO: stderr: ""
Apr 27 16:28:32.127: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Apr 27 16:28:32.138: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pods e2e-test-httpd-pod --namespace=kubectl-5614'
Apr 27 16:28:38.535: INFO: stderr: ""
Apr 27 16:28:38.535: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:28:38.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5614" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":277,"completed":83,"skipped":1334,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:28:38.569: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1503
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:28:38.753: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:28:39.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1503" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":277,"completed":84,"skipped":1356,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:28:39.391: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6065
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name projected-secret-test-a115f048-9fad-4dfc-98a1-95687de6d2d0
STEP: Creating a pod to test consume secrets
Apr 27 16:28:39.613: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4f44ddb9-d10b-48ad-83d7-7aef0e84acab" in namespace "projected-6065" to be "Succeeded or Failed"
Apr 27 16:28:39.624: INFO: Pod "pod-projected-secrets-4f44ddb9-d10b-48ad-83d7-7aef0e84acab": Phase="Pending", Reason="", readiness=false. Elapsed: 10.474775ms
Apr 27 16:28:41.636: INFO: Pod "pod-projected-secrets-4f44ddb9-d10b-48ad-83d7-7aef0e84acab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02203797s
Apr 27 16:28:43.646: INFO: Pod "pod-projected-secrets-4f44ddb9-d10b-48ad-83d7-7aef0e84acab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032936455s
STEP: Saw pod success
Apr 27 16:28:43.647: INFO: Pod "pod-projected-secrets-4f44ddb9-d10b-48ad-83d7-7aef0e84acab" satisfied condition "Succeeded or Failed"
Apr 27 16:28:43.657: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-projected-secrets-4f44ddb9-d10b-48ad-83d7-7aef0e84acab container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:28:43.688: INFO: Waiting for pod pod-projected-secrets-4f44ddb9-d10b-48ad-83d7-7aef0e84acab to disappear
Apr 27 16:28:43.698: INFO: Pod pod-projected-secrets-4f44ddb9-d10b-48ad-83d7-7aef0e84acab no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:28:43.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6065" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":277,"completed":85,"skipped":1393,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:28:43.731: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9531
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-9531
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-9531
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9531
Apr 27 16:28:44.154: INFO: Found 0 stateful pods, waiting for 1
Apr 27 16:28:54.166: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Apr 27 16:28:54.177: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-9531 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:28:54.714: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:28:54.714: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:28:54.715: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:28:54.726: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 27 16:29:04.738: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:29:04.739: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:29:04.783: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999432s
Apr 27 16:29:05.795: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.989135164s
Apr 27 16:29:06.807: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.97683514s
Apr 27 16:29:07.819: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.965072176s
Apr 27 16:29:08.831: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.952648765s
Apr 27 16:29:09.843: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.940442509s
Apr 27 16:29:10.856: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.92822515s
Apr 27 16:29:11.868: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.916124457s
Apr 27 16:29:12.882: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.903733413s
Apr 27 16:29:13.894: INFO: Verifying statefulset ss doesn't scale past 1 for another 889.197468ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9531
Apr 27 16:29:14.905: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-9531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:29:15.413: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 16:29:15.413: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:29:15.413: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:29:15.425: INFO: Found 1 stateful pods, waiting for 3
Apr 27 16:29:25.437: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:29:25.437: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:29:25.437: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Apr 27 16:29:25.461: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-9531 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:29:25.989: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:29:25.989: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:29:25.989: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:29:25.989: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-9531 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:29:26.509: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:29:26.509: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:29:26.509: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:29:26.509: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-9531 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:29:27.028: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:29:27.028: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:29:27.028: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:29:27.028: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:29:27.039: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr 27 16:29:37.062: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:29:37.062: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:29:37.062: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:29:37.096: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999137s
Apr 27 16:29:38.108: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.988575514s
Apr 27 16:29:39.121: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.976602339s
Apr 27 16:29:40.133: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.963612392s
Apr 27 16:29:41.150: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.950773992s
Apr 27 16:29:42.163: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.934052382s
Apr 27 16:29:43.175: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.921553293s
Apr 27 16:29:44.187: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.909594776s
Apr 27 16:29:45.199: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.897008587s
Apr 27 16:29:46.212: INFO: Verifying statefulset ss doesn't scale past 3 for another 884.811577ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9531
Apr 27 16:29:47.224: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-9531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:29:47.754: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 16:29:47.754: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:29:47.754: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:29:47.754: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-9531 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:29:48.293: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 16:29:48.293: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:29:48.293: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:29:48.293: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-9531 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:29:48.814: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 16:29:48.814: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:29:48.814: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:29:48.814: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 16:30:08.863: INFO: Deleting all statefulset in ns statefulset-9531
Apr 27 16:30:08.881: INFO: Scaling statefulset ss to 0
Apr 27 16:30:08.914: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:30:08.924: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:08.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9531" for this suite.
•{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":277,"completed":86,"skipped":1414,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:08.993: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-9345
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 27 16:30:17.399: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 16:30:17.409: INFO: Pod pod-with-poststart-http-hook still exists
Apr 27 16:30:19.410: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 16:30:19.422: INFO: Pod pod-with-poststart-http-hook still exists
Apr 27 16:30:21.410: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 16:30:21.421: INFO: Pod pod-with-poststart-http-hook still exists
Apr 27 16:30:23.410: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 16:30:23.422: INFO: Pod pod-with-poststart-http-hook still exists
Apr 27 16:30:25.410: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 16:30:25.422: INFO: Pod pod-with-poststart-http-hook still exists
Apr 27 16:30:27.410: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 16:30:27.421: INFO: Pod pod-with-poststart-http-hook still exists
Apr 27 16:30:29.410: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 16:30:29.423: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:29.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9345" for this suite.
•{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":277,"completed":87,"skipped":1473,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:29.456: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5220
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:33.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5220" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":277,"completed":88,"skipped":1496,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:33.740: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8712
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating pod
Apr 27 16:30:37.985: INFO: Pod pod-hostip-2a3075a6-fcb8-41fe-a8c5-ddbbd39550f1 has hostIP: 10.250.0.5
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:37.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8712" for this suite.
•{"msg":"PASSED [k8s.io] Pods should get a host IP [NodeConformance] [Conformance]","total":277,"completed":89,"skipped":1520,"failed":0}

------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:38.016: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5076
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:30:38.224: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 27 16:30:42.248: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr 27 16:30:44.260: INFO: Creating deployment "test-rollover-deployment"
Apr 27 16:30:44.286: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr 27 16:30:46.324: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr 27 16:30:46.351: INFO: Ensure that both replica sets have 1 created replica
Apr 27 16:30:46.373: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr 27 16:30:46.395: INFO: Updating deployment test-rollover-deployment
Apr 27 16:30:46.395: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr 27 16:30:48.419: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr 27 16:30:48.442: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr 27 16:30:48.464: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 16:30:48.464: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601844, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601844, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601846, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601844, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:30:50.487: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 16:30:50.487: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601844, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601844, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601848, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601844, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:30:52.487: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 16:30:52.487: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601844, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601844, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601848, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601844, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:30:54.487: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 16:30:54.487: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601844, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601844, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601848, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601844, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:30:56.487: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 16:30:56.487: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601844, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601844, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601848, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601844, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:30:58.487: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 16:30:58.487: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601844, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601844, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601848, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601844, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:31:00.487: INFO: 
Apr 27 16:31:00.487: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Apr 27 16:31:00.520: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-5076 /apis/apps/v1/namespaces/deployment-5076/deployments/test-rollover-deployment 8891a9f5-ab18-454d-b63b-19ce88ae79b5 13721 2 2020-04-27 16:30:44 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-04-27 16:30:46 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 16:30:59 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0058b18a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-04-27 16:30:44 +0000 UTC,LastTransitionTime:2020-04-27 16:30:44 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-84f7f6f64b" has successfully progressed.,LastUpdateTime:2020-04-27 16:30:59 +0000 UTC,LastTransitionTime:2020-04-27 16:30:44 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 27 16:31:00.531: INFO: New ReplicaSet "test-rollover-deployment-84f7f6f64b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-84f7f6f64b  deployment-5076 /apis/apps/v1/namespaces/deployment-5076/replicasets/test-rollover-deployment-84f7f6f64b 06e34bf7-75f9-4771-a13b-c2689d71119d 13714 2 2020-04-27 16:30:46 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 8891a9f5-ab18-454d-b63b-19ce88ae79b5 0xc0058b1f07 0xc0058b1f08}] []  [{kube-controller-manager Update apps/v1 2020-04-27 16:30:58 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 56 56 57 49 97 57 102 53 45 97 98 49 56 45 52 53 52 100 45 98 54 51 98 45 49 57 99 101 56 56 97 101 55 57 98 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 84f7f6f64b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0058b1f98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:31:00.531: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr 27 16:31:00.531: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-5076 /apis/apps/v1/namespaces/deployment-5076/replicasets/test-rollover-controller a825cc04-4426-41f3-8a2c-736fed935dc7 13720 2 2020-04-27 16:30:38 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 8891a9f5-ab18-454d-b63b-19ce88ae79b5 0xc0058b1ce7 0xc0058b1ce8}] []  [{e2e.test Update apps/v1 2020-04-27 16:30:38 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 16:30:59 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 56 56 57 49 97 57 102 53 45 97 98 49 56 45 52 53 52 100 45 98 54 51 98 45 49 57 99 101 56 56 97 101 55 57 98 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0058b1d88 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:31:00.531: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-5686c4cfd5  deployment-5076 /apis/apps/v1/namespaces/deployment-5076/replicasets/test-rollover-deployment-5686c4cfd5 04e2be9f-de78-4978-be3a-0e933997c3c4 13657 2 2020-04-27 16:30:44 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 8891a9f5-ab18-454d-b63b-19ce88ae79b5 0xc0058b1e07 0xc0058b1e08}] []  [{kube-controller-manager Update apps/v1 2020-04-27 16:30:46 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 56 56 57 49 97 57 102 53 45 97 98 49 56 45 52 53 52 100 45 98 54 51 98 45 49 57 99 101 56 56 97 101 55 57 98 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 114 101 100 105 115 45 115 108 97 118 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5686c4cfd5,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0058b1e98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:31:00.542: INFO: Pod "test-rollover-deployment-84f7f6f64b-rrzsq" is available:
&Pod{ObjectMeta:{test-rollover-deployment-84f7f6f64b-rrzsq test-rollover-deployment-84f7f6f64b- deployment-5076 /api/v1/namespaces/deployment-5076/pods/test-rollover-deployment-84f7f6f64b-rrzsq 6c5b5269-4a62-40b8-b90d-486e65951bc3 13674 0 2020-04-27 16:30:46 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[cni.projectcalico.org/podIP:100.64.1.112/32 cni.projectcalico.org/podIPs:100.64.1.112/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rollover-deployment-84f7f6f64b 06e34bf7-75f9-4771-a13b-c2689d71119d 0xc00586c577 0xc00586c578}] []  [{kube-controller-manager Update v1 2020-04-27 16:30:46 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 54 101 51 52 98 102 55 45 55 53 102 57 45 52 55 55 49 45 97 49 51 98 45 99 50 54 56 57 100 55 49 49 49 57 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:30:47 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:30:48 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 49 49 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-72cpv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-72cpv,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-72cpv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:30:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:30:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:30:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:30:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.1.112,StartTime:2020-04-27 16:30:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:30:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://22c25067efa4f386ee309a1ca1a2acde01ba4e1597317af3a4faf7e885392b29,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.112,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:00.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5076" for this suite.
•{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":277,"completed":90,"skipped":1520,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:00.575: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-9580
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:31:00.758: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:03.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9580" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":277,"completed":91,"skipped":1547,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:03.345: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-985
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:31:03.824: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3366f095-99c9-4bda-ba1b-512ef8d79c54" in namespace "projected-985" to be "Succeeded or Failed"
Apr 27 16:31:03.834: INFO: Pod "downwardapi-volume-3366f095-99c9-4bda-ba1b-512ef8d79c54": Phase="Pending", Reason="", readiness=false. Elapsed: 10.532135ms
Apr 27 16:31:05.846: INFO: Pod "downwardapi-volume-3366f095-99c9-4bda-ba1b-512ef8d79c54": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021581418s
Apr 27 16:31:07.857: INFO: Pod "downwardapi-volume-3366f095-99c9-4bda-ba1b-512ef8d79c54": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032979011s
STEP: Saw pod success
Apr 27 16:31:07.857: INFO: Pod "downwardapi-volume-3366f095-99c9-4bda-ba1b-512ef8d79c54" satisfied condition "Succeeded or Failed"
Apr 27 16:31:07.868: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod downwardapi-volume-3366f095-99c9-4bda-ba1b-512ef8d79c54 container client-container: <nil>
STEP: delete the pod
Apr 27 16:31:07.941: INFO: Waiting for pod downwardapi-volume-3366f095-99c9-4bda-ba1b-512ef8d79c54 to disappear
Apr 27 16:31:07.952: INFO: Pod downwardapi-volume-3366f095-99c9-4bda-ba1b-512ef8d79c54 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:07.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-985" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":277,"completed":92,"skipped":1563,"failed":0}
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:07.983: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3134
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:31:08.179: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0bb5d8ac-26b6-40e9-afcc-0036903bbc16" in namespace "projected-3134" to be "Succeeded or Failed"
Apr 27 16:31:08.189: INFO: Pod "downwardapi-volume-0bb5d8ac-26b6-40e9-afcc-0036903bbc16": Phase="Pending", Reason="", readiness=false. Elapsed: 10.327768ms
Apr 27 16:31:10.201: INFO: Pod "downwardapi-volume-0bb5d8ac-26b6-40e9-afcc-0036903bbc16": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022051703s
Apr 27 16:31:12.213: INFO: Pod "downwardapi-volume-0bb5d8ac-26b6-40e9-afcc-0036903bbc16": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034143757s
STEP: Saw pod success
Apr 27 16:31:12.213: INFO: Pod "downwardapi-volume-0bb5d8ac-26b6-40e9-afcc-0036903bbc16" satisfied condition "Succeeded or Failed"
Apr 27 16:31:12.224: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod downwardapi-volume-0bb5d8ac-26b6-40e9-afcc-0036903bbc16 container client-container: <nil>
STEP: delete the pod
Apr 27 16:31:12.263: INFO: Waiting for pod downwardapi-volume-0bb5d8ac-26b6-40e9-afcc-0036903bbc16 to disappear
Apr 27 16:31:12.273: INFO: Pod downwardapi-volume-0bb5d8ac-26b6-40e9-afcc-0036903bbc16 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:12.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3134" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":277,"completed":93,"skipped":1564,"failed":0}
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:12.306: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4651
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:31:12.527: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 27 16:31:16.549: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Apr 27 16:31:20.636: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-4651 /apis/apps/v1/namespaces/deployment-4651/deployments/test-cleanup-deployment 25825645-cab0-4f57-a8aa-b73752688c52 13944 1 2020-04-27 16:31:16 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 2020-04-27 16:31:16 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 16:31:18 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004a76538 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-04-27 16:31:16 +0000 UTC,LastTransitionTime:2020-04-27 16:31:16 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-b4867b47f" has successfully progressed.,LastUpdateTime:2020-04-27 16:31:18 +0000 UTC,LastTransitionTime:2020-04-27 16:31:16 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 27 16:31:20.653: INFO: New ReplicaSet "test-cleanup-deployment-b4867b47f" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-b4867b47f  deployment-4651 /apis/apps/v1/namespaces/deployment-4651/replicasets/test-cleanup-deployment-b4867b47f 85d1b4a0-5f55-4799-b14b-77205f33a0e8 13937 1 2020-04-27 16:31:16 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 25825645-cab0-4f57-a8aa-b73752688c52 0xc004a76990 0xc004a76991}] []  [{kube-controller-manager Update apps/v1 2020-04-27 16:31:18 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 53 56 50 53 54 52 53 45 99 97 98 48 45 52 102 53 55 45 97 56 97 97 45 98 55 51 55 53 50 54 56 56 99 53 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: b4867b47f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004a76a08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:31:20.665: INFO: Pod "test-cleanup-deployment-b4867b47f-k2v6c" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-b4867b47f-k2v6c test-cleanup-deployment-b4867b47f- deployment-4651 /api/v1/namespaces/deployment-4651/pods/test-cleanup-deployment-b4867b47f-k2v6c 05b723a8-62cb-4cab-bff8-667d23ee896f 13936 0 2020-04-27 16:31:16 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[cni.projectcalico.org/podIP:100.64.1.116/32 cni.projectcalico.org/podIPs:100.64.1.116/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-cleanup-deployment-b4867b47f 85d1b4a0-5f55-4799-b14b-77205f33a0e8 0xc004a76e30 0xc004a76e31}] []  [{kube-controller-manager Update v1 2020-04-27 16:31:16 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 56 53 100 49 98 52 97 48 45 53 102 53 53 45 52 55 57 57 45 98 49 52 98 45 55 55 50 48 53 102 51 51 97 48 101 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:31:17 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:31:18 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 49 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2tjrj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2tjrj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2tjrj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:31:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:31:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:31:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:31:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.1.116,StartTime:2020-04-27 16:31:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:31:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://cd3cce1309d80dec4f7ced269db879ac0bbb5c4ce5ef2e1c3b5675387abadec0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.116,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:20.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4651" for this suite.
•{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":277,"completed":94,"skipped":1568,"failed":0}
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:20.698: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-29
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 27 16:31:28.998: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 16:31:29.022: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 27 16:31:31.022: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 16:31:31.034: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 27 16:31:33.022: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 16:31:33.033: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 27 16:31:35.022: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 16:31:35.034: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 27 16:31:37.022: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 16:31:37.033: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 27 16:31:39.022: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 16:31:39.033: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:39.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-29" for this suite.
•{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":277,"completed":95,"skipped":1581,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:39.088: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2711
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:31:39.346: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Apr 27 16:31:39.390: INFO: Number of nodes with available pods: 0
Apr 27 16:31:39.390: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 16:31:40.425: INFO: Number of nodes with available pods: 0
Apr 27 16:31:40.425: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 16:31:41.425: INFO: Number of nodes with available pods: 1
Apr 27 16:31:41.425: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 16:31:42.424: INFO: Number of nodes with available pods: 2
Apr 27 16:31:42.424: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Apr 27 16:31:42.514: INFO: Wrong image for pod: daemon-set-l4l2k. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:31:42.514: INFO: Wrong image for pod: daemon-set-zpdfj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:31:43.537: INFO: Wrong image for pod: daemon-set-l4l2k. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:31:43.537: INFO: Wrong image for pod: daemon-set-zpdfj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:31:44.537: INFO: Wrong image for pod: daemon-set-l4l2k. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:31:44.537: INFO: Wrong image for pod: daemon-set-zpdfj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:31:45.536: INFO: Wrong image for pod: daemon-set-l4l2k. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:31:45.537: INFO: Pod daemon-set-l4l2k is not available
Apr 27 16:31:45.537: INFO: Wrong image for pod: daemon-set-zpdfj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:31:46.536: INFO: Pod daemon-set-85bqn is not available
Apr 27 16:31:46.536: INFO: Wrong image for pod: daemon-set-zpdfj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:31:47.537: INFO: Pod daemon-set-85bqn is not available
Apr 27 16:31:47.537: INFO: Wrong image for pod: daemon-set-zpdfj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:31:48.536: INFO: Wrong image for pod: daemon-set-zpdfj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:31:49.537: INFO: Wrong image for pod: daemon-set-zpdfj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:31:49.537: INFO: Pod daemon-set-zpdfj is not available
Apr 27 16:31:50.537: INFO: Wrong image for pod: daemon-set-zpdfj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:31:50.537: INFO: Pod daemon-set-zpdfj is not available
Apr 27 16:31:51.537: INFO: Wrong image for pod: daemon-set-zpdfj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:31:51.537: INFO: Pod daemon-set-zpdfj is not available
Apr 27 16:31:52.537: INFO: Wrong image for pod: daemon-set-zpdfj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:31:52.537: INFO: Pod daemon-set-zpdfj is not available
Apr 27 16:31:53.537: INFO: Wrong image for pod: daemon-set-zpdfj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:31:53.537: INFO: Pod daemon-set-zpdfj is not available
Apr 27 16:31:54.537: INFO: Wrong image for pod: daemon-set-zpdfj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:31:54.537: INFO: Pod daemon-set-zpdfj is not available
Apr 27 16:31:55.537: INFO: Wrong image for pod: daemon-set-zpdfj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:31:55.537: INFO: Pod daemon-set-zpdfj is not available
Apr 27 16:31:56.537: INFO: Wrong image for pod: daemon-set-zpdfj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:31:56.537: INFO: Pod daemon-set-zpdfj is not available
Apr 27 16:31:57.537: INFO: Wrong image for pod: daemon-set-zpdfj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:31:57.537: INFO: Pod daemon-set-zpdfj is not available
Apr 27 16:31:58.540: INFO: Pod daemon-set-fz9g7 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Apr 27 16:31:58.582: INFO: Number of nodes with available pods: 1
Apr 27 16:31:58.582: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r is running more than one daemon pod
Apr 27 16:31:59.614: INFO: Number of nodes with available pods: 1
Apr 27 16:31:59.614: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r is running more than one daemon pod
Apr 27 16:32:00.614: INFO: Number of nodes with available pods: 1
Apr 27 16:32:00.614: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r is running more than one daemon pod
Apr 27 16:32:01.613: INFO: Number of nodes with available pods: 2
Apr 27 16:32:01.614: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2711, will wait for the garbage collector to delete the pods
Apr 27 16:32:01.751: INFO: Deleting DaemonSet.extensions daemon-set took: 13.201377ms
Apr 27 16:32:02.252: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.420495ms
Apr 27 16:32:08.565: INFO: Number of nodes with available pods: 0
Apr 27 16:32:08.565: INFO: Number of running nodes: 0, number of available pods: 0
Apr 27 16:32:08.575: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2711/daemonsets","resourceVersion":"14260"},"items":null}

Apr 27 16:32:08.586: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2711/pods","resourceVersion":"14260"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:32:08.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2711" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":277,"completed":96,"skipped":1592,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:32:08.652: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3510
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:32:09.445: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601929, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601929, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601929, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601929, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:32:11.456: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601929, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601929, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601929, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601929, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:32:14.477: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:32:14.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3510" for this suite.
STEP: Destroying namespace "webhook-3510-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":277,"completed":97,"skipped":1600,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:32:14.840: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5685
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-5685
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 27 16:32:15.026: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 27 16:32:15.086: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:32:17.097: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:32:19.098: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:32:21.098: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:32:23.097: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:32:25.097: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:32:27.097: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:32:29.098: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:32:31.098: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:32:33.097: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:32:35.098: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr 27 16:32:35.120: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Apr 27 16:32:39.186: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.123:8080/dial?request=hostname&protocol=http&host=100.64.0.31&port=8080&tries=1'] Namespace:pod-network-test-5685 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:32:39.186: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:32:39.623: INFO: Waiting for responses: map[]
Apr 27 16:32:39.638: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.123:8080/dial?request=hostname&protocol=http&host=100.64.1.122&port=8080&tries=1'] Namespace:pod-network-test-5685 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:32:39.638: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:32:40.041: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:32:40.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5685" for this suite.
•{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":277,"completed":98,"skipped":1642,"failed":0}
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:32:40.076: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4015
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:32:40.260: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:32:44.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4015" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":277,"completed":99,"skipped":1655,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:32:44.401: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4381
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:32:44.585: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr 27 16:32:44.611: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 27 16:32:48.634: INFO: Creating deployment "test-rolling-update-deployment"
Apr 27 16:32:48.646: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr 27 16:32:48.669: INFO: deployment "test-rolling-update-deployment" doesn't have the required revision set
Apr 27 16:32:50.693: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr 27 16:32:50.704: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601968, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601968, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601968, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601968, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-59d5cb45c7\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:32:52.716: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Apr 27 16:32:52.750: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-4381 /apis/apps/v1/namespaces/deployment-4381/deployments/test-rolling-update-deployment fbd909af-5069-4ec6-a86b-4b50d8f3cd8a 14599 1 2020-04-27 16:32:48 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2020-04-27 16:32:48 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 16:32:50 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0060d6f38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-04-27 16:32:48 +0000 UTC,LastTransitionTime:2020-04-27 16:32:48 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-59d5cb45c7" has successfully progressed.,LastUpdateTime:2020-04-27 16:32:50 +0000 UTC,LastTransitionTime:2020-04-27 16:32:48 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 27 16:32:52.762: INFO: New ReplicaSet "test-rolling-update-deployment-59d5cb45c7" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7  deployment-4381 /apis/apps/v1/namespaces/deployment-4381/replicasets/test-rolling-update-deployment-59d5cb45c7 9e0f2408-5c64-4fda-a7c8-cc35c77ef7aa 14592 1 2020-04-27 16:32:48 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment fbd909af-5069-4ec6-a86b-4b50d8f3cd8a 0xc0060d74a7 0xc0060d74a8}] []  [{kube-controller-manager Update apps/v1 2020-04-27 16:32:50 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 98 100 57 48 57 97 102 45 53 48 54 57 45 52 101 99 54 45 97 56 54 98 45 52 98 53 48 100 56 102 51 99 100 56 97 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 59d5cb45c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0060d7538 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:32:52.762: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr 27 16:32:52.762: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-4381 /apis/apps/v1/namespaces/deployment-4381/replicasets/test-rolling-update-controller 32741d75-9966-4908-8a44-1ceae55eabec 14598 2 2020-04-27 16:32:44 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment fbd909af-5069-4ec6-a86b-4b50d8f3cd8a 0xc0060d7397 0xc0060d7398}] []  [{e2e.test Update apps/v1 2020-04-27 16:32:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 16:32:50 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 98 100 57 48 57 97 102 45 53 48 54 57 45 52 101 99 54 45 97 56 54 98 45 52 98 53 48 100 56 102 51 99 100 56 97 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0060d7438 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:32:52.774: INFO: Pod "test-rolling-update-deployment-59d5cb45c7-85qd2" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7-85qd2 test-rolling-update-deployment-59d5cb45c7- deployment-4381 /api/v1/namespaces/deployment-4381/pods/test-rolling-update-deployment-59d5cb45c7-85qd2 655312d0-e091-4a8a-b6ac-0d68e2b0f3bd 14591 0 2020-04-27 16:32:48 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[cni.projectcalico.org/podIP:100.64.1.126/32 cni.projectcalico.org/podIPs:100.64.1.126/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rolling-update-deployment-59d5cb45c7 9e0f2408-5c64-4fda-a7c8-cc35c77ef7aa 0xc0060d7a37 0xc0060d7a38}] []  [{kube-controller-manager Update v1 2020-04-27 16:32:48 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 101 48 102 50 52 48 56 45 53 99 54 52 45 52 102 100 97 45 97 55 99 56 45 99 99 51 53 99 55 55 101 102 55 97 97 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:32:49 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:32:50 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 49 50 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fj8lf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fj8lf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fj8lf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:32:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:32:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:32:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:32:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.1.126,StartTime:2020-04-27 16:32:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:32:50 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://91d550f1104c8659362acf3a94d6988497806d93e8b6b9be378eaf59b6e3ee43,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.126,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:32:52.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4381" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":277,"completed":100,"skipped":1669,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:32:52.810: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5356
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-c4931281-e186-4a3a-bef7-b0b11071c298
STEP: Creating a pod to test consume configMaps
Apr 27 16:32:53.022: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0715b901-fff4-495f-976e-3179b61b0f86" in namespace "projected-5356" to be "Succeeded or Failed"
Apr 27 16:32:53.032: INFO: Pod "pod-projected-configmaps-0715b901-fff4-495f-976e-3179b61b0f86": Phase="Pending", Reason="", readiness=false. Elapsed: 10.359327ms
Apr 27 16:32:55.044: INFO: Pod "pod-projected-configmaps-0715b901-fff4-495f-976e-3179b61b0f86": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021867628s
Apr 27 16:32:57.056: INFO: Pod "pod-projected-configmaps-0715b901-fff4-495f-976e-3179b61b0f86": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033801024s
STEP: Saw pod success
Apr 27 16:32:57.056: INFO: Pod "pod-projected-configmaps-0715b901-fff4-495f-976e-3179b61b0f86" satisfied condition "Succeeded or Failed"
Apr 27 16:32:57.067: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-projected-configmaps-0715b901-fff4-495f-976e-3179b61b0f86 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:32:57.107: INFO: Waiting for pod pod-projected-configmaps-0715b901-fff4-495f-976e-3179b61b0f86 to disappear
Apr 27 16:32:57.117: INFO: Pod pod-projected-configmaps-0715b901-fff4-495f-976e-3179b61b0f86 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:32:57.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5356" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":277,"completed":101,"skipped":1676,"failed":0}
S
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:32:57.150: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6820
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 27 16:33:01.923: INFO: Successfully updated pod "pod-update-fb9a9aeb-380f-4375-963b-4745f3b8290f"
STEP: verifying the updated pod is in kubernetes
Apr 27 16:33:01.946: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:33:01.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6820" for this suite.
•{"msg":"PASSED [k8s.io] Pods should be updated [NodeConformance] [Conformance]","total":277,"completed":102,"skipped":1677,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:33:01.980: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1020
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-1839e78e-5d0f-461c-8ea5-a9b6edf7d087
STEP: Creating secret with name s-test-opt-upd-c8d615e7-71b1-43a5-964b-8d1597e1cf7f
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-1839e78e-5d0f-461c-8ea5-a9b6edf7d087
STEP: Updating secret s-test-opt-upd-c8d615e7-71b1-43a5-964b-8d1597e1cf7f
STEP: Creating secret with name s-test-opt-create-17c2d439-f052-49b2-9725-b379b79830ab
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:33:08.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1020" for this suite.
•{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":103,"skipped":1705,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:33:08.636: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1675
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:33:08.821: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr 27 16:33:12.599: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-1675 create -f -'
Apr 27 16:33:13.387: INFO: stderr: ""
Apr 27 16:33:13.388: INFO: stdout: "e2e-test-crd-publish-openapi-2706-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 27 16:33:13.388: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-1675 delete e2e-test-crd-publish-openapi-2706-crds test-cr'
Apr 27 16:33:13.586: INFO: stderr: ""
Apr 27 16:33:13.586: INFO: stdout: "e2e-test-crd-publish-openapi-2706-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Apr 27 16:33:13.586: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-1675 apply -f -'
Apr 27 16:33:13.842: INFO: stderr: ""
Apr 27 16:33:13.842: INFO: stdout: "e2e-test-crd-publish-openapi-2706-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 27 16:33:13.842: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-1675 delete e2e-test-crd-publish-openapi-2706-crds test-cr'
Apr 27 16:33:13.972: INFO: stderr: ""
Apr 27 16:33:13.972: INFO: stdout: "e2e-test-crd-publish-openapi-2706-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Apr 27 16:33:13.972: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-2706-crds'
Apr 27 16:33:14.201: INFO: stderr: ""
Apr 27 16:33:14.201: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2706-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:33:17.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1675" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":277,"completed":104,"skipped":1722,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:33:17.999: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-8880
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Apr 27 16:33:18.822: INFO: Pod name wrapped-volume-race-176c1b56-9140-4f31-aabd-2ee29f949c6e: Found 0 pods out of 5
Apr 27 16:33:23.862: INFO: Pod name wrapped-volume-race-176c1b56-9140-4f31-aabd-2ee29f949c6e: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-176c1b56-9140-4f31-aabd-2ee29f949c6e in namespace emptydir-wrapper-8880, will wait for the garbage collector to delete the pods
Apr 27 16:33:28.015: INFO: Deleting ReplicationController wrapped-volume-race-176c1b56-9140-4f31-aabd-2ee29f949c6e took: 14.690832ms
Apr 27 16:33:28.515: INFO: Terminating ReplicationController wrapped-volume-race-176c1b56-9140-4f31-aabd-2ee29f949c6e pods took: 500.275211ms
STEP: Creating RC which spawns configmap-volume pods
Apr 27 16:33:37.554: INFO: Pod name wrapped-volume-race-69e9104a-a296-4824-a700-a27e2cd99197: Found 0 pods out of 5
Apr 27 16:33:42.596: INFO: Pod name wrapped-volume-race-69e9104a-a296-4824-a700-a27e2cd99197: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-69e9104a-a296-4824-a700-a27e2cd99197 in namespace emptydir-wrapper-8880, will wait for the garbage collector to delete the pods
Apr 27 16:33:44.749: INFO: Deleting ReplicationController wrapped-volume-race-69e9104a-a296-4824-a700-a27e2cd99197 took: 14.004741ms
Apr 27 16:33:44.850: INFO: Terminating ReplicationController wrapped-volume-race-69e9104a-a296-4824-a700-a27e2cd99197 pods took: 100.465243ms
STEP: Creating RC which spawns configmap-volume pods
Apr 27 16:33:58.696: INFO: Pod name wrapped-volume-race-2b06bd62-1926-4a11-97b1-c1f2341cb2a6: Found 0 pods out of 5
Apr 27 16:34:03.739: INFO: Pod name wrapped-volume-race-2b06bd62-1926-4a11-97b1-c1f2341cb2a6: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-2b06bd62-1926-4a11-97b1-c1f2341cb2a6 in namespace emptydir-wrapper-8880, will wait for the garbage collector to delete the pods
Apr 27 16:34:07.894: INFO: Deleting ReplicationController wrapped-volume-race-2b06bd62-1926-4a11-97b1-c1f2341cb2a6 took: 14.377575ms
Apr 27 16:34:08.394: INFO: Terminating ReplicationController wrapped-volume-race-2b06bd62-1926-4a11-97b1-c1f2341cb2a6 pods took: 500.366822ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:34:19.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8880" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":277,"completed":105,"skipped":1749,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:34:19.343: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5197
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:34:30.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5197" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":277,"completed":106,"skipped":1774,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:34:30.671: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8959
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:34:34.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8959" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":107,"skipped":1818,"failed":0}
S
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:34:34.949: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8406
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Apr 27 16:34:35.156: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Apr 27 16:34:44.253: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:34:44.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8406" for this suite.
•{"msg":"PASSED [k8s.io] Pods should be submitted and removed [NodeConformance] [Conformance]","total":277,"completed":108,"skipped":1819,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:34:44.295: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9226
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-6da4571f-8f63-4f72-a71a-ae85b68fde8a
STEP: Creating a pod to test consume secrets
Apr 27 16:34:44.536: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b45ccece-58fc-45bd-9391-e423ff56313c" in namespace "projected-9226" to be "Succeeded or Failed"
Apr 27 16:34:44.547: INFO: Pod "pod-projected-secrets-b45ccece-58fc-45bd-9391-e423ff56313c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.331955ms
Apr 27 16:34:46.559: INFO: Pod "pod-projected-secrets-b45ccece-58fc-45bd-9391-e423ff56313c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023007746s
STEP: Saw pod success
Apr 27 16:34:46.559: INFO: Pod "pod-projected-secrets-b45ccece-58fc-45bd-9391-e423ff56313c" satisfied condition "Succeeded or Failed"
Apr 27 16:34:46.570: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-projected-secrets-b45ccece-58fc-45bd-9391-e423ff56313c container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:34:46.605: INFO: Waiting for pod pod-projected-secrets-b45ccece-58fc-45bd-9391-e423ff56313c to disappear
Apr 27 16:34:46.616: INFO: Pod pod-projected-secrets-b45ccece-58fc-45bd-9391-e423ff56313c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:34:46.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9226" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":109,"skipped":1832,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:34:46.648: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4603
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:34:46.887: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"4a4d2dab-cc13-4ac0-bfbb-664eff8cffd9", Controller:(*bool)(0xc005fef2a6), BlockOwnerDeletion:(*bool)(0xc005fef2a7)}}
Apr 27 16:34:46.899: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"762ca6a8-07ee-42e3-872c-9559622847dc", Controller:(*bool)(0xc0060d7776), BlockOwnerDeletion:(*bool)(0xc0060d7777)}}
Apr 27 16:34:46.911: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"1418e2f3-9f99-408b-b67b-19b00591e967", Controller:(*bool)(0xc006084ab6), BlockOwnerDeletion:(*bool)(0xc006084ab7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:34:51.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4603" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":277,"completed":110,"skipped":1874,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:34:51.972: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5068
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Starting the proxy
Apr 27 16:34:52.161: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy --unix-socket=/tmp/kubectl-proxy-unix018298475/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:34:52.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5068" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":277,"completed":111,"skipped":1886,"failed":0}
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:34:52.260: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-159
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-2fpm
STEP: Creating a pod to test atomic-volume-subpath
Apr 27 16:34:52.488: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-2fpm" in namespace "subpath-159" to be "Succeeded or Failed"
Apr 27 16:34:52.498: INFO: Pod "pod-subpath-test-configmap-2fpm": Phase="Pending", Reason="", readiness=false. Elapsed: 10.480109ms
Apr 27 16:34:54.510: INFO: Pod "pod-subpath-test-configmap-2fpm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02248891s
Apr 27 16:34:56.523: INFO: Pod "pod-subpath-test-configmap-2fpm": Phase="Running", Reason="", readiness=true. Elapsed: 4.034855087s
Apr 27 16:34:58.534: INFO: Pod "pod-subpath-test-configmap-2fpm": Phase="Running", Reason="", readiness=true. Elapsed: 6.046488595s
Apr 27 16:35:00.546: INFO: Pod "pod-subpath-test-configmap-2fpm": Phase="Running", Reason="", readiness=true. Elapsed: 8.058473278s
Apr 27 16:35:02.558: INFO: Pod "pod-subpath-test-configmap-2fpm": Phase="Running", Reason="", readiness=true. Elapsed: 10.070478414s
Apr 27 16:35:04.570: INFO: Pod "pod-subpath-test-configmap-2fpm": Phase="Running", Reason="", readiness=true. Elapsed: 12.082288275s
Apr 27 16:35:06.582: INFO: Pod "pod-subpath-test-configmap-2fpm": Phase="Running", Reason="", readiness=true. Elapsed: 14.094092623s
Apr 27 16:35:08.594: INFO: Pod "pod-subpath-test-configmap-2fpm": Phase="Running", Reason="", readiness=true. Elapsed: 16.105748545s
Apr 27 16:35:10.605: INFO: Pod "pod-subpath-test-configmap-2fpm": Phase="Running", Reason="", readiness=true. Elapsed: 18.117481086s
Apr 27 16:35:12.617: INFO: Pod "pod-subpath-test-configmap-2fpm": Phase="Running", Reason="", readiness=true. Elapsed: 20.129418759s
Apr 27 16:35:14.629: INFO: Pod "pod-subpath-test-configmap-2fpm": Phase="Running", Reason="", readiness=true. Elapsed: 22.141357337s
Apr 27 16:35:16.642: INFO: Pod "pod-subpath-test-configmap-2fpm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.154060666s
STEP: Saw pod success
Apr 27 16:35:16.642: INFO: Pod "pod-subpath-test-configmap-2fpm" satisfied condition "Succeeded or Failed"
Apr 27 16:35:16.654: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-subpath-test-configmap-2fpm container test-container-subpath-configmap-2fpm: <nil>
STEP: delete the pod
Apr 27 16:35:16.739: INFO: Waiting for pod pod-subpath-test-configmap-2fpm to disappear
Apr 27 16:35:16.751: INFO: Pod pod-subpath-test-configmap-2fpm no longer exists
STEP: Deleting pod pod-subpath-test-configmap-2fpm
Apr 27 16:35:16.751: INFO: Deleting pod "pod-subpath-test-configmap-2fpm" in namespace "subpath-159"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:35:16.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-159" for this suite.
•{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]","total":277,"completed":112,"skipped":1887,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:35:16.798: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8111
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:35:17.719: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602117, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602117, loc:(*time.Location)(0x7b501e0)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-779fdc84d9\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602117, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602117, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:35:19.730: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602117, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602117, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602117, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602117, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:35:22.750: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:35:22.761: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:35:24.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8111" for this suite.
STEP: Destroying namespace "webhook-8111-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":277,"completed":113,"skipped":1894,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:35:24.525: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-668
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:171
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating server pod server in namespace prestop-668
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-668
STEP: Deleting pre-stop pod
Apr 27 16:35:37.899: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:35:37.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-668" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":277,"completed":114,"skipped":1920,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:35:37.944: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8486
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-1702f6b5-5ddb-40a1-8742-a4bfae5ecdac
STEP: Creating a pod to test consume configMaps
Apr 27 16:35:38.158: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0222bfc9-4ecc-451a-899b-720f98cc41b7" in namespace "projected-8486" to be "Succeeded or Failed"
Apr 27 16:35:38.168: INFO: Pod "pod-projected-configmaps-0222bfc9-4ecc-451a-899b-720f98cc41b7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.539083ms
Apr 27 16:35:40.180: INFO: Pod "pod-projected-configmaps-0222bfc9-4ecc-451a-899b-720f98cc41b7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022450814s
Apr 27 16:35:42.192: INFO: Pod "pod-projected-configmaps-0222bfc9-4ecc-451a-899b-720f98cc41b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034388214s
STEP: Saw pod success
Apr 27 16:35:42.192: INFO: Pod "pod-projected-configmaps-0222bfc9-4ecc-451a-899b-720f98cc41b7" satisfied condition "Succeeded or Failed"
Apr 27 16:35:42.203: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-projected-configmaps-0222bfc9-4ecc-451a-899b-720f98cc41b7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:35:42.239: INFO: Waiting for pod pod-projected-configmaps-0222bfc9-4ecc-451a-899b-720f98cc41b7 to disappear
Apr 27 16:35:42.250: INFO: Pod pod-projected-configmaps-0222bfc9-4ecc-451a-899b-720f98cc41b7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:35:42.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8486" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":115,"skipped":1951,"failed":0}
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:35:42.283: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8871
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-7815653b-0c36-4334-98e4-dc10530ea1b4
STEP: Creating a pod to test consume configMaps
Apr 27 16:35:42.499: INFO: Waiting up to 5m0s for pod "pod-configmaps-5078ad15-5452-4af8-a82c-f99f03e45b8f" in namespace "configmap-8871" to be "Succeeded or Failed"
Apr 27 16:35:42.509: INFO: Pod "pod-configmaps-5078ad15-5452-4af8-a82c-f99f03e45b8f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.397782ms
Apr 27 16:35:44.521: INFO: Pod "pod-configmaps-5078ad15-5452-4af8-a82c-f99f03e45b8f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021982319s
Apr 27 16:35:46.532: INFO: Pod "pod-configmaps-5078ad15-5452-4af8-a82c-f99f03e45b8f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033151961s
STEP: Saw pod success
Apr 27 16:35:46.532: INFO: Pod "pod-configmaps-5078ad15-5452-4af8-a82c-f99f03e45b8f" satisfied condition "Succeeded or Failed"
Apr 27 16:35:46.542: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-configmaps-5078ad15-5452-4af8-a82c-f99f03e45b8f container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:35:46.575: INFO: Waiting for pod pod-configmaps-5078ad15-5452-4af8-a82c-f99f03e45b8f to disappear
Apr 27 16:35:46.586: INFO: Pod pod-configmaps-5078ad15-5452-4af8-a82c-f99f03e45b8f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:35:46.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8871" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":277,"completed":116,"skipped":1955,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:35:46.622: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2729
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:35:47.193: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602147, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602147, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602147, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602147, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:35:49.204: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602147, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602147, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602147, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602147, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:35:52.228: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:35:52.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2729" for this suite.
STEP: Destroying namespace "webhook-2729-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":277,"completed":117,"skipped":1982,"failed":0}
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:35:52.586: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6220
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:35:56.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6220" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":277,"completed":118,"skipped":1989,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:35:56.873: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3336
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on tmpfs
Apr 27 16:35:57.073: INFO: Waiting up to 5m0s for pod "pod-5db82956-28e9-417f-a734-bf650544ac97" in namespace "emptydir-3336" to be "Succeeded or Failed"
Apr 27 16:35:57.083: INFO: Pod "pod-5db82956-28e9-417f-a734-bf650544ac97": Phase="Pending", Reason="", readiness=false. Elapsed: 10.200903ms
Apr 27 16:35:59.095: INFO: Pod "pod-5db82956-28e9-417f-a734-bf650544ac97": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022143844s
Apr 27 16:36:01.107: INFO: Pod "pod-5db82956-28e9-417f-a734-bf650544ac97": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033941111s
STEP: Saw pod success
Apr 27 16:36:01.107: INFO: Pod "pod-5db82956-28e9-417f-a734-bf650544ac97" satisfied condition "Succeeded or Failed"
Apr 27 16:36:01.117: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-5db82956-28e9-417f-a734-bf650544ac97 container test-container: <nil>
STEP: delete the pod
Apr 27 16:36:01.156: INFO: Waiting for pod pod-5db82956-28e9-417f-a734-bf650544ac97 to disappear
Apr 27 16:36:01.166: INFO: Pod pod-5db82956-28e9-417f-a734-bf650544ac97 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:01.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3336" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":119,"skipped":1997,"failed":0}

------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:01.201: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2776
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-szknm in namespace proxy-2776
I0427 16:36:01.421778    7292 runners.go:190] Created replication controller with name: proxy-service-szknm, namespace: proxy-2776, replica count: 1
I0427 16:36:02.472516    7292 runners.go:190] proxy-service-szknm Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0427 16:36:03.472894    7292 runners.go:190] proxy-service-szknm Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0427 16:36:04.473145    7292 runners.go:190] proxy-service-szknm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 16:36:05.473414    7292 runners.go:190] proxy-service-szknm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 16:36:06.473712    7292 runners.go:190] proxy-service-szknm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 16:36:07.474016    7292 runners.go:190] proxy-service-szknm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 16:36:08.474307    7292 runners.go:190] proxy-service-szknm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 16:36:09.474609    7292 runners.go:190] proxy-service-szknm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 16:36:10.474944    7292 runners.go:190] proxy-service-szknm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 16:36:11.475266    7292 runners.go:190] proxy-service-szknm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 16:36:12.475571    7292 runners.go:190] proxy-service-szknm Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 27 16:36:12.487: INFO: setup took 11.096527055s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Apr 27 16:36:12.508: INFO: (0) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/rewriteme">test</a> (200; 21.421215ms)
Apr 27 16:36:12.508: INFO: (0) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:160/proxy/: foo (200; 21.352936ms)
Apr 27 16:36:12.508: INFO: (0) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname1/proxy/: foo (200; 21.478228ms)
Apr 27 16:36:12.513: INFO: (0) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname2/proxy/: bar (200; 25.594201ms)
Apr 27 16:36:12.513: INFO: (0) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:160/proxy/: foo (200; 26.31473ms)
Apr 27 16:36:12.514: INFO: (0) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/rewriteme">... (200; 26.478689ms)
Apr 27 16:36:12.514: INFO: (0) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/rewriteme">test<... (200; 26.511654ms)
Apr 27 16:36:12.515: INFO: (0) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:462/proxy/: tls qux (200; 28.164702ms)
Apr 27 16:36:12.517: INFO: (0) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname1/proxy/: foo (200; 29.848253ms)
Apr 27 16:36:12.517: INFO: (0) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname2/proxy/: tls qux (200; 30.275962ms)
Apr 27 16:36:12.517: INFO: (0) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname1/proxy/: tls baz (200; 30.738909ms)
Apr 27 16:36:12.518: INFO: (0) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:460/proxy/: tls baz (200; 30.52847ms)
Apr 27 16:36:12.518: INFO: (0) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:162/proxy/: bar (200; 30.766935ms)
Apr 27 16:36:12.518: INFO: (0) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname2/proxy/: bar (200; 30.379782ms)
Apr 27 16:36:12.518: INFO: (0) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:162/proxy/: bar (200; 30.769166ms)
Apr 27 16:36:12.598: INFO: (0) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/tlsrewritem... (200; 111.146541ms)
Apr 27 16:36:12.612: INFO: (1) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:162/proxy/: bar (200; 13.274465ms)
Apr 27 16:36:12.612: INFO: (1) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/rewriteme">test</a> (200; 13.658939ms)
Apr 27 16:36:12.612: INFO: (1) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:160/proxy/: foo (200; 13.784131ms)
Apr 27 16:36:12.613: INFO: (1) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:160/proxy/: foo (200; 13.877709ms)
Apr 27 16:36:12.613: INFO: (1) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/rewriteme">... (200; 13.90392ms)
Apr 27 16:36:12.613: INFO: (1) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:460/proxy/: tls baz (200; 13.905919ms)
Apr 27 16:36:12.613: INFO: (1) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/rewriteme">test<... (200; 14.080426ms)
Apr 27 16:36:12.613: INFO: (1) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:462/proxy/: tls qux (200; 14.176321ms)
Apr 27 16:36:12.613: INFO: (1) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/tlsrewritem... (200; 14.151434ms)
Apr 27 16:36:12.613: INFO: (1) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname1/proxy/: tls baz (200; 14.020321ms)
Apr 27 16:36:12.613: INFO: (1) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname2/proxy/: bar (200; 14.12795ms)
Apr 27 16:36:12.613: INFO: (1) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname1/proxy/: foo (200; 14.378337ms)
Apr 27 16:36:12.613: INFO: (1) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname2/proxy/: tls qux (200; 14.070959ms)
Apr 27 16:36:12.613: INFO: (1) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname1/proxy/: foo (200; 14.345433ms)
Apr 27 16:36:12.613: INFO: (1) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:162/proxy/: bar (200; 14.518657ms)
Apr 27 16:36:12.614: INFO: (1) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname2/proxy/: bar (200; 14.878448ms)
Apr 27 16:36:12.628: INFO: (2) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname1/proxy/: foo (200; 14.502767ms)
Apr 27 16:36:12.628: INFO: (2) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/rewriteme">... (200; 14.1755ms)
Apr 27 16:36:12.628: INFO: (2) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/rewriteme">test</a> (200; 14.226864ms)
Apr 27 16:36:12.628: INFO: (2) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:462/proxy/: tls qux (200; 14.275452ms)
Apr 27 16:36:12.628: INFO: (2) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:160/proxy/: foo (200; 14.546143ms)
Apr 27 16:36:12.628: INFO: (2) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/rewriteme">test<... (200; 14.45585ms)
Apr 27 16:36:12.628: INFO: (2) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname2/proxy/: bar (200; 14.371709ms)
Apr 27 16:36:12.628: INFO: (2) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:162/proxy/: bar (200; 14.368278ms)
Apr 27 16:36:12.628: INFO: (2) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:460/proxy/: tls baz (200; 14.458281ms)
Apr 27 16:36:12.629: INFO: (2) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname1/proxy/: tls baz (200; 14.56159ms)
Apr 27 16:36:12.629: INFO: (2) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname2/proxy/: tls qux (200; 14.487591ms)
Apr 27 16:36:12.630: INFO: (2) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:162/proxy/: bar (200; 15.998524ms)
Apr 27 16:36:12.630: INFO: (2) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:160/proxy/: foo (200; 16.006232ms)
Apr 27 16:36:12.630: INFO: (2) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname1/proxy/: foo (200; 16.084821ms)
Apr 27 16:36:12.631: INFO: (2) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/tlsrewritem... (200; 16.477826ms)
Apr 27 16:36:12.633: INFO: (2) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname2/proxy/: bar (200; 18.494002ms)
Apr 27 16:36:12.648: INFO: (3) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname1/proxy/: tls baz (200; 14.675854ms)
Apr 27 16:36:12.648: INFO: (3) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:162/proxy/: bar (200; 14.483405ms)
Apr 27 16:36:12.648: INFO: (3) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:162/proxy/: bar (200; 14.52173ms)
Apr 27 16:36:12.648: INFO: (3) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:460/proxy/: tls baz (200; 14.635107ms)
Apr 27 16:36:12.648: INFO: (3) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/rewriteme">test<... (200; 14.550559ms)
Apr 27 16:36:12.648: INFO: (3) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:462/proxy/: tls qux (200; 14.702068ms)
Apr 27 16:36:12.648: INFO: (3) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:160/proxy/: foo (200; 14.605678ms)
Apr 27 16:36:12.648: INFO: (3) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/rewriteme">... (200; 14.740043ms)
Apr 27 16:36:12.648: INFO: (3) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/tlsrewritem... (200; 14.520891ms)
Apr 27 16:36:12.648: INFO: (3) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/rewriteme">test</a> (200; 14.529049ms)
Apr 27 16:36:12.648: INFO: (3) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:160/proxy/: foo (200; 14.67691ms)
Apr 27 16:36:12.648: INFO: (3) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname2/proxy/: tls qux (200; 14.643188ms)
Apr 27 16:36:12.689: INFO: (3) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname2/proxy/: bar (200; 55.664134ms)
Apr 27 16:36:12.689: INFO: (3) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname1/proxy/: foo (200; 55.611978ms)
Apr 27 16:36:12.689: INFO: (3) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname1/proxy/: foo (200; 55.765865ms)
Apr 27 16:36:12.689: INFO: (3) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname2/proxy/: bar (200; 55.73833ms)
Apr 27 16:36:12.705: INFO: (4) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:160/proxy/: foo (200; 15.658093ms)
Apr 27 16:36:12.705: INFO: (4) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/rewriteme">... (200; 16.222704ms)
Apr 27 16:36:12.705: INFO: (4) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname1/proxy/: tls baz (200; 16.302197ms)
Apr 27 16:36:12.705: INFO: (4) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:462/proxy/: tls qux (200; 16.410018ms)
Apr 27 16:36:12.705: INFO: (4) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/rewriteme">test</a> (200; 16.360965ms)
Apr 27 16:36:12.705: INFO: (4) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname1/proxy/: foo (200; 16.436435ms)
Apr 27 16:36:12.705: INFO: (4) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:162/proxy/: bar (200; 16.332321ms)
Apr 27 16:36:12.706: INFO: (4) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname2/proxy/: bar (200; 16.552133ms)
Apr 27 16:36:12.706: INFO: (4) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/rewriteme">test<... (200; 17.310379ms)
Apr 27 16:36:12.706: INFO: (4) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname2/proxy/: tls qux (200; 17.403011ms)
Apr 27 16:36:12.707: INFO: (4) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:160/proxy/: foo (200; 17.727269ms)
Apr 27 16:36:12.707: INFO: (4) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:460/proxy/: tls baz (200; 17.8969ms)
Apr 27 16:36:12.707: INFO: (4) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:162/proxy/: bar (200; 17.677348ms)
Apr 27 16:36:12.707: INFO: (4) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname2/proxy/: bar (200; 17.710522ms)
Apr 27 16:36:12.707: INFO: (4) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/tlsrewritem... (200; 17.957544ms)
Apr 27 16:36:12.707: INFO: (4) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname1/proxy/: foo (200; 17.762527ms)
Apr 27 16:36:12.721: INFO: (5) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/rewriteme">... (200; 13.532013ms)
Apr 27 16:36:12.721: INFO: (5) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/rewriteme">test<... (200; 13.580062ms)
Apr 27 16:36:12.721: INFO: (5) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/rewriteme">test</a> (200; 13.427925ms)
Apr 27 16:36:12.721: INFO: (5) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:460/proxy/: tls baz (200; 13.630776ms)
Apr 27 16:36:12.721: INFO: (5) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:160/proxy/: foo (200; 13.538506ms)
Apr 27 16:36:12.721: INFO: (5) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:162/proxy/: bar (200; 13.610425ms)
Apr 27 16:36:12.721: INFO: (5) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname1/proxy/: foo (200; 13.522596ms)
Apr 27 16:36:12.721: INFO: (5) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:162/proxy/: bar (200; 13.882648ms)
Apr 27 16:36:12.721: INFO: (5) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname1/proxy/: tls baz (200; 13.984347ms)
Apr 27 16:36:12.721: INFO: (5) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/tlsrewritem... (200; 13.904413ms)
Apr 27 16:36:12.721: INFO: (5) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname2/proxy/: tls qux (200; 13.936654ms)
Apr 27 16:36:12.721: INFO: (5) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:462/proxy/: tls qux (200; 13.986347ms)
Apr 27 16:36:12.721: INFO: (5) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:160/proxy/: foo (200; 14.365171ms)
Apr 27 16:36:12.722: INFO: (5) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname2/proxy/: bar (200; 14.712327ms)
Apr 27 16:36:12.722: INFO: (5) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname1/proxy/: foo (200; 14.904577ms)
Apr 27 16:36:12.723: INFO: (5) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname2/proxy/: bar (200; 15.328141ms)
Apr 27 16:36:12.736: INFO: (6) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/rewriteme">test</a> (200; 12.847492ms)
Apr 27 16:36:12.736: INFO: (6) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:160/proxy/: foo (200; 12.918938ms)
Apr 27 16:36:12.736: INFO: (6) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/tlsrewritem... (200; 12.825099ms)
Apr 27 16:36:12.736: INFO: (6) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname1/proxy/: foo (200; 13.056675ms)
Apr 27 16:36:12.736: INFO: (6) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:162/proxy/: bar (200; 13.156763ms)
Apr 27 16:36:12.736: INFO: (6) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/rewriteme">test<... (200; 13.417907ms)
Apr 27 16:36:12.737: INFO: (6) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname1/proxy/: tls baz (200; 13.828684ms)
Apr 27 16:36:12.737: INFO: (6) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/rewriteme">... (200; 13.87359ms)
Apr 27 16:36:12.737: INFO: (6) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname2/proxy/: tls qux (200; 13.818588ms)
Apr 27 16:36:12.737: INFO: (6) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:462/proxy/: tls qux (200; 13.916453ms)
Apr 27 16:36:12.737: INFO: (6) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:460/proxy/: tls baz (200; 13.948056ms)
Apr 27 16:36:12.737: INFO: (6) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname2/proxy/: bar (200; 13.913626ms)
Apr 27 16:36:12.737: INFO: (6) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname1/proxy/: foo (200; 14.743465ms)
Apr 27 16:36:12.737: INFO: (6) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname2/proxy/: bar (200; 14.8203ms)
Apr 27 16:36:12.737: INFO: (6) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:160/proxy/: foo (200; 14.892642ms)
Apr 27 16:36:12.739: INFO: (6) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:162/proxy/: bar (200; 15.972105ms)
Apr 27 16:36:12.752: INFO: (7) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:162/proxy/: bar (200; 12.959073ms)
Apr 27 16:36:12.752: INFO: (7) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname1/proxy/: tls baz (200; 12.902082ms)
Apr 27 16:36:12.752: INFO: (7) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:462/proxy/: tls qux (200; 12.953849ms)
Apr 27 16:36:12.752: INFO: (7) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:160/proxy/: foo (200; 12.970459ms)
Apr 27 16:36:12.752: INFO: (7) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:162/proxy/: bar (200; 12.975259ms)
Apr 27 16:36:12.752: INFO: (7) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/tlsrewritem... (200; 12.938629ms)
Apr 27 16:36:12.752: INFO: (7) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/rewriteme">test<... (200; 13.067707ms)
Apr 27 16:36:12.752: INFO: (7) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/rewriteme">test</a> (200; 13.014449ms)
Apr 27 16:36:12.752: INFO: (7) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:160/proxy/: foo (200; 13.186241ms)
Apr 27 16:36:12.752: INFO: (7) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/rewriteme">... (200; 13.03657ms)
Apr 27 16:36:12.752: INFO: (7) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:460/proxy/: tls baz (200; 13.139608ms)
Apr 27 16:36:12.752: INFO: (7) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname2/proxy/: tls qux (200; 13.441208ms)
Apr 27 16:36:12.753: INFO: (7) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname2/proxy/: bar (200; 14.269659ms)
Apr 27 16:36:12.753: INFO: (7) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname1/proxy/: foo (200; 14.370874ms)
Apr 27 16:36:12.753: INFO: (7) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname1/proxy/: foo (200; 14.52633ms)
Apr 27 16:36:12.753: INFO: (7) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname2/proxy/: bar (200; 14.488239ms)
Apr 27 16:36:12.766: INFO: (8) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:162/proxy/: bar (200; 12.229902ms)
Apr 27 16:36:12.766: INFO: (8) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:460/proxy/: tls baz (200; 12.195437ms)
Apr 27 16:36:12.766: INFO: (8) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:160/proxy/: foo (200; 12.246422ms)
Apr 27 16:36:12.766: INFO: (8) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/rewriteme">test</a> (200; 12.36173ms)
Apr 27 16:36:12.767: INFO: (8) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/tlsrewritem... (200; 13.106593ms)
Apr 27 16:36:12.767: INFO: (8) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname2/proxy/: bar (200; 13.229975ms)
Apr 27 16:36:12.767: INFO: (8) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/rewriteme">... (200; 13.15802ms)
Apr 27 16:36:12.767: INFO: (8) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname1/proxy/: tls baz (200; 13.286785ms)
Apr 27 16:36:12.767: INFO: (8) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname1/proxy/: foo (200; 13.167419ms)
Apr 27 16:36:12.767: INFO: (8) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/rewriteme">test<... (200; 13.182875ms)
Apr 27 16:36:12.767: INFO: (8) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname1/proxy/: foo (200; 13.463306ms)
Apr 27 16:36:12.767: INFO: (8) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname2/proxy/: bar (200; 13.430619ms)
Apr 27 16:36:12.767: INFO: (8) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname2/proxy/: tls qux (200; 13.784996ms)
Apr 27 16:36:12.768: INFO: (8) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:160/proxy/: foo (200; 14.552444ms)
Apr 27 16:36:12.768: INFO: (8) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:462/proxy/: tls qux (200; 14.403407ms)
Apr 27 16:36:12.768: INFO: (8) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:162/proxy/: bar (200; 14.754524ms)
Apr 27 16:36:12.782: INFO: (9) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/tlsrewritem... (200; 13.283356ms)
Apr 27 16:36:12.782: INFO: (9) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:162/proxy/: bar (200; 13.079104ms)
Apr 27 16:36:12.782: INFO: (9) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:160/proxy/: foo (200; 13.236693ms)
Apr 27 16:36:12.782: INFO: (9) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:162/proxy/: bar (200; 13.346468ms)
Apr 27 16:36:12.782: INFO: (9) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/rewriteme">... (200; 13.155718ms)
Apr 27 16:36:12.782: INFO: (9) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/rewriteme">test<... (200; 13.128153ms)
Apr 27 16:36:12.782: INFO: (9) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:160/proxy/: foo (200; 13.271883ms)
Apr 27 16:36:12.782: INFO: (9) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:460/proxy/: tls baz (200; 13.854713ms)
Apr 27 16:36:12.783: INFO: (9) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname2/proxy/: bar (200; 13.933557ms)
Apr 27 16:36:12.783: INFO: (9) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:462/proxy/: tls qux (200; 13.895085ms)
Apr 27 16:36:12.783: INFO: (9) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/rewriteme">test</a> (200; 13.91191ms)
Apr 27 16:36:12.783: INFO: (9) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname2/proxy/: tls qux (200; 13.914806ms)
Apr 27 16:36:12.783: INFO: (9) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname1/proxy/: tls baz (200; 14.03596ms)
Apr 27 16:36:12.783: INFO: (9) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname2/proxy/: bar (200; 14.137244ms)
Apr 27 16:36:12.783: INFO: (9) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname1/proxy/: foo (200; 14.314597ms)
Apr 27 16:36:12.783: INFO: (9) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname1/proxy/: foo (200; 14.42204ms)
Apr 27 16:36:12.796: INFO: (10) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/rewriteme">... (200; 12.445321ms)
Apr 27 16:36:12.796: INFO: (10) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:460/proxy/: tls baz (200; 13.140056ms)
Apr 27 16:36:12.797: INFO: (10) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/tlsrewritem... (200; 13.360672ms)
Apr 27 16:36:12.796: INFO: (10) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/rewriteme">test<... (200; 13.304836ms)
Apr 27 16:36:12.797: INFO: (10) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/rewriteme">test</a> (200; 13.615245ms)
Apr 27 16:36:12.797: INFO: (10) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:462/proxy/: tls qux (200; 13.493553ms)
Apr 27 16:36:12.797: INFO: (10) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:160/proxy/: foo (200; 13.441665ms)
Apr 27 16:36:12.797: INFO: (10) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:162/proxy/: bar (200; 13.523633ms)
Apr 27 16:36:12.797: INFO: (10) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:160/proxy/: foo (200; 13.370954ms)
Apr 27 16:36:12.797: INFO: (10) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:162/proxy/: bar (200; 13.421559ms)
Apr 27 16:36:12.797: INFO: (10) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname2/proxy/: tls qux (200; 13.732854ms)
Apr 27 16:36:12.808: INFO: (10) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname1/proxy/: foo (200; 24.730919ms)
Apr 27 16:36:12.808: INFO: (10) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname1/proxy/: tls baz (200; 24.772141ms)
Apr 27 16:36:12.808: INFO: (10) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname1/proxy/: foo (200; 24.662684ms)
Apr 27 16:36:12.808: INFO: (10) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname2/proxy/: bar (200; 24.736581ms)
Apr 27 16:36:12.808: INFO: (10) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname2/proxy/: bar (200; 24.838401ms)
Apr 27 16:36:12.821: INFO: (11) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:162/proxy/: bar (200; 13.162499ms)
Apr 27 16:36:12.821: INFO: (11) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/rewriteme">test<... (200; 13.212183ms)
Apr 27 16:36:12.821: INFO: (11) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:162/proxy/: bar (200; 13.253557ms)
Apr 27 16:36:12.821: INFO: (11) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/rewriteme">... (200; 13.217013ms)
Apr 27 16:36:12.821: INFO: (11) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:160/proxy/: foo (200; 13.162339ms)
Apr 27 16:36:12.821: INFO: (11) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:460/proxy/: tls baz (200; 13.21689ms)
Apr 27 16:36:12.821: INFO: (11) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/rewriteme">test</a> (200; 13.209652ms)
Apr 27 16:36:12.822: INFO: (11) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname1/proxy/: tls baz (200; 13.797863ms)
Apr 27 16:36:12.822: INFO: (11) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/tlsrewritem... (200; 14.013704ms)
Apr 27 16:36:12.822: INFO: (11) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname2/proxy/: bar (200; 13.885347ms)
Apr 27 16:36:12.822: INFO: (11) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname2/proxy/: tls qux (200; 13.849162ms)
Apr 27 16:36:12.822: INFO: (11) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:160/proxy/: foo (200; 13.782323ms)
Apr 27 16:36:12.822: INFO: (11) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:462/proxy/: tls qux (200; 14.000467ms)
Apr 27 16:36:12.822: INFO: (11) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname1/proxy/: foo (200; 14.324456ms)
Apr 27 16:36:12.822: INFO: (11) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname2/proxy/: bar (200; 14.278873ms)
Apr 27 16:36:12.864: INFO: (11) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname1/proxy/: foo (200; 55.709218ms)
Apr 27 16:36:12.878: INFO: (12) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:460/proxy/: tls baz (200; 13.433683ms)
Apr 27 16:36:12.878: INFO: (12) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/tlsrewritem... (200; 13.564043ms)
Apr 27 16:36:12.878: INFO: (12) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname1/proxy/: tls baz (200; 13.687984ms)
Apr 27 16:36:12.878: INFO: (12) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/rewriteme">test<... (200; 13.674568ms)
Apr 27 16:36:12.878: INFO: (12) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/rewriteme">test</a> (200; 13.65005ms)
Apr 27 16:36:12.878: INFO: (12) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname2/proxy/: bar (200; 13.659152ms)
Apr 27 16:36:12.878: INFO: (12) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:162/proxy/: bar (200; 13.594345ms)
Apr 27 16:36:12.878: INFO: (12) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname2/proxy/: tls qux (200; 13.483576ms)
Apr 27 16:36:12.878: INFO: (12) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname1/proxy/: foo (200; 13.652835ms)
Apr 27 16:36:12.878: INFO: (12) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:160/proxy/: foo (200; 13.705153ms)
Apr 27 16:36:12.878: INFO: (12) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:462/proxy/: tls qux (200; 13.652339ms)
Apr 27 16:36:12.878: INFO: (12) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/rewriteme">... (200; 13.571917ms)
Apr 27 16:36:12.878: INFO: (12) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname2/proxy/: bar (200; 13.866611ms)
Apr 27 16:36:12.878: INFO: (12) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:162/proxy/: bar (200; 13.856995ms)
Apr 27 16:36:12.878: INFO: (12) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname1/proxy/: foo (200; 14.034579ms)
Apr 27 16:36:12.879: INFO: (12) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:160/proxy/: foo (200; 14.82728ms)
Apr 27 16:36:12.893: INFO: (13) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:462/proxy/: tls qux (200; 13.505408ms)
Apr 27 16:36:12.893: INFO: (13) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/rewriteme">test</a> (200; 13.559987ms)
Apr 27 16:36:12.893: INFO: (13) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname2/proxy/: bar (200; 13.640611ms)
Apr 27 16:36:12.893: INFO: (13) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/rewriteme">test<... (200; 13.605608ms)
Apr 27 16:36:12.893: INFO: (13) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname1/proxy/: foo (200; 13.837176ms)
Apr 27 16:36:12.893: INFO: (13) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/rewriteme">... (200; 13.667012ms)
Apr 27 16:36:12.893: INFO: (13) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname1/proxy/: tls baz (200; 13.64454ms)
Apr 27 16:36:12.893: INFO: (13) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:160/proxy/: foo (200; 13.759704ms)
Apr 27 16:36:12.893: INFO: (13) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/tlsrewritem... (200; 13.730539ms)
Apr 27 16:36:12.893: INFO: (13) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname2/proxy/: tls qux (200; 13.681432ms)
Apr 27 16:36:12.893: INFO: (13) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:460/proxy/: tls baz (200; 13.616751ms)
Apr 27 16:36:12.893: INFO: (13) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname2/proxy/: bar (200; 13.720198ms)
Apr 27 16:36:12.933: INFO: (13) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:162/proxy/: bar (200; 54.423393ms)
Apr 27 16:36:12.933: INFO: (13) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:162/proxy/: bar (200; 54.34827ms)
Apr 27 16:36:12.933: INFO: (13) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname1/proxy/: foo (200; 54.275301ms)
Apr 27 16:36:12.933: INFO: (13) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:160/proxy/: foo (200; 54.259262ms)
Apr 27 16:36:12.947: INFO: (14) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:162/proxy/: bar (200; 12.779035ms)
Apr 27 16:36:12.947: INFO: (14) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:160/proxy/: foo (200; 12.786267ms)
Apr 27 16:36:12.947: INFO: (14) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:462/proxy/: tls qux (200; 12.805847ms)
Apr 27 16:36:12.947: INFO: (14) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/rewriteme">... (200; 12.958344ms)
Apr 27 16:36:12.947: INFO: (14) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/tlsrewritem... (200; 12.915419ms)
Apr 27 16:36:12.947: INFO: (14) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:162/proxy/: bar (200; 13.093565ms)
Apr 27 16:36:12.947: INFO: (14) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:460/proxy/: tls baz (200; 13.118122ms)
Apr 27 16:36:12.947: INFO: (14) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/rewriteme">test</a> (200; 13.473028ms)
Apr 27 16:36:12.947: INFO: (14) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:160/proxy/: foo (200; 13.238446ms)
Apr 27 16:36:12.947: INFO: (14) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/rewriteme">test<... (200; 13.660183ms)
Apr 27 16:36:12.948: INFO: (14) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname2/proxy/: bar (200; 14.05462ms)
Apr 27 16:36:12.948: INFO: (14) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname1/proxy/: tls baz (200; 13.922147ms)
Apr 27 16:36:12.948: INFO: (14) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname2/proxy/: bar (200; 13.967963ms)
Apr 27 16:36:12.948: INFO: (14) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname2/proxy/: tls qux (200; 14.083765ms)
Apr 27 16:36:12.948: INFO: (14) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname1/proxy/: foo (200; 14.062273ms)
Apr 27 16:36:12.948: INFO: (14) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname1/proxy/: foo (200; 14.257855ms)
Apr 27 16:36:12.962: INFO: (15) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:160/proxy/: foo (200; 13.386984ms)
Apr 27 16:36:12.962: INFO: (15) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname2/proxy/: tls qux (200; 13.463415ms)
Apr 27 16:36:12.962: INFO: (15) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/rewriteme">test<... (200; 13.571853ms)
Apr 27 16:36:12.962: INFO: (15) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/tlsrewritem... (200; 13.519296ms)
Apr 27 16:36:12.962: INFO: (15) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/rewriteme">... (200; 13.457226ms)
Apr 27 16:36:12.962: INFO: (15) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:160/proxy/: foo (200; 13.459489ms)
Apr 27 16:36:12.962: INFO: (15) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname2/proxy/: bar (200; 13.5557ms)
Apr 27 16:36:12.962: INFO: (15) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/rewriteme">test</a> (200; 13.453317ms)
Apr 27 16:36:12.962: INFO: (15) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname1/proxy/: tls baz (200; 13.638846ms)
Apr 27 16:36:12.962: INFO: (15) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname2/proxy/: bar (200; 13.499015ms)
Apr 27 16:36:12.962: INFO: (15) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:462/proxy/: tls qux (200; 13.539103ms)
Apr 27 16:36:12.963: INFO: (15) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:460/proxy/: tls baz (200; 15.36623ms)
Apr 27 16:36:12.964: INFO: (15) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:162/proxy/: bar (200; 15.97786ms)
Apr 27 16:36:12.964: INFO: (15) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:162/proxy/: bar (200; 16.11878ms)
Apr 27 16:36:12.965: INFO: (15) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname1/proxy/: foo (200; 16.482039ms)
Apr 27 16:36:12.965: INFO: (15) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname1/proxy/: foo (200; 16.603141ms)
Apr 27 16:36:12.978: INFO: (16) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:462/proxy/: tls qux (200; 12.590732ms)
Apr 27 16:36:12.978: INFO: (16) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/rewriteme">test<... (200; 12.64965ms)
Apr 27 16:36:12.978: INFO: (16) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/tlsrewritem... (200; 12.754246ms)
Apr 27 16:36:12.978: INFO: (16) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:160/proxy/: foo (200; 12.656632ms)
Apr 27 16:36:12.978: INFO: (16) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/rewriteme">test</a> (200; 12.989309ms)
Apr 27 16:36:12.978: INFO: (16) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:162/proxy/: bar (200; 12.997166ms)
Apr 27 16:36:12.978: INFO: (16) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname2/proxy/: tls qux (200; 12.984202ms)
Apr 27 16:36:12.978: INFO: (16) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname1/proxy/: foo (200; 13.093973ms)
Apr 27 16:36:12.978: INFO: (16) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/rewriteme">... (200; 13.087171ms)
Apr 27 16:36:12.978: INFO: (16) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname1/proxy/: tls baz (200; 13.002639ms)
Apr 27 16:36:12.978: INFO: (16) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:460/proxy/: tls baz (200; 13.02761ms)
Apr 27 16:36:12.979: INFO: (16) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname2/proxy/: bar (200; 13.65332ms)
Apr 27 16:36:12.979: INFO: (16) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:160/proxy/: foo (200; 14.038304ms)
Apr 27 16:36:12.979: INFO: (16) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname2/proxy/: bar (200; 14.107921ms)
Apr 27 16:36:12.979: INFO: (16) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname1/proxy/: foo (200; 14.479902ms)
Apr 27 16:36:12.979: INFO: (16) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:162/proxy/: bar (200; 14.701491ms)
Apr 27 16:36:12.993: INFO: (17) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:162/proxy/: bar (200; 13.326558ms)
Apr 27 16:36:12.993: INFO: (17) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:162/proxy/: bar (200; 13.373883ms)
Apr 27 16:36:12.993: INFO: (17) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:460/proxy/: tls baz (200; 13.390862ms)
Apr 27 16:36:12.993: INFO: (17) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/rewriteme">test</a> (200; 13.435396ms)
Apr 27 16:36:12.993: INFO: (17) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname2/proxy/: tls qux (200; 13.400088ms)
Apr 27 16:36:12.993: INFO: (17) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:462/proxy/: tls qux (200; 13.637776ms)
Apr 27 16:36:12.993: INFO: (17) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname1/proxy/: tls baz (200; 13.434991ms)
Apr 27 16:36:12.993: INFO: (17) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/rewriteme">... (200; 13.584521ms)
Apr 27 16:36:12.993: INFO: (17) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/rewriteme">test<... (200; 13.615986ms)
Apr 27 16:36:12.993: INFO: (17) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname1/proxy/: foo (200; 13.529591ms)
Apr 27 16:36:12.993: INFO: (17) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/tlsrewritem... (200; 13.487655ms)
Apr 27 16:36:12.993: INFO: (17) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:160/proxy/: foo (200; 13.654273ms)
Apr 27 16:36:13.034: INFO: (17) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname1/proxy/: foo (200; 54.650718ms)
Apr 27 16:36:13.034: INFO: (17) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname2/proxy/: bar (200; 54.809884ms)
Apr 27 16:36:13.034: INFO: (17) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:160/proxy/: foo (200; 54.781956ms)
Apr 27 16:36:13.034: INFO: (17) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname2/proxy/: bar (200; 54.742738ms)
Apr 27 16:36:13.048: INFO: (18) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/rewriteme">test<... (200; 12.852157ms)
Apr 27 16:36:13.048: INFO: (18) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:162/proxy/: bar (200; 12.913023ms)
Apr 27 16:36:13.048: INFO: (18) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:462/proxy/: tls qux (200; 13.169033ms)
Apr 27 16:36:13.048: INFO: (18) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:162/proxy/: bar (200; 13.003371ms)
Apr 27 16:36:13.048: INFO: (18) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/rewriteme">... (200; 12.96304ms)
Apr 27 16:36:13.048: INFO: (18) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/rewriteme">test</a> (200; 13.01833ms)
Apr 27 16:36:13.048: INFO: (18) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:160/proxy/: foo (200; 12.901724ms)
Apr 27 16:36:13.048: INFO: (18) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:460/proxy/: tls baz (200; 12.922343ms)
Apr 27 16:36:13.048: INFO: (18) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:160/proxy/: foo (200; 12.976457ms)
Apr 27 16:36:13.048: INFO: (18) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/tlsrewritem... (200; 13.3981ms)
Apr 27 16:36:13.049: INFO: (18) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname2/proxy/: tls qux (200; 13.988575ms)
Apr 27 16:36:13.049: INFO: (18) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname2/proxy/: bar (200; 14.016998ms)
Apr 27 16:36:13.049: INFO: (18) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname1/proxy/: foo (200; 14.127818ms)
Apr 27 16:36:13.049: INFO: (18) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname1/proxy/: tls baz (200; 14.000091ms)
Apr 27 16:36:13.049: INFO: (18) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname2/proxy/: bar (200; 14.229418ms)
Apr 27 16:36:13.049: INFO: (18) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname1/proxy/: foo (200; 14.731287ms)
Apr 27 16:36:13.067: INFO: (19) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:162/proxy/: bar (200; 17.635172ms)
Apr 27 16:36:13.067: INFO: (19) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:160/proxy/: foo (200; 17.653822ms)
Apr 27 16:36:13.067: INFO: (19) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:462/proxy/: tls qux (200; 17.520611ms)
Apr 27 16:36:13.067: INFO: (19) /api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/http:proxy-service-szknm-7rcwv:1080/proxy/rewriteme">... (200; 17.660129ms)
Apr 27 16:36:13.067: INFO: (19) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname1/proxy/: tls baz (200; 17.522934ms)
Apr 27 16:36:13.067: INFO: (19) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:443/proxy/tlsrewritem... (200; 17.586346ms)
Apr 27 16:36:13.067: INFO: (19) /api/v1/namespaces/proxy-2776/pods/https:proxy-service-szknm-7rcwv:460/proxy/: tls baz (200; 17.495303ms)
Apr 27 16:36:13.067: INFO: (19) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname1/proxy/: foo (200; 17.64649ms)
Apr 27 16:36:13.067: INFO: (19) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:162/proxy/: bar (200; 17.598032ms)
Apr 27 16:36:13.067: INFO: (19) /api/v1/namespaces/proxy-2776/services/https:proxy-service-szknm:tlsportname2/proxy/: tls qux (200; 17.541263ms)
Apr 27 16:36:13.067: INFO: (19) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:1080/proxy/rewriteme">test<... (200; 17.583746ms)
Apr 27 16:36:13.068: INFO: (19) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/: <a href="/api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv/proxy/rewriteme">test</a> (200; 18.292382ms)
Apr 27 16:36:13.109: INFO: (19) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname1/proxy/: foo (200; 58.954651ms)
Apr 27 16:36:13.109: INFO: (19) /api/v1/namespaces/proxy-2776/services/http:proxy-service-szknm:portname2/proxy/: bar (200; 58.904049ms)
Apr 27 16:36:13.109: INFO: (19) /api/v1/namespaces/proxy-2776/pods/proxy-service-szknm-7rcwv:160/proxy/: foo (200; 58.911889ms)
Apr 27 16:36:13.109: INFO: (19) /api/v1/namespaces/proxy-2776/services/proxy-service-szknm:portname2/proxy/: bar (200; 59.028289ms)
STEP: deleting ReplicationController proxy-service-szknm in namespace proxy-2776, will wait for the garbage collector to delete the pods
Apr 27 16:36:13.185: INFO: Deleting ReplicationController proxy-service-szknm took: 13.808823ms
Apr 27 16:36:13.286: INFO: Terminating ReplicationController proxy-service-szknm pods took: 100.454329ms
[AfterEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:18.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2776" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":277,"completed":120,"skipped":1997,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:18.619: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6670
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-cf32bc46-5eab-42f6-9901-bc7e599ceb45
STEP: Creating a pod to test consume configMaps
Apr 27 16:36:18.833: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3c1aa0e3-302c-49c7-9f4e-a84146d9ee6c" in namespace "projected-6670" to be "Succeeded or Failed"
Apr 27 16:36:18.843: INFO: Pod "pod-projected-configmaps-3c1aa0e3-302c-49c7-9f4e-a84146d9ee6c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.542012ms
Apr 27 16:36:20.855: INFO: Pod "pod-projected-configmaps-3c1aa0e3-302c-49c7-9f4e-a84146d9ee6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022530666s
Apr 27 16:36:22.868: INFO: Pod "pod-projected-configmaps-3c1aa0e3-302c-49c7-9f4e-a84146d9ee6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035084384s
STEP: Saw pod success
Apr 27 16:36:22.868: INFO: Pod "pod-projected-configmaps-3c1aa0e3-302c-49c7-9f4e-a84146d9ee6c" satisfied condition "Succeeded or Failed"
Apr 27 16:36:22.879: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-projected-configmaps-3c1aa0e3-302c-49c7-9f4e-a84146d9ee6c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:36:22.918: INFO: Waiting for pod pod-projected-configmaps-3c1aa0e3-302c-49c7-9f4e-a84146d9ee6c to disappear
Apr 27 16:36:22.928: INFO: Pod pod-projected-configmaps-3c1aa0e3-302c-49c7-9f4e-a84146d9ee6c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:22.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6670" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":277,"completed":121,"skipped":2040,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:22.964: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-953
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-cc8e770a-fa55-4a86-a34b-58039f495bad
STEP: Creating a pod to test consume configMaps
Apr 27 16:36:23.182: INFO: Waiting up to 5m0s for pod "pod-configmaps-b32febd1-97db-412d-8bda-e318ebfb7802" in namespace "configmap-953" to be "Succeeded or Failed"
Apr 27 16:36:23.192: INFO: Pod "pod-configmaps-b32febd1-97db-412d-8bda-e318ebfb7802": Phase="Pending", Reason="", readiness=false. Elapsed: 10.226115ms
Apr 27 16:36:25.204: INFO: Pod "pod-configmaps-b32febd1-97db-412d-8bda-e318ebfb7802": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021752098s
Apr 27 16:36:27.215: INFO: Pod "pod-configmaps-b32febd1-97db-412d-8bda-e318ebfb7802": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033313389s
STEP: Saw pod success
Apr 27 16:36:27.216: INFO: Pod "pod-configmaps-b32febd1-97db-412d-8bda-e318ebfb7802" satisfied condition "Succeeded or Failed"
Apr 27 16:36:27.227: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-configmaps-b32febd1-97db-412d-8bda-e318ebfb7802 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:36:27.271: INFO: Waiting for pod pod-configmaps-b32febd1-97db-412d-8bda-e318ebfb7802 to disappear
Apr 27 16:36:27.282: INFO: Pod pod-configmaps-b32febd1-97db-412d-8bda-e318ebfb7802 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:27.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-953" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":277,"completed":122,"skipped":2054,"failed":0}
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:27.315: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7706
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Apr 27 16:36:27.513: INFO: namespace kubectl-7706
Apr 27 16:36:27.513: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-7706'
Apr 27 16:36:27.816: INFO: stderr: ""
Apr 27 16:36:27.816: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Apr 27 16:36:28.829: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 16:36:28.829: INFO: Found 0 / 1
Apr 27 16:36:29.827: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 16:36:29.827: INFO: Found 0 / 1
Apr 27 16:36:30.828: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 16:36:30.828: INFO: Found 1 / 1
Apr 27 16:36:30.828: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 27 16:36:30.839: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 16:36:30.839: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 27 16:36:30.839: INFO: wait on agnhost-master startup in kubectl-7706 
Apr 27 16:36:30.839: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs agnhost-master-vqckq agnhost-master --namespace=kubectl-7706'
Apr 27 16:36:31.060: INFO: stderr: ""
Apr 27 16:36:31.060: INFO: stdout: "Paused\n"
STEP: exposing RC
Apr 27 16:36:31.060: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config expose rc agnhost-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-7706'
Apr 27 16:36:31.211: INFO: stderr: ""
Apr 27 16:36:31.211: INFO: stdout: "service/rm2 exposed\n"
Apr 27 16:36:31.222: INFO: Service rm2 in namespace kubectl-7706 found.
STEP: exposing service
Apr 27 16:36:33.244: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-7706'
Apr 27 16:36:33.382: INFO: stderr: ""
Apr 27 16:36:33.382: INFO: stdout: "service/rm3 exposed\n"
Apr 27 16:36:33.393: INFO: Service rm3 in namespace kubectl-7706 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:35.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7706" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":277,"completed":123,"skipped":2062,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:35.448: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4818
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:36:36.037: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602196, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602196, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602196, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602195, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:36:38.049: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602196, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602196, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602196, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602195, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:36:41.070: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:36:41.082: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6891-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:41.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4818" for this suite.
STEP: Destroying namespace "webhook-4818-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":277,"completed":124,"skipped":2078,"failed":0}
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:41.967: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5909
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating secret secrets-5909/secret-test-a010a0ab-2e8c-45f4-ba63-c9f52daa92a6
STEP: Creating a pod to test consume secrets
Apr 27 16:36:42.179: INFO: Waiting up to 5m0s for pod "pod-configmaps-7df6b56a-6bf8-4dad-bc4b-db55947764c4" in namespace "secrets-5909" to be "Succeeded or Failed"
Apr 27 16:36:42.190: INFO: Pod "pod-configmaps-7df6b56a-6bf8-4dad-bc4b-db55947764c4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.702416ms
Apr 27 16:36:44.201: INFO: Pod "pod-configmaps-7df6b56a-6bf8-4dad-bc4b-db55947764c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022265345s
Apr 27 16:36:46.215: INFO: Pod "pod-configmaps-7df6b56a-6bf8-4dad-bc4b-db55947764c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035891474s
STEP: Saw pod success
Apr 27 16:36:46.215: INFO: Pod "pod-configmaps-7df6b56a-6bf8-4dad-bc4b-db55947764c4" satisfied condition "Succeeded or Failed"
Apr 27 16:36:46.226: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-configmaps-7df6b56a-6bf8-4dad-bc4b-db55947764c4 container env-test: <nil>
STEP: delete the pod
Apr 27 16:36:46.263: INFO: Waiting for pod pod-configmaps-7df6b56a-6bf8-4dad-bc4b-db55947764c4 to disappear
Apr 27 16:36:46.273: INFO: Pod pod-configmaps-7df6b56a-6bf8-4dad-bc4b-db55947764c4 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:46.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5909" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":277,"completed":125,"skipped":2079,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:46.307: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-443
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Apr 27 16:36:46.534: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:47.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-443" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":277,"completed":126,"skipped":2089,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:47.629: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6633
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-2beae57e-42f5-4f5d-bb1b-3dbe4d317042
STEP: Creating a pod to test consume configMaps
Apr 27 16:36:47.843: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-dc26da10-64d1-4678-8e78-e924f6e104b8" in namespace "projected-6633" to be "Succeeded or Failed"
Apr 27 16:36:47.853: INFO: Pod "pod-projected-configmaps-dc26da10-64d1-4678-8e78-e924f6e104b8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.014138ms
Apr 27 16:36:49.865: INFO: Pod "pod-projected-configmaps-dc26da10-64d1-4678-8e78-e924f6e104b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021425319s
Apr 27 16:36:51.876: INFO: Pod "pod-projected-configmaps-dc26da10-64d1-4678-8e78-e924f6e104b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032432613s
STEP: Saw pod success
Apr 27 16:36:51.876: INFO: Pod "pod-projected-configmaps-dc26da10-64d1-4678-8e78-e924f6e104b8" satisfied condition "Succeeded or Failed"
Apr 27 16:36:51.887: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-projected-configmaps-dc26da10-64d1-4678-8e78-e924f6e104b8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:36:51.928: INFO: Waiting for pod pod-projected-configmaps-dc26da10-64d1-4678-8e78-e924f6e104b8 to disappear
Apr 27 16:36:51.938: INFO: Pod pod-projected-configmaps-dc26da10-64d1-4678-8e78-e924f6e104b8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:51.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6633" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":127,"skipped":2104,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:51.972: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-9299
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's command
Apr 27 16:36:52.181: INFO: Waiting up to 5m0s for pod "var-expansion-c80dcf87-d0e2-4ee4-b2e8-2613d079ee83" in namespace "var-expansion-9299" to be "Succeeded or Failed"
Apr 27 16:36:52.192: INFO: Pod "var-expansion-c80dcf87-d0e2-4ee4-b2e8-2613d079ee83": Phase="Pending", Reason="", readiness=false. Elapsed: 10.669394ms
Apr 27 16:36:54.204: INFO: Pod "var-expansion-c80dcf87-d0e2-4ee4-b2e8-2613d079ee83": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022068065s
Apr 27 16:36:56.215: INFO: Pod "var-expansion-c80dcf87-d0e2-4ee4-b2e8-2613d079ee83": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033627364s
STEP: Saw pod success
Apr 27 16:36:56.215: INFO: Pod "var-expansion-c80dcf87-d0e2-4ee4-b2e8-2613d079ee83" satisfied condition "Succeeded or Failed"
Apr 27 16:36:56.226: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod var-expansion-c80dcf87-d0e2-4ee4-b2e8-2613d079ee83 container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:36:56.262: INFO: Waiting for pod var-expansion-c80dcf87-d0e2-4ee4-b2e8-2613d079ee83 to disappear
Apr 27 16:36:56.273: INFO: Pod var-expansion-c80dcf87-d0e2-4ee4-b2e8-2613d079ee83 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:56.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9299" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":277,"completed":128,"skipped":2120,"failed":0}
SSS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:56.305: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-512
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching services
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:56.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-512" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":277,"completed":129,"skipped":2123,"failed":0}
S
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:56.555: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6832
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Apr 27 16:37:01.352: INFO: Successfully updated pod "annotationupdatec5227760-17f2-431f-85f8-6fe987f48013"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:37:03.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6832" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":277,"completed":130,"skipped":2124,"failed":0}
SS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:37:03.454: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-5403
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:37:03.642: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating replication controller svc-latency-rc in namespace svc-latency-5403
I0427 16:37:03.661975    7292 runners.go:190] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5403, replica count: 1
I0427 16:37:04.712725    7292 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0427 16:37:05.713074    7292 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0427 16:37:06.713314    7292 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 27 16:37:06.836: INFO: Created: latency-svc-zmgnx
Apr 27 16:37:06.847: INFO: Got endpoints: latency-svc-zmgnx [33.867468ms]
Apr 27 16:37:06.926: INFO: Created: latency-svc-qfznl
Apr 27 16:37:07.023: INFO: Created: latency-svc-czwkp
Apr 27 16:37:07.023: INFO: Got endpoints: latency-svc-qfznl [175.882902ms]
Apr 27 16:37:07.032: INFO: Created: latency-svc-mnbsv
Apr 27 16:37:07.032: INFO: Got endpoints: latency-svc-czwkp [184.662641ms]
Apr 27 16:37:07.040: INFO: Created: latency-svc-ndrgw
Apr 27 16:37:07.040: INFO: Got endpoints: latency-svc-mnbsv [192.546151ms]
Apr 27 16:37:07.044: INFO: Got endpoints: latency-svc-ndrgw [196.9005ms]
Apr 27 16:37:07.049: INFO: Created: latency-svc-pndp8
Apr 27 16:37:07.123: INFO: Created: latency-svc-dmp5x
Apr 27 16:37:07.123: INFO: Got endpoints: latency-svc-pndp8 [275.944431ms]
Apr 27 16:37:07.125: INFO: Got endpoints: latency-svc-dmp5x [277.964622ms]
Apr 27 16:37:07.132: INFO: Created: latency-svc-s6m4x
Apr 27 16:37:07.140: INFO: Got endpoints: latency-svc-s6m4x [292.891335ms]
Apr 27 16:37:07.144: INFO: Created: latency-svc-8vvtk
Apr 27 16:37:07.155: INFO: Created: latency-svc-f8klv
Apr 27 16:37:07.155: INFO: Got endpoints: latency-svc-8vvtk [307.438524ms]
Apr 27 16:37:07.158: INFO: Got endpoints: latency-svc-f8klv [310.110944ms]
Apr 27 16:37:07.164: INFO: Created: latency-svc-kbkv2
Apr 27 16:37:07.170: INFO: Got endpoints: latency-svc-kbkv2 [322.885379ms]
Apr 27 16:37:07.176: INFO: Created: latency-svc-glhg9
Apr 27 16:37:07.183: INFO: Created: latency-svc-sl7fn
Apr 27 16:37:07.183: INFO: Got endpoints: latency-svc-glhg9 [336.112451ms]
Apr 27 16:37:07.185: INFO: Got endpoints: latency-svc-sl7fn [337.664851ms]
Apr 27 16:37:07.193: INFO: Created: latency-svc-7gpb5
Apr 27 16:37:07.198: INFO: Got endpoints: latency-svc-7gpb5 [350.66528ms]
Apr 27 16:37:07.204: INFO: Created: latency-svc-h8hnw
Apr 27 16:37:07.216: INFO: Created: latency-svc-lqzxt
Apr 27 16:37:07.216: INFO: Got endpoints: latency-svc-h8hnw [368.418048ms]
Apr 27 16:37:07.223: INFO: Got endpoints: latency-svc-lqzxt [375.438584ms]
Apr 27 16:37:07.223: INFO: Created: latency-svc-q2fmk
Apr 27 16:37:07.227: INFO: Got endpoints: latency-svc-q2fmk [203.920596ms]
Apr 27 16:37:07.235: INFO: Created: latency-svc-l9xhd
Apr 27 16:37:07.239: INFO: Got endpoints: latency-svc-l9xhd [207.430815ms]
Apr 27 16:37:07.266: INFO: Created: latency-svc-686n6
Apr 27 16:37:07.276: INFO: Created: latency-svc-9z8mc
Apr 27 16:37:07.276: INFO: Got endpoints: latency-svc-686n6 [236.420695ms]
Apr 27 16:37:07.284: INFO: Got endpoints: latency-svc-9z8mc [239.156155ms]
Apr 27 16:37:07.291: INFO: Created: latency-svc-r7xs2
Apr 27 16:37:07.296: INFO: Got endpoints: latency-svc-r7xs2 [172.940869ms]
Apr 27 16:37:07.305: INFO: Created: latency-svc-vv4xx
Apr 27 16:37:07.313: INFO: Created: latency-svc-ws92p
Apr 27 16:37:07.313: INFO: Got endpoints: latency-svc-vv4xx [187.481664ms]
Apr 27 16:37:07.319: INFO: Got endpoints: latency-svc-ws92p [177.954255ms]
Apr 27 16:37:07.325: INFO: Created: latency-svc-dq6lc
Apr 27 16:37:07.334: INFO: Got endpoints: latency-svc-dq6lc [178.78413ms]
Apr 27 16:37:07.334: INFO: Created: latency-svc-g4k54
Apr 27 16:37:07.340: INFO: Got endpoints: latency-svc-g4k54 [182.201864ms]
Apr 27 16:37:07.345: INFO: Created: latency-svc-fgxcs
Apr 27 16:37:07.352: INFO: Created: latency-svc-m5fwg
Apr 27 16:37:07.352: INFO: Got endpoints: latency-svc-fgxcs [181.220822ms]
Apr 27 16:37:07.357: INFO: Got endpoints: latency-svc-m5fwg [173.139031ms]
Apr 27 16:37:07.363: INFO: Created: latency-svc-gvchq
Apr 27 16:37:07.377: INFO: Created: latency-svc-95dgr
Apr 27 16:37:07.377: INFO: Got endpoints: latency-svc-gvchq [191.67381ms]
Apr 27 16:37:07.379: INFO: Got endpoints: latency-svc-95dgr [180.371131ms]
Apr 27 16:37:07.386: INFO: Created: latency-svc-24rc9
Apr 27 16:37:07.389: INFO: Got endpoints: latency-svc-24rc9 [172.465181ms]
Apr 27 16:37:07.394: INFO: Created: latency-svc-fstdd
Apr 27 16:37:07.397: INFO: Got endpoints: latency-svc-fstdd [173.468946ms]
Apr 27 16:37:07.402: INFO: Created: latency-svc-l69b5
Apr 27 16:37:07.403: INFO: Got endpoints: latency-svc-l69b5 [176.329943ms]
Apr 27 16:37:07.413: INFO: Created: latency-svc-zjxc5
Apr 27 16:37:07.422: INFO: Created: latency-svc-lwh95
Apr 27 16:37:07.422: INFO: Got endpoints: latency-svc-zjxc5 [182.632224ms]
Apr 27 16:37:07.428: INFO: Got endpoints: latency-svc-lwh95 [151.34737ms]
Apr 27 16:37:07.433: INFO: Created: latency-svc-bshdx
Apr 27 16:37:07.442: INFO: Created: latency-svc-kj2js
Apr 27 16:37:07.442: INFO: Got endpoints: latency-svc-bshdx [158.074041ms]
Apr 27 16:37:07.447: INFO: Got endpoints: latency-svc-kj2js [150.383472ms]
Apr 27 16:37:07.453: INFO: Created: latency-svc-9bpw9
Apr 27 16:37:07.460: INFO: Created: latency-svc-87bzd
Apr 27 16:37:07.460: INFO: Got endpoints: latency-svc-9bpw9 [147.215683ms]
Apr 27 16:37:07.464: INFO: Got endpoints: latency-svc-87bzd [145.588617ms]
Apr 27 16:37:07.474: INFO: Created: latency-svc-rtgk5
Apr 27 16:37:07.488: INFO: Created: latency-svc-6q4wz
Apr 27 16:37:07.488: INFO: Got endpoints: latency-svc-rtgk5 [154.463823ms]
Apr 27 16:37:07.490: INFO: Got endpoints: latency-svc-6q4wz [150.029663ms]
Apr 27 16:37:07.499: INFO: Created: latency-svc-fjddx
Apr 27 16:37:07.502: INFO: Got endpoints: latency-svc-fjddx [149.867917ms]
Apr 27 16:37:07.507: INFO: Created: latency-svc-wztbk
Apr 27 16:37:07.514: INFO: Got endpoints: latency-svc-wztbk [156.83049ms]
Apr 27 16:37:07.514: INFO: Created: latency-svc-ddjv6
Apr 27 16:37:07.529: INFO: Created: latency-svc-hf9jk
Apr 27 16:37:07.537: INFO: Created: latency-svc-qgtsr
Apr 27 16:37:07.537: INFO: Got endpoints: latency-svc-ddjv6 [160.263138ms]
Apr 27 16:37:07.547: INFO: Created: latency-svc-xtbvr
Apr 27 16:37:07.554: INFO: Created: latency-svc-4f59q
Apr 27 16:37:07.566: INFO: Created: latency-svc-hkpv9
Apr 27 16:37:07.574: INFO: Created: latency-svc-jktkg
Apr 27 16:37:07.582: INFO: Created: latency-svc-8v5w4
Apr 27 16:37:07.588: INFO: Got endpoints: latency-svc-hf9jk [208.671192ms]
Apr 27 16:37:07.601: INFO: Created: latency-svc-s2q4p
Apr 27 16:37:07.609: INFO: Created: latency-svc-pgrfk
Apr 27 16:37:07.627: INFO: Created: latency-svc-kljv4
Apr 27 16:37:07.639: INFO: Got endpoints: latency-svc-qgtsr [250.342973ms]
Apr 27 16:37:07.639: INFO: Created: latency-svc-ft9vd
Apr 27 16:37:07.650: INFO: Created: latency-svc-kbnd4
Apr 27 16:37:07.658: INFO: Created: latency-svc-s87xs
Apr 27 16:37:07.665: INFO: Created: latency-svc-2fbvx
Apr 27 16:37:07.677: INFO: Created: latency-svc-5g79c
Apr 27 16:37:07.685: INFO: Created: latency-svc-ztw52
Apr 27 16:37:07.685: INFO: Got endpoints: latency-svc-xtbvr [288.501963ms]
Apr 27 16:37:07.724: INFO: Created: latency-svc-f28nw
Apr 27 16:37:07.731: INFO: Created: latency-svc-ggmh6
Apr 27 16:37:07.736: INFO: Got endpoints: latency-svc-4f59q [332.845696ms]
Apr 27 16:37:07.756: INFO: Created: latency-svc-jx68b
Apr 27 16:37:07.787: INFO: Got endpoints: latency-svc-hkpv9 [364.512348ms]
Apr 27 16:37:07.808: INFO: Created: latency-svc-k7b2d
Apr 27 16:37:07.836: INFO: Got endpoints: latency-svc-jktkg [407.834455ms]
Apr 27 16:37:07.856: INFO: Created: latency-svc-6smrz
Apr 27 16:37:07.885: INFO: Got endpoints: latency-svc-8v5w4 [443.366075ms]
Apr 27 16:37:07.903: INFO: Created: latency-svc-zvrx2
Apr 27 16:37:07.942: INFO: Got endpoints: latency-svc-s2q4p [494.743873ms]
Apr 27 16:37:07.960: INFO: Created: latency-svc-dqggr
Apr 27 16:37:07.985: INFO: Got endpoints: latency-svc-pgrfk [524.773294ms]
Apr 27 16:37:08.004: INFO: Created: latency-svc-594nt
Apr 27 16:37:08.035: INFO: Got endpoints: latency-svc-kljv4 [570.602286ms]
Apr 27 16:37:08.056: INFO: Created: latency-svc-rbhq8
Apr 27 16:37:08.087: INFO: Got endpoints: latency-svc-ft9vd [599.031768ms]
Apr 27 16:37:08.106: INFO: Created: latency-svc-x2b4j
Apr 27 16:37:08.135: INFO: Got endpoints: latency-svc-kbnd4 [644.551445ms]
Apr 27 16:37:08.156: INFO: Created: latency-svc-qztzt
Apr 27 16:37:08.185: INFO: Got endpoints: latency-svc-s87xs [683.420847ms]
Apr 27 16:37:08.204: INFO: Created: latency-svc-nmhwv
Apr 27 16:37:08.235: INFO: Got endpoints: latency-svc-2fbvx [721.329651ms]
Apr 27 16:37:08.254: INFO: Created: latency-svc-9mv2p
Apr 27 16:37:08.286: INFO: Got endpoints: latency-svc-5g79c [748.415853ms]
Apr 27 16:37:08.305: INFO: Created: latency-svc-92rm7
Apr 27 16:37:08.337: INFO: Got endpoints: latency-svc-ztw52 [748.925052ms]
Apr 27 16:37:08.356: INFO: Created: latency-svc-2cqsj
Apr 27 16:37:08.387: INFO: Got endpoints: latency-svc-f28nw [748.118143ms]
Apr 27 16:37:08.409: INFO: Created: latency-svc-xbtb2
Apr 27 16:37:08.435: INFO: Got endpoints: latency-svc-ggmh6 [749.855631ms]
Apr 27 16:37:08.455: INFO: Created: latency-svc-kjxmj
Apr 27 16:37:08.485: INFO: Got endpoints: latency-svc-jx68b [748.556341ms]
Apr 27 16:37:08.504: INFO: Created: latency-svc-ph8dw
Apr 27 16:37:08.536: INFO: Got endpoints: latency-svc-k7b2d [748.873645ms]
Apr 27 16:37:08.554: INFO: Created: latency-svc-6zzqh
Apr 27 16:37:08.590: INFO: Got endpoints: latency-svc-6smrz [754.693427ms]
Apr 27 16:37:08.609: INFO: Created: latency-svc-sklp4
Apr 27 16:37:08.634: INFO: Got endpoints: latency-svc-zvrx2 [749.005564ms]
Apr 27 16:37:08.661: INFO: Created: latency-svc-q69jv
Apr 27 16:37:08.685: INFO: Got endpoints: latency-svc-dqggr [742.740749ms]
Apr 27 16:37:08.705: INFO: Created: latency-svc-b5k5d
Apr 27 16:37:08.736: INFO: Got endpoints: latency-svc-594nt [751.574789ms]
Apr 27 16:37:08.755: INFO: Created: latency-svc-jsrv2
Apr 27 16:37:08.787: INFO: Got endpoints: latency-svc-rbhq8 [751.617863ms]
Apr 27 16:37:08.807: INFO: Created: latency-svc-5r7ws
Apr 27 16:37:08.835: INFO: Got endpoints: latency-svc-x2b4j [747.742129ms]
Apr 27 16:37:08.854: INFO: Created: latency-svc-zmk9q
Apr 27 16:37:08.885: INFO: Got endpoints: latency-svc-qztzt [749.906967ms]
Apr 27 16:37:08.904: INFO: Created: latency-svc-xtvzt
Apr 27 16:37:08.941: INFO: Got endpoints: latency-svc-nmhwv [755.534282ms]
Apr 27 16:37:08.964: INFO: Created: latency-svc-qng2f
Apr 27 16:37:08.986: INFO: Got endpoints: latency-svc-9mv2p [751.128471ms]
Apr 27 16:37:09.005: INFO: Created: latency-svc-s6q7f
Apr 27 16:37:09.037: INFO: Got endpoints: latency-svc-92rm7 [750.994168ms]
Apr 27 16:37:09.057: INFO: Created: latency-svc-v76rk
Apr 27 16:37:09.085: INFO: Got endpoints: latency-svc-2cqsj [748.364061ms]
Apr 27 16:37:09.107: INFO: Created: latency-svc-6gwsx
Apr 27 16:37:09.135: INFO: Got endpoints: latency-svc-xbtb2 [747.852526ms]
Apr 27 16:37:09.154: INFO: Created: latency-svc-dlr4d
Apr 27 16:37:09.192: INFO: Got endpoints: latency-svc-kjxmj [756.396672ms]
Apr 27 16:37:09.211: INFO: Created: latency-svc-vplzd
Apr 27 16:37:09.239: INFO: Got endpoints: latency-svc-ph8dw [753.42834ms]
Apr 27 16:37:09.258: INFO: Created: latency-svc-mx4gj
Apr 27 16:37:09.286: INFO: Got endpoints: latency-svc-6zzqh [749.691842ms]
Apr 27 16:37:09.306: INFO: Created: latency-svc-w45rq
Apr 27 16:37:09.336: INFO: Got endpoints: latency-svc-sklp4 [745.183791ms]
Apr 27 16:37:09.359: INFO: Created: latency-svc-j28qv
Apr 27 16:37:09.386: INFO: Got endpoints: latency-svc-q69jv [751.932386ms]
Apr 27 16:37:09.405: INFO: Created: latency-svc-xbtdj
Apr 27 16:37:09.437: INFO: Got endpoints: latency-svc-b5k5d [751.990387ms]
Apr 27 16:37:09.458: INFO: Created: latency-svc-rsv7w
Apr 27 16:37:09.490: INFO: Got endpoints: latency-svc-jsrv2 [753.602594ms]
Apr 27 16:37:09.511: INFO: Created: latency-svc-72m6q
Apr 27 16:37:09.537: INFO: Got endpoints: latency-svc-5r7ws [749.858244ms]
Apr 27 16:37:09.555: INFO: Created: latency-svc-xbkd5
Apr 27 16:37:09.590: INFO: Got endpoints: latency-svc-zmk9q [754.673225ms]
Apr 27 16:37:09.611: INFO: Created: latency-svc-g2bxk
Apr 27 16:37:09.635: INFO: Got endpoints: latency-svc-xtvzt [749.742161ms]
Apr 27 16:37:09.654: INFO: Created: latency-svc-62jgz
Apr 27 16:37:09.690: INFO: Got endpoints: latency-svc-qng2f [748.896677ms]
Apr 27 16:37:09.709: INFO: Created: latency-svc-xrn6v
Apr 27 16:37:09.737: INFO: Got endpoints: latency-svc-s6q7f [750.438677ms]
Apr 27 16:37:09.756: INFO: Created: latency-svc-rs2zx
Apr 27 16:37:09.785: INFO: Got endpoints: latency-svc-v76rk [748.218501ms]
Apr 27 16:37:09.807: INFO: Created: latency-svc-kkzj2
Apr 27 16:37:09.836: INFO: Got endpoints: latency-svc-6gwsx [750.820941ms]
Apr 27 16:37:09.856: INFO: Created: latency-svc-jf2xl
Apr 27 16:37:09.891: INFO: Got endpoints: latency-svc-dlr4d [756.226859ms]
Apr 27 16:37:09.911: INFO: Created: latency-svc-4zwdk
Apr 27 16:37:09.940: INFO: Got endpoints: latency-svc-vplzd [748.729281ms]
Apr 27 16:37:09.961: INFO: Created: latency-svc-kgzl7
Apr 27 16:37:09.985: INFO: Got endpoints: latency-svc-mx4gj [746.348787ms]
Apr 27 16:37:10.008: INFO: Created: latency-svc-zh97b
Apr 27 16:37:10.038: INFO: Got endpoints: latency-svc-w45rq [752.207721ms]
Apr 27 16:37:10.058: INFO: Created: latency-svc-bkzs4
Apr 27 16:37:10.085: INFO: Got endpoints: latency-svc-j28qv [749.541646ms]
Apr 27 16:37:10.107: INFO: Created: latency-svc-fflqv
Apr 27 16:37:10.135: INFO: Got endpoints: latency-svc-xbtdj [748.590868ms]
Apr 27 16:37:10.155: INFO: Created: latency-svc-8sxn9
Apr 27 16:37:10.185: INFO: Got endpoints: latency-svc-rsv7w [747.995381ms]
Apr 27 16:37:10.204: INFO: Created: latency-svc-znw2b
Apr 27 16:37:10.237: INFO: Got endpoints: latency-svc-72m6q [746.659717ms]
Apr 27 16:37:10.258: INFO: Created: latency-svc-lbpmb
Apr 27 16:37:10.285: INFO: Got endpoints: latency-svc-xbkd5 [748.117357ms]
Apr 27 16:37:10.304: INFO: Created: latency-svc-nd9wd
Apr 27 16:37:10.337: INFO: Got endpoints: latency-svc-g2bxk [746.912444ms]
Apr 27 16:37:10.358: INFO: Created: latency-svc-bdfpl
Apr 27 16:37:10.385: INFO: Got endpoints: latency-svc-62jgz [750.266135ms]
Apr 27 16:37:10.405: INFO: Created: latency-svc-5jdqc
Apr 27 16:37:10.438: INFO: Got endpoints: latency-svc-xrn6v [747.890867ms]
Apr 27 16:37:10.457: INFO: Created: latency-svc-zs5f9
Apr 27 16:37:10.485: INFO: Got endpoints: latency-svc-rs2zx [748.260744ms]
Apr 27 16:37:10.509: INFO: Created: latency-svc-kqxqk
Apr 27 16:37:10.536: INFO: Got endpoints: latency-svc-kkzj2 [750.809198ms]
Apr 27 16:37:10.556: INFO: Created: latency-svc-sk6zx
Apr 27 16:37:10.587: INFO: Got endpoints: latency-svc-jf2xl [750.848083ms]
Apr 27 16:37:10.607: INFO: Created: latency-svc-755dv
Apr 27 16:37:10.635: INFO: Got endpoints: latency-svc-4zwdk [743.386825ms]
Apr 27 16:37:10.657: INFO: Created: latency-svc-cntkz
Apr 27 16:37:10.690: INFO: Got endpoints: latency-svc-kgzl7 [749.701437ms]
Apr 27 16:37:10.710: INFO: Created: latency-svc-lm8k8
Apr 27 16:37:10.735: INFO: Got endpoints: latency-svc-zh97b [749.804001ms]
Apr 27 16:37:10.755: INFO: Created: latency-svc-944t4
Apr 27 16:37:10.787: INFO: Got endpoints: latency-svc-bkzs4 [748.474809ms]
Apr 27 16:37:10.808: INFO: Created: latency-svc-kvjk7
Apr 27 16:37:10.835: INFO: Got endpoints: latency-svc-fflqv [749.589707ms]
Apr 27 16:37:10.856: INFO: Created: latency-svc-88cf5
Apr 27 16:37:10.890: INFO: Got endpoints: latency-svc-8sxn9 [754.625035ms]
Apr 27 16:37:10.908: INFO: Created: latency-svc-blfx7
Apr 27 16:37:10.940: INFO: Got endpoints: latency-svc-znw2b [754.953866ms]
Apr 27 16:37:10.960: INFO: Created: latency-svc-qzqtz
Apr 27 16:37:10.986: INFO: Got endpoints: latency-svc-lbpmb [748.725065ms]
Apr 27 16:37:11.005: INFO: Created: latency-svc-xncq9
Apr 27 16:37:11.035: INFO: Got endpoints: latency-svc-nd9wd [749.790895ms]
Apr 27 16:37:11.053: INFO: Created: latency-svc-97h2g
Apr 27 16:37:11.092: INFO: Got endpoints: latency-svc-bdfpl [754.588218ms]
Apr 27 16:37:11.111: INFO: Created: latency-svc-5b8km
Apr 27 16:37:11.143: INFO: Got endpoints: latency-svc-5jdqc [757.954158ms]
Apr 27 16:37:11.164: INFO: Created: latency-svc-9tmtz
Apr 27 16:37:11.185: INFO: Got endpoints: latency-svc-zs5f9 [746.822848ms]
Apr 27 16:37:11.206: INFO: Created: latency-svc-85jll
Apr 27 16:37:11.237: INFO: Got endpoints: latency-svc-kqxqk [751.767919ms]
Apr 27 16:37:11.258: INFO: Created: latency-svc-66jph
Apr 27 16:37:11.287: INFO: Got endpoints: latency-svc-sk6zx [750.419955ms]
Apr 27 16:37:11.309: INFO: Created: latency-svc-bgwb6
Apr 27 16:37:11.337: INFO: Got endpoints: latency-svc-755dv [749.833487ms]
Apr 27 16:37:11.357: INFO: Created: latency-svc-2w8bw
Apr 27 16:37:11.387: INFO: Got endpoints: latency-svc-cntkz [751.855409ms]
Apr 27 16:37:11.406: INFO: Created: latency-svc-sq4tl
Apr 27 16:37:11.435: INFO: Got endpoints: latency-svc-lm8k8 [745.18523ms]
Apr 27 16:37:11.457: INFO: Created: latency-svc-ztrwt
Apr 27 16:37:11.490: INFO: Got endpoints: latency-svc-944t4 [755.44013ms]
Apr 27 16:37:11.510: INFO: Created: latency-svc-c42s8
Apr 27 16:37:11.588: INFO: Got endpoints: latency-svc-88cf5 [752.329221ms]
Apr 27 16:37:11.588: INFO: Got endpoints: latency-svc-kvjk7 [801.000649ms]
Apr 27 16:37:11.609: INFO: Created: latency-svc-snb76
Apr 27 16:37:11.620: INFO: Created: latency-svc-5ld2j
Apr 27 16:37:11.635: INFO: Got endpoints: latency-svc-blfx7 [744.932613ms]
Apr 27 16:37:11.654: INFO: Created: latency-svc-bv6s9
Apr 27 16:37:11.691: INFO: Got endpoints: latency-svc-qzqtz [750.946784ms]
Apr 27 16:37:11.711: INFO: Created: latency-svc-qk685
Apr 27 16:37:11.735: INFO: Got endpoints: latency-svc-xncq9 [749.621122ms]
Apr 27 16:37:11.764: INFO: Created: latency-svc-725td
Apr 27 16:37:11.788: INFO: Got endpoints: latency-svc-97h2g [752.894612ms]
Apr 27 16:37:11.809: INFO: Created: latency-svc-r9jc5
Apr 27 16:37:11.835: INFO: Got endpoints: latency-svc-5b8km [743.272394ms]
Apr 27 16:37:11.862: INFO: Created: latency-svc-lkjd4
Apr 27 16:37:11.885: INFO: Got endpoints: latency-svc-9tmtz [742.01092ms]
Apr 27 16:37:11.904: INFO: Created: latency-svc-2bjvp
Apr 27 16:37:11.937: INFO: Got endpoints: latency-svc-85jll [751.749543ms]
Apr 27 16:37:11.957: INFO: Created: latency-svc-dvwsc
Apr 27 16:37:11.990: INFO: Got endpoints: latency-svc-66jph [753.081696ms]
Apr 27 16:37:12.009: INFO: Created: latency-svc-zxttr
Apr 27 16:37:12.035: INFO: Got endpoints: latency-svc-bgwb6 [748.156026ms]
Apr 27 16:37:12.055: INFO: Created: latency-svc-jrppv
Apr 27 16:37:12.087: INFO: Got endpoints: latency-svc-2w8bw [749.80101ms]
Apr 27 16:37:12.107: INFO: Created: latency-svc-t4j2b
Apr 27 16:37:12.135: INFO: Got endpoints: latency-svc-sq4tl [747.67484ms]
Apr 27 16:37:12.154: INFO: Created: latency-svc-kmkqk
Apr 27 16:37:12.188: INFO: Got endpoints: latency-svc-ztrwt [751.952647ms]
Apr 27 16:37:12.208: INFO: Created: latency-svc-sxz7w
Apr 27 16:37:12.235: INFO: Got endpoints: latency-svc-c42s8 [744.611531ms]
Apr 27 16:37:12.255: INFO: Created: latency-svc-264r5
Apr 27 16:37:12.286: INFO: Got endpoints: latency-svc-snb76 [698.217835ms]
Apr 27 16:37:12.312: INFO: Created: latency-svc-mclpm
Apr 27 16:37:12.335: INFO: Got endpoints: latency-svc-5ld2j [747.264829ms]
Apr 27 16:37:12.355: INFO: Created: latency-svc-nd7jl
Apr 27 16:37:12.388: INFO: Got endpoints: latency-svc-bv6s9 [752.791863ms]
Apr 27 16:37:12.411: INFO: Created: latency-svc-6v6vj
Apr 27 16:37:12.440: INFO: Got endpoints: latency-svc-qk685 [748.740205ms]
Apr 27 16:37:12.459: INFO: Created: latency-svc-2qn9n
Apr 27 16:37:12.490: INFO: Got endpoints: latency-svc-725td [754.040306ms]
Apr 27 16:37:12.521: INFO: Created: latency-svc-b4c55
Apr 27 16:37:12.537: INFO: Got endpoints: latency-svc-r9jc5 [748.986316ms]
Apr 27 16:37:12.556: INFO: Created: latency-svc-mxbm4
Apr 27 16:37:12.586: INFO: Got endpoints: latency-svc-lkjd4 [750.84255ms]
Apr 27 16:37:12.605: INFO: Created: latency-svc-rld85
Apr 27 16:37:12.635: INFO: Got endpoints: latency-svc-2bjvp [749.405553ms]
Apr 27 16:37:12.653: INFO: Created: latency-svc-kbk2r
Apr 27 16:37:12.687: INFO: Got endpoints: latency-svc-dvwsc [750.12843ms]
Apr 27 16:37:12.707: INFO: Created: latency-svc-drljb
Apr 27 16:37:12.735: INFO: Got endpoints: latency-svc-zxttr [745.175967ms]
Apr 27 16:37:12.756: INFO: Created: latency-svc-mrfzv
Apr 27 16:37:12.785: INFO: Got endpoints: latency-svc-jrppv [749.703408ms]
Apr 27 16:37:12.805: INFO: Created: latency-svc-bt44s
Apr 27 16:37:12.841: INFO: Got endpoints: latency-svc-t4j2b [754.033002ms]
Apr 27 16:37:12.861: INFO: Created: latency-svc-rxzt5
Apr 27 16:37:12.890: INFO: Got endpoints: latency-svc-kmkqk [755.491148ms]
Apr 27 16:37:12.908: INFO: Created: latency-svc-94rbj
Apr 27 16:37:12.935: INFO: Got endpoints: latency-svc-sxz7w [747.390301ms]
Apr 27 16:37:13.022: INFO: Created: latency-svc-5pwxw
Apr 27 16:37:13.025: INFO: Got endpoints: latency-svc-264r5 [789.922819ms]
Apr 27 16:37:13.125: INFO: Got endpoints: latency-svc-nd7jl [789.697687ms]
Apr 27 16:37:13.130: INFO: Got endpoints: latency-svc-mclpm [843.886587ms]
Apr 27 16:37:13.223: INFO: Created: latency-svc-gzmxq
Apr 27 16:37:13.223: INFO: Got endpoints: latency-svc-6v6vj [835.347439ms]
Apr 27 16:37:13.232: INFO: Got endpoints: latency-svc-2qn9n [791.913729ms]
Apr 27 16:37:13.237: INFO: Created: latency-svc-sd4vw
Apr 27 16:37:13.237: INFO: Got endpoints: latency-svc-b4c55 [747.212264ms]
Apr 27 16:37:13.247: INFO: Created: latency-svc-qkfmm
Apr 27 16:37:13.254: INFO: Created: latency-svc-h9zj8
Apr 27 16:37:13.269: INFO: Created: latency-svc-pjrkf
Apr 27 16:37:13.277: INFO: Created: latency-svc-s9m8r
Apr 27 16:37:13.285: INFO: Got endpoints: latency-svc-mxbm4 [748.337359ms]
Apr 27 16:37:13.305: INFO: Created: latency-svc-ktkpp
Apr 27 16:37:13.335: INFO: Got endpoints: latency-svc-rld85 [749.483103ms]
Apr 27 16:37:13.354: INFO: Created: latency-svc-rv5bf
Apr 27 16:37:13.385: INFO: Got endpoints: latency-svc-kbk2r [749.86057ms]
Apr 27 16:37:13.404: INFO: Created: latency-svc-4vk7k
Apr 27 16:37:13.436: INFO: Got endpoints: latency-svc-drljb [748.812707ms]
Apr 27 16:37:13.459: INFO: Created: latency-svc-gcqpl
Apr 27 16:37:13.488: INFO: Got endpoints: latency-svc-mrfzv [752.942505ms]
Apr 27 16:37:13.507: INFO: Created: latency-svc-dg84h
Apr 27 16:37:13.535: INFO: Got endpoints: latency-svc-bt44s [750.579847ms]
Apr 27 16:37:13.555: INFO: Created: latency-svc-952dp
Apr 27 16:37:13.585: INFO: Got endpoints: latency-svc-rxzt5 [744.607826ms]
Apr 27 16:37:13.605: INFO: Created: latency-svc-5lgrv
Apr 27 16:37:13.635: INFO: Got endpoints: latency-svc-94rbj [744.359437ms]
Apr 27 16:37:13.653: INFO: Created: latency-svc-xvmz2
Apr 27 16:37:13.687: INFO: Got endpoints: latency-svc-5pwxw [751.588294ms]
Apr 27 16:37:13.715: INFO: Created: latency-svc-znxk9
Apr 27 16:37:13.735: INFO: Got endpoints: latency-svc-gzmxq [709.340741ms]
Apr 27 16:37:13.753: INFO: Created: latency-svc-sx2z7
Apr 27 16:37:13.785: INFO: Got endpoints: latency-svc-sd4vw [659.749719ms]
Apr 27 16:37:13.803: INFO: Created: latency-svc-lrr4v
Apr 27 16:37:13.835: INFO: Got endpoints: latency-svc-qkfmm [704.734615ms]
Apr 27 16:37:13.855: INFO: Created: latency-svc-fk8kp
Apr 27 16:37:13.885: INFO: Got endpoints: latency-svc-h9zj8 [661.639705ms]
Apr 27 16:37:13.907: INFO: Created: latency-svc-4z4qw
Apr 27 16:37:13.937: INFO: Got endpoints: latency-svc-pjrkf [705.305218ms]
Apr 27 16:37:13.957: INFO: Created: latency-svc-xkw7t
Apr 27 16:37:13.985: INFO: Got endpoints: latency-svc-s9m8r [748.410445ms]
Apr 27 16:37:14.004: INFO: Created: latency-svc-qfjpk
Apr 27 16:37:14.037: INFO: Got endpoints: latency-svc-ktkpp [751.477349ms]
Apr 27 16:37:14.062: INFO: Created: latency-svc-mpwgq
Apr 27 16:37:14.085: INFO: Got endpoints: latency-svc-rv5bf [749.859968ms]
Apr 27 16:37:14.104: INFO: Created: latency-svc-6dxh9
Apr 27 16:37:14.143: INFO: Got endpoints: latency-svc-4vk7k [758.275712ms]
Apr 27 16:37:14.161: INFO: Created: latency-svc-jb7rg
Apr 27 16:37:14.185: INFO: Got endpoints: latency-svc-gcqpl [749.295344ms]
Apr 27 16:37:14.204: INFO: Created: latency-svc-shgb4
Apr 27 16:37:14.237: INFO: Got endpoints: latency-svc-dg84h [748.243844ms]
Apr 27 16:37:14.258: INFO: Created: latency-svc-qqrxf
Apr 27 16:37:14.287: INFO: Got endpoints: latency-svc-952dp [751.243254ms]
Apr 27 16:37:14.306: INFO: Created: latency-svc-qcbb2
Apr 27 16:37:14.335: INFO: Got endpoints: latency-svc-5lgrv [749.678603ms]
Apr 27 16:37:14.358: INFO: Created: latency-svc-6mskm
Apr 27 16:37:14.392: INFO: Got endpoints: latency-svc-xvmz2 [756.805538ms]
Apr 27 16:37:14.417: INFO: Created: latency-svc-72pjw
Apr 27 16:37:14.435: INFO: Got endpoints: latency-svc-znxk9 [748.232943ms]
Apr 27 16:37:14.454: INFO: Created: latency-svc-nsl6r
Apr 27 16:37:14.485: INFO: Got endpoints: latency-svc-sx2z7 [750.526966ms]
Apr 27 16:37:14.504: INFO: Created: latency-svc-pw27j
Apr 27 16:37:14.535: INFO: Got endpoints: latency-svc-lrr4v [750.70568ms]
Apr 27 16:37:14.554: INFO: Created: latency-svc-sj89d
Apr 27 16:37:14.585: INFO: Got endpoints: latency-svc-fk8kp [750.369469ms]
Apr 27 16:37:14.605: INFO: Created: latency-svc-q7jt6
Apr 27 16:37:14.637: INFO: Got endpoints: latency-svc-4z4qw [751.826218ms]
Apr 27 16:37:14.656: INFO: Created: latency-svc-t6frm
Apr 27 16:37:14.686: INFO: Got endpoints: latency-svc-xkw7t [748.343451ms]
Apr 27 16:37:14.705: INFO: Created: latency-svc-h8rd2
Apr 27 16:37:14.737: INFO: Got endpoints: latency-svc-qfjpk [751.570331ms]
Apr 27 16:37:14.789: INFO: Got endpoints: latency-svc-mpwgq [752.507387ms]
Apr 27 16:37:14.835: INFO: Got endpoints: latency-svc-6dxh9 [749.699013ms]
Apr 27 16:37:14.885: INFO: Got endpoints: latency-svc-jb7rg [741.904819ms]
Apr 27 16:37:14.935: INFO: Got endpoints: latency-svc-shgb4 [750.252167ms]
Apr 27 16:37:14.988: INFO: Got endpoints: latency-svc-qqrxf [750.697956ms]
Apr 27 16:37:15.037: INFO: Got endpoints: latency-svc-qcbb2 [750.015197ms]
Apr 27 16:37:15.087: INFO: Got endpoints: latency-svc-6mskm [751.349179ms]
Apr 27 16:37:15.135: INFO: Got endpoints: latency-svc-72pjw [743.562335ms]
Apr 27 16:37:15.185: INFO: Got endpoints: latency-svc-nsl6r [750.026853ms]
Apr 27 16:37:15.236: INFO: Got endpoints: latency-svc-pw27j [750.644123ms]
Apr 27 16:37:15.286: INFO: Got endpoints: latency-svc-sj89d [750.288564ms]
Apr 27 16:37:15.337: INFO: Got endpoints: latency-svc-q7jt6 [751.347931ms]
Apr 27 16:37:15.386: INFO: Got endpoints: latency-svc-t6frm [748.614056ms]
Apr 27 16:37:15.437: INFO: Got endpoints: latency-svc-h8rd2 [751.274069ms]
Apr 27 16:37:15.437: INFO: Latencies: [145.588617ms 147.215683ms 149.867917ms 150.029663ms 150.383472ms 151.34737ms 154.463823ms 156.83049ms 158.074041ms 160.263138ms 172.465181ms 172.940869ms 173.139031ms 173.468946ms 175.882902ms 176.329943ms 177.954255ms 178.78413ms 180.371131ms 181.220822ms 182.201864ms 182.632224ms 184.662641ms 187.481664ms 191.67381ms 192.546151ms 196.9005ms 203.920596ms 207.430815ms 208.671192ms 236.420695ms 239.156155ms 250.342973ms 275.944431ms 277.964622ms 288.501963ms 292.891335ms 307.438524ms 310.110944ms 322.885379ms 332.845696ms 336.112451ms 337.664851ms 350.66528ms 364.512348ms 368.418048ms 375.438584ms 407.834455ms 443.366075ms 494.743873ms 524.773294ms 570.602286ms 599.031768ms 644.551445ms 659.749719ms 661.639705ms 683.420847ms 698.217835ms 704.734615ms 705.305218ms 709.340741ms 721.329651ms 741.904819ms 742.01092ms 742.740749ms 743.272394ms 743.386825ms 743.562335ms 744.359437ms 744.607826ms 744.611531ms 744.932613ms 745.175967ms 745.183791ms 745.18523ms 746.348787ms 746.659717ms 746.822848ms 746.912444ms 747.212264ms 747.264829ms 747.390301ms 747.67484ms 747.742129ms 747.852526ms 747.890867ms 747.995381ms 748.117357ms 748.118143ms 748.156026ms 748.218501ms 748.232943ms 748.243844ms 748.260744ms 748.337359ms 748.343451ms 748.364061ms 748.410445ms 748.415853ms 748.474809ms 748.556341ms 748.590868ms 748.614056ms 748.725065ms 748.729281ms 748.740205ms 748.812707ms 748.873645ms 748.896677ms 748.925052ms 748.986316ms 749.005564ms 749.295344ms 749.405553ms 749.483103ms 749.541646ms 749.589707ms 749.621122ms 749.678603ms 749.691842ms 749.699013ms 749.701437ms 749.703408ms 749.742161ms 749.790895ms 749.80101ms 749.804001ms 749.833487ms 749.855631ms 749.858244ms 749.859968ms 749.86057ms 749.906967ms 750.015197ms 750.026853ms 750.12843ms 750.252167ms 750.266135ms 750.288564ms 750.369469ms 750.419955ms 750.438677ms 750.526966ms 750.579847ms 750.644123ms 750.697956ms 750.70568ms 750.809198ms 750.820941ms 750.84255ms 750.848083ms 750.946784ms 750.994168ms 751.128471ms 751.243254ms 751.274069ms 751.347931ms 751.349179ms 751.477349ms 751.570331ms 751.574789ms 751.588294ms 751.617863ms 751.749543ms 751.767919ms 751.826218ms 751.855409ms 751.932386ms 751.952647ms 751.990387ms 752.207721ms 752.329221ms 752.507387ms 752.791863ms 752.894612ms 752.942505ms 753.081696ms 753.42834ms 753.602594ms 754.033002ms 754.040306ms 754.588218ms 754.625035ms 754.673225ms 754.693427ms 754.953866ms 755.44013ms 755.491148ms 755.534282ms 756.226859ms 756.396672ms 756.805538ms 757.954158ms 758.275712ms 789.697687ms 789.922819ms 791.913729ms 801.000649ms 835.347439ms 843.886587ms]
Apr 27 16:37:15.437: INFO: 50 %ile: 748.556341ms
Apr 27 16:37:15.438: INFO: 90 %ile: 754.040306ms
Apr 27 16:37:15.438: INFO: 99 %ile: 835.347439ms
Apr 27 16:37:15.438: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:37:15.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-5403" for this suite.
•{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":277,"completed":131,"skipped":2126,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:37:15.473: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3610
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:37:19.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3610" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":277,"completed":132,"skipped":2141,"failed":0}
SSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:37:19.731: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-2769
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:37:19.934: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-4696abea-6af7-400b-8114-37a0e2e35b7e" in namespace "security-context-test-2769" to be "Succeeded or Failed"
Apr 27 16:37:19.946: INFO: Pod "busybox-readonly-false-4696abea-6af7-400b-8114-37a0e2e35b7e": Phase="Pending", Reason="", readiness=false. Elapsed: 11.674407ms
Apr 27 16:37:21.957: INFO: Pod "busybox-readonly-false-4696abea-6af7-400b-8114-37a0e2e35b7e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022823736s
Apr 27 16:37:23.968: INFO: Pod "busybox-readonly-false-4696abea-6af7-400b-8114-37a0e2e35b7e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033883332s
Apr 27 16:37:23.968: INFO: Pod "busybox-readonly-false-4696abea-6af7-400b-8114-37a0e2e35b7e" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:37:23.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2769" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":277,"completed":133,"skipped":2146,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:37:24.000: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5213
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-35461064-64b4-452f-aa18-992b3b4e099a
STEP: Creating a pod to test consume secrets
Apr 27 16:37:24.224: INFO: Waiting up to 5m0s for pod "pod-secrets-51938ff6-fe0e-4e66-9e7e-d83c5820f001" in namespace "secrets-5213" to be "Succeeded or Failed"
Apr 27 16:37:24.240: INFO: Pod "pod-secrets-51938ff6-fe0e-4e66-9e7e-d83c5820f001": Phase="Pending", Reason="", readiness=false. Elapsed: 15.844761ms
Apr 27 16:37:26.251: INFO: Pod "pod-secrets-51938ff6-fe0e-4e66-9e7e-d83c5820f001": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027378571s
Apr 27 16:37:28.263: INFO: Pod "pod-secrets-51938ff6-fe0e-4e66-9e7e-d83c5820f001": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039175333s
STEP: Saw pod success
Apr 27 16:37:28.263: INFO: Pod "pod-secrets-51938ff6-fe0e-4e66-9e7e-d83c5820f001" satisfied condition "Succeeded or Failed"
Apr 27 16:37:28.274: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-secrets-51938ff6-fe0e-4e66-9e7e-d83c5820f001 container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:37:28.309: INFO: Waiting for pod pod-secrets-51938ff6-fe0e-4e66-9e7e-d83c5820f001 to disappear
Apr 27 16:37:28.334: INFO: Pod pod-secrets-51938ff6-fe0e-4e66-9e7e-d83c5820f001 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:37:28.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5213" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":134,"skipped":2173,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:37:28.370: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5261
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Apr 27 16:37:38.633: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0427 16:37:38.633588    7292 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:37:38.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5261" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":277,"completed":135,"skipped":2197,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:37:38.665: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2732
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:37:40.057: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602260, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602260, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602260, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602260, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:37:42.070: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602260, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602260, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602260, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602260, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:37:45.095: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:37:45.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2732" for this suite.
STEP: Destroying namespace "webhook-2732-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":277,"completed":136,"skipped":2215,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:37:45.909: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-8925
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:37:46.113: INFO: Waiting up to 5m0s for pod "busybox-user-65534-ed5c2399-7133-40a6-9a45-d9952129794c" in namespace "security-context-test-8925" to be "Succeeded or Failed"
Apr 27 16:37:46.124: INFO: Pod "busybox-user-65534-ed5c2399-7133-40a6-9a45-d9952129794c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.123119ms
Apr 27 16:37:48.136: INFO: Pod "busybox-user-65534-ed5c2399-7133-40a6-9a45-d9952129794c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023173708s
Apr 27 16:37:50.148: INFO: Pod "busybox-user-65534-ed5c2399-7133-40a6-9a45-d9952129794c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035323631s
Apr 27 16:37:50.148: INFO: Pod "busybox-user-65534-ed5c2399-7133-40a6-9a45-d9952129794c" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:37:50.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8925" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":137,"skipped":2245,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:37:50.181: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5604
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-49e8d6d0-0a09-4886-8401-678de829beb1
STEP: Creating configMap with name cm-test-opt-upd-912621c0-526e-431a-bf36-6ee0239b46fe
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-49e8d6d0-0a09-4886-8401-678de829beb1
STEP: Updating configmap cm-test-opt-upd-912621c0-526e-431a-bf36-6ee0239b46fe
STEP: Creating configMap with name cm-test-opt-create-cc0956f9-ac90-4b1b-b00d-bab462f15596
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:37:56.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5604" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":138,"skipped":2290,"failed":0}
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:37:56.882: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2165
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:37:57.853: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602277, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602277, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602277, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602277, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:37:59.865: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602277, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602277, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602277, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602277, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:38:02.884: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:38:02.896: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2056-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:04.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2165" for this suite.
STEP: Destroying namespace "webhook-2165-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":277,"completed":139,"skipped":2294,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:04.625: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4319
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-0ccceeaa-db7a-443c-955f-f7623378fc93
STEP: Creating a pod to test consume secrets
Apr 27 16:38:05.025: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8c13dafe-cdec-4934-9bd4-c3ed059b9e87" in namespace "projected-4319" to be "Succeeded or Failed"
Apr 27 16:38:05.036: INFO: Pod "pod-projected-secrets-8c13dafe-cdec-4934-9bd4-c3ed059b9e87": Phase="Pending", Reason="", readiness=false. Elapsed: 10.584428ms
Apr 27 16:38:07.047: INFO: Pod "pod-projected-secrets-8c13dafe-cdec-4934-9bd4-c3ed059b9e87": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021395283s
Apr 27 16:38:09.058: INFO: Pod "pod-projected-secrets-8c13dafe-cdec-4934-9bd4-c3ed059b9e87": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033096245s
STEP: Saw pod success
Apr 27 16:38:09.058: INFO: Pod "pod-projected-secrets-8c13dafe-cdec-4934-9bd4-c3ed059b9e87" satisfied condition "Succeeded or Failed"
Apr 27 16:38:09.069: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-projected-secrets-8c13dafe-cdec-4934-9bd4-c3ed059b9e87 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:38:09.105: INFO: Waiting for pod pod-projected-secrets-8c13dafe-cdec-4934-9bd4-c3ed059b9e87 to disappear
Apr 27 16:38:09.115: INFO: Pod pod-projected-secrets-8c13dafe-cdec-4934-9bd4-c3ed059b9e87 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:09.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4319" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":140,"skipped":2304,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:09.148: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-467
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-abaf9e54-70be-45c1-ad12-8154a738a160
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:13.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-467" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":141,"skipped":2325,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:13.531: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4661
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-4661/configmap-test-ba37d63b-d1fd-4558-85b1-ad2278873f53
STEP: Creating a pod to test consume configMaps
Apr 27 16:38:13.746: INFO: Waiting up to 5m0s for pod "pod-configmaps-6e378e5d-26a3-4052-962f-c330d4f79090" in namespace "configmap-4661" to be "Succeeded or Failed"
Apr 27 16:38:13.757: INFO: Pod "pod-configmaps-6e378e5d-26a3-4052-962f-c330d4f79090": Phase="Pending", Reason="", readiness=false. Elapsed: 10.287723ms
Apr 27 16:38:15.769: INFO: Pod "pod-configmaps-6e378e5d-26a3-4052-962f-c330d4f79090": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022345843s
STEP: Saw pod success
Apr 27 16:38:15.769: INFO: Pod "pod-configmaps-6e378e5d-26a3-4052-962f-c330d4f79090" satisfied condition "Succeeded or Failed"
Apr 27 16:38:15.780: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-configmaps-6e378e5d-26a3-4052-962f-c330d4f79090 container env-test: <nil>
STEP: delete the pod
Apr 27 16:38:15.856: INFO: Waiting for pod pod-configmaps-6e378e5d-26a3-4052-962f-c330d4f79090 to disappear
Apr 27 16:38:15.867: INFO: Pod pod-configmaps-6e378e5d-26a3-4052-962f-c330d4f79090 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:15.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4661" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":277,"completed":142,"skipped":2340,"failed":0}
SSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:15.898: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5343
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Apr 27 16:38:16.098: INFO: Waiting up to 5m0s for pod "downward-api-eede7ccf-3ce8-42a9-9f21-8231b6dc9c3c" in namespace "downward-api-5343" to be "Succeeded or Failed"
Apr 27 16:38:16.108: INFO: Pod "downward-api-eede7ccf-3ce8-42a9-9f21-8231b6dc9c3c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.239035ms
Apr 27 16:38:18.120: INFO: Pod "downward-api-eede7ccf-3ce8-42a9-9f21-8231b6dc9c3c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022150791s
Apr 27 16:38:20.133: INFO: Pod "downward-api-eede7ccf-3ce8-42a9-9f21-8231b6dc9c3c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034597892s
STEP: Saw pod success
Apr 27 16:38:20.133: INFO: Pod "downward-api-eede7ccf-3ce8-42a9-9f21-8231b6dc9c3c" satisfied condition "Succeeded or Failed"
Apr 27 16:38:20.144: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod downward-api-eede7ccf-3ce8-42a9-9f21-8231b6dc9c3c container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:38:20.181: INFO: Waiting for pod downward-api-eede7ccf-3ce8-42a9-9f21-8231b6dc9c3c to disappear
Apr 27 16:38:20.191: INFO: Pod downward-api-eede7ccf-3ce8-42a9-9f21-8231b6dc9c3c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:20.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5343" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":277,"completed":143,"skipped":2344,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:20.229: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-883
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with configMap that has name projected-configmap-test-upd-4f9b2bf9-4f1c-457d-a719-0a9c1d28215e
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-4f9b2bf9-4f1c-457d-a719-0a9c1d28215e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:39:45.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-883" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":144,"skipped":2350,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:39:45.554: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5103
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Apr 27 16:39:45.784: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5103 /api/v1/namespaces/watch-5103/configmaps/e2e-watch-test-configmap-a 1330c8fd-d2e4-4cfb-b9ae-55c1d8f228a1 19630 0 2020-04-27 16:39:45 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:39:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:39:45.784: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5103 /api/v1/namespaces/watch-5103/configmaps/e2e-watch-test-configmap-a 1330c8fd-d2e4-4cfb-b9ae-55c1d8f228a1 19630 0 2020-04-27 16:39:45 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:39:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Apr 27 16:39:55.806: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5103 /api/v1/namespaces/watch-5103/configmaps/e2e-watch-test-configmap-a 1330c8fd-d2e4-4cfb-b9ae-55c1d8f228a1 19677 0 2020-04-27 16:39:45 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:39:55 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:39:55.807: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5103 /api/v1/namespaces/watch-5103/configmaps/e2e-watch-test-configmap-a 1330c8fd-d2e4-4cfb-b9ae-55c1d8f228a1 19677 0 2020-04-27 16:39:45 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:39:55 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Apr 27 16:40:05.830: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5103 /api/v1/namespaces/watch-5103/configmaps/e2e-watch-test-configmap-a 1330c8fd-d2e4-4cfb-b9ae-55c1d8f228a1 19717 0 2020-04-27 16:39:45 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:40:05 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:40:05.831: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5103 /api/v1/namespaces/watch-5103/configmaps/e2e-watch-test-configmap-a 1330c8fd-d2e4-4cfb-b9ae-55c1d8f228a1 19717 0 2020-04-27 16:39:45 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:40:05 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Apr 27 16:40:15.845: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5103 /api/v1/namespaces/watch-5103/configmaps/e2e-watch-test-configmap-a 1330c8fd-d2e4-4cfb-b9ae-55c1d8f228a1 19758 0 2020-04-27 16:39:45 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:40:05 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:40:15.845: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5103 /api/v1/namespaces/watch-5103/configmaps/e2e-watch-test-configmap-a 1330c8fd-d2e4-4cfb-b9ae-55c1d8f228a1 19758 0 2020-04-27 16:39:45 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:40:05 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Apr 27 16:40:25.859: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5103 /api/v1/namespaces/watch-5103/configmaps/e2e-watch-test-configmap-b 3aeb452b-8aab-47d2-b759-72744d3cab09 19818 0 2020-04-27 16:40:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-04-27 16:40:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:40:25.859: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5103 /api/v1/namespaces/watch-5103/configmaps/e2e-watch-test-configmap-b 3aeb452b-8aab-47d2-b759-72744d3cab09 19818 0 2020-04-27 16:40:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-04-27 16:40:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Apr 27 16:40:35.873: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5103 /api/v1/namespaces/watch-5103/configmaps/e2e-watch-test-configmap-b 3aeb452b-8aab-47d2-b759-72744d3cab09 19856 0 2020-04-27 16:40:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-04-27 16:40:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:40:35.873: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5103 /api/v1/namespaces/watch-5103/configmaps/e2e-watch-test-configmap-b 3aeb452b-8aab-47d2-b759-72744d3cab09 19856 0 2020-04-27 16:40:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-04-27 16:40:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:40:45.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5103" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":277,"completed":145,"skipped":2355,"failed":0}
SSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:40:45.908: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8680
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:40:46.120: INFO: The status of Pod test-webserver-003280da-5ddc-4784-bb41-dcd76a6fe53c is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:40:48.133: INFO: The status of Pod test-webserver-003280da-5ddc-4784-bb41-dcd76a6fe53c is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:40:50.132: INFO: The status of Pod test-webserver-003280da-5ddc-4784-bb41-dcd76a6fe53c is Running (Ready = false)
Apr 27 16:40:52.133: INFO: The status of Pod test-webserver-003280da-5ddc-4784-bb41-dcd76a6fe53c is Running (Ready = false)
Apr 27 16:40:54.132: INFO: The status of Pod test-webserver-003280da-5ddc-4784-bb41-dcd76a6fe53c is Running (Ready = false)
Apr 27 16:40:56.133: INFO: The status of Pod test-webserver-003280da-5ddc-4784-bb41-dcd76a6fe53c is Running (Ready = false)
Apr 27 16:40:58.132: INFO: The status of Pod test-webserver-003280da-5ddc-4784-bb41-dcd76a6fe53c is Running (Ready = false)
Apr 27 16:41:00.132: INFO: The status of Pod test-webserver-003280da-5ddc-4784-bb41-dcd76a6fe53c is Running (Ready = false)
Apr 27 16:41:02.132: INFO: The status of Pod test-webserver-003280da-5ddc-4784-bb41-dcd76a6fe53c is Running (Ready = false)
Apr 27 16:41:04.132: INFO: The status of Pod test-webserver-003280da-5ddc-4784-bb41-dcd76a6fe53c is Running (Ready = true)
Apr 27 16:41:04.143: INFO: Container started at 2020-04-27 16:40:47 +0000 UTC, pod became ready at 2020-04-27 16:41:03 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:04.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8680" for this suite.
•{"msg":"PASSED [k8s.io] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":277,"completed":146,"skipped":2360,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:04.175: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-802
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:41:04.358: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:04.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-802" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":277,"completed":147,"skipped":2373,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:04.949: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8544
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:41:05.148: INFO: Waiting up to 5m0s for pod "downwardapi-volume-338af2b7-8712-4cb0-ac94-4693599e28d8" in namespace "downward-api-8544" to be "Succeeded or Failed"
Apr 27 16:41:05.162: INFO: Pod "downwardapi-volume-338af2b7-8712-4cb0-ac94-4693599e28d8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.329904ms
Apr 27 16:41:07.173: INFO: Pod "downwardapi-volume-338af2b7-8712-4cb0-ac94-4693599e28d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025531933s
Apr 27 16:41:09.185: INFO: Pod "downwardapi-volume-338af2b7-8712-4cb0-ac94-4693599e28d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036938584s
STEP: Saw pod success
Apr 27 16:41:09.185: INFO: Pod "downwardapi-volume-338af2b7-8712-4cb0-ac94-4693599e28d8" satisfied condition "Succeeded or Failed"
Apr 27 16:41:09.195: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod downwardapi-volume-338af2b7-8712-4cb0-ac94-4693599e28d8 container client-container: <nil>
STEP: delete the pod
Apr 27 16:41:09.267: INFO: Waiting for pod downwardapi-volume-338af2b7-8712-4cb0-ac94-4693599e28d8 to disappear
Apr 27 16:41:09.277: INFO: Pod downwardapi-volume-338af2b7-8712-4cb0-ac94-4693599e28d8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:09.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8544" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":277,"completed":148,"skipped":2407,"failed":0}

------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:09.314: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9581
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Apr 27 16:41:09.592: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9581 /api/v1/namespaces/watch-9581/configmaps/e2e-watch-test-label-changed f744d12a-c5bd-4628-b57d-000d4117eef2 20040 0 2020-04-27 16:41:09 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:41:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:41:09.592: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9581 /api/v1/namespaces/watch-9581/configmaps/e2e-watch-test-label-changed f744d12a-c5bd-4628-b57d-000d4117eef2 20041 0 2020-04-27 16:41:09 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:41:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:41:09.592: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9581 /api/v1/namespaces/watch-9581/configmaps/e2e-watch-test-label-changed f744d12a-c5bd-4628-b57d-000d4117eef2 20042 0 2020-04-27 16:41:09 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:41:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Apr 27 16:41:19.670: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9581 /api/v1/namespaces/watch-9581/configmaps/e2e-watch-test-label-changed f744d12a-c5bd-4628-b57d-000d4117eef2 20099 0 2020-04-27 16:41:09 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:41:19 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:41:19.670: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9581 /api/v1/namespaces/watch-9581/configmaps/e2e-watch-test-label-changed f744d12a-c5bd-4628-b57d-000d4117eef2 20100 0 2020-04-27 16:41:09 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:41:19 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:41:19.671: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9581 /api/v1/namespaces/watch-9581/configmaps/e2e-watch-test-label-changed f744d12a-c5bd-4628-b57d-000d4117eef2 20101 0 2020-04-27 16:41:09 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:41:19 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:19.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9581" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":277,"completed":149,"skipped":2407,"failed":0}
SSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:19.703: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9103
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:41:21.967: INFO: Waiting up to 5m0s for pod "client-envvars-ffbce2c7-6190-4252-b04f-cae9a0c29f0d" in namespace "pods-9103" to be "Succeeded or Failed"
Apr 27 16:41:21.978: INFO: Pod "client-envvars-ffbce2c7-6190-4252-b04f-cae9a0c29f0d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.625263ms
Apr 27 16:41:23.990: INFO: Pod "client-envvars-ffbce2c7-6190-4252-b04f-cae9a0c29f0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02271993s
Apr 27 16:41:26.002: INFO: Pod "client-envvars-ffbce2c7-6190-4252-b04f-cae9a0c29f0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034682332s
STEP: Saw pod success
Apr 27 16:41:26.002: INFO: Pod "client-envvars-ffbce2c7-6190-4252-b04f-cae9a0c29f0d" satisfied condition "Succeeded or Failed"
Apr 27 16:41:26.012: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod client-envvars-ffbce2c7-6190-4252-b04f-cae9a0c29f0d container env3cont: <nil>
STEP: delete the pod
Apr 27 16:41:26.046: INFO: Waiting for pod client-envvars-ffbce2c7-6190-4252-b04f-cae9a0c29f0d to disappear
Apr 27 16:41:26.058: INFO: Pod client-envvars-ffbce2c7-6190-4252-b04f-cae9a0c29f0d no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:26.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9103" for this suite.
•{"msg":"PASSED [k8s.io] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":277,"completed":150,"skipped":2410,"failed":0}
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:26.091: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4223
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Apr 27 16:41:26.277: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 27 16:41:26.320: INFO: Waiting for terminating namespaces to be deleted...
Apr 27 16:41:26.340: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 before test
Apr 27 16:41:26.429: INFO: coredns-5cb857d789-6774c from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:26.429: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:41:26.429: INFO: kubernetes-dashboard-6b586c4cb4-kgfwx from kubernetes-dashboard started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:26.429: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 27 16:41:26.429: INFO: calico-typha-deploy-784665cc66-sklqn from kube-system started at 2020-04-27 15:55:18 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:26.429: INFO: 	Container calico-typha ready: true, restart count 0
Apr 27 16:41:26.429: INFO: calico-node-zzbmr from kube-system started at 2020-04-27 15:58:17 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:26.429: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:41:26.429: INFO: kube-proxy-z62w2 from kube-system started at 2020-04-27 15:54:25 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:26.430: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:41:26.430: INFO: addons-nginx-ingress-controller-6cf77756b5-8pc2l from kube-system started at 2020-04-27 15:55:07 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:26.430: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 27 16:41:26.430: INFO: vpn-shoot-6df545ddcb-7js5s from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:26.430: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 27 16:41:26.430: INFO: node-exporter-sq8cz from kube-system started at 2020-04-27 15:54:25 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:26.430: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:41:26.430: INFO: blackbox-exporter-5dc75b79b7-rlcrv from kube-system started at 2020-04-27 15:54:25 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:26.430: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 27 16:41:26.430: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-vvrz9 from kube-system started at 2020-04-27 15:55:07 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:26.430: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr 27 16:41:26.430: INFO: calico-typha-vertical-autoscaler-5b477c88cf-b245g from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:26.430: INFO: 	Container autoscaler ready: true, restart count 3
Apr 27 16:41:26.430: INFO: coredns-5cb857d789-dh4pj from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:26.430: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:41:26.430: INFO: dashboard-metrics-scraper-76c7b697bc-44kb6 from kubernetes-dashboard started at 2020-04-27 15:55:09 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:26.430: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 27 16:41:26.430: INFO: calico-node-vertical-autoscaler-74d4897db8-5nqsp from kube-system started at 2020-04-27 15:55:18 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:26.430: INFO: 	Container autoscaler ready: true, restart count 3
Apr 27 16:41:26.430: INFO: node-problem-detector-jtcdh from kube-system started at 2020-04-27 15:54:25 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:26.430: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 16:41:26.430: INFO: calico-typha-horizontal-autoscaler-6fdd5d8746-5wf5t from kube-system started at 2020-04-27 15:55:07 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:26.430: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 16:41:26.430: INFO: metrics-server-66897b5d79-tngw9 from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:26.430: INFO: 	Container metrics-server ready: true, restart count 0
Apr 27 16:41:26.430: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r before test
Apr 27 16:41:26.466: INFO: server-envvars-70330cdd-72fc-4d76-ab6f-ebe60087f5b9 from pods-9103 started at 2020-04-27 16:41:19 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:26.466: INFO: 	Container srv ready: true, restart count 0
Apr 27 16:41:26.466: INFO: node-problem-detector-pd7fh from kube-system started at 2020-04-27 15:55:26 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:26.466: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 16:41:26.466: INFO: node-exporter-l2x79 from kube-system started at 2020-04-27 15:55:26 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:26.466: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:41:26.466: INFO: calico-node-wqvt4 from kube-system started at 2020-04-27 15:58:38 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:26.466: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:41:26.466: INFO: kube-proxy-w7wxs from kube-system started at 2020-04-27 15:55:26 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:26.466: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1609bac21f43e35d], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1609bac21fbcb39b], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:27.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4223" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":277,"completed":151,"skipped":2412,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:27.582: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1396
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 27 16:41:27.785: INFO: Waiting up to 5m0s for pod "pod-afc3d3c2-8f6c-4ac7-b74d-78fd787bcc82" in namespace "emptydir-1396" to be "Succeeded or Failed"
Apr 27 16:41:27.798: INFO: Pod "pod-afc3d3c2-8f6c-4ac7-b74d-78fd787bcc82": Phase="Pending", Reason="", readiness=false. Elapsed: 13.725386ms
Apr 27 16:41:29.810: INFO: Pod "pod-afc3d3c2-8f6c-4ac7-b74d-78fd787bcc82": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025686787s
Apr 27 16:41:31.822: INFO: Pod "pod-afc3d3c2-8f6c-4ac7-b74d-78fd787bcc82": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037497433s
STEP: Saw pod success
Apr 27 16:41:31.822: INFO: Pod "pod-afc3d3c2-8f6c-4ac7-b74d-78fd787bcc82" satisfied condition "Succeeded or Failed"
Apr 27 16:41:31.833: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-afc3d3c2-8f6c-4ac7-b74d-78fd787bcc82 container test-container: <nil>
STEP: delete the pod
Apr 27 16:41:31.871: INFO: Waiting for pod pod-afc3d3c2-8f6c-4ac7-b74d-78fd787bcc82 to disappear
Apr 27 16:41:31.881: INFO: Pod pod-afc3d3c2-8f6c-4ac7-b74d-78fd787bcc82 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:31.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1396" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":152,"skipped":2424,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Lease 
  lease API should be available [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Lease
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:31.918: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename lease-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in lease-test-2771
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Lease
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:32.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-2771" for this suite.
•{"msg":"PASSED [k8s.io] Lease lease API should be available [Conformance]","total":277,"completed":153,"skipped":2487,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:32.276: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5400
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-a927d4ea-2fd2-4c23-8eec-bc18dbd19726
STEP: Creating a pod to test consume secrets
Apr 27 16:41:32.488: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4c349b6c-78bd-40b2-9e5c-409a4f6dfa8a" in namespace "projected-5400" to be "Succeeded or Failed"
Apr 27 16:41:32.498: INFO: Pod "pod-projected-secrets-4c349b6c-78bd-40b2-9e5c-409a4f6dfa8a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.48551ms
Apr 27 16:41:34.510: INFO: Pod "pod-projected-secrets-4c349b6c-78bd-40b2-9e5c-409a4f6dfa8a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022091503s
Apr 27 16:41:36.522: INFO: Pod "pod-projected-secrets-4c349b6c-78bd-40b2-9e5c-409a4f6dfa8a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033912344s
STEP: Saw pod success
Apr 27 16:41:36.522: INFO: Pod "pod-projected-secrets-4c349b6c-78bd-40b2-9e5c-409a4f6dfa8a" satisfied condition "Succeeded or Failed"
Apr 27 16:41:36.533: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-projected-secrets-4c349b6c-78bd-40b2-9e5c-409a4f6dfa8a container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:41:36.568: INFO: Waiting for pod pod-projected-secrets-4c349b6c-78bd-40b2-9e5c-409a4f6dfa8a to disappear
Apr 27 16:41:36.578: INFO: Pod pod-projected-secrets-4c349b6c-78bd-40b2-9e5c-409a4f6dfa8a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:36.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5400" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":154,"skipped":2522,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:36.611: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6124
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:40.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6124" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":155,"skipped":2549,"failed":0}
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:40.897: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1055
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Apr 27 16:41:41.082: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 27 16:41:41.125: INFO: Waiting for terminating namespaces to be deleted...
Apr 27 16:41:41.136: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 before test
Apr 27 16:41:41.174: INFO: node-exporter-sq8cz from kube-system started at 2020-04-27 15:54:25 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:41.175: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:41:41.175: INFO: blackbox-exporter-5dc75b79b7-rlcrv from kube-system started at 2020-04-27 15:54:25 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:41.175: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 27 16:41:41.175: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-vvrz9 from kube-system started at 2020-04-27 15:55:07 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:41.175: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr 27 16:41:41.175: INFO: node-problem-detector-jtcdh from kube-system started at 2020-04-27 15:54:25 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:41.175: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 16:41:41.175: INFO: calico-typha-horizontal-autoscaler-6fdd5d8746-5wf5t from kube-system started at 2020-04-27 15:55:07 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:41.175: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 16:41:41.175: INFO: metrics-server-66897b5d79-tngw9 from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:41.175: INFO: 	Container metrics-server ready: true, restart count 0
Apr 27 16:41:41.175: INFO: calico-typha-vertical-autoscaler-5b477c88cf-b245g from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:41.175: INFO: 	Container autoscaler ready: true, restart count 3
Apr 27 16:41:41.175: INFO: coredns-5cb857d789-dh4pj from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:41.175: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:41:41.175: INFO: dashboard-metrics-scraper-76c7b697bc-44kb6 from kubernetes-dashboard started at 2020-04-27 15:55:09 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:41.175: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 27 16:41:41.175: INFO: calico-node-vertical-autoscaler-74d4897db8-5nqsp from kube-system started at 2020-04-27 15:55:18 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:41.175: INFO: 	Container autoscaler ready: true, restart count 3
Apr 27 16:41:41.175: INFO: kube-proxy-z62w2 from kube-system started at 2020-04-27 15:54:25 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:41.175: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:41:41.175: INFO: addons-nginx-ingress-controller-6cf77756b5-8pc2l from kube-system started at 2020-04-27 15:55:07 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:41.175: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 27 16:41:41.175: INFO: vpn-shoot-6df545ddcb-7js5s from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:41.175: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 27 16:41:41.175: INFO: coredns-5cb857d789-6774c from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:41.175: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:41:41.175: INFO: kubernetes-dashboard-6b586c4cb4-kgfwx from kubernetes-dashboard started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:41.175: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 27 16:41:41.175: INFO: calico-typha-deploy-784665cc66-sklqn from kube-system started at 2020-04-27 15:55:18 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:41.175: INFO: 	Container calico-typha ready: true, restart count 0
Apr 27 16:41:41.175: INFO: calico-node-zzbmr from kube-system started at 2020-04-27 15:58:17 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:41.175: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:41:41.175: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r before test
Apr 27 16:41:41.212: INFO: node-exporter-l2x79 from kube-system started at 2020-04-27 15:55:26 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:41.213: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:41:41.213: INFO: calico-node-wqvt4 from kube-system started at 2020-04-27 15:58:38 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:41.213: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:41:41.213: INFO: kube-proxy-w7wxs from kube-system started at 2020-04-27 15:55:26 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:41.213: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:41:41.213: INFO: node-problem-detector-pd7fh from kube-system started at 2020-04-27 15:55:26 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:41.213: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 16:41:41.213: INFO: busybox-readonly-fsd4dae5a6-72ee-4c3c-b3f1-10c360cb62d9 from kubelet-test-6124 started at 2020-04-27 16:41:36 +0000 UTC (1 container statuses recorded)
Apr 27 16:41:41.213: INFO: 	Container busybox-readonly-fsd4dae5a6-72ee-4c3c-b3f1-10c360cb62d9 ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-5c29a588-2fcf-4eb9-be5c-47b42575bcb5 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-5c29a588-2fcf-4eb9-be5c-47b42575bcb5 off the node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r
STEP: verifying the node doesn't have the label kubernetes.io/e2e-5c29a588-2fcf-4eb9-be5c-47b42575bcb5
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:49.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1055" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":277,"completed":156,"skipped":2552,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:49.453: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2942
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2942.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2942.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2942.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2942.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 16:41:53.909: INFO: DNS probes using dns-test-eb02f60a-995c-4050-87d1-afecac6021fa succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2942.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2942.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2942.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2942.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 16:42:00.098: INFO: File wheezy_udp@dns-test-service-3.dns-2942.svc.cluster.local from pod  dns-2942/dns-test-56cca8d9-e7f2-4aa5-b06d-e6598f3d1d85 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 16:42:00.181: INFO: File jessie_udp@dns-test-service-3.dns-2942.svc.cluster.local from pod  dns-2942/dns-test-56cca8d9-e7f2-4aa5-b06d-e6598f3d1d85 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 16:42:00.181: INFO: Lookups using dns-2942/dns-test-56cca8d9-e7f2-4aa5-b06d-e6598f3d1d85 failed for: [wheezy_udp@dns-test-service-3.dns-2942.svc.cluster.local jessie_udp@dns-test-service-3.dns-2942.svc.cluster.local]

Apr 27 16:42:05.196: INFO: File wheezy_udp@dns-test-service-3.dns-2942.svc.cluster.local from pod  dns-2942/dns-test-56cca8d9-e7f2-4aa5-b06d-e6598f3d1d85 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 16:42:05.280: INFO: File jessie_udp@dns-test-service-3.dns-2942.svc.cluster.local from pod  dns-2942/dns-test-56cca8d9-e7f2-4aa5-b06d-e6598f3d1d85 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 16:42:05.280: INFO: Lookups using dns-2942/dns-test-56cca8d9-e7f2-4aa5-b06d-e6598f3d1d85 failed for: [wheezy_udp@dns-test-service-3.dns-2942.svc.cluster.local jessie_udp@dns-test-service-3.dns-2942.svc.cluster.local]

Apr 27 16:42:10.196: INFO: File wheezy_udp@dns-test-service-3.dns-2942.svc.cluster.local from pod  dns-2942/dns-test-56cca8d9-e7f2-4aa5-b06d-e6598f3d1d85 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 16:42:10.239: INFO: File jessie_udp@dns-test-service-3.dns-2942.svc.cluster.local from pod  dns-2942/dns-test-56cca8d9-e7f2-4aa5-b06d-e6598f3d1d85 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 16:42:10.239: INFO: Lookups using dns-2942/dns-test-56cca8d9-e7f2-4aa5-b06d-e6598f3d1d85 failed for: [wheezy_udp@dns-test-service-3.dns-2942.svc.cluster.local jessie_udp@dns-test-service-3.dns-2942.svc.cluster.local]

Apr 27 16:42:15.237: INFO: File wheezy_udp@dns-test-service-3.dns-2942.svc.cluster.local from pod  dns-2942/dns-test-56cca8d9-e7f2-4aa5-b06d-e6598f3d1d85 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 16:42:15.279: INFO: File jessie_udp@dns-test-service-3.dns-2942.svc.cluster.local from pod  dns-2942/dns-test-56cca8d9-e7f2-4aa5-b06d-e6598f3d1d85 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 16:42:15.279: INFO: Lookups using dns-2942/dns-test-56cca8d9-e7f2-4aa5-b06d-e6598f3d1d85 failed for: [wheezy_udp@dns-test-service-3.dns-2942.svc.cluster.local jessie_udp@dns-test-service-3.dns-2942.svc.cluster.local]

Apr 27 16:42:20.196: INFO: File wheezy_udp@dns-test-service-3.dns-2942.svc.cluster.local from pod  dns-2942/dns-test-56cca8d9-e7f2-4aa5-b06d-e6598f3d1d85 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 16:42:20.280: INFO: File jessie_udp@dns-test-service-3.dns-2942.svc.cluster.local from pod  dns-2942/dns-test-56cca8d9-e7f2-4aa5-b06d-e6598f3d1d85 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 16:42:20.280: INFO: Lookups using dns-2942/dns-test-56cca8d9-e7f2-4aa5-b06d-e6598f3d1d85 failed for: [wheezy_udp@dns-test-service-3.dns-2942.svc.cluster.local jessie_udp@dns-test-service-3.dns-2942.svc.cluster.local]

Apr 27 16:42:25.239: INFO: DNS probes using dns-test-56cca8d9-e7f2-4aa5-b06d-e6598f3d1d85 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2942.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-2942.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2942.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-2942.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 16:42:31.545: INFO: DNS probes using dns-test-b60e13c3-ad5f-40bb-aea3-a2979b6dbaa7 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:42:31.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2942" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":277,"completed":157,"skipped":2588,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:42:31.615: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3479
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-491c1236-7281-40f4-867c-faa8434151a9
STEP: Creating a pod to test consume secrets
Apr 27 16:42:31.836: INFO: Waiting up to 5m0s for pod "pod-secrets-34c3951b-8690-45f5-8f8b-84c7697a1b50" in namespace "secrets-3479" to be "Succeeded or Failed"
Apr 27 16:42:31.847: INFO: Pod "pod-secrets-34c3951b-8690-45f5-8f8b-84c7697a1b50": Phase="Pending", Reason="", readiness=false. Elapsed: 10.326773ms
Apr 27 16:42:33.859: INFO: Pod "pod-secrets-34c3951b-8690-45f5-8f8b-84c7697a1b50": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022182118s
Apr 27 16:42:35.871: INFO: Pod "pod-secrets-34c3951b-8690-45f5-8f8b-84c7697a1b50": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034202046s
STEP: Saw pod success
Apr 27 16:42:35.871: INFO: Pod "pod-secrets-34c3951b-8690-45f5-8f8b-84c7697a1b50" satisfied condition "Succeeded or Failed"
Apr 27 16:42:35.882: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-secrets-34c3951b-8690-45f5-8f8b-84c7697a1b50 container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:42:35.917: INFO: Waiting for pod pod-secrets-34c3951b-8690-45f5-8f8b-84c7697a1b50 to disappear
Apr 27 16:42:35.928: INFO: Pod pod-secrets-34c3951b-8690-45f5-8f8b-84c7697a1b50 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:42:35.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3479" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":158,"skipped":2595,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:42:35.960: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7583
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:42:36.463: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Apr 27 16:42:38.496: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602556, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602556, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602556, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602556, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:42:41.529: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:42:41.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7583" for this suite.
STEP: Destroying namespace "webhook-7583-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":277,"completed":159,"skipped":2598,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:42:41.958: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-6946
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Apr 27 16:42:42.141: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the sample API server.
Apr 27 16:42:43.000: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:42:45.013: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:42:47.024: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:42:49.013: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:42:51.012: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:42:53.012: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:42:55.013: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:42:57.013: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:42:59.013: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:43:01.014: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:43:03.012: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:43:05.012: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:43:07.012: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:43:09.013: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:43:11.012: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602589, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602562, loc:(*time.Location)(0x7b501e0)}}, Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" has successfully progressed."}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602590, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602590, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:43:14.152: INFO: Waited 1.127283604s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:43:15.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-6946" for this suite.
•{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":277,"completed":160,"skipped":2605,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:43:15.069: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1522
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:43:15.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1522" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":277,"completed":161,"skipped":2612,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:43:15.366: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-7091
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Apr 27 16:43:15.551: INFO: PodSpec: initContainers in spec.initContainers
Apr 27 16:44:03.645: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-bb0a6920-9b86-43ec-a432-b32850481b3f", GenerateName:"", Namespace:"init-container-7091", SelfLink:"/api/v1/namespaces/init-container-7091/pods/pod-init-bb0a6920-9b86-43ec-a432-b32850481b3f", UID:"9360fa43-cf07-4d2b-89b5-ce0e5394bcb5", ResourceVersion:"21185", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63723602595, loc:(*time.Location)(0x7b501e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"551472191"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.64.1.193/32", "cni.projectcalico.org/podIPs":"100.64.1.193/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc003d92b40), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003d92b60)}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc003d92b80), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003d92ba0)}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc003d92bc0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003d92be0)}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-fz9n9", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0026e1e80), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fz9n9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fz9n9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.2", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fz9n9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0060d7148), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002fee2a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0060d71c0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0060d71e0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0060d71e8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0060d71ec), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602595, loc:(*time.Location)(0x7b501e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602595, loc:(*time.Location)(0x7b501e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602595, loc:(*time.Location)(0x7b501e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602595, loc:(*time.Location)(0x7b501e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.0.5", PodIP:"100.64.1.193", PodIPs:[]v1.PodIP{v1.PodIP{IP:"100.64.1.193"}}, StartTime:(*v1.Time)(0xc003d92c00), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002fee380)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002fee3f0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://23c3b9c37280466a7a3bb2b9871ef9faaa19e7f57c862c18672fb5c2f4b68e90", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003d92c40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003d92c20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.2", ImageID:"", ContainerID:"", Started:(*bool)(0xc0060d726f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:03.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7091" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":277,"completed":162,"skipped":2681,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:03.682: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-120
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:13.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-120" for this suite.
•{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":277,"completed":163,"skipped":2690,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:13.919: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7292
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 27 16:44:14.116: INFO: Waiting up to 5m0s for pod "pod-f3ec966a-1b0b-4220-9aee-77bbd04af27d" in namespace "emptydir-7292" to be "Succeeded or Failed"
Apr 27 16:44:14.127: INFO: Pod "pod-f3ec966a-1b0b-4220-9aee-77bbd04af27d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.044103ms
Apr 27 16:44:16.140: INFO: Pod "pod-f3ec966a-1b0b-4220-9aee-77bbd04af27d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023774647s
Apr 27 16:44:18.152: INFO: Pod "pod-f3ec966a-1b0b-4220-9aee-77bbd04af27d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035350969s
STEP: Saw pod success
Apr 27 16:44:18.152: INFO: Pod "pod-f3ec966a-1b0b-4220-9aee-77bbd04af27d" satisfied condition "Succeeded or Failed"
Apr 27 16:44:18.163: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-f3ec966a-1b0b-4220-9aee-77bbd04af27d container test-container: <nil>
STEP: delete the pod
Apr 27 16:44:18.310: INFO: Waiting for pod pod-f3ec966a-1b0b-4220-9aee-77bbd04af27d to disappear
Apr 27 16:44:18.321: INFO: Pod pod-f3ec966a-1b0b-4220-9aee-77bbd04af27d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:18.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7292" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":164,"skipped":2705,"failed":0}
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:18.362: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2185
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 27 16:44:18.559: INFO: Waiting up to 5m0s for pod "pod-61822c9f-c74d-4f5e-acc2-2a7b35b05346" in namespace "emptydir-2185" to be "Succeeded or Failed"
Apr 27 16:44:18.569: INFO: Pod "pod-61822c9f-c74d-4f5e-acc2-2a7b35b05346": Phase="Pending", Reason="", readiness=false. Elapsed: 10.16669ms
Apr 27 16:44:20.580: INFO: Pod "pod-61822c9f-c74d-4f5e-acc2-2a7b35b05346": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021211006s
Apr 27 16:44:22.592: INFO: Pod "pod-61822c9f-c74d-4f5e-acc2-2a7b35b05346": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032862282s
STEP: Saw pod success
Apr 27 16:44:22.592: INFO: Pod "pod-61822c9f-c74d-4f5e-acc2-2a7b35b05346" satisfied condition "Succeeded or Failed"
Apr 27 16:44:22.602: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-61822c9f-c74d-4f5e-acc2-2a7b35b05346 container test-container: <nil>
STEP: delete the pod
Apr 27 16:44:22.634: INFO: Waiting for pod pod-61822c9f-c74d-4f5e-acc2-2a7b35b05346 to disappear
Apr 27 16:44:22.644: INFO: Pod pod-61822c9f-c74d-4f5e-acc2-2a7b35b05346 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:22.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2185" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":165,"skipped":2709,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:22.676: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2531
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:44:22.873: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d398fc21-88bf-4fea-9eb1-d0205e02ccbd" in namespace "downward-api-2531" to be "Succeeded or Failed"
Apr 27 16:44:22.883: INFO: Pod "downwardapi-volume-d398fc21-88bf-4fea-9eb1-d0205e02ccbd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.849971ms
Apr 27 16:44:24.895: INFO: Pod "downwardapi-volume-d398fc21-88bf-4fea-9eb1-d0205e02ccbd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022161231s
Apr 27 16:44:26.906: INFO: Pod "downwardapi-volume-d398fc21-88bf-4fea-9eb1-d0205e02ccbd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033633417s
STEP: Saw pod success
Apr 27 16:44:26.906: INFO: Pod "downwardapi-volume-d398fc21-88bf-4fea-9eb1-d0205e02ccbd" satisfied condition "Succeeded or Failed"
Apr 27 16:44:26.917: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod downwardapi-volume-d398fc21-88bf-4fea-9eb1-d0205e02ccbd container client-container: <nil>
STEP: delete the pod
Apr 27 16:44:26.954: INFO: Waiting for pod downwardapi-volume-d398fc21-88bf-4fea-9eb1-d0205e02ccbd to disappear
Apr 27 16:44:26.964: INFO: Pod downwardapi-volume-d398fc21-88bf-4fea-9eb1-d0205e02ccbd no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:26.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2531" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":277,"completed":166,"skipped":2740,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:26.994: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5742
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:44:27.196: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2de9e067-34c1-4c32-a9e8-31ddea7f2097" in namespace "downward-api-5742" to be "Succeeded or Failed"
Apr 27 16:44:27.206: INFO: Pod "downwardapi-volume-2de9e067-34c1-4c32-a9e8-31ddea7f2097": Phase="Pending", Reason="", readiness=false. Elapsed: 9.959173ms
Apr 27 16:44:29.217: INFO: Pod "downwardapi-volume-2de9e067-34c1-4c32-a9e8-31ddea7f2097": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020906438s
Apr 27 16:44:31.228: INFO: Pod "downwardapi-volume-2de9e067-34c1-4c32-a9e8-31ddea7f2097": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032197497s
STEP: Saw pod success
Apr 27 16:44:31.228: INFO: Pod "downwardapi-volume-2de9e067-34c1-4c32-a9e8-31ddea7f2097" satisfied condition "Succeeded or Failed"
Apr 27 16:44:31.238: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod downwardapi-volume-2de9e067-34c1-4c32-a9e8-31ddea7f2097 container client-container: <nil>
STEP: delete the pod
Apr 27 16:44:31.316: INFO: Waiting for pod downwardapi-volume-2de9e067-34c1-4c32-a9e8-31ddea7f2097 to disappear
Apr 27 16:44:31.341: INFO: Pod downwardapi-volume-2de9e067-34c1-4c32-a9e8-31ddea7f2097 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:31.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5742" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":277,"completed":167,"skipped":2741,"failed":0}

------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:31.373: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1118
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on node default medium
Apr 27 16:44:31.573: INFO: Waiting up to 5m0s for pod "pod-4ded7b6a-c165-4bf1-baae-350393768a97" in namespace "emptydir-1118" to be "Succeeded or Failed"
Apr 27 16:44:31.584: INFO: Pod "pod-4ded7b6a-c165-4bf1-baae-350393768a97": Phase="Pending", Reason="", readiness=false. Elapsed: 10.376128ms
Apr 27 16:44:33.596: INFO: Pod "pod-4ded7b6a-c165-4bf1-baae-350393768a97": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022381294s
Apr 27 16:44:35.607: INFO: Pod "pod-4ded7b6a-c165-4bf1-baae-350393768a97": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033943882s
STEP: Saw pod success
Apr 27 16:44:35.607: INFO: Pod "pod-4ded7b6a-c165-4bf1-baae-350393768a97" satisfied condition "Succeeded or Failed"
Apr 27 16:44:35.618: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-4ded7b6a-c165-4bf1-baae-350393768a97 container test-container: <nil>
STEP: delete the pod
Apr 27 16:44:35.656: INFO: Waiting for pod pod-4ded7b6a-c165-4bf1-baae-350393768a97 to disappear
Apr 27 16:44:35.666: INFO: Pod pod-4ded7b6a-c165-4bf1-baae-350393768a97 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:35.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1118" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":168,"skipped":2741,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:35.700: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3494
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:44:35.897: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d3df1569-39e7-4ab3-aed8-393728566d8e" in namespace "projected-3494" to be "Succeeded or Failed"
Apr 27 16:44:35.908: INFO: Pod "downwardapi-volume-d3df1569-39e7-4ab3-aed8-393728566d8e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.322796ms
Apr 27 16:44:37.920: INFO: Pod "downwardapi-volume-d3df1569-39e7-4ab3-aed8-393728566d8e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02213005s
Apr 27 16:44:39.931: INFO: Pod "downwardapi-volume-d3df1569-39e7-4ab3-aed8-393728566d8e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033767427s
STEP: Saw pod success
Apr 27 16:44:39.931: INFO: Pod "downwardapi-volume-d3df1569-39e7-4ab3-aed8-393728566d8e" satisfied condition "Succeeded or Failed"
Apr 27 16:44:39.942: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod downwardapi-volume-d3df1569-39e7-4ab3-aed8-393728566d8e container client-container: <nil>
STEP: delete the pod
Apr 27 16:44:39.979: INFO: Waiting for pod downwardapi-volume-d3df1569-39e7-4ab3-aed8-393728566d8e to disappear
Apr 27 16:44:39.990: INFO: Pod downwardapi-volume-d3df1569-39e7-4ab3-aed8-393728566d8e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:39.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3494" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":277,"completed":169,"skipped":2760,"failed":0}

------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:40.022: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7723
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Apr 27 16:45:20.316: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0427 16:45:20.316490    7292 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:45:20.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7723" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":277,"completed":170,"skipped":2760,"failed":0}
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:45:20.346: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4580
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Apr 27 16:45:20.530: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 27 16:45:20.564: INFO: Waiting for terminating namespaces to be deleted...
Apr 27 16:45:20.575: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 before test
Apr 27 16:45:20.666: INFO: calico-node-zzbmr from kube-system started at 2020-04-27 15:58:17 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.666: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:45:20.666: INFO: simpletest.rc-4z29v from gc-7723 started at 2020-04-27 16:44:40 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.666: INFO: 	Container nginx ready: true, restart count 0
Apr 27 16:45:20.666: INFO: kube-proxy-z62w2 from kube-system started at 2020-04-27 15:54:25 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.666: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:45:20.666: INFO: addons-nginx-ingress-controller-6cf77756b5-8pc2l from kube-system started at 2020-04-27 15:55:07 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.666: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 27 16:45:20.666: INFO: vpn-shoot-6df545ddcb-7js5s from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.666: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 27 16:45:20.666: INFO: coredns-5cb857d789-6774c from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.666: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:45:20.666: INFO: kubernetes-dashboard-6b586c4cb4-kgfwx from kubernetes-dashboard started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.666: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 27 16:45:20.666: INFO: calico-typha-deploy-784665cc66-sklqn from kube-system started at 2020-04-27 15:55:18 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.666: INFO: 	Container calico-typha ready: true, restart count 0
Apr 27 16:45:20.666: INFO: node-exporter-sq8cz from kube-system started at 2020-04-27 15:54:25 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.666: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:45:20.666: INFO: blackbox-exporter-5dc75b79b7-rlcrv from kube-system started at 2020-04-27 15:54:25 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.666: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 27 16:45:20.666: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-vvrz9 from kube-system started at 2020-04-27 15:55:07 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.666: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr 27 16:45:20.666: INFO: calico-node-vertical-autoscaler-74d4897db8-5nqsp from kube-system started at 2020-04-27 15:55:18 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.666: INFO: 	Container autoscaler ready: true, restart count 3
Apr 27 16:45:20.666: INFO: node-problem-detector-jtcdh from kube-system started at 2020-04-27 15:54:25 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.666: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 16:45:20.666: INFO: calico-typha-horizontal-autoscaler-6fdd5d8746-5wf5t from kube-system started at 2020-04-27 15:55:07 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.666: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 16:45:20.666: INFO: metrics-server-66897b5d79-tngw9 from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.666: INFO: 	Container metrics-server ready: true, restart count 0
Apr 27 16:45:20.666: INFO: calico-typha-vertical-autoscaler-5b477c88cf-b245g from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.666: INFO: 	Container autoscaler ready: true, restart count 3
Apr 27 16:45:20.666: INFO: coredns-5cb857d789-dh4pj from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.666: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:45:20.666: INFO: dashboard-metrics-scraper-76c7b697bc-44kb6 from kubernetes-dashboard started at 2020-04-27 15:55:09 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.666: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 27 16:45:20.666: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r before test
Apr 27 16:45:20.716: INFO: simpletest.rc-nx8cb from gc-7723 started at 2020-04-27 16:44:40 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.716: INFO: 	Container nginx ready: true, restart count 0
Apr 27 16:45:20.716: INFO: simpletest.rc-qs68m from gc-7723 started at 2020-04-27 16:44:40 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.716: INFO: 	Container nginx ready: true, restart count 0
Apr 27 16:45:20.716: INFO: simpletest.rc-l4hxs from gc-7723 started at 2020-04-27 16:44:40 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.716: INFO: 	Container nginx ready: true, restart count 0
Apr 27 16:45:20.716: INFO: node-exporter-l2x79 from kube-system started at 2020-04-27 15:55:26 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.716: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:45:20.716: INFO: simpletest.rc-f2zn6 from gc-7723 started at 2020-04-27 16:44:40 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.716: INFO: 	Container nginx ready: true, restart count 0
Apr 27 16:45:20.716: INFO: simpletest.rc-4qqms from gc-7723 started at 2020-04-27 16:44:40 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.716: INFO: 	Container nginx ready: true, restart count 0
Apr 27 16:45:20.716: INFO: calico-node-wqvt4 from kube-system started at 2020-04-27 15:58:38 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.716: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:45:20.716: INFO: kube-proxy-w7wxs from kube-system started at 2020-04-27 15:55:26 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.716: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:45:20.716: INFO: simpletest.rc-9c8k4 from gc-7723 started at 2020-04-27 16:44:40 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.716: INFO: 	Container nginx ready: true, restart count 0
Apr 27 16:45:20.716: INFO: simpletest.rc-p9vsr from gc-7723 started at 2020-04-27 16:44:40 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.716: INFO: 	Container nginx ready: true, restart count 0
Apr 27 16:45:20.716: INFO: simpletest.rc-76vp7 from gc-7723 started at 2020-04-27 16:44:40 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.716: INFO: 	Container nginx ready: true, restart count 0
Apr 27 16:45:20.716: INFO: node-problem-detector-pd7fh from kube-system started at 2020-04-27 15:55:26 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.716: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 16:45:20.716: INFO: simpletest.rc-lbjgl from gc-7723 started at 2020-04-27 16:44:40 +0000 UTC (1 container statuses recorded)
Apr 27 16:45:20.716: INFO: 	Container nginx ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-3fe7bc44-05a3-404a-be7b-1226b63fd2cd 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-3fe7bc44-05a3-404a-be7b-1226b63fd2cd off the node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r
STEP: verifying the node doesn't have the label kubernetes.io/e2e-3fe7bc44-05a3-404a-be7b-1226b63fd2cd
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:45:36.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4580" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]","total":277,"completed":171,"skipped":2762,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:45:36.997: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8011
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:45:37.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8011" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":277,"completed":172,"skipped":2765,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:45:37.233: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-7864
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2295
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-4551
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:45:43.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7864" for this suite.
STEP: Destroying namespace "nsdeletetest-2295" for this suite.
Apr 27 16:45:43.872: INFO: Namespace nsdeletetest-2295 was already deleted
STEP: Destroying namespace "nsdeletetest-4551" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":277,"completed":173,"skipped":2774,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:45:43.884: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-6695
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:45:44.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-6695" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":277,"completed":174,"skipped":2799,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:45:44.122: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-413
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-413
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-413
STEP: Creating statefulset with conflicting port in namespace statefulset-413
STEP: Waiting until pod test-pod will start running in namespace statefulset-413
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-413
Apr 27 16:45:48.406: INFO: Observed stateful pod in namespace: statefulset-413, name: ss-0, uid: 1647bc45-206e-497e-84c4-404615061198, status phase: Pending. Waiting for statefulset controller to delete.
Apr 27 16:45:48.407: INFO: Observed stateful pod in namespace: statefulset-413, name: ss-0, uid: 1647bc45-206e-497e-84c4-404615061198, status phase: Failed. Waiting for statefulset controller to delete.
Apr 27 16:45:48.494: INFO: Observed stateful pod in namespace: statefulset-413, name: ss-0, uid: 1647bc45-206e-497e-84c4-404615061198, status phase: Failed. Waiting for statefulset controller to delete.
Apr 27 16:45:48.500: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-413
STEP: Removing pod with conflicting port in namespace statefulset-413
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-413 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 16:45:52.547: INFO: Deleting all statefulset in ns statefulset-413
Apr 27 16:45:52.557: INFO: Scaling statefulset ss to 0
Apr 27 16:46:02.607: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:46:02.618: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:02.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-413" for this suite.
•{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":277,"completed":175,"skipped":2816,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:02.685: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3594
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Apr 27 16:46:07.465: INFO: Successfully updated pod "labelsupdate9b671501-7a8e-4cc2-a883-d42b3df74566"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:09.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3594" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":277,"completed":176,"skipped":2837,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:09.533: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5505
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Apr 27 16:46:09.734: INFO: Created pod &Pod{ObjectMeta:{dns-5505  dns-5505 /api/v1/namespaces/dns-5505/pods/dns-5505 efadcfc6-9e12-4515-9c56-e40e9fa9cc32 22277 0 2020-04-27 16:46:09 +0000 UTC <nil> <nil> map[] map[kubernetes.io/psp:e2e-test-privileged-psp] [] []  [{e2e.test Update v1 2020-04-27 16:46:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 67 111 110 102 105 103 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 115 101 114 118 101 114 115 34 58 123 125 44 34 102 58 115 101 97 114 99 104 101 115 34 58 123 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rrj22,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rrj22,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rrj22,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:46:09.745: INFO: The status of Pod dns-5505 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:46:11.757: INFO: The status of Pod dns-5505 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:46:13.757: INFO: The status of Pod dns-5505 is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
Apr 27 16:46:13.757: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-5505 PodName:dns-5505 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:46:13.757: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Verifying customized DNS server is configured on pod...
Apr 27 16:46:14.117: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-5505 PodName:dns-5505 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:46:14.117: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:46:14.572: INFO: Deleting pod dns-5505...
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:14.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5505" for this suite.
•{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":277,"completed":177,"skipped":2849,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:14.621: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6262
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 27 16:46:14.846: INFO: Waiting up to 5m0s for pod "pod-27c54000-08a4-4973-a4c1-028b72b310fd" in namespace "emptydir-6262" to be "Succeeded or Failed"
Apr 27 16:46:14.856: INFO: Pod "pod-27c54000-08a4-4973-a4c1-028b72b310fd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.025367ms
Apr 27 16:46:16.868: INFO: Pod "pod-27c54000-08a4-4973-a4c1-028b72b310fd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022322254s
Apr 27 16:46:18.880: INFO: Pod "pod-27c54000-08a4-4973-a4c1-028b72b310fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033979488s
STEP: Saw pod success
Apr 27 16:46:18.880: INFO: Pod "pod-27c54000-08a4-4973-a4c1-028b72b310fd" satisfied condition "Succeeded or Failed"
Apr 27 16:46:18.890: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-27c54000-08a4-4973-a4c1-028b72b310fd container test-container: <nil>
STEP: delete the pod
Apr 27 16:46:18.925: INFO: Waiting for pod pod-27c54000-08a4-4973-a4c1-028b72b310fd to disappear
Apr 27 16:46:18.935: INFO: Pod pod-27c54000-08a4-4973-a4c1-028b72b310fd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:18.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6262" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":178,"skipped":2882,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:18.968: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-9228
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Apr 27 16:46:19.153: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:46:22.276: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:36.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9228" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":277,"completed":179,"skipped":2884,"failed":0}
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:36.710: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7844
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-bfe78aee-7c6e-4a85-87e9-43eb77d770f5 in namespace container-probe-7844
Apr 27 16:46:40.928: INFO: Started pod busybox-bfe78aee-7c6e-4a85-87e9-43eb77d770f5 in namespace container-probe-7844
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 16:46:40.939: INFO: Initial restart count of pod busybox-bfe78aee-7c6e-4a85-87e9-43eb77d770f5 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:50:42.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7844" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":277,"completed":180,"skipped":2887,"failed":0}
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:50:42.429: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-7305
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:50:42.742: INFO: (0) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 105.97648ms)
Apr 27 16:50:42.756: INFO: (1) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 13.876064ms)
Apr 27 16:50:42.771: INFO: (2) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 14.242639ms)
Apr 27 16:50:42.785: INFO: (3) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 13.840387ms)
Apr 27 16:50:42.797: INFO: (4) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 12.618179ms)
Apr 27 16:50:42.810: INFO: (5) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 12.651875ms)
Apr 27 16:50:42.823: INFO: (6) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 12.668426ms)
Apr 27 16:50:42.836: INFO: (7) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 12.626742ms)
Apr 27 16:50:42.848: INFO: (8) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 12.49237ms)
Apr 27 16:50:42.861: INFO: (9) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 12.759263ms)
Apr 27 16:50:42.874: INFO: (10) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 12.514746ms)
Apr 27 16:50:42.886: INFO: (11) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 12.260146ms)
Apr 27 16:50:42.898: INFO: (12) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 12.488497ms)
Apr 27 16:50:42.911: INFO: (13) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 12.036499ms)
Apr 27 16:50:42.924: INFO: (14) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 12.827801ms)
Apr 27 16:50:42.936: INFO: (15) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 12.798716ms)
Apr 27 16:50:42.949: INFO: (16) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 12.551381ms)
Apr 27 16:50:42.961: INFO: (17) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 12.374461ms)
Apr 27 16:50:42.974: INFO: (18) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 12.164304ms)
Apr 27 16:50:42.986: INFO: (19) /api/v1/nodes/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 12.327773ms)
[AfterEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:50:42.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7305" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node using proxy subresource  [Conformance]","total":277,"completed":181,"skipped":2891,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:50:43.010: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6956
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:50:43.210: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f6abb3b1-15fc-4ae7-a03a-ba1d6507da24" in namespace "projected-6956" to be "Succeeded or Failed"
Apr 27 16:50:43.223: INFO: Pod "downwardapi-volume-f6abb3b1-15fc-4ae7-a03a-ba1d6507da24": Phase="Pending", Reason="", readiness=false. Elapsed: 13.341212ms
Apr 27 16:50:45.236: INFO: Pod "downwardapi-volume-f6abb3b1-15fc-4ae7-a03a-ba1d6507da24": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025494699s
Apr 27 16:50:47.247: INFO: Pod "downwardapi-volume-f6abb3b1-15fc-4ae7-a03a-ba1d6507da24": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036975568s
STEP: Saw pod success
Apr 27 16:50:47.247: INFO: Pod "downwardapi-volume-f6abb3b1-15fc-4ae7-a03a-ba1d6507da24" satisfied condition "Succeeded or Failed"
Apr 27 16:50:47.258: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod downwardapi-volume-f6abb3b1-15fc-4ae7-a03a-ba1d6507da24 container client-container: <nil>
STEP: delete the pod
Apr 27 16:50:47.295: INFO: Waiting for pod downwardapi-volume-f6abb3b1-15fc-4ae7-a03a-ba1d6507da24 to disappear
Apr 27 16:50:47.307: INFO: Pod downwardapi-volume-f6abb3b1-15fc-4ae7-a03a-ba1d6507da24 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:50:47.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6956" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":277,"completed":182,"skipped":2925,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:50:47.351: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2806
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Apr 27 16:50:47.534: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:51:07.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2806" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":277,"completed":183,"skipped":2968,"failed":0}

------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:51:07.509: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8828
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-425a5a9a-5958-4da7-a068-a4d54e8fe692 in namespace container-probe-8828
Apr 27 16:51:11.748: INFO: Started pod liveness-425a5a9a-5958-4da7-a068-a4d54e8fe692 in namespace container-probe-8828
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 16:51:11.759: INFO: Initial restart count of pod liveness-425a5a9a-5958-4da7-a068-a4d54e8fe692 is 0
Apr 27 16:51:35.908: INFO: Restart count of pod container-probe-8828/liveness-425a5a9a-5958-4da7-a068-a4d54e8fe692 is now 1 (24.148896853s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:51:35.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8828" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":277,"completed":184,"skipped":2968,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:51:35.954: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-3766
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating replication controller my-hostname-basic-f4e81670-e2ca-4720-983d-b4a9d8a8b88f
Apr 27 16:51:36.174: INFO: Pod name my-hostname-basic-f4e81670-e2ca-4720-983d-b4a9d8a8b88f: Found 1 pods out of 1
Apr 27 16:51:36.174: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-f4e81670-e2ca-4720-983d-b4a9d8a8b88f" are running
Apr 27 16:51:40.196: INFO: Pod "my-hostname-basic-f4e81670-e2ca-4720-983d-b4a9d8a8b88f-bplxc" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 16:51:36 +0000 UTC Reason: Message:}])
Apr 27 16:51:40.196: INFO: Trying to dial the pod
Apr 27 16:51:45.316: INFO: Controller my-hostname-basic-f4e81670-e2ca-4720-983d-b4a9d8a8b88f: Got expected result from replica 1 [my-hostname-basic-f4e81670-e2ca-4720-983d-b4a9d8a8b88f-bplxc]: "my-hostname-basic-f4e81670-e2ca-4720-983d-b4a9d8a8b88f-bplxc", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:51:45.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3766" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":277,"completed":185,"skipped":2990,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:51:45.363: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6969
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 27 16:51:48.623: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:51:48.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6969" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":277,"completed":186,"skipped":3017,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:51:48.689: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5961
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:51:49.305: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603109, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603109, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603109, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603109, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:51:51.316: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603109, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603109, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603109, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603109, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:51:54.338: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:51:54.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5961" for this suite.
STEP: Destroying namespace "webhook-5961-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":277,"completed":187,"skipped":3037,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:51:54.662: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9975
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-d3cb34f6-0da0-4739-ad1b-e09a95280ac4
STEP: Creating a pod to test consume secrets
Apr 27 16:51:54.870: INFO: Waiting up to 5m0s for pod "pod-secrets-78d45663-891d-485f-a4bf-a98735d805b2" in namespace "secrets-9975" to be "Succeeded or Failed"
Apr 27 16:51:54.880: INFO: Pod "pod-secrets-78d45663-891d-485f-a4bf-a98735d805b2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.881993ms
Apr 27 16:51:56.893: INFO: Pod "pod-secrets-78d45663-891d-485f-a4bf-a98735d805b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023007897s
Apr 27 16:51:58.905: INFO: Pod "pod-secrets-78d45663-891d-485f-a4bf-a98735d805b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03486554s
STEP: Saw pod success
Apr 27 16:51:58.905: INFO: Pod "pod-secrets-78d45663-891d-485f-a4bf-a98735d805b2" satisfied condition "Succeeded or Failed"
Apr 27 16:51:58.917: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-secrets-78d45663-891d-485f-a4bf-a98735d805b2 container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:51:58.955: INFO: Waiting for pod pod-secrets-78d45663-891d-485f-a4bf-a98735d805b2 to disappear
Apr 27 16:51:58.970: INFO: Pod pod-secrets-78d45663-891d-485f-a4bf-a98735d805b2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:51:58.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9975" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":188,"skipped":3058,"failed":0}
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:51:59.004: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4667
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating api versions
Apr 27 16:51:59.195: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config api-versions'
Apr 27 16:51:59.355: INFO: stderr: ""
Apr 27 16:51:59.355: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncert.gardener.cloud/v1alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1beta1\ndns.gardener.cloud/v1alpha1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:51:59.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4667" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":277,"completed":189,"skipped":3066,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:51:59.390: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-604
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:52:59.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-604" for this suite.
•{"msg":"PASSED [k8s.io] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":277,"completed":190,"skipped":3078,"failed":0}
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:52:59.631: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6939
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Apr 27 16:52:59.818: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:03.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6939" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":277,"completed":191,"skipped":3088,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:03.753: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1383
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-620286b8-0930-48d2-825d-ca8f27fe8a3d
STEP: Creating configMap with name cm-test-opt-upd-37fa2db4-f863-420f-be13-57f1fa56f030
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-620286b8-0930-48d2-825d-ca8f27fe8a3d
STEP: Updating configmap cm-test-opt-upd-37fa2db4-f863-420f-be13-57f1fa56f030
STEP: Creating configMap with name cm-test-opt-create-25880b3f-18a5-4092-a7ce-fec340521f0f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:10.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1383" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":192,"skipped":3101,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:10.421: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8476
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 27 16:53:18.715: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:53:18.726: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 16:53:20.726: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:53:20.737: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 16:53:22.726: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:53:22.738: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 16:53:24.726: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:53:24.738: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 16:53:26.726: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:53:26.738: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 16:53:28.726: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:53:28.737: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:28.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8476" for this suite.
•{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":277,"completed":193,"skipped":3183,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:28.786: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4702
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:53:29.699: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603209, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603209, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603209, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603209, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:53:31.712: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603209, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603209, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603209, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603209, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:53:34.730: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:34.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4702" for this suite.
STEP: Destroying namespace "webhook-4702-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":277,"completed":194,"skipped":3189,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:34.995: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4991
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-7246
STEP: Creating secret with name secret-test-2293dc61-c3ea-431a-b0ff-1e1c647328a5
STEP: Creating a pod to test consume secrets
Apr 27 16:53:35.465: INFO: Waiting up to 5m0s for pod "pod-secrets-e6213e04-f224-4092-b454-418f0a1f39a3" in namespace "secrets-4991" to be "Succeeded or Failed"
Apr 27 16:53:35.475: INFO: Pod "pod-secrets-e6213e04-f224-4092-b454-418f0a1f39a3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.227646ms
Apr 27 16:53:37.487: INFO: Pod "pod-secrets-e6213e04-f224-4092-b454-418f0a1f39a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022264207s
Apr 27 16:53:39.500: INFO: Pod "pod-secrets-e6213e04-f224-4092-b454-418f0a1f39a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035587899s
STEP: Saw pod success
Apr 27 16:53:39.500: INFO: Pod "pod-secrets-e6213e04-f224-4092-b454-418f0a1f39a3" satisfied condition "Succeeded or Failed"
Apr 27 16:53:39.512: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-secrets-e6213e04-f224-4092-b454-418f0a1f39a3 container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:53:39.550: INFO: Waiting for pod pod-secrets-e6213e04-f224-4092-b454-418f0a1f39a3 to disappear
Apr 27 16:53:39.560: INFO: Pod pod-secrets-e6213e04-f224-4092-b454-418f0a1f39a3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:39.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4991" for this suite.
STEP: Destroying namespace "secret-namespace-7246" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":277,"completed":195,"skipped":3223,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:39.604: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5829
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Apr 27 16:53:43.860: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-5829 PodName:pod-sharedvolume-7cee469a-e4ba-4257-b90b-17981daec8ec ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:53:43.860: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:53:44.220: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:44.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5829" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":277,"completed":196,"skipped":3233,"failed":0}
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:44.256: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6548
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Apr 27 16:53:44.441: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:48.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6548" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":277,"completed":197,"skipped":3239,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:48.548: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6541
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-6541
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 27 16:53:48.730: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 27 16:53:48.805: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:53:50.817: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:53:52.819: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:53:54.818: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:53:56.819: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:53:58.818: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:54:00.818: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:54:02.817: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:54:04.817: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:54:06.818: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:54:08.817: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:54:10.819: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr 27 16:54:10.840: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Apr 27 16:54:14.940: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.0.38:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6541 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:54:14.940: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:54:15.368: INFO: Found all expected endpoints: [netserver-0]
Apr 27 16:54:15.379: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.1.239:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6541 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:54:15.379: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:54:15.776: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:54:15.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6541" for this suite.
•{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":198,"skipped":3252,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:54:15.809: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-603
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 27 16:54:16.007: INFO: Waiting up to 5m0s for pod "pod-4825950d-68b3-42ce-b971-c6f0b83d4943" in namespace "emptydir-603" to be "Succeeded or Failed"
Apr 27 16:54:16.021: INFO: Pod "pod-4825950d-68b3-42ce-b971-c6f0b83d4943": Phase="Pending", Reason="", readiness=false. Elapsed: 13.550639ms
Apr 27 16:54:18.033: INFO: Pod "pod-4825950d-68b3-42ce-b971-c6f0b83d4943": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025269679s
Apr 27 16:54:20.048: INFO: Pod "pod-4825950d-68b3-42ce-b971-c6f0b83d4943": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040179839s
STEP: Saw pod success
Apr 27 16:54:20.048: INFO: Pod "pod-4825950d-68b3-42ce-b971-c6f0b83d4943" satisfied condition "Succeeded or Failed"
Apr 27 16:54:20.058: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-4825950d-68b3-42ce-b971-c6f0b83d4943 container test-container: <nil>
STEP: delete the pod
Apr 27 16:54:20.115: INFO: Waiting for pod pod-4825950d-68b3-42ce-b971-c6f0b83d4943 to disappear
Apr 27 16:54:20.125: INFO: Pod pod-4825950d-68b3-42ce-b971-c6f0b83d4943 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:54:20.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-603" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":199,"skipped":3261,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:54:20.160: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-455
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a Namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nspatchtest-a5624086-5288-4408-8135-dc209787a7f0-4857
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:54:20.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-455" for this suite.
STEP: Destroying namespace "nspatchtest-a5624086-5288-4408-8135-dc209787a7f0-4857" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":277,"completed":200,"skipped":3269,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:54:20.662: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5809
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-t9fj
STEP: Creating a pod to test atomic-volume-subpath
Apr 27 16:54:20.883: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-t9fj" in namespace "subpath-5809" to be "Succeeded or Failed"
Apr 27 16:54:20.893: INFO: Pod "pod-subpath-test-configmap-t9fj": Phase="Pending", Reason="", readiness=false. Elapsed: 10.226267ms
Apr 27 16:54:22.904: INFO: Pod "pod-subpath-test-configmap-t9fj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021113114s
Apr 27 16:54:24.915: INFO: Pod "pod-subpath-test-configmap-t9fj": Phase="Running", Reason="", readiness=true. Elapsed: 4.031953426s
Apr 27 16:54:26.926: INFO: Pod "pod-subpath-test-configmap-t9fj": Phase="Running", Reason="", readiness=true. Elapsed: 6.043306902s
Apr 27 16:54:28.938: INFO: Pod "pod-subpath-test-configmap-t9fj": Phase="Running", Reason="", readiness=true. Elapsed: 8.054787048s
Apr 27 16:54:30.950: INFO: Pod "pod-subpath-test-configmap-t9fj": Phase="Running", Reason="", readiness=true. Elapsed: 10.066847177s
Apr 27 16:54:32.961: INFO: Pod "pod-subpath-test-configmap-t9fj": Phase="Running", Reason="", readiness=true. Elapsed: 12.078249303s
Apr 27 16:54:34.973: INFO: Pod "pod-subpath-test-configmap-t9fj": Phase="Running", Reason="", readiness=true. Elapsed: 14.089964506s
Apr 27 16:54:36.985: INFO: Pod "pod-subpath-test-configmap-t9fj": Phase="Running", Reason="", readiness=true. Elapsed: 16.101890463s
Apr 27 16:54:38.997: INFO: Pod "pod-subpath-test-configmap-t9fj": Phase="Running", Reason="", readiness=true. Elapsed: 18.113994714s
Apr 27 16:54:41.009: INFO: Pod "pod-subpath-test-configmap-t9fj": Phase="Running", Reason="", readiness=true. Elapsed: 20.125564417s
Apr 27 16:54:43.020: INFO: Pod "pod-subpath-test-configmap-t9fj": Phase="Running", Reason="", readiness=true. Elapsed: 22.137111847s
Apr 27 16:54:45.032: INFO: Pod "pod-subpath-test-configmap-t9fj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.148877223s
STEP: Saw pod success
Apr 27 16:54:45.032: INFO: Pod "pod-subpath-test-configmap-t9fj" satisfied condition "Succeeded or Failed"
Apr 27 16:54:45.043: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-subpath-test-configmap-t9fj container test-container-subpath-configmap-t9fj: <nil>
STEP: delete the pod
Apr 27 16:54:45.079: INFO: Waiting for pod pod-subpath-test-configmap-t9fj to disappear
Apr 27 16:54:45.090: INFO: Pod pod-subpath-test-configmap-t9fj no longer exists
STEP: Deleting pod pod-subpath-test-configmap-t9fj
Apr 27 16:54:45.090: INFO: Deleting pod "pod-subpath-test-configmap-t9fj" in namespace "subpath-5809"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:54:45.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5809" for this suite.
•{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [LinuxOnly] [Conformance]","total":277,"completed":201,"skipped":3308,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:54:45.136: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6781
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-8361e2b2-6000-4f2b-a924-6e2e7f6b8322
STEP: Creating a pod to test consume secrets
Apr 27 16:54:45.359: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fc19407c-c18d-4949-b8ac-e3eee1cf066f" in namespace "projected-6781" to be "Succeeded or Failed"
Apr 27 16:54:45.370: INFO: Pod "pod-projected-secrets-fc19407c-c18d-4949-b8ac-e3eee1cf066f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.367077ms
Apr 27 16:54:47.382: INFO: Pod "pod-projected-secrets-fc19407c-c18d-4949-b8ac-e3eee1cf066f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022533125s
Apr 27 16:54:49.394: INFO: Pod "pod-projected-secrets-fc19407c-c18d-4949-b8ac-e3eee1cf066f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034566465s
STEP: Saw pod success
Apr 27 16:54:49.394: INFO: Pod "pod-projected-secrets-fc19407c-c18d-4949-b8ac-e3eee1cf066f" satisfied condition "Succeeded or Failed"
Apr 27 16:54:49.405: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-projected-secrets-fc19407c-c18d-4949-b8ac-e3eee1cf066f container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:54:49.438: INFO: Waiting for pod pod-projected-secrets-fc19407c-c18d-4949-b8ac-e3eee1cf066f to disappear
Apr 27 16:54:49.448: INFO: Pod pod-projected-secrets-fc19407c-c18d-4949-b8ac-e3eee1cf066f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:54:49.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6781" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":202,"skipped":3354,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:54:49.480: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2302
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name secret-emptykey-test-b3c6713e-8aa5-47b4-adc3-81a1d357e205
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:54:49.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2302" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should fail to create secret due to empty secret key [Conformance]","total":277,"completed":203,"skipped":3376,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:54:49.704: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5704
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-2effe2fa-6998-4f32-b759-f60daf7432c8
STEP: Creating a pod to test consume secrets
Apr 27 16:54:49.921: INFO: Waiting up to 5m0s for pod "pod-secrets-ebe26662-8c4f-4aa2-a81f-ba0099da62ea" in namespace "secrets-5704" to be "Succeeded or Failed"
Apr 27 16:54:49.931: INFO: Pod "pod-secrets-ebe26662-8c4f-4aa2-a81f-ba0099da62ea": Phase="Pending", Reason="", readiness=false. Elapsed: 10.255593ms
Apr 27 16:54:51.943: INFO: Pod "pod-secrets-ebe26662-8c4f-4aa2-a81f-ba0099da62ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021749471s
STEP: Saw pod success
Apr 27 16:54:51.943: INFO: Pod "pod-secrets-ebe26662-8c4f-4aa2-a81f-ba0099da62ea" satisfied condition "Succeeded or Failed"
Apr 27 16:54:51.953: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-secrets-ebe26662-8c4f-4aa2-a81f-ba0099da62ea container secret-env-test: <nil>
STEP: delete the pod
Apr 27 16:54:51.988: INFO: Waiting for pod pod-secrets-ebe26662-8c4f-4aa2-a81f-ba0099da62ea to disappear
Apr 27 16:54:51.998: INFO: Pod pod-secrets-ebe26662-8c4f-4aa2-a81f-ba0099da62ea no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:54:51.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5704" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":277,"completed":204,"skipped":3381,"failed":0}
SSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:54:52.029: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8229
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 27 16:54:56.793: INFO: Successfully updated pod "pod-update-activedeadlineseconds-986cd93a-6332-4244-bad5-da20b754bffa"
Apr 27 16:54:56.793: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-986cd93a-6332-4244-bad5-da20b754bffa" in namespace "pods-8229" to be "terminated due to deadline exceeded"
Apr 27 16:54:56.804: INFO: Pod "pod-update-activedeadlineseconds-986cd93a-6332-4244-bad5-da20b754bffa": Phase="Running", Reason="", readiness=true. Elapsed: 10.548388ms
Apr 27 16:54:58.815: INFO: Pod "pod-update-activedeadlineseconds-986cd93a-6332-4244-bad5-da20b754bffa": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.022188617s
Apr 27 16:54:58.816: INFO: Pod "pod-update-activedeadlineseconds-986cd93a-6332-4244-bad5-da20b754bffa" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:54:58.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8229" for this suite.
•{"msg":"PASSED [k8s.io] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":277,"completed":205,"skipped":3385,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:54:58.848: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9850
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:54:59.625: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603299, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603299, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603299, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603299, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:55:01.636: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603299, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603299, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603299, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603299, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:55:04.658: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:55:04.670: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7241-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:55:06.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9850" for this suite.
STEP: Destroying namespace "webhook-9850-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":277,"completed":206,"skipped":3422,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:55:06.425: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7740
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating cluster-info
Apr 27 16:55:06.608: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config cluster-info'
Apr 27 16:55:07.170: INFO: stderr: ""
Apr 27 16:55:07.170: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:55:07.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7740" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]","total":277,"completed":207,"skipped":3436,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:55:07.202: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-4577
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2286
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1189
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:55:22.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4577" for this suite.
STEP: Destroying namespace "nsdeletetest-2286" for this suite.
Apr 27 16:55:22.858: INFO: Namespace nsdeletetest-2286 was already deleted
STEP: Destroying namespace "nsdeletetest-1189" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":277,"completed":208,"skipped":3442,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:55:22.870: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2616
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-2616
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating stateful set ss in namespace statefulset-2616
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2616
Apr 27 16:55:23.100: INFO: Found 0 stateful pods, waiting for 1
Apr 27 16:55:33.117: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Apr 27 16:55:33.129: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:55:33.651: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:55:33.651: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:55:33.651: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:55:33.662: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 27 16:55:43.675: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:55:43.675: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:55:43.719: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Apr 27 16:55:43.719: INFO: ss-0  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:23 +0000 UTC  }]
Apr 27 16:55:43.719: INFO: ss-1                                                  Pending         []
Apr 27 16:55:43.719: INFO: 
Apr 27 16:55:43.719: INFO: StatefulSet ss has not reached scale 3, at 2
Apr 27 16:55:44.735: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.988888654s
Apr 27 16:55:45.747: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.972538627s
Apr 27 16:55:46.759: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.960717194s
Apr 27 16:55:47.772: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.948533887s
Apr 27 16:55:48.784: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.935694522s
Apr 27 16:55:49.796: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.923170063s
Apr 27 16:55:50.809: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.911128954s
Apr 27 16:55:51.822: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.898389363s
Apr 27 16:55:52.835: INFO: Verifying statefulset ss doesn't scale past 3 for another 885.993994ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2616
Apr 27 16:55:53.847: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:55:54.373: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 16:55:54.373: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:55:54.373: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:55:54.373: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:55:54.905: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 27 16:55:54.905: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:55:54.905: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:55:54.906: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:55:55.461: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 27 16:55:55.461: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:55:55.461: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:55:55.473: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:55:55.473: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:55:55.473: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Apr 27 16:55:55.484: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:55:56.008: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:55:56.008: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:55:56.008: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:55:56.008: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:55:56.527: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:55:56.527: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:55:56.527: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:55:56.527: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:55:57.054: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:55:57.054: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:55:57.054: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:55:57.054: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:55:57.065: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr 27 16:56:07.088: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:56:07.088: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:56:07.088: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:56:07.124: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Apr 27 16:56:07.124: INFO: ss-0  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:23 +0000 UTC  }]
Apr 27 16:56:07.124: INFO: ss-1  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  }]
Apr 27 16:56:07.125: INFO: ss-2  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  }]
Apr 27 16:56:07.125: INFO: 
Apr 27 16:56:07.125: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 27 16:56:08.137: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Apr 27 16:56:08.137: INFO: ss-0  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:23 +0000 UTC  }]
Apr 27 16:56:08.137: INFO: ss-1  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  }]
Apr 27 16:56:08.137: INFO: ss-2  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  }]
Apr 27 16:56:08.137: INFO: 
Apr 27 16:56:08.137: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 27 16:56:09.149: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Apr 27 16:56:09.149: INFO: ss-0  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:23 +0000 UTC  }]
Apr 27 16:56:09.149: INFO: ss-1  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  }]
Apr 27 16:56:09.149: INFO: ss-2  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  }]
Apr 27 16:56:09.149: INFO: 
Apr 27 16:56:09.149: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 27 16:56:10.161: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Apr 27 16:56:10.161: INFO: ss-0  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:23 +0000 UTC  }]
Apr 27 16:56:10.161: INFO: ss-1  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  }]
Apr 27 16:56:10.161: INFO: ss-2  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  }]
Apr 27 16:56:10.161: INFO: 
Apr 27 16:56:10.161: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 27 16:56:11.173: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Apr 27 16:56:11.173: INFO: ss-0  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:23 +0000 UTC  }]
Apr 27 16:56:11.173: INFO: ss-1  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  }]
Apr 27 16:56:11.173: INFO: ss-2  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  }]
Apr 27 16:56:11.173: INFO: 
Apr 27 16:56:11.173: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 27 16:56:12.185: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Apr 27 16:56:12.185: INFO: ss-0  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:23 +0000 UTC  }]
Apr 27 16:56:12.185: INFO: ss-1  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  }]
Apr 27 16:56:12.185: INFO: ss-2  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  }]
Apr 27 16:56:12.185: INFO: 
Apr 27 16:56:12.185: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 27 16:56:13.197: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Apr 27 16:56:13.197: INFO: ss-0  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:23 +0000 UTC  }]
Apr 27 16:56:13.197: INFO: ss-1  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  }]
Apr 27 16:56:13.197: INFO: ss-2  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  }]
Apr 27 16:56:13.197: INFO: 
Apr 27 16:56:13.197: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 27 16:56:14.210: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Apr 27 16:56:14.210: INFO: ss-0  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:23 +0000 UTC  }]
Apr 27 16:56:14.210: INFO: ss-1  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  }]
Apr 27 16:56:14.210: INFO: ss-2  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  }]
Apr 27 16:56:14.210: INFO: 
Apr 27 16:56:14.210: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 27 16:56:15.222: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Apr 27 16:56:15.223: INFO: ss-0  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:23 +0000 UTC  }]
Apr 27 16:56:15.224: INFO: ss-1  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  }]
Apr 27 16:56:15.224: INFO: ss-2  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  }]
Apr 27 16:56:15.224: INFO: 
Apr 27 16:56:15.224: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 27 16:56:16.237: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Apr 27 16:56:16.237: INFO: ss-0  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:23 +0000 UTC  }]
Apr 27 16:56:16.237: INFO: ss-1  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  }]
Apr 27 16:56:16.237: INFO: ss-2  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:55:43 +0000 UTC  }]
Apr 27 16:56:16.237: INFO: 
Apr 27 16:56:16.237: INFO: StatefulSet ss has not reached scale 0, at 3
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2616
Apr 27 16:56:17.250: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:56:17.507: INFO: rc: 1
Apr 27 16:56:17.507: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Apr 27 16:56:27.508: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:56:27.651: INFO: rc: 1
Apr 27 16:56:27.651: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 16:56:37.652: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:56:37.778: INFO: rc: 1
Apr 27 16:56:37.778: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 16:56:47.778: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:56:47.903: INFO: rc: 1
Apr 27 16:56:47.903: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 16:56:57.903: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:56:58.038: INFO: rc: 1
Apr 27 16:56:58.039: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 16:57:08.040: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:57:08.166: INFO: rc: 1
Apr 27 16:57:08.166: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 16:57:18.166: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:57:18.305: INFO: rc: 1
Apr 27 16:57:18.306: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 16:57:28.306: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:57:28.441: INFO: rc: 1
Apr 27 16:57:28.442: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 16:57:38.442: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:57:38.550: INFO: rc: 1
Apr 27 16:57:38.550: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 16:57:48.550: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:57:53.665: INFO: rc: 1
Apr 27 16:57:53.666: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 16:58:03.666: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:58:03.798: INFO: rc: 1
Apr 27 16:58:03.798: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 16:58:13.798: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:58:13.960: INFO: rc: 1
Apr 27 16:58:13.960: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 16:58:23.961: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:58:24.095: INFO: rc: 1
Apr 27 16:58:24.095: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 16:58:34.096: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:58:34.231: INFO: rc: 1
Apr 27 16:58:34.231: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 16:58:44.231: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:58:44.360: INFO: rc: 1
Apr 27 16:58:44.360: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 16:58:54.360: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:58:54.491: INFO: rc: 1
Apr 27 16:58:54.491: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 16:59:04.492: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:59:04.613: INFO: rc: 1
Apr 27 16:59:04.613: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 16:59:14.614: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:59:14.736: INFO: rc: 1
Apr 27 16:59:14.736: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 16:59:24.737: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:59:24.865: INFO: rc: 1
Apr 27 16:59:24.865: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 16:59:34.865: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:59:34.993: INFO: rc: 1
Apr 27 16:59:34.993: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 16:59:44.994: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:59:45.119: INFO: rc: 1
Apr 27 16:59:45.119: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 16:59:55.119: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:59:55.249: INFO: rc: 1
Apr 27 16:59:55.249: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:00:05.250: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:00:05.386: INFO: rc: 1
Apr 27 17:00:05.386: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:00:15.387: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:00:15.521: INFO: rc: 1
Apr 27 17:00:15.522: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:00:25.522: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:00:25.705: INFO: rc: 1
Apr 27 17:00:25.705: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:00:35.706: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:00:35.831: INFO: rc: 1
Apr 27 17:00:35.831: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:00:45.831: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:00:45.955: INFO: rc: 1
Apr 27 17:00:45.955: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:00:55.955: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:00:56.071: INFO: rc: 1
Apr 27 17:00:56.071: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:01:06.072: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:01:06.206: INFO: rc: 1
Apr 27 17:01:06.206: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:01:16.207: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:01:16.334: INFO: rc: 1
Apr 27 17:01:16.334: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:01:26.335: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-2616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:01:26.456: INFO: rc: 1
Apr 27 17:01:26.456: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: 
Apr 27 17:01:26.456: INFO: Scaling statefulset ss to 0
Apr 27 17:01:26.490: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 17:01:26.502: INFO: Deleting all statefulset in ns statefulset-2616
Apr 27 17:01:26.513: INFO: Scaling statefulset ss to 0
Apr 27 17:01:26.546: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 17:01:26.558: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:01:26.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2616" for this suite.

• [SLOW TEST:363.762 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":277,"completed":209,"skipped":3477,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:01:26.633: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3502
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Apr 27 17:01:37.029: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
W0427 17:01:37.029069    7292 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 27 17:01:37.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3502" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":277,"completed":210,"skipped":3498,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:01:37.057: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7448
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-e17c5d58-7e30-4f20-9f2b-0dd7d44bfe81
STEP: Creating a pod to test consume secrets
Apr 27 17:01:37.272: INFO: Waiting up to 5m0s for pod "pod-secrets-d0495df9-26be-458a-b3b7-e00a96c5c208" in namespace "secrets-7448" to be "Succeeded or Failed"
Apr 27 17:01:37.282: INFO: Pod "pod-secrets-d0495df9-26be-458a-b3b7-e00a96c5c208": Phase="Pending", Reason="", readiness=false. Elapsed: 10.748382ms
Apr 27 17:01:39.294: INFO: Pod "pod-secrets-d0495df9-26be-458a-b3b7-e00a96c5c208": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022563299s
Apr 27 17:01:41.307: INFO: Pod "pod-secrets-d0495df9-26be-458a-b3b7-e00a96c5c208": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0349872s
STEP: Saw pod success
Apr 27 17:01:41.307: INFO: Pod "pod-secrets-d0495df9-26be-458a-b3b7-e00a96c5c208" satisfied condition "Succeeded or Failed"
Apr 27 17:01:41.318: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-secrets-d0495df9-26be-458a-b3b7-e00a96c5c208 container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:01:41.447: INFO: Waiting for pod pod-secrets-d0495df9-26be-458a-b3b7-e00a96c5c208 to disappear
Apr 27 17:01:41.458: INFO: Pod pod-secrets-d0495df9-26be-458a-b3b7-e00a96c5c208 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:01:41.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7448" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":211,"skipped":3509,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:01:41.491: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9827
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1418
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Apr 27 17:01:41.676: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-pod --restart=Never --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-9827'
Apr 27 17:01:41.805: INFO: stderr: ""
Apr 27 17:01:41.805: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1423
Apr 27 17:01:41.816: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pods e2e-test-httpd-pod --namespace=kubectl-9827'
Apr 27 17:01:47.498: INFO: stderr: ""
Apr 27 17:01:47.498: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:01:47.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9827" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":277,"completed":212,"skipped":3526,"failed":0}
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:01:47.531: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2261
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:01:47.723: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config version'
Apr 27 17:01:47.843: INFO: stderr: ""
Apr 27 17:01:47.843: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.2\", GitCommit:\"52c56ce7a8272c798dbc29846288d7cd9fbae032\", GitTreeState:\"clean\", BuildDate:\"2020-04-16T11:56:40Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.2\", GitCommit:\"52c56ce7a8272c798dbc29846288d7cd9fbae032\", GitTreeState:\"clean\", BuildDate:\"2020-04-16T11:48:36Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:01:47.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2261" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":277,"completed":213,"skipped":3532,"failed":0}
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:01:47.877: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-3898
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:01:48.065: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Apr 27 17:01:49.147: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:01:49.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3898" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":277,"completed":214,"skipped":3538,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:01:49.195: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5644
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Apr 27 17:01:53.993: INFO: Successfully updated pod "annotationupdate3f9d1722-4294-4b82-a5d3-dcb6a2cb34b0"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:01:58.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5644" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":277,"completed":215,"skipped":3573,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:01:58.113: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7000
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Apr 27 17:01:58.301: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 17:02:01.506: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:02:15.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7000" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":277,"completed":216,"skipped":3577,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:02:15.604: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6051
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:02:15.806: INFO: Waiting up to 5m0s for pod "downwardapi-volume-002816c1-1280-4138-86ae-6d6887a704ed" in namespace "downward-api-6051" to be "Succeeded or Failed"
Apr 27 17:02:15.816: INFO: Pod "downwardapi-volume-002816c1-1280-4138-86ae-6d6887a704ed": Phase="Pending", Reason="", readiness=false. Elapsed: 10.346475ms
Apr 27 17:02:17.829: INFO: Pod "downwardapi-volume-002816c1-1280-4138-86ae-6d6887a704ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022980248s
Apr 27 17:02:19.841: INFO: Pod "downwardapi-volume-002816c1-1280-4138-86ae-6d6887a704ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035298165s
STEP: Saw pod success
Apr 27 17:02:19.841: INFO: Pod "downwardapi-volume-002816c1-1280-4138-86ae-6d6887a704ed" satisfied condition "Succeeded or Failed"
Apr 27 17:02:19.856: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod downwardapi-volume-002816c1-1280-4138-86ae-6d6887a704ed container client-container: <nil>
STEP: delete the pod
Apr 27 17:02:19.893: INFO: Waiting for pod downwardapi-volume-002816c1-1280-4138-86ae-6d6887a704ed to disappear
Apr 27 17:02:19.904: INFO: Pod downwardapi-volume-002816c1-1280-4138-86ae-6d6887a704ed no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:02:19.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6051" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":277,"completed":217,"skipped":3604,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:02:19.937: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1263
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 27 17:02:23.208: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:02:23.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1263" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":218,"skipped":3644,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:02:23.271: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1825
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Apr 27 17:02:23.474: INFO: Waiting up to 5m0s for pod "downward-api-311b1270-f06d-4628-bd34-c5258a922f06" in namespace "downward-api-1825" to be "Succeeded or Failed"
Apr 27 17:02:23.484: INFO: Pod "downward-api-311b1270-f06d-4628-bd34-c5258a922f06": Phase="Pending", Reason="", readiness=false. Elapsed: 10.487456ms
Apr 27 17:02:25.496: INFO: Pod "downward-api-311b1270-f06d-4628-bd34-c5258a922f06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02262558s
Apr 27 17:02:27.508: INFO: Pod "downward-api-311b1270-f06d-4628-bd34-c5258a922f06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034555435s
STEP: Saw pod success
Apr 27 17:02:27.508: INFO: Pod "downward-api-311b1270-f06d-4628-bd34-c5258a922f06" satisfied condition "Succeeded or Failed"
Apr 27 17:02:27.520: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod downward-api-311b1270-f06d-4628-bd34-c5258a922f06 container dapi-container: <nil>
STEP: delete the pod
Apr 27 17:02:27.551: INFO: Waiting for pod downward-api-311b1270-f06d-4628-bd34-c5258a922f06 to disappear
Apr 27 17:02:27.562: INFO: Pod downward-api-311b1270-f06d-4628-bd34-c5258a922f06 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:02:27.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1825" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":277,"completed":219,"skipped":3668,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:02:27.600: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-639
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test env composition
Apr 27 17:02:27.798: INFO: Waiting up to 5m0s for pod "var-expansion-fc78e413-fd75-4ab9-90f0-74c172e03f9e" in namespace "var-expansion-639" to be "Succeeded or Failed"
Apr 27 17:02:27.809: INFO: Pod "var-expansion-fc78e413-fd75-4ab9-90f0-74c172e03f9e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.961846ms
Apr 27 17:02:29.820: INFO: Pod "var-expansion-fc78e413-fd75-4ab9-90f0-74c172e03f9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022821882s
STEP: Saw pod success
Apr 27 17:02:29.822: INFO: Pod "var-expansion-fc78e413-fd75-4ab9-90f0-74c172e03f9e" satisfied condition "Succeeded or Failed"
Apr 27 17:02:29.833: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod var-expansion-fc78e413-fd75-4ab9-90f0-74c172e03f9e container dapi-container: <nil>
STEP: delete the pod
Apr 27 17:02:29.875: INFO: Waiting for pod var-expansion-fc78e413-fd75-4ab9-90f0-74c172e03f9e to disappear
Apr 27 17:02:29.885: INFO: Pod var-expansion-fc78e413-fd75-4ab9-90f0-74c172e03f9e no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:02:29.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-639" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":277,"completed":220,"skipped":3715,"failed":0}
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:02:29.916: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2212
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-992af9c9-313a-4142-bc7a-00e06ea1e9ed
STEP: Creating a pod to test consume configMaps
Apr 27 17:02:30.130: INFO: Waiting up to 5m0s for pod "pod-configmaps-bc5deb76-adea-48f1-986b-e535a3fe72ae" in namespace "configmap-2212" to be "Succeeded or Failed"
Apr 27 17:02:30.140: INFO: Pod "pod-configmaps-bc5deb76-adea-48f1-986b-e535a3fe72ae": Phase="Pending", Reason="", readiness=false. Elapsed: 10.132116ms
Apr 27 17:02:32.152: INFO: Pod "pod-configmaps-bc5deb76-adea-48f1-986b-e535a3fe72ae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021885108s
Apr 27 17:02:34.164: INFO: Pod "pod-configmaps-bc5deb76-adea-48f1-986b-e535a3fe72ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033538478s
STEP: Saw pod success
Apr 27 17:02:34.164: INFO: Pod "pod-configmaps-bc5deb76-adea-48f1-986b-e535a3fe72ae" satisfied condition "Succeeded or Failed"
Apr 27 17:02:34.174: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-configmaps-bc5deb76-adea-48f1-986b-e535a3fe72ae container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 17:02:34.212: INFO: Waiting for pod pod-configmaps-bc5deb76-adea-48f1-986b-e535a3fe72ae to disappear
Apr 27 17:02:34.222: INFO: Pod pod-configmaps-bc5deb76-adea-48f1-986b-e535a3fe72ae no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:02:34.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2212" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":221,"skipped":3716,"failed":0}
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:02:34.253: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5836
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:02:34.499: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Apr 27 17:02:34.521: INFO: Number of nodes with available pods: 0
Apr 27 17:02:34.521: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Apr 27 17:02:34.581: INFO: Number of nodes with available pods: 0
Apr 27 17:02:34.581: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:02:35.593: INFO: Number of nodes with available pods: 0
Apr 27 17:02:35.593: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:02:36.596: INFO: Number of nodes with available pods: 0
Apr 27 17:02:36.596: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:02:37.594: INFO: Number of nodes with available pods: 1
Apr 27 17:02:37.594: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Apr 27 17:02:37.659: INFO: Number of nodes with available pods: 0
Apr 27 17:02:37.659: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Apr 27 17:02:37.696: INFO: Number of nodes with available pods: 0
Apr 27 17:02:37.696: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:02:38.708: INFO: Number of nodes with available pods: 0
Apr 27 17:02:38.708: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:02:39.708: INFO: Number of nodes with available pods: 0
Apr 27 17:02:39.708: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:02:40.708: INFO: Number of nodes with available pods: 0
Apr 27 17:02:40.708: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:02:41.708: INFO: Number of nodes with available pods: 0
Apr 27 17:02:41.708: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:02:42.709: INFO: Number of nodes with available pods: 0
Apr 27 17:02:42.709: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:02:43.710: INFO: Number of nodes with available pods: 0
Apr 27 17:02:43.710: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:02:44.709: INFO: Number of nodes with available pods: 0
Apr 27 17:02:44.709: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:02:45.708: INFO: Number of nodes with available pods: 0
Apr 27 17:02:45.708: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:02:46.709: INFO: Number of nodes with available pods: 0
Apr 27 17:02:46.709: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:02:47.708: INFO: Number of nodes with available pods: 0
Apr 27 17:02:47.709: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:02:48.708: INFO: Number of nodes with available pods: 0
Apr 27 17:02:48.709: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:02:49.708: INFO: Number of nodes with available pods: 0
Apr 27 17:02:49.708: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:02:50.708: INFO: Number of nodes with available pods: 1
Apr 27 17:02:50.708: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5836, will wait for the garbage collector to delete the pods
Apr 27 17:02:50.804: INFO: Deleting DaemonSet.extensions daemon-set took: 12.848467ms
Apr 27 17:02:51.305: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.481435ms
Apr 27 17:02:57.316: INFO: Number of nodes with available pods: 0
Apr 27 17:02:57.316: INFO: Number of running nodes: 0, number of available pods: 0
Apr 27 17:02:57.327: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5836/daemonsets","resourceVersion":"27763"},"items":null}

Apr 27 17:02:57.339: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5836/pods","resourceVersion":"27763"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:02:57.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5836" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":277,"completed":222,"skipped":3719,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should patch a secret [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:02:57.444: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-863
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a secret [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:02:57.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-863" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should patch a secret [Conformance]","total":277,"completed":223,"skipped":3744,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:02:57.729: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-353
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-ab703e15-9f4a-4972-9301-8c0c54cd49e1
STEP: Creating a pod to test consume configMaps
Apr 27 17:02:57.940: INFO: Waiting up to 5m0s for pod "pod-configmaps-e73c0182-0e3b-4577-ad33-938e93e95b8b" in namespace "configmap-353" to be "Succeeded or Failed"
Apr 27 17:02:57.951: INFO: Pod "pod-configmaps-e73c0182-0e3b-4577-ad33-938e93e95b8b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.412456ms
Apr 27 17:02:59.962: INFO: Pod "pod-configmaps-e73c0182-0e3b-4577-ad33-938e93e95b8b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022253134s
Apr 27 17:03:01.974: INFO: Pod "pod-configmaps-e73c0182-0e3b-4577-ad33-938e93e95b8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034046123s
STEP: Saw pod success
Apr 27 17:03:01.974: INFO: Pod "pod-configmaps-e73c0182-0e3b-4577-ad33-938e93e95b8b" satisfied condition "Succeeded or Failed"
Apr 27 17:03:01.986: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-configmaps-e73c0182-0e3b-4577-ad33-938e93e95b8b container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 17:03:02.021: INFO: Waiting for pod pod-configmaps-e73c0182-0e3b-4577-ad33-938e93e95b8b to disappear
Apr 27 17:03:02.031: INFO: Pod pod-configmaps-e73c0182-0e3b-4577-ad33-938e93e95b8b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:02.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-353" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":224,"skipped":3757,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:02.063: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4653
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:03:02.255: INFO: Creating deployment "webserver-deployment"
Apr 27 17:03:02.268: INFO: Waiting for observed generation 1
Apr 27 17:03:04.292: INFO: Waiting for all required pods to come up
Apr 27 17:03:04.312: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Apr 27 17:03:12.345: INFO: Waiting for deployment "webserver-deployment" to complete
Apr 27 17:03:12.378: INFO: Updating deployment "webserver-deployment" with a non-existent image
Apr 27 17:03:12.400: INFO: Updating deployment webserver-deployment
Apr 27 17:03:12.400: INFO: Waiting for observed generation 2
Apr 27 17:03:14.425: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr 27 17:03:14.436: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr 27 17:03:14.448: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 27 17:03:14.480: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr 27 17:03:14.480: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr 27 17:03:14.492: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 27 17:03:14.513: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Apr 27 17:03:14.513: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Apr 27 17:03:14.536: INFO: Updating deployment webserver-deployment
Apr 27 17:03:14.536: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Apr 27 17:03:14.562: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr 27 17:03:16.585: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Apr 27 17:03:16.608: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-4653 /apis/apps/v1/namespaces/deployment-4653/deployments/webserver-deployment 001424e6-90c5-42c7-96a3-d3a21cf21adf 28041 3 2020-04-27 17:03:02 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0068522e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-04-27 17:03:14 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-6676bcd6d4" is progressing.,LastUpdateTime:2020-04-27 17:03:14 +0000 UTC,LastTransitionTime:2020-04-27 17:03:02 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Apr 27 17:03:16.623: INFO: New ReplicaSet "webserver-deployment-6676bcd6d4" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-6676bcd6d4  deployment-4653 /apis/apps/v1/namespaces/deployment-4653/replicasets/webserver-deployment-6676bcd6d4 19a13fdf-bdcc-43ac-ab6e-5e52d0accbf7 28032 3 2020-04-27 17:03:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 001424e6-90c5-42c7-96a3-d3a21cf21adf 0xc006852787 0xc006852788}] []  [{kube-controller-manager Update apps/v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 48 49 52 50 52 101 54 45 57 48 99 53 45 52 50 99 55 45 57 54 97 51 45 100 51 97 50 49 99 102 50 49 97 100 102 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 6676bcd6d4,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006852808 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 17:03:16.624: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Apr 27 17:03:16.624: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-84855cf797  deployment-4653 /apis/apps/v1/namespaces/deployment-4653/replicasets/webserver-deployment-84855cf797 14eb7323-42b1-4118-8c7b-16f249d11031 28039 3 2020-04-27 17:03:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 001424e6-90c5-42c7-96a3-d3a21cf21adf 0xc006852867 0xc006852868}] []  [{kube-controller-manager Update apps/v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 48 49 52 50 52 101 54 45 57 48 99 53 45 52 50 99 55 45 57 54 97 51 45 100 51 97 50 49 99 102 50 49 97 100 102 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 84855cf797,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0068528d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Apr 27 17:03:16.656: INFO: Pod "webserver-deployment-6676bcd6d4-2dq6x" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-2dq6x webserver-deployment-6676bcd6d4- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-6676bcd6d4-2dq6x 96bb154c-b5c5-48fe-9918-f852e8ab9041 28069 0 2020-04-27 17:03:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:100.64.1.26/32 cni.projectcalico.org/podIPs:100.64.1.26/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 19a13fdf-bdcc-43ac-ab6e-5e52d0accbf7 0xc006852e57 0xc006852e58}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 57 97 49 51 102 100 102 45 98 100 99 99 45 52 51 97 99 45 97 98 54 101 45 53 101 53 50 100 48 97 99 99 98 102 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:12 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:03:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2020-04-27 17:03:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.657: INFO: Pod "webserver-deployment-6676bcd6d4-494kp" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-494kp webserver-deployment-6676bcd6d4- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-6676bcd6d4-494kp 322bbbab-662f-4dd8-9f38-c01364b9e7bd 28052 0 2020-04-27 17:03:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 19a13fdf-bdcc-43ac-ab6e-5e52d0accbf7 0xc006853000 0xc006853001}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 57 97 49 51 102 100 102 45 98 100 99 99 45 52 51 97 99 45 97 98 54 101 45 53 101 53 50 100 48 97 99 99 98 102 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2020-04-27 17:03:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.657: INFO: Pod "webserver-deployment-6676bcd6d4-7fbhr" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-7fbhr webserver-deployment-6676bcd6d4- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-6676bcd6d4-7fbhr 575bc2ec-5f1d-44f1-8747-37705c79a57d 28047 0 2020-04-27 17:03:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 19a13fdf-bdcc-43ac-ab6e-5e52d0accbf7 0xc006853190 0xc006853191}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 57 97 49 51 102 100 102 45 98 100 99 99 45 52 51 97 99 45 97 98 54 101 45 53 101 53 50 100 48 97 99 99 98 102 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2020-04-27 17:03:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.657: INFO: Pod "webserver-deployment-6676bcd6d4-88w2d" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-88w2d webserver-deployment-6676bcd6d4- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-6676bcd6d4-88w2d 393b4bce-6260-483b-bcfd-ce836a5ce390 28070 0 2020-04-27 17:03:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:100.64.1.27/32 cni.projectcalico.org/podIPs:100.64.1.27/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 19a13fdf-bdcc-43ac-ab6e-5e52d0accbf7 0xc006853340 0xc006853341}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 57 97 49 51 102 100 102 45 98 100 99 99 45 52 51 97 99 45 97 98 54 101 45 53 101 53 50 100 48 97 99 99 98 102 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:12 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:03:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2020-04-27 17:03:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.657: INFO: Pod "webserver-deployment-6676bcd6d4-c8hcp" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-c8hcp webserver-deployment-6676bcd6d4- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-6676bcd6d4-c8hcp 40f27feb-a0d8-4ef5-a11b-ea18d387bdd6 28067 0 2020-04-27 17:03:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:100.64.0.44/32 cni.projectcalico.org/podIPs:100.64.0.44/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 19a13fdf-bdcc-43ac-ab6e-5e52d0accbf7 0xc006853530 0xc006853531}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 57 97 49 51 102 100 102 45 98 100 99 99 45 52 51 97 99 45 97 98 54 101 45 53 101 53 50 100 48 97 99 99 98 102 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:03:13 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2020-04-27 17:03:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login',},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.658: INFO: Pod "webserver-deployment-6676bcd6d4-cgb25" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-cgb25 webserver-deployment-6676bcd6d4- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-6676bcd6d4-cgb25 66854851-daf1-4fa7-85d5-950c8f081505 28060 0 2020-04-27 17:03:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:100.64.1.24/32 cni.projectcalico.org/podIPs:100.64.1.24/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 19a13fdf-bdcc-43ac-ab6e-5e52d0accbf7 0xc006853710 0xc006853711}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 57 97 49 51 102 100 102 45 98 100 99 99 45 52 51 97 99 45 97 98 54 101 45 53 101 53 50 100 48 97 99 99 98 102 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:12 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:03:15 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2020-04-27 17:03:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.658: INFO: Pod "webserver-deployment-6676bcd6d4-gbqmv" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-gbqmv webserver-deployment-6676bcd6d4- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-6676bcd6d4-gbqmv e999d50e-8e31-4003-8902-2aea2cb23be7 28049 0 2020-04-27 17:03:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 19a13fdf-bdcc-43ac-ab6e-5e52d0accbf7 0xc0068538c0 0xc0068538c1}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 57 97 49 51 102 100 102 45 98 100 99 99 45 52 51 97 99 45 97 98 54 101 45 53 101 53 50 100 48 97 99 99 98 102 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2020-04-27 17:03:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.658: INFO: Pod "webserver-deployment-6676bcd6d4-h2hpn" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-h2hpn webserver-deployment-6676bcd6d4- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-6676bcd6d4-h2hpn ef2eeef1-08e0-4507-bdc9-d46ebaeceb49 28056 0 2020-04-27 17:03:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 19a13fdf-bdcc-43ac-ab6e-5e52d0accbf7 0xc006853a50 0xc006853a51}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 57 97 49 51 102 100 102 45 98 100 99 99 45 52 51 97 99 45 97 98 54 101 45 53 101 53 50 100 48 97 99 99 98 102 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2020-04-27 17:03:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.658: INFO: Pod "webserver-deployment-6676bcd6d4-h6qk2" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-h6qk2 webserver-deployment-6676bcd6d4- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-6676bcd6d4-h6qk2 766719eb-9727-4719-9af2-032783c61dfa 28048 0 2020-04-27 17:03:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 19a13fdf-bdcc-43ac-ab6e-5e52d0accbf7 0xc006853be0 0xc006853be1}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 57 97 49 51 102 100 102 45 98 100 99 99 45 52 51 97 99 45 97 98 54 101 45 53 101 53 50 100 48 97 99 99 98 102 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2020-04-27 17:03:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.659: INFO: Pod "webserver-deployment-6676bcd6d4-hs4xb" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-hs4xb webserver-deployment-6676bcd6d4- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-6676bcd6d4-hs4xb 8af80e90-9a13-4fbe-90a2-934e188c8c14 28068 0 2020-04-27 17:03:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:100.64.1.25/32 cni.projectcalico.org/podIPs:100.64.1.25/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 19a13fdf-bdcc-43ac-ab6e-5e52d0accbf7 0xc006853d90 0xc006853d91}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 57 97 49 51 102 100 102 45 98 100 99 99 45 52 51 97 99 45 97 98 54 101 45 53 101 53 50 100 48 97 99 99 98 102 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:12 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:03:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2020-04-27 17:03:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.659: INFO: Pod "webserver-deployment-6676bcd6d4-hzv9f" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-hzv9f webserver-deployment-6676bcd6d4- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-6676bcd6d4-hzv9f bf63a0d8-0f48-42d9-b40b-7f3ce00b5183 28043 0 2020-04-27 17:03:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 19a13fdf-bdcc-43ac-ab6e-5e52d0accbf7 0xc006853f40 0xc006853f41}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 57 97 49 51 102 100 102 45 98 100 99 99 45 52 51 97 99 45 97 98 54 101 45 53 101 53 50 100 48 97 99 99 98 102 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2020-04-27 17:03:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.659: INFO: Pod "webserver-deployment-6676bcd6d4-q69gl" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-q69gl webserver-deployment-6676bcd6d4- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-6676bcd6d4-q69gl 43db8ad1-8159-4f06-9beb-98c07e2ce5ba 28026 0 2020-04-27 17:03:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 19a13fdf-bdcc-43ac-ab6e-5e52d0accbf7 0xc0068240d0 0xc0068240d1}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 57 97 49 51 102 100 102 45 98 100 99 99 45 52 51 97 99 45 97 98 54 101 45 53 101 53 50 100 48 97 99 99 98 102 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2020-04-27 17:03:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.659: INFO: Pod "webserver-deployment-6676bcd6d4-vx5xx" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-vx5xx webserver-deployment-6676bcd6d4- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-6676bcd6d4-vx5xx 346034cd-a999-459e-a9d0-44877f8c2368 28045 0 2020-04-27 17:03:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 19a13fdf-bdcc-43ac-ab6e-5e52d0accbf7 0xc006824260 0xc006824261}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 57 97 49 51 102 100 102 45 98 100 99 99 45 52 51 97 99 45 97 98 54 101 45 53 101 53 50 100 48 97 99 99 98 102 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2020-04-27 17:03:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.660: INFO: Pod "webserver-deployment-84855cf797-22j24" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-22j24 webserver-deployment-84855cf797- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-84855cf797-22j24 2146fcd5-00dd-484d-a7ea-2311428c575c 28054 0 2020-04-27 17:03:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 14eb7323-42b1-4118-8c7b-16f249d11031 0xc0068243f0 0xc0068243f1}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 52 101 98 55 51 50 51 45 52 50 98 49 45 52 49 49 56 45 56 99 55 98 45 49 54 102 50 52 57 100 49 49 48 51 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2020-04-27 17:03:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.660: INFO: Pod "webserver-deployment-84855cf797-45cgw" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-45cgw webserver-deployment-84855cf797- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-84855cf797-45cgw db6652bc-e2bb-452a-95a8-7557cc54e960 28055 0 2020-04-27 17:03:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 14eb7323-42b1-4118-8c7b-16f249d11031 0xc006824560 0xc006824561}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 52 101 98 55 51 50 51 45 52 50 98 49 45 52 49 49 56 45 56 99 55 98 45 49 54 102 50 52 57 100 49 49 48 51 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2020-04-27 17:03:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.660: INFO: Pod "webserver-deployment-84855cf797-4vftm" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-4vftm webserver-deployment-84855cf797- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-84855cf797-4vftm ce7269d4-9086-416a-802b-3519a1db84e2 28053 0 2020-04-27 17:03:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 14eb7323-42b1-4118-8c7b-16f249d11031 0xc0068246d0 0xc0068246d1}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 52 101 98 55 51 50 51 45 52 50 98 49 45 52 49 49 56 45 56 99 55 98 45 49 54 102 50 52 57 100 49 49 48 51 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2020-04-27 17:03:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.660: INFO: Pod "webserver-deployment-84855cf797-88h6s" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-88h6s webserver-deployment-84855cf797- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-84855cf797-88h6s d879b923-7a7e-4c1d-9531-6fac2f5280c8 28050 0 2020-04-27 17:03:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 14eb7323-42b1-4118-8c7b-16f249d11031 0xc006824840 0xc006824841}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 52 101 98 55 51 50 51 45 52 50 98 49 45 52 49 49 56 45 56 99 55 98 45 49 54 102 50 52 57 100 49 49 48 51 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2020-04-27 17:03:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.661: INFO: Pod "webserver-deployment-84855cf797-8fcdw" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-8fcdw webserver-deployment-84855cf797- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-84855cf797-8fcdw 00d65405-368a-4726-940f-5c3e1f9b9675 27869 0 2020-04-27 17:03:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.0.43/32 cni.projectcalico.org/podIPs:100.64.0.43/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 14eb7323-42b1-4118-8c7b-16f249d11031 0xc0068249d0 0xc0068249d1}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 52 101 98 55 51 50 51 45 52 50 98 49 45 52 49 49 56 45 56 99 55 98 45 49 54 102 50 52 57 100 49 49 48 51 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:03:03 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 48 46 52 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.0.43,StartTime:2020-04-27 17:03:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:03:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://f71050a478f43a0205af787b8f0c7e42719d97321f1cb49b8bce57ac65409690,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.43,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.661: INFO: Pod "webserver-deployment-84855cf797-blg5h" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-blg5h webserver-deployment-84855cf797- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-84855cf797-blg5h 534d4d57-4da6-410c-94f5-3542093df59e 28044 0 2020-04-27 17:03:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 14eb7323-42b1-4118-8c7b-16f249d11031 0xc006824b80 0xc006824b81}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 52 101 98 55 51 50 51 45 52 50 98 49 45 52 49 49 56 45 56 99 55 98 45 49 54 102 50 52 57 100 49 49 48 51 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2020-04-27 17:03:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.661: INFO: Pod "webserver-deployment-84855cf797-cnpl7" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-cnpl7 webserver-deployment-84855cf797- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-84855cf797-cnpl7 02f9085b-1165-4f83-b2e2-62fc09aa871f 28027 0 2020-04-27 17:03:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 14eb7323-42b1-4118-8c7b-16f249d11031 0xc006824cf0 0xc006824cf1}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 52 101 98 55 51 50 51 45 52 50 98 49 45 52 49 49 56 45 56 99 55 98 45 49 54 102 50 52 57 100 49 49 48 51 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2020-04-27 17:03:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.661: INFO: Pod "webserver-deployment-84855cf797-d29sp" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-d29sp webserver-deployment-84855cf797- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-84855cf797-d29sp 8e6042e7-0ef7-403d-b356-9f8f1ea93e57 27926 0 2020-04-27 17:03:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.21/32 cni.projectcalico.org/podIPs:100.64.1.21/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 14eb7323-42b1-4118-8c7b-16f249d11031 0xc006824e80 0xc006824e81}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 52 101 98 55 51 50 51 45 52 50 98 49 45 52 49 49 56 45 56 99 55 98 45 49 54 102 50 52 57 100 49 49 48 51 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:03:07 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:11 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 50 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.1.21,StartTime:2020-04-27 17:03:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:03:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://efe4daf34665149a5eb2717c986afb54f7faadd9fe08683a5cc253ee2de10311,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.21,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.662: INFO: Pod "webserver-deployment-84855cf797-gn9kb" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-gn9kb webserver-deployment-84855cf797- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-84855cf797-gn9kb c8919607-7eda-429d-96a6-72e9ecfef563 28051 0 2020-04-27 17:03:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 14eb7323-42b1-4118-8c7b-16f249d11031 0xc006825030 0xc006825031}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 52 101 98 55 51 50 51 45 52 50 98 49 45 52 49 49 56 45 56 99 55 98 45 49 54 102 50 52 57 100 49 49 48 51 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2020-04-27 17:03:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.662: INFO: Pod "webserver-deployment-84855cf797-klrzh" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-klrzh webserver-deployment-84855cf797- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-84855cf797-klrzh d04c00f6-22f5-4708-9941-5be2ad885a6c 27915 0 2020-04-27 17:03:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.17/32 cni.projectcalico.org/podIPs:100.64.1.17/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 14eb7323-42b1-4118-8c7b-16f249d11031 0xc0068251c0 0xc0068251c1}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 52 101 98 55 51 50 51 45 52 50 98 49 45 52 49 49 56 45 56 99 55 98 45 49 54 102 50 52 57 100 49 49 48 51 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:03:06 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:10 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 49 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.1.17,StartTime:2020-04-27 17:03:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:03:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://63e7ceed60a75514f8a4313c93a9be9e48ef23ed2326a8e309b013ad30345730,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.17,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.662: INFO: Pod "webserver-deployment-84855cf797-mfbmk" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-mfbmk webserver-deployment-84855cf797- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-84855cf797-mfbmk 62832f05-684b-4a40-8f93-ac11ed5fa65b 27912 0 2020-04-27 17:03:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.15/32 cni.projectcalico.org/podIPs:100.64.1.15/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 14eb7323-42b1-4118-8c7b-16f249d11031 0xc0068253a0 0xc0068253a1}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 52 101 98 55 51 50 51 45 52 50 98 49 45 52 49 49 56 45 56 99 55 98 45 49 54 102 50 52 57 100 49 49 48 51 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:03:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:09 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 49 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.1.15,StartTime:2020-04-27 17:03:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:03:07 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://891a752913801d339b20f68b8509eb0ba4a978bb95759f564fbb166d8b8f2b17,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.15,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.662: INFO: Pod "webserver-deployment-84855cf797-pjf6m" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-pjf6m webserver-deployment-84855cf797- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-84855cf797-pjf6m 38f7082f-2db8-4226-8460-14ecf6cfe27a 28021 0 2020-04-27 17:03:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 14eb7323-42b1-4118-8c7b-16f249d11031 0xc006825550 0xc006825551}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 52 101 98 55 51 50 51 45 52 50 98 49 45 52 49 49 56 45 56 99 55 98 45 49 54 102 50 52 57 100 49 49 48 51 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2020-04-27 17:03:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.663: INFO: Pod "webserver-deployment-84855cf797-r4bc6" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-r4bc6 webserver-deployment-84855cf797- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-84855cf797-r4bc6 939ca1ec-3334-4257-b156-c7faa04c3ee2 27918 0 2020-04-27 17:03:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.18/32 cni.projectcalico.org/podIPs:100.64.1.18/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 14eb7323-42b1-4118-8c7b-16f249d11031 0xc0068256e0 0xc0068256e1}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 52 101 98 55 51 50 51 45 52 50 98 49 45 52 49 49 56 45 56 99 55 98 45 49 54 102 50 52 57 100 49 49 48 51 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:03:06 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:10 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 49 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.1.18,StartTime:2020-04-27 17:03:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:03:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://9be84ecf202fd0d65da4a2c8d74034bc024cd71270b2893b4cc51b1e3693fb96,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.18,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.663: INFO: Pod "webserver-deployment-84855cf797-rpmgs" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-rpmgs webserver-deployment-84855cf797- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-84855cf797-rpmgs 336c40f1-28e5-4a1f-a8b4-6c3ca1d7b914 28046 0 2020-04-27 17:03:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 14eb7323-42b1-4118-8c7b-16f249d11031 0xc006825890 0xc006825891}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 52 101 98 55 51 50 51 45 52 50 98 49 45 52 49 49 56 45 56 99 55 98 45 49 54 102 50 52 57 100 49 49 48 51 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2020-04-27 17:03:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.663: INFO: Pod "webserver-deployment-84855cf797-sdpdq" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-sdpdq webserver-deployment-84855cf797- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-84855cf797-sdpdq 94e5bc1f-6661-4e0d-af7b-aa7ef0de9587 27900 0 2020-04-27 17:03:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.16/32 cni.projectcalico.org/podIPs:100.64.1.16/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 14eb7323-42b1-4118-8c7b-16f249d11031 0xc006825a20 0xc006825a21}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 52 101 98 55 51 50 51 45 52 50 98 49 45 52 49 49 56 45 56 99 55 98 45 49 54 102 50 52 57 100 49 49 48 51 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:03:05 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:08 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.1.16,StartTime:2020-04-27 17:03:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:03:07 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://3efc21ee3c25d6c59e2532df6154740097ff36f319870c2e1b5e4bbbf216a091,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.16,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.663: INFO: Pod "webserver-deployment-84855cf797-v7t75" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-v7t75 webserver-deployment-84855cf797- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-84855cf797-v7t75 692e86cf-bc60-4556-b22c-223998e44dcc 27929 0 2020-04-27 17:03:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.23/32 cni.projectcalico.org/podIPs:100.64.1.23/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 14eb7323-42b1-4118-8c7b-16f249d11031 0xc006825bf0 0xc006825bf1}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 52 101 98 55 51 50 51 45 52 50 98 49 45 52 49 49 56 45 56 99 55 98 45 49 54 102 50 52 57 100 49 49 48 51 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:03:08 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:11 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 50 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.1.23,StartTime:2020-04-27 17:03:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:03:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://cdcf4c1367bd7129ab774a4305f3b4dee5e84943abe69ff153c88f9fa3cb9070,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.23,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.664: INFO: Pod "webserver-deployment-84855cf797-vwtd7" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-vwtd7 webserver-deployment-84855cf797- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-84855cf797-vwtd7 454715d0-23d2-418e-b588-76483dec0bb1 28058 0 2020-04-27 17:03:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 14eb7323-42b1-4118-8c7b-16f249d11031 0xc006825da0 0xc006825da1}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 52 101 98 55 51 50 51 45 52 50 98 49 45 52 49 49 56 45 56 99 55 98 45 49 54 102 50 52 57 100 49 49 48 51 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:15 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2020-04-27 17:03:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.664: INFO: Pod "webserver-deployment-84855cf797-vxt9v" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-vxt9v webserver-deployment-84855cf797- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-84855cf797-vxt9v 49325f59-83c5-4214-8997-f3b3830e6d5c 28057 0 2020-04-27 17:03:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 14eb7323-42b1-4118-8c7b-16f249d11031 0xc006825f10 0xc006825f11}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 52 101 98 55 51 50 51 45 52 50 98 49 45 52 49 49 56 45 56 99 55 98 45 49 54 102 50 52 57 100 49 49 48 51 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2020-04-27 17:03:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.664: INFO: Pod "webserver-deployment-84855cf797-xfdkm" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-xfdkm webserver-deployment-84855cf797- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-84855cf797-xfdkm eb03ddb9-5559-4278-bb3b-be360b69acb5 27923 0 2020-04-27 17:03:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.20/32 cni.projectcalico.org/podIPs:100.64.1.20/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 14eb7323-42b1-4118-8c7b-16f249d11031 0xc0067fa0a0 0xc0067fa0a1}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 52 101 98 55 51 50 51 45 52 50 98 49 45 52 49 49 56 45 56 99 55 98 45 49 54 102 50 52 57 100 49 49 48 51 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:03:07 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:11 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 50 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.1.20,StartTime:2020-04-27 17:03:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:03:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://6bb4a301bcc6ec18e2dd30892a8b0ed74cee50a097f76b9fa0ffeffee01a70a3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.20,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:03:16.664: INFO: Pod "webserver-deployment-84855cf797-xqsrg" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-xqsrg webserver-deployment-84855cf797- deployment-4653 /api/v1/namespaces/deployment-4653/pods/webserver-deployment-84855cf797-xqsrg 0990bbfc-1755-4b4d-bd8f-30cf162e77c8 28042 0 2020-04-27 17:03:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 14eb7323-42b1-4118-8c7b-16f249d11031 0xc0067fa250 0xc0067fa251}] []  [{kube-controller-manager Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 52 101 98 55 51 50 51 45 52 50 98 49 45 52 49 49 56 45 56 99 55 98 45 49 54 102 50 52 57 100 49 49 48 51 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:03:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mp4fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mp4fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mp4fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:03:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2020-04-27 17:03:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:16.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4653" for this suite.
•{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":277,"completed":225,"skipped":3771,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:16.689: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2533
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:30.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2533" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":277,"completed":226,"skipped":3804,"failed":0}
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:30.057: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7913
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-fe9b13f9-054b-46b2-8750-be3864b2688a
STEP: Creating a pod to test consume secrets
Apr 27 17:03:30.268: INFO: Waiting up to 5m0s for pod "pod-secrets-42e1c647-7e35-47bb-ae7b-8a727ad67d96" in namespace "secrets-7913" to be "Succeeded or Failed"
Apr 27 17:03:30.279: INFO: Pod "pod-secrets-42e1c647-7e35-47bb-ae7b-8a727ad67d96": Phase="Pending", Reason="", readiness=false. Elapsed: 10.691699ms
Apr 27 17:03:32.291: INFO: Pod "pod-secrets-42e1c647-7e35-47bb-ae7b-8a727ad67d96": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022383951s
Apr 27 17:03:34.302: INFO: Pod "pod-secrets-42e1c647-7e35-47bb-ae7b-8a727ad67d96": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034039102s
STEP: Saw pod success
Apr 27 17:03:34.302: INFO: Pod "pod-secrets-42e1c647-7e35-47bb-ae7b-8a727ad67d96" satisfied condition "Succeeded or Failed"
Apr 27 17:03:34.313: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-secrets-42e1c647-7e35-47bb-ae7b-8a727ad67d96 container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:03:34.352: INFO: Waiting for pod pod-secrets-42e1c647-7e35-47bb-ae7b-8a727ad67d96 to disappear
Apr 27 17:03:34.367: INFO: Pod pod-secrets-42e1c647-7e35-47bb-ae7b-8a727ad67d96 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:34.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7913" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":277,"completed":227,"skipped":3807,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:34.401: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1327
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-1327
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-1327
I0427 17:03:34.641683    7292 runners.go:190] Created replication controller with name: externalname-service, namespace: services-1327, replica count: 2
Apr 27 17:03:37.692: INFO: Creating new exec pod
I0427 17:03:37.692462    7292 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 27 17:03:42.835: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-1327 execpodhtvfc -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Apr 27 17:03:43.446: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 27 17:03:43.446: INFO: stdout: ""
Apr 27 17:03:43.446: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-1327 execpodhtvfc -- /bin/sh -x -c nc -zv -t -w 2 100.105.156.200 80'
Apr 27 17:03:43.931: INFO: stderr: "+ nc -zv -t -w 2 100.105.156.200 80\nConnection to 100.105.156.200 80 port [tcp/http] succeeded!\n"
Apr 27 17:03:43.931: INFO: stdout: ""
Apr 27 17:03:43.931: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-1327 execpodhtvfc -- /bin/sh -x -c nc -zv -t -w 2 10.250.0.4 31625'
Apr 27 17:03:44.487: INFO: stderr: "+ nc -zv -t -w 2 10.250.0.4 31625\nConnection to 10.250.0.4 31625 port [tcp/31625] succeeded!\n"
Apr 27 17:03:44.487: INFO: stdout: ""
Apr 27 17:03:44.487: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-1327 execpodhtvfc -- /bin/sh -x -c nc -zv -t -w 2 10.250.0.5 31625'
Apr 27 17:03:45.084: INFO: stderr: "+ nc -zv -t -w 2 10.250.0.5 31625\nConnection to 10.250.0.5 31625 port [tcp/31625] succeeded!\n"
Apr 27 17:03:45.084: INFO: stdout: ""
Apr 27 17:03:45.084: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:45.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1327" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":277,"completed":228,"skipped":3823,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:45.150: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-5876
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Apr 27 17:03:45.332: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 27 17:03:45.387: INFO: Waiting for terminating namespaces to be deleted...
Apr 27 17:03:45.398: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 before test
Apr 27 17:03:45.430: INFO: dashboard-metrics-scraper-76c7b697bc-44kb6 from kubernetes-dashboard started at 2020-04-27 15:55:09 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.430: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 27 17:03:45.430: INFO: node-problem-detector-jtcdh from kube-system started at 2020-04-27 15:54:25 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.430: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 17:03:45.430: INFO: calico-typha-horizontal-autoscaler-6fdd5d8746-5wf5t from kube-system started at 2020-04-27 15:55:07 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.430: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 17:03:45.430: INFO: metrics-server-66897b5d79-tngw9 from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.430: INFO: 	Container metrics-server ready: true, restart count 0
Apr 27 17:03:45.430: INFO: coredns-5cb857d789-dh4pj from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.430: INFO: 	Container coredns ready: true, restart count 0
Apr 27 17:03:45.430: INFO: kube-proxy-z62w2 from kube-system started at 2020-04-27 15:54:25 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.430: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 17:03:45.430: INFO: addons-nginx-ingress-controller-6cf77756b5-8pc2l from kube-system started at 2020-04-27 15:55:07 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.430: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 27 17:03:45.430: INFO: vpn-shoot-6df545ddcb-7js5s from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.431: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 27 17:03:45.431: INFO: calico-node-zzbmr from kube-system started at 2020-04-27 15:58:17 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.431: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 17:03:45.431: INFO: externalname-service-mwqn5 from services-1327 started at 2020-04-27 17:03:34 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.431: INFO: 	Container externalname-service ready: true, restart count 0
Apr 27 17:03:45.431: INFO: node-exporter-sq8cz from kube-system started at 2020-04-27 15:54:25 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.431: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 17:03:45.431: INFO: blackbox-exporter-5dc75b79b7-rlcrv from kube-system started at 2020-04-27 15:54:25 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.431: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 27 17:03:45.431: INFO: calico-typha-vertical-autoscaler-5b477c88cf-b245g from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.431: INFO: 	Container autoscaler ready: true, restart count 3
Apr 27 17:03:45.431: INFO: calico-node-vertical-autoscaler-74d4897db8-5nqsp from kube-system started at 2020-04-27 15:55:18 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.431: INFO: 	Container autoscaler ready: true, restart count 3
Apr 27 17:03:45.431: INFO: coredns-5cb857d789-6774c from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.431: INFO: 	Container coredns ready: true, restart count 0
Apr 27 17:03:45.431: INFO: kubernetes-dashboard-6b586c4cb4-kgfwx from kubernetes-dashboard started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.431: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 27 17:03:45.431: INFO: calico-typha-deploy-784665cc66-sklqn from kube-system started at 2020-04-27 15:55:18 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.431: INFO: 	Container calico-typha ready: true, restart count 0
Apr 27 17:03:45.431: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-vvrz9 from kube-system started at 2020-04-27 15:55:07 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.431: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr 27 17:03:45.431: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r before test
Apr 27 17:03:45.472: INFO: calico-node-wqvt4 from kube-system started at 2020-04-27 15:58:38 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.472: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 17:03:45.472: INFO: kube-proxy-w7wxs from kube-system started at 2020-04-27 15:55:26 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.472: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 17:03:45.472: INFO: externalname-service-gvr7w from services-1327 started at 2020-04-27 17:03:34 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.472: INFO: 	Container externalname-service ready: true, restart count 0
Apr 27 17:03:45.472: INFO: execpodhtvfc from services-1327 started at 2020-04-27 17:03:37 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.472: INFO: 	Container agnhost-pause ready: true, restart count 0
Apr 27 17:03:45.472: INFO: node-problem-detector-pd7fh from kube-system started at 2020-04-27 15:55:26 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.472: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 17:03:45.472: INFO: node-exporter-l2x79 from kube-system started at 2020-04-27 15:55:26 +0000 UTC (1 container statuses recorded)
Apr 27 17:03:45.472: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-ff2e7098-95c3-436d-98d5-f8ea8b52c45a 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-ff2e7098-95c3-436d-98d5-f8ea8b52c45a off the node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r
STEP: verifying the node doesn't have the label kubernetes.io/e2e-ff2e7098-95c3-436d-98d5-f8ea8b52c45a
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:08:53.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5876" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:308.580 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":277,"completed":229,"skipped":3841,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:08:53.731: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6651
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl logs
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1288
STEP: creating an pod
Apr 27 17:08:53.919: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run logs-generator --image=us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 --namespace=kubectl-6651 -- logs-generator --log-lines-total 100 --run-duration 20s'
Apr 27 17:08:54.439: INFO: stderr: ""
Apr 27 17:08:54.439: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Waiting for log generator to start.
Apr 27 17:08:54.439: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Apr 27 17:08:54.439: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-6651" to be "running and ready, or succeeded"
Apr 27 17:08:54.451: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 11.18951ms
Apr 27 17:08:56.463: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023299445s
Apr 27 17:08:58.475: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.035428931s
Apr 27 17:08:58.475: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Apr 27 17:08:58.475: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Apr 27 17:08:58.475: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-6651'
Apr 27 17:08:58.676: INFO: stderr: ""
Apr 27 17:08:58.676: INFO: stdout: "I0427 17:08:56.062868       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/t5gg 385\nI0427 17:08:56.263016       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/j9b5 484\nI0427 17:08:56.463015       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/krg5 453\nI0427 17:08:56.663037       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/f7h 247\nI0427 17:08:56.863038       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/86sc 304\nI0427 17:08:57.063007       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/gv9j 513\nI0427 17:08:57.263002       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/rd4 306\nI0427 17:08:57.463028       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/xlj 240\nI0427 17:08:57.663033       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/6wtg 519\nI0427 17:08:57.863004       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/s6lh 527\nI0427 17:08:58.062969       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/8qp 451\nI0427 17:08:58.264909       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/l88 478\nI0427 17:08:58.463045       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/kube-system/pods/ddb7 570\nI0427 17:08:58.663048       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/ldt 502\n"
STEP: limiting log lines
Apr 27 17:08:58.677: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-6651 --tail=1'
Apr 27 17:08:58.810: INFO: stderr: ""
Apr 27 17:08:58.810: INFO: stdout: "I0427 17:08:58.663048       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/ldt 502\n"
Apr 27 17:08:58.810: INFO: got output "I0427 17:08:58.663048       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/ldt 502\n"
STEP: limiting log bytes
Apr 27 17:08:58.810: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-6651 --limit-bytes=1'
Apr 27 17:08:59.091: INFO: stderr: ""
Apr 27 17:08:59.091: INFO: stdout: "I"
Apr 27 17:08:59.092: INFO: got output "I"
STEP: exposing timestamps
Apr 27 17:08:59.092: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-6651 --tail=1 --timestamps'
Apr 27 17:08:59.220: INFO: stderr: ""
Apr 27 17:08:59.220: INFO: stdout: "2020-04-27T17:08:59.0631746Z I0427 17:08:59.062996       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/wb74 592\n"
Apr 27 17:08:59.220: INFO: got output "2020-04-27T17:08:59.0631746Z I0427 17:08:59.062996       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/wb74 592\n"
STEP: restricting to a time range
Apr 27 17:09:01.721: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-6651 --since=1s'
Apr 27 17:09:01.851: INFO: stderr: ""
Apr 27 17:09:01.851: INFO: stdout: "I0427 17:09:00.862974       1 logs_generator.go:76] 24 PUT /api/v1/namespaces/kube-system/pods/9dl4 507\nI0427 17:09:01.062959       1 logs_generator.go:76] 25 POST /api/v1/namespaces/kube-system/pods/b2r 525\nI0427 17:09:01.262996       1 logs_generator.go:76] 26 GET /api/v1/namespaces/kube-system/pods/h5ln 316\nI0427 17:09:01.463024       1 logs_generator.go:76] 27 POST /api/v1/namespaces/ns/pods/f7wf 538\nI0427 17:09:01.663036       1 logs_generator.go:76] 28 POST /api/v1/namespaces/default/pods/6cc 478\n"
Apr 27 17:09:01.852: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-6651 --since=24h'
Apr 27 17:09:01.995: INFO: stderr: ""
Apr 27 17:09:01.995: INFO: stdout: "I0427 17:08:56.062868       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/t5gg 385\nI0427 17:08:56.263016       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/j9b5 484\nI0427 17:08:56.463015       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/krg5 453\nI0427 17:08:56.663037       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/f7h 247\nI0427 17:08:56.863038       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/86sc 304\nI0427 17:08:57.063007       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/gv9j 513\nI0427 17:08:57.263002       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/rd4 306\nI0427 17:08:57.463028       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/xlj 240\nI0427 17:08:57.663033       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/6wtg 519\nI0427 17:08:57.863004       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/s6lh 527\nI0427 17:08:58.062969       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/8qp 451\nI0427 17:08:58.264909       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/l88 478\nI0427 17:08:58.463045       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/kube-system/pods/ddb7 570\nI0427 17:08:58.663048       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/ldt 502\nI0427 17:08:58.862983       1 logs_generator.go:76] 14 GET /api/v1/namespaces/ns/pods/mnp 529\nI0427 17:08:59.062996       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/wb74 592\nI0427 17:08:59.262982       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/2f9 243\nI0427 17:08:59.462981       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/dtr 306\nI0427 17:08:59.662994       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/m6gg 342\nI0427 17:08:59.863105       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/hhg 304\nI0427 17:09:00.063193       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/rfj 514\nI0427 17:09:00.263139       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/m4w8 525\nI0427 17:09:00.463012       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/default/pods/26q 478\nI0427 17:09:00.663000       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/ns/pods/b2vl 376\nI0427 17:09:00.862974       1 logs_generator.go:76] 24 PUT /api/v1/namespaces/kube-system/pods/9dl4 507\nI0427 17:09:01.062959       1 logs_generator.go:76] 25 POST /api/v1/namespaces/kube-system/pods/b2r 525\nI0427 17:09:01.262996       1 logs_generator.go:76] 26 GET /api/v1/namespaces/kube-system/pods/h5ln 316\nI0427 17:09:01.463024       1 logs_generator.go:76] 27 POST /api/v1/namespaces/ns/pods/f7wf 538\nI0427 17:09:01.663036       1 logs_generator.go:76] 28 POST /api/v1/namespaces/default/pods/6cc 478\nI0427 17:09:01.862983       1 logs_generator.go:76] 29 PUT /api/v1/namespaces/kube-system/pods/mcf 540\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1294
Apr 27 17:09:01.995: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pod logs-generator --namespace=kubectl-6651'
Apr 27 17:09:04.986: INFO: stderr: ""
Apr 27 17:09:04.986: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:09:04.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6651" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":277,"completed":230,"skipped":3877,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:09:05.019: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-1176
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:09:05.206: INFO: Creating ReplicaSet my-hostname-basic-0b952cf9-b765-4ab0-9211-8b3146f6affd
Apr 27 17:09:05.233: INFO: Pod name my-hostname-basic-0b952cf9-b765-4ab0-9211-8b3146f6affd: Found 1 pods out of 1
Apr 27 17:09:05.233: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-0b952cf9-b765-4ab0-9211-8b3146f6affd" is running
Apr 27 17:09:07.256: INFO: Pod "my-hostname-basic-0b952cf9-b765-4ab0-9211-8b3146f6affd-5z85f" is running (conditions: [])
Apr 27 17:09:07.256: INFO: Trying to dial the pod
Apr 27 17:09:12.375: INFO: Controller my-hostname-basic-0b952cf9-b765-4ab0-9211-8b3146f6affd: Got expected result from replica 1 [my-hostname-basic-0b952cf9-b765-4ab0-9211-8b3146f6affd-5z85f]: "my-hostname-basic-0b952cf9-b765-4ab0-9211-8b3146f6affd-5z85f", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:09:12.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1176" for this suite.
•{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":277,"completed":231,"skipped":3915,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:09:12.410: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1702
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap that has name configmap-test-emptyKey-d3ebd5bd-1024-4c8e-b88c-3ed29a5330fe
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:09:12.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1702" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":277,"completed":232,"skipped":3924,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:09:12.638: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5906
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override command
Apr 27 17:09:12.845: INFO: Waiting up to 5m0s for pod "client-containers-bf8f7e00-7f68-411e-ad9a-cb9d27368ef3" in namespace "containers-5906" to be "Succeeded or Failed"
Apr 27 17:09:12.855: INFO: Pod "client-containers-bf8f7e00-7f68-411e-ad9a-cb9d27368ef3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.454748ms
Apr 27 17:09:14.867: INFO: Pod "client-containers-bf8f7e00-7f68-411e-ad9a-cb9d27368ef3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022284478s
Apr 27 17:09:16.879: INFO: Pod "client-containers-bf8f7e00-7f68-411e-ad9a-cb9d27368ef3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034500373s
STEP: Saw pod success
Apr 27 17:09:16.879: INFO: Pod "client-containers-bf8f7e00-7f68-411e-ad9a-cb9d27368ef3" satisfied condition "Succeeded or Failed"
Apr 27 17:09:16.890: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod client-containers-bf8f7e00-7f68-411e-ad9a-cb9d27368ef3 container test-container: <nil>
STEP: delete the pod
Apr 27 17:09:16.925: INFO: Waiting for pod client-containers-bf8f7e00-7f68-411e-ad9a-cb9d27368ef3 to disappear
Apr 27 17:09:16.939: INFO: Pod client-containers-bf8f7e00-7f68-411e-ad9a-cb9d27368ef3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:09:16.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5906" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":277,"completed":233,"skipped":4043,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:09:16.976: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8830
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-37f580cb-75b5-494f-acc2-3d9a9035f0dd
STEP: Creating a pod to test consume secrets
Apr 27 17:09:17.195: INFO: Waiting up to 5m0s for pod "pod-secrets-4b8b1e1c-90f9-40d3-a373-9ea6f0899515" in namespace "secrets-8830" to be "Succeeded or Failed"
Apr 27 17:09:17.223: INFO: Pod "pod-secrets-4b8b1e1c-90f9-40d3-a373-9ea6f0899515": Phase="Pending", Reason="", readiness=false. Elapsed: 27.761683ms
Apr 27 17:09:19.234: INFO: Pod "pod-secrets-4b8b1e1c-90f9-40d3-a373-9ea6f0899515": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039061905s
Apr 27 17:09:21.246: INFO: Pod "pod-secrets-4b8b1e1c-90f9-40d3-a373-9ea6f0899515": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051132498s
STEP: Saw pod success
Apr 27 17:09:21.246: INFO: Pod "pod-secrets-4b8b1e1c-90f9-40d3-a373-9ea6f0899515" satisfied condition "Succeeded or Failed"
Apr 27 17:09:21.257: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-secrets-4b8b1e1c-90f9-40d3-a373-9ea6f0899515 container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:09:21.294: INFO: Waiting for pod pod-secrets-4b8b1e1c-90f9-40d3-a373-9ea6f0899515 to disappear
Apr 27 17:09:21.305: INFO: Pod pod-secrets-4b8b1e1c-90f9-40d3-a373-9ea6f0899515 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:09:21.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8830" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":234,"skipped":4061,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:09:21.338: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4896
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service nodeport-service with the type=NodePort in namespace services-4896
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-4896
STEP: creating replication controller externalsvc in namespace services-4896
I0427 17:09:21.595249    7292 runners.go:190] Created replication controller with name: externalsvc, namespace: services-4896, replica count: 2
I0427 17:09:24.646284    7292 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Apr 27 17:09:24.691: INFO: Creating new exec pod
Apr 27 17:09:28.726: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-4896 execpodg5gn6 -- /bin/sh -x -c nslookup nodeport-service'
Apr 27 17:09:29.310: INFO: stderr: "+ nslookup nodeport-service\n"
Apr 27 17:09:29.310: INFO: stdout: "Server:\t\t100.104.0.10\nAddress:\t100.104.0.10#53\n\nnodeport-service.services-4896.svc.cluster.local\tcanonical name = externalsvc.services-4896.svc.cluster.local.\nName:\texternalsvc.services-4896.svc.cluster.local\nAddress: 100.106.64.37\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-4896, will wait for the garbage collector to delete the pods
Apr 27 17:09:29.387: INFO: Deleting ReplicationController externalsvc took: 14.964102ms
Apr 27 17:09:29.888: INFO: Terminating ReplicationController externalsvc pods took: 500.563228ms
Apr 27 17:09:38.618: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:09:38.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4896" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":277,"completed":235,"skipped":4089,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:09:38.667: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5382
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-5382
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating statefulset ss in namespace statefulset-5382
Apr 27 17:09:38.891: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Apr 27 17:09:48.903: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 17:09:48.969: INFO: Deleting all statefulset in ns statefulset-5382
Apr 27 17:09:48.980: INFO: Scaling statefulset ss to 0
Apr 27 17:10:09.027: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 17:10:09.038: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:10:09.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5382" for this suite.
•{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":277,"completed":236,"skipped":4110,"failed":0}

------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:10:09.109: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8748
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-8748
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Apr 27 17:10:09.332: INFO: Found 1 stateful pods, waiting for 3
Apr 27 17:10:19.345: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 17:10:19.345: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 17:10:19.345: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 17:10:19.387: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8748 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 17:10:19.995: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 17:10:19.995: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 17:10:19.995: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Apr 27 17:10:30.084: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Apr 27 17:10:30.120: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8748 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:10:30.700: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 17:10:30.700: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 17:10:30.700: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 17:10:40.768: INFO: Waiting for StatefulSet statefulset-8748/ss2 to complete update
Apr 27 17:10:40.768: INFO: Waiting for Pod statefulset-8748/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 27 17:10:40.768: INFO: Waiting for Pod statefulset-8748/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 27 17:10:50.791: INFO: Waiting for StatefulSet statefulset-8748/ss2 to complete update
Apr 27 17:10:50.791: INFO: Waiting for Pod statefulset-8748/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Apr 27 17:11:00.792: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8748 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 17:11:01.396: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 17:11:01.396: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 17:11:01.396: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 17:11:11.480: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Apr 27 17:11:11.514: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8748 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:11:12.006: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 17:11:12.006: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 17:11:12.006: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 17:11:32.075: INFO: Waiting for StatefulSet statefulset-8748/ss2 to complete update
Apr 27 17:11:32.075: INFO: Waiting for Pod statefulset-8748/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 17:11:42.099: INFO: Deleting all statefulset in ns statefulset-8748
Apr 27 17:11:42.110: INFO: Scaling statefulset ss2 to 0
Apr 27 17:12:02.158: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 17:12:02.170: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:12:02.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8748" for this suite.
•{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":277,"completed":237,"skipped":4110,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:12:02.239: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6901
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:12:02.914: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604322, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604322, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604322, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604322, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:12:04.925: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604322, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604322, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604322, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604322, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:12:07.946: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:12:18.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6901" for this suite.
STEP: Destroying namespace "webhook-6901-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":277,"completed":238,"skipped":4115,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:12:18.594: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9073
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9073.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-9073.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9073.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-9073.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9073.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9073.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-9073.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9073.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-9073.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9073.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 17:12:22.932: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:22.975: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:22.988: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:23.001: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:23.180: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:23.194: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:23.210: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:23.223: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:23.320: INFO: Lookups using dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9073.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9073.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local jessie_udp@dns-test-service-2.dns-9073.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9073.svc.cluster.local]

Apr 27 17:12:28.334: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:28.348: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:28.360: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:28.380: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:28.560: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:28.609: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:28.624: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:28.636: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:28.775: INFO: Lookups using dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9073.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9073.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local jessie_udp@dns-test-service-2.dns-9073.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9073.svc.cluster.local]

Apr 27 17:12:33.335: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:33.378: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:33.392: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:33.404: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:33.583: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:33.596: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:33.608: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:33.619: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:33.715: INFO: Lookups using dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9073.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9073.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local jessie_udp@dns-test-service-2.dns-9073.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9073.svc.cluster.local]

Apr 27 17:12:38.334: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:38.347: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:38.360: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:38.382: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:38.522: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:38.536: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:38.549: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:38.563: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:38.701: INFO: Lookups using dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9073.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9073.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local jessie_udp@dns-test-service-2.dns-9073.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9073.svc.cluster.local]

Apr 27 17:12:43.335: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:43.378: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:43.391: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:43.406: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:43.547: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:43.559: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:43.571: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:43.585: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:43.682: INFO: Lookups using dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9073.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9073.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local jessie_udp@dns-test-service-2.dns-9073.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9073.svc.cluster.local]

Apr 27 17:12:48.334: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:48.347: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:48.360: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:48.391: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:48.573: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:48.587: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:48.599: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:48.612: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9073.svc.cluster.local from pod dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40: the server could not find the requested resource (get pods dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40)
Apr 27 17:12:48.748: INFO: Lookups using dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9073.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9073.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9073.svc.cluster.local jessie_udp@dns-test-service-2.dns-9073.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9073.svc.cluster.local]

Apr 27 17:12:54.095: INFO: DNS probes using dns-9073/dns-test-5000eeaa-d16e-4647-9809-c0f99d4d3a40 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:12:54.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9073" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":277,"completed":239,"skipped":4137,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:12:54.167: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-910
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:12:54.352: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr 27 17:12:58.448: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-910 create -f -'
Apr 27 17:12:59.177: INFO: stderr: ""
Apr 27 17:12:59.177: INFO: stdout: "e2e-test-crd-publish-openapi-2978-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 27 17:12:59.177: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-910 delete e2e-test-crd-publish-openapi-2978-crds test-cr'
Apr 27 17:12:59.364: INFO: stderr: ""
Apr 27 17:12:59.364: INFO: stdout: "e2e-test-crd-publish-openapi-2978-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Apr 27 17:12:59.364: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-910 apply -f -'
Apr 27 17:12:59.643: INFO: stderr: ""
Apr 27 17:12:59.643: INFO: stdout: "e2e-test-crd-publish-openapi-2978-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 27 17:12:59.643: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-910 delete e2e-test-crd-publish-openapi-2978-crds test-cr'
Apr 27 17:12:59.797: INFO: stderr: ""
Apr 27 17:12:59.797: INFO: stdout: "e2e-test-crd-publish-openapi-2978-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Apr 27 17:12:59.797: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-2978-crds'
Apr 27 17:13:00.075: INFO: stderr: ""
Apr 27 17:13:00.075: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2978-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:13:03.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-910" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":277,"completed":240,"skipped":4154,"failed":0}
SSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:13:03.756: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-1631
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Apr 27 17:13:08.506: INFO: Successfully updated pod "adopt-release-kqt77"
STEP: Checking that the Job readopts the Pod
Apr 27 17:13:08.506: INFO: Waiting up to 15m0s for pod "adopt-release-kqt77" in namespace "job-1631" to be "adopted"
Apr 27 17:13:08.517: INFO: Pod "adopt-release-kqt77": Phase="Running", Reason="", readiness=true. Elapsed: 10.483754ms
Apr 27 17:13:10.529: INFO: Pod "adopt-release-kqt77": Phase="Running", Reason="", readiness=true. Elapsed: 2.022918239s
Apr 27 17:13:10.529: INFO: Pod "adopt-release-kqt77" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Apr 27 17:13:11.055: INFO: Successfully updated pod "adopt-release-kqt77"
STEP: Checking that the Job releases the Pod
Apr 27 17:13:11.055: INFO: Waiting up to 15m0s for pod "adopt-release-kqt77" in namespace "job-1631" to be "released"
Apr 27 17:13:11.070: INFO: Pod "adopt-release-kqt77": Phase="Running", Reason="", readiness=true. Elapsed: 14.727305ms
Apr 27 17:13:11.070: INFO: Pod "adopt-release-kqt77" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:13:11.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1631" for this suite.
•{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":277,"completed":241,"skipped":4157,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:13:11.102: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-461
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-downwardapi-bsvv
STEP: Creating a pod to test atomic-volume-subpath
Apr 27 17:13:11.325: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-bsvv" in namespace "subpath-461" to be "Succeeded or Failed"
Apr 27 17:13:11.335: INFO: Pod "pod-subpath-test-downwardapi-bsvv": Phase="Pending", Reason="", readiness=false. Elapsed: 10.540134ms
Apr 27 17:13:13.347: INFO: Pod "pod-subpath-test-downwardapi-bsvv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022271472s
Apr 27 17:13:15.358: INFO: Pod "pod-subpath-test-downwardapi-bsvv": Phase="Running", Reason="", readiness=true. Elapsed: 4.033534463s
Apr 27 17:13:17.378: INFO: Pod "pod-subpath-test-downwardapi-bsvv": Phase="Running", Reason="", readiness=true. Elapsed: 6.053611282s
Apr 27 17:13:19.391: INFO: Pod "pod-subpath-test-downwardapi-bsvv": Phase="Running", Reason="", readiness=true. Elapsed: 8.06571505s
Apr 27 17:13:21.402: INFO: Pod "pod-subpath-test-downwardapi-bsvv": Phase="Running", Reason="", readiness=true. Elapsed: 10.077102729s
Apr 27 17:13:23.414: INFO: Pod "pod-subpath-test-downwardapi-bsvv": Phase="Running", Reason="", readiness=true. Elapsed: 12.088855621s
Apr 27 17:13:25.426: INFO: Pod "pod-subpath-test-downwardapi-bsvv": Phase="Running", Reason="", readiness=true. Elapsed: 14.101123446s
Apr 27 17:13:27.438: INFO: Pod "pod-subpath-test-downwardapi-bsvv": Phase="Running", Reason="", readiness=true. Elapsed: 16.112957309s
Apr 27 17:13:29.450: INFO: Pod "pod-subpath-test-downwardapi-bsvv": Phase="Running", Reason="", readiness=true. Elapsed: 18.124885472s
Apr 27 17:13:31.461: INFO: Pod "pod-subpath-test-downwardapi-bsvv": Phase="Running", Reason="", readiness=true. Elapsed: 20.13634231s
Apr 27 17:13:33.473: INFO: Pod "pod-subpath-test-downwardapi-bsvv": Phase="Running", Reason="", readiness=true. Elapsed: 22.147902755s
Apr 27 17:13:35.485: INFO: Pod "pod-subpath-test-downwardapi-bsvv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.159728449s
STEP: Saw pod success
Apr 27 17:13:35.485: INFO: Pod "pod-subpath-test-downwardapi-bsvv" satisfied condition "Succeeded or Failed"
Apr 27 17:13:35.496: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-subpath-test-downwardapi-bsvv container test-container-subpath-downwardapi-bsvv: <nil>
STEP: delete the pod
Apr 27 17:13:35.656: INFO: Waiting for pod pod-subpath-test-downwardapi-bsvv to disappear
Apr 27 17:13:35.667: INFO: Pod pod-subpath-test-downwardapi-bsvv no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-bsvv
Apr 27 17:13:35.667: INFO: Deleting pod "pod-subpath-test-downwardapi-bsvv" in namespace "subpath-461"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:13:35.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-461" for this suite.
•{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [LinuxOnly] [Conformance]","total":277,"completed":242,"skipped":4179,"failed":0}
SSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:13:35.713: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8101
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Apr 27 17:13:35.898: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-8101'
Apr 27 17:13:36.180: INFO: stderr: ""
Apr 27 17:13:36.180: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 27 17:13:36.180: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8101'
Apr 27 17:13:36.296: INFO: stderr: ""
Apr 27 17:13:36.296: INFO: stdout: "update-demo-nautilus-dz8j2 update-demo-nautilus-gsnsf "
Apr 27 17:13:36.296: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-dz8j2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8101'
Apr 27 17:13:36.404: INFO: stderr: ""
Apr 27 17:13:36.404: INFO: stdout: ""
Apr 27 17:13:36.404: INFO: update-demo-nautilus-dz8j2 is created but not running
Apr 27 17:13:41.405: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8101'
Apr 27 17:13:41.533: INFO: stderr: ""
Apr 27 17:13:41.533: INFO: stdout: "update-demo-nautilus-dz8j2 update-demo-nautilus-gsnsf "
Apr 27 17:13:41.533: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-dz8j2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8101'
Apr 27 17:13:41.656: INFO: stderr: ""
Apr 27 17:13:41.656: INFO: stdout: "true"
Apr 27 17:13:41.656: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-dz8j2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8101'
Apr 27 17:13:41.763: INFO: stderr: ""
Apr 27 17:13:41.764: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 17:13:41.764: INFO: validating pod update-demo-nautilus-dz8j2
Apr 27 17:13:41.861: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 17:13:41.861: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 17:13:41.861: INFO: update-demo-nautilus-dz8j2 is verified up and running
Apr 27 17:13:41.861: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-gsnsf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8101'
Apr 27 17:13:41.968: INFO: stderr: ""
Apr 27 17:13:41.968: INFO: stdout: "true"
Apr 27 17:13:41.968: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-gsnsf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8101'
Apr 27 17:13:42.080: INFO: stderr: ""
Apr 27 17:13:42.080: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 17:13:42.081: INFO: validating pod update-demo-nautilus-gsnsf
Apr 27 17:13:42.177: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 17:13:42.177: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 17:13:42.177: INFO: update-demo-nautilus-gsnsf is verified up and running
STEP: using delete to clean up resources
Apr 27 17:13:42.178: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-8101'
Apr 27 17:13:42.298: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 17:13:42.298: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 27 17:13:42.298: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8101'
Apr 27 17:13:42.420: INFO: stderr: "No resources found in kubectl-8101 namespace.\n"
Apr 27 17:13:42.420: INFO: stdout: ""
Apr 27 17:13:42.420: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-8101 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 27 17:13:42.545: INFO: stderr: ""
Apr 27 17:13:42.545: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:13:42.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8101" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":277,"completed":243,"skipped":4184,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:13:42.582: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4442
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:13:42.770: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-4442'
Apr 27 17:13:43.062: INFO: stderr: ""
Apr 27 17:13:43.063: INFO: stdout: "replicationcontroller/agnhost-master created\n"
Apr 27 17:13:43.063: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-4442'
Apr 27 17:13:43.352: INFO: stderr: ""
Apr 27 17:13:43.352: INFO: stdout: "service/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Apr 27 17:13:44.387: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:13:44.387: INFO: Found 0 / 1
Apr 27 17:13:45.379: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:13:45.379: INFO: Found 0 / 1
Apr 27 17:13:46.379: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:13:46.379: INFO: Found 1 / 1
Apr 27 17:13:46.379: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 27 17:13:46.390: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:13:46.390: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 27 17:13:46.390: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe pod agnhost-master-d9lxr --namespace=kubectl-4442'
Apr 27 17:13:46.525: INFO: stderr: ""
Apr 27 17:13:46.525: INFO: stdout: "Name:         agnhost-master-d9lxr\nNamespace:    kubectl-4442\nPriority:     0\nNode:         shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r/10.250.0.5\nStart Time:   Mon, 27 Apr 2020 17:13:43 +0000\nLabels:       app=agnhost\n              role=master\nAnnotations:  cni.projectcalico.org/podIP: 100.64.1.62/32\n              cni.projectcalico.org/podIPs: 100.64.1.62/32\n              kubernetes.io/psp: e2e-test-privileged-psp\nStatus:       Running\nIP:           100.64.1.62\nIPs:\n  IP:           100.64.1.62\nControlled By:  ReplicationController/agnhost-master\nContainers:\n  agnhost-master:\n    Container ID:   docker://bb5049f534707d96c394b71561a21a464284cfbd371b20bbe3b7a4c1c43b76a7\n    Image:          us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Image ID:       docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 27 Apr 2020 17:13:45 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-fjts7 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-fjts7:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-fjts7\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                                                     Message\n  ----    ------     ----       ----                                                     -------\n  Normal  Scheduled  <unknown>  default-scheduler                                        Successfully assigned kubectl-4442/agnhost-master-d9lxr to shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r\n  Normal  Pulled     2s         kubelet, shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Container image \"us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\" already present on machine\n  Normal  Created    2s         kubelet, shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Created container agnhost-master\n  Normal  Started    1s         kubelet, shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r  Started container agnhost-master\n"
Apr 27 17:13:46.525: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe rc agnhost-master --namespace=kubectl-4442'
Apr 27 17:13:46.671: INFO: stderr: ""
Apr 27 17:13:46.671: INFO: stdout: "Name:         agnhost-master\nNamespace:    kubectl-4442\nSelector:     app=agnhost,role=master\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=master\n  Containers:\n   agnhost-master:\n    Image:        us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-master-d9lxr\n"
Apr 27 17:13:46.671: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe service agnhost-master --namespace=kubectl-4442'
Apr 27 17:13:46.812: INFO: stderr: ""
Apr 27 17:13:46.812: INFO: stdout: "Name:              agnhost-master\nNamespace:         kubectl-4442\nLabels:            app=agnhost\n                   role=master\nAnnotations:       <none>\nSelector:          app=agnhost,role=master\nType:              ClusterIP\nIP:                100.105.155.99\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         100.64.1.62:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr 27 17:13:46.833: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2'
Apr 27 17:13:47.008: INFO: stderr: ""
Apr 27 17:13:47.008: INFO: stdout: "Name:               shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=Standard_D2_v3\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=westeurope\n                    failure-domain.beta.kubernetes.io/zone=0\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/instance-type=Standard_D2_v3\n                    node.kubernetes.io/role=node\n                    topology.kubernetes.io/region=westeurope\n                    topology.kubernetes.io/zone=0\n                    worker.garden.sapcloud.io/group=worker-1\n                    worker.gardener.cloud/pool=worker-1\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    node.machine.sapcloud.io/last-applied-anno-labels-taints:\n                      {\"metadata\":{\"creationTimestamp\":null,\"labels\":{\"node.kubernetes.io/role\":\"node\",\"worker.garden.sapcloud.io/group\":\"worker-1\",\"worker.gard...\n                    projectcalico.org/IPv4IPIPTunnelAddr: 100.64.0.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 27 Apr 2020 15:54:23 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2\n  AcquireTime:     <unset>\n  RenewTime:       Mon, 27 Apr 2020 17:13:39 +0000\nConditions:\n  Type                          Status  LastHeartbeatTime                 LastTransitionTime                Reason                          Message\n  ----                          ------  -----------------                 ------------------                ------                          -------\n  FrequentUnregisterNetDevice   False   Mon, 27 Apr 2020 17:13:35 +0000   Mon, 27 Apr 2020 15:57:41 +0000   NoFrequentUnregisterNetDevice   node is functioning properly\n  FrequentKubeletRestart        False   Mon, 27 Apr 2020 17:13:35 +0000   Mon, 27 Apr 2020 15:57:41 +0000   NoFrequentKubeletRestart        kubelet is functioning properly\n  FrequentDockerRestart         False   Mon, 27 Apr 2020 17:13:35 +0000   Mon, 27 Apr 2020 15:57:41 +0000   NoFrequentDockerRestart         docker is functioning properly\n  FrequentContainerdRestart     False   Mon, 27 Apr 2020 17:13:35 +0000   Mon, 27 Apr 2020 15:57:41 +0000   NoFrequentContainerdRestart     containerd is functioning properly\n  KernelDeadlock                False   Mon, 27 Apr 2020 17:13:35 +0000   Mon, 27 Apr 2020 15:57:41 +0000   KernelHasNoDeadlock             kernel has no deadlock\n  ReadonlyFilesystem            False   Mon, 27 Apr 2020 17:13:35 +0000   Mon, 27 Apr 2020 15:57:41 +0000   FilesystemIsNotReadOnly         Filesystem is not read-only\n  CorruptDockerOverlay2         False   Mon, 27 Apr 2020 17:13:35 +0000   Mon, 27 Apr 2020 15:57:41 +0000   NoCorruptDockerOverlay2         docker overlay2 is functioning properly\n  NetworkUnavailable            False   Mon, 27 Apr 2020 15:54:40 +0000   Mon, 27 Apr 2020 15:54:40 +0000   RouteCreated                    RouteController created a route\n  MemoryPressure                False   Mon, 27 Apr 2020 17:13:45 +0000   Mon, 27 Apr 2020 15:54:23 +0000   KubeletHasSufficientMemory      kubelet has sufficient memory available\n  DiskPressure                  False   Mon, 27 Apr 2020 17:13:45 +0000   Mon, 27 Apr 2020 15:54:23 +0000   KubeletHasNoDiskPressure        kubelet has no disk pressure\n  PIDPressure                   False   Mon, 27 Apr 2020 17:13:45 +0000   Mon, 27 Apr 2020 15:54:23 +0000   KubeletHasSufficientPID         kubelet has sufficient PID available\n  Ready                         True    Mon, 27 Apr 2020 17:13:45 +0000   Mon, 27 Apr 2020 15:55:07 +0000   KubeletReady                    kubelet is posting ready status\nAddresses:\n  Hostname:    shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2\n  InternalIP:  10.250.0.4\nCapacity:\n  attachable-volumes-azure-disk:  4\n  cpu:                            2\n  ephemeral-storage:              33136428Ki\n  hugepages-1Gi:                  0\n  hugepages-2Mi:                  0\n  memory:                         8145312Ki\n  pods:                           110\nAllocatable:\n  attachable-volumes-azure-disk:  4\n  cpu:                            1920m\n  ephemeral-storage:              32235117134\n  hugepages-1Gi:                  0\n  hugepages-2Mi:                  0\n  memory:                         6850017684\n  pods:                           110\nSystem Info:\n  Machine ID:                 83ab9a3fa05f49f382a3a391522e1f28\n  System UUID:                a279bc78-0323-924e-945d-54859cfac092\n  Boot ID:                    fdf3eb34-0b63-435d-9fcb-a310e11ac802\n  Kernel Version:             4.19.86-coreos\n  OS Image:                   Container Linux by CoreOS 2303.3.0 (Rhyolite)\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://18.6.3\n  Kubelet Version:            v1.18.2\n  Kube-Proxy Version:         v1.18.2\nPodCIDR:                      100.64.0.0/24\nPodCIDRs:                     100.64.0.0/24\nProviderID:                   azure:///subscriptions/0b9904be-2a50-4fda-a947-c5f1b1d07666/resourceGroups/shoot--it--tmcuv-7tj/providers/Microsoft.Compute/virtualMachines/shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2\nNon-terminated Pods:          (17 in total)\n  Namespace                   Name                                                               CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                   ----                                                               ------------  ----------  ---------------  -------------  ---\n  kube-system                 addons-nginx-ingress-controller-6cf77756b5-8pc2l                   100m (5%)     2 (104%)    100Mi (1%)       1Gi (15%)      80m\n  kube-system                 addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-vvrz9    0 (0%)        0 (0%)      0 (0%)           0 (0%)         80m\n  kube-system                 blackbox-exporter-5dc75b79b7-rlcrv                                 5m (0%)       10m (0%)    5Mi (0%)         35Mi (0%)      80m\n  kube-system                 calico-node-vertical-autoscaler-74d4897db8-5nqsp                   10m (0%)      10m (0%)    50Mi (0%)        50Mi (0%)      80m\n  kube-system                 calico-node-zzbmr                                                  250m (13%)    800m (41%)  100Mi (1%)       700Mi (10%)    75m\n  kube-system                 calico-typha-deploy-784665cc66-sklqn                               200m (10%)    500m (26%)  100Mi (1%)       700Mi (10%)    80m\n  kube-system                 calico-typha-horizontal-autoscaler-6fdd5d8746-5wf5t                10m (0%)      10m (0%)    50Mi (0%)        50Mi (0%)      80m\n  kube-system                 calico-typha-vertical-autoscaler-5b477c88cf-b245g                  10m (0%)      10m (0%)    50Mi (0%)        50Mi (0%)      80m\n  kube-system                 coredns-5cb857d789-6774c                                           50m (2%)      100m (5%)   15Mi (0%)        100Mi (1%)     80m\n  kube-system                 coredns-5cb857d789-dh4pj                                           50m (2%)      100m (5%)   15Mi (0%)        100Mi (1%)     80m\n  kube-system                 kube-proxy-z62w2                                                   20m (1%)      0 (0%)      64Mi (0%)        0 (0%)         79m\n  kube-system                 metrics-server-66897b5d79-tngw9                                    20m (1%)      100m (5%)   100Mi (1%)       1Gi (15%)      80m\n  kube-system                 node-exporter-sq8cz                                                5m (0%)       25m (1%)    10Mi (0%)        100Mi (1%)     79m\n  kube-system                 node-problem-detector-jtcdh                                        20m (1%)      200m (10%)  20Mi (0%)        100Mi (1%)     79m\n  kube-system                 vpn-shoot-6df545ddcb-7js5s                                         100m (5%)     1 (52%)     100Mi (1%)       1000Mi (15%)   80m\n  kubernetes-dashboard        dashboard-metrics-scraper-76c7b697bc-44kb6                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         80m\n  kubernetes-dashboard        kubernetes-dashboard-6b586c4cb4-kgfwx                              50m (2%)      100m (5%)   50Mi (0%)        256Mi (3%)     80m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                       Requests     Limits\n  --------                       --------     ------\n  cpu                            900m (46%)   4965m (258%)\n  memory                         829Mi (12%)  5289Mi (80%)\n  ephemeral-storage              0 (0%)       0 (0%)\n  hugepages-1Gi                  0 (0%)       0 (0%)\n  hugepages-2Mi                  0 (0%)       0 (0%)\n  attachable-volumes-azure-disk  0            0\nEvents:                          <none>\n"
Apr 27 17:13:47.008: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe namespace kubectl-4442'
Apr 27 17:13:47.143: INFO: stderr: ""
Apr 27 17:13:47.143: INFO: stdout: "Name:         kubectl-4442\nLabels:       e2e-framework=kubectl\n              e2e-run=cb249f49-815c-4512-beef-dd3a6acd2447\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:13:47.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4442" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":277,"completed":244,"skipped":4197,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:13:47.176: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-620
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-620
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 27 17:13:47.361: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 27 17:13:47.427: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 17:13:49.439: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 17:13:51.439: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:13:53.439: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:13:55.438: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:13:57.439: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:13:59.439: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:14:01.439: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:14:03.439: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:14:05.439: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr 27 17:14:05.525: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Apr 27 17:14:09.674: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.64:8080/dial?request=hostname&protocol=udp&host=100.64.0.64&port=8081&tries=1'] Namespace:pod-network-test-620 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 17:14:09.674: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 17:14:10.105: INFO: Waiting for responses: map[]
Apr 27 17:14:10.116: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.64:8080/dial?request=hostname&protocol=udp&host=100.64.1.63&port=8081&tries=1'] Namespace:pod-network-test-620 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 17:14:10.117: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 17:14:10.593: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:10.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-620" for this suite.
•{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":277,"completed":245,"skipped":4262,"failed":0}
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:10.628: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8156
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 27 17:14:10.828: INFO: Waiting up to 5m0s for pod "pod-5b7fe692-8f54-435c-bf95-8f115616fc0f" in namespace "emptydir-8156" to be "Succeeded or Failed"
Apr 27 17:14:10.839: INFO: Pod "pod-5b7fe692-8f54-435c-bf95-8f115616fc0f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.672076ms
Apr 27 17:14:12.850: INFO: Pod "pod-5b7fe692-8f54-435c-bf95-8f115616fc0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022194777s
Apr 27 17:14:14.862: INFO: Pod "pod-5b7fe692-8f54-435c-bf95-8f115616fc0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034163275s
STEP: Saw pod success
Apr 27 17:14:14.862: INFO: Pod "pod-5b7fe692-8f54-435c-bf95-8f115616fc0f" satisfied condition "Succeeded or Failed"
Apr 27 17:14:14.873: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-5b7fe692-8f54-435c-bf95-8f115616fc0f container test-container: <nil>
STEP: delete the pod
Apr 27 17:14:14.911: INFO: Waiting for pod pod-5b7fe692-8f54-435c-bf95-8f115616fc0f to disappear
Apr 27 17:14:14.921: INFO: Pod pod-5b7fe692-8f54-435c-bf95-8f115616fc0f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:14.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8156" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":246,"skipped":4267,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:14.957: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-32
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:14:15.157: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-9d35bef3-7594-4fce-8f06-9f554e54d579" in namespace "security-context-test-32" to be "Succeeded or Failed"
Apr 27 17:14:15.167: INFO: Pod "busybox-privileged-false-9d35bef3-7594-4fce-8f06-9f554e54d579": Phase="Pending", Reason="", readiness=false. Elapsed: 10.207339ms
Apr 27 17:14:17.178: INFO: Pod "busybox-privileged-false-9d35bef3-7594-4fce-8f06-9f554e54d579": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021303109s
Apr 27 17:14:19.190: INFO: Pod "busybox-privileged-false-9d35bef3-7594-4fce-8f06-9f554e54d579": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032791315s
Apr 27 17:14:19.190: INFO: Pod "busybox-privileged-false-9d35bef3-7594-4fce-8f06-9f554e54d579" satisfied condition "Succeeded or Failed"
Apr 27 17:14:19.207: INFO: Got logs for pod "busybox-privileged-false-9d35bef3-7594-4fce-8f06-9f554e54d579": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:19.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-32" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":247,"skipped":4278,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:19.246: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-3799
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:23.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3799" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":277,"completed":248,"skipped":4299,"failed":0}
SSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:23.574: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6621
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Apr 27 17:14:23.769: INFO: Waiting up to 5m0s for pod "downward-api-94fa4950-905c-4908-a3f9-0dc91c981c02" in namespace "downward-api-6621" to be "Succeeded or Failed"
Apr 27 17:14:23.780: INFO: Pod "downward-api-94fa4950-905c-4908-a3f9-0dc91c981c02": Phase="Pending", Reason="", readiness=false. Elapsed: 10.476627ms
Apr 27 17:14:25.792: INFO: Pod "downward-api-94fa4950-905c-4908-a3f9-0dc91c981c02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022514125s
Apr 27 17:14:27.804: INFO: Pod "downward-api-94fa4950-905c-4908-a3f9-0dc91c981c02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034688129s
STEP: Saw pod success
Apr 27 17:14:27.804: INFO: Pod "downward-api-94fa4950-905c-4908-a3f9-0dc91c981c02" satisfied condition "Succeeded or Failed"
Apr 27 17:14:27.815: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod downward-api-94fa4950-905c-4908-a3f9-0dc91c981c02 container dapi-container: <nil>
STEP: delete the pod
Apr 27 17:14:27.851: INFO: Waiting for pod downward-api-94fa4950-905c-4908-a3f9-0dc91c981c02 to disappear
Apr 27 17:14:27.862: INFO: Pod downward-api-94fa4950-905c-4908-a3f9-0dc91c981c02 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:27.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6621" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":277,"completed":249,"skipped":4302,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:27.898: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-9960
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 27 17:14:36.198: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 27 17:14:36.208: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 27 17:14:38.209: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 27 17:14:38.220: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 27 17:14:40.209: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 27 17:14:40.220: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:40.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9960" for this suite.
•{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":277,"completed":250,"skipped":4316,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:40.254: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-7209
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test hostPath mode
Apr 27 17:14:40.455: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-7209" to be "Succeeded or Failed"
Apr 27 17:14:40.467: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 11.349442ms
Apr 27 17:14:42.479: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023716965s
Apr 27 17:14:44.491: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035899034s
STEP: Saw pod success
Apr 27 17:14:44.491: INFO: Pod "pod-host-path-test" satisfied condition "Succeeded or Failed"
Apr 27 17:14:44.502: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Apr 27 17:14:44.619: INFO: Waiting for pod pod-host-path-test to disappear
Apr 27 17:14:44.630: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:44.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-7209" for this suite.
•{"msg":"PASSED [sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":251,"skipped":4324,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:44.663: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3277
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:51.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3277" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":277,"completed":252,"skipped":4337,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:51.920: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9874
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Apr 27 17:14:52.103: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 27 17:14:52.146: INFO: Waiting for terminating namespaces to be deleted...
Apr 27 17:14:52.157: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 before test
Apr 27 17:14:52.188: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-vvrz9 from kube-system started at 2020-04-27 15:55:07 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:52.188: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr 27 17:14:52.188: INFO: node-problem-detector-jtcdh from kube-system started at 2020-04-27 15:54:25 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:52.188: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 17:14:52.188: INFO: calico-typha-horizontal-autoscaler-6fdd5d8746-5wf5t from kube-system started at 2020-04-27 15:55:07 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:52.188: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 17:14:52.188: INFO: metrics-server-66897b5d79-tngw9 from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:52.188: INFO: 	Container metrics-server ready: true, restart count 0
Apr 27 17:14:52.188: INFO: coredns-5cb857d789-dh4pj from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:52.188: INFO: 	Container coredns ready: true, restart count 0
Apr 27 17:14:52.188: INFO: dashboard-metrics-scraper-76c7b697bc-44kb6 from kubernetes-dashboard started at 2020-04-27 15:55:09 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:52.188: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 27 17:14:52.188: INFO: kube-proxy-z62w2 from kube-system started at 2020-04-27 15:54:25 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:52.188: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 17:14:52.188: INFO: addons-nginx-ingress-controller-6cf77756b5-8pc2l from kube-system started at 2020-04-27 15:55:07 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:52.188: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 27 17:14:52.188: INFO: vpn-shoot-6df545ddcb-7js5s from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:52.188: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 27 17:14:52.188: INFO: calico-node-zzbmr from kube-system started at 2020-04-27 15:58:17 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:52.188: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 17:14:52.188: INFO: node-exporter-sq8cz from kube-system started at 2020-04-27 15:54:25 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:52.188: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 17:14:52.188: INFO: blackbox-exporter-5dc75b79b7-rlcrv from kube-system started at 2020-04-27 15:54:25 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:52.188: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 27 17:14:52.188: INFO: calico-typha-vertical-autoscaler-5b477c88cf-b245g from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:52.188: INFO: 	Container autoscaler ready: true, restart count 3
Apr 27 17:14:52.188: INFO: calico-node-vertical-autoscaler-74d4897db8-5nqsp from kube-system started at 2020-04-27 15:55:18 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:52.188: INFO: 	Container autoscaler ready: true, restart count 3
Apr 27 17:14:52.188: INFO: coredns-5cb857d789-6774c from kube-system started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:52.188: INFO: 	Container coredns ready: true, restart count 0
Apr 27 17:14:52.188: INFO: kubernetes-dashboard-6b586c4cb4-kgfwx from kubernetes-dashboard started at 2020-04-27 15:55:08 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:52.188: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 27 17:14:52.188: INFO: calico-typha-deploy-784665cc66-sklqn from kube-system started at 2020-04-27 15:55:18 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:52.188: INFO: 	Container calico-typha ready: true, restart count 0
Apr 27 17:14:52.189: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r before test
Apr 27 17:14:52.242: INFO: node-exporter-l2x79 from kube-system started at 2020-04-27 15:55:26 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:52.242: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 17:14:52.242: INFO: calico-node-wqvt4 from kube-system started at 2020-04-27 15:58:38 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:52.242: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 17:14:52.242: INFO: kube-proxy-w7wxs from kube-system started at 2020-04-27 15:55:26 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:52.242: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 17:14:52.242: INFO: node-problem-detector-pd7fh from kube-system started at 2020-04-27 15:55:26 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:52.242: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 17:14:52.242: INFO: pod-handle-http-request from container-lifecycle-hook-9960 started at 2020-04-27 17:14:28 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:52.242: INFO: 	Container pod-handle-http-request ready: false, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: verifying the node has the label node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2
STEP: verifying the node has the label node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r
Apr 27 17:14:52.332: INFO: Pod pod-handle-http-request requesting resource cpu=0m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r
Apr 27 17:14:52.332: INFO: Pod addons-nginx-ingress-controller-6cf77756b5-8pc2l requesting resource cpu=100m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2
Apr 27 17:14:52.332: INFO: Pod addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-vvrz9 requesting resource cpu=0m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2
Apr 27 17:14:52.332: INFO: Pod blackbox-exporter-5dc75b79b7-rlcrv requesting resource cpu=5m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2
Apr 27 17:14:52.332: INFO: Pod calico-node-vertical-autoscaler-74d4897db8-5nqsp requesting resource cpu=10m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2
Apr 27 17:14:52.332: INFO: Pod calico-node-wqvt4 requesting resource cpu=250m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r
Apr 27 17:14:52.332: INFO: Pod calico-node-zzbmr requesting resource cpu=250m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2
Apr 27 17:14:52.332: INFO: Pod calico-typha-deploy-784665cc66-sklqn requesting resource cpu=200m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2
Apr 27 17:14:52.332: INFO: Pod calico-typha-horizontal-autoscaler-6fdd5d8746-5wf5t requesting resource cpu=10m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2
Apr 27 17:14:52.332: INFO: Pod calico-typha-vertical-autoscaler-5b477c88cf-b245g requesting resource cpu=10m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2
Apr 27 17:14:52.332: INFO: Pod coredns-5cb857d789-6774c requesting resource cpu=50m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2
Apr 27 17:14:52.332: INFO: Pod coredns-5cb857d789-dh4pj requesting resource cpu=50m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2
Apr 27 17:14:52.332: INFO: Pod kube-proxy-w7wxs requesting resource cpu=20m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r
Apr 27 17:14:52.332: INFO: Pod kube-proxy-z62w2 requesting resource cpu=20m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2
Apr 27 17:14:52.332: INFO: Pod metrics-server-66897b5d79-tngw9 requesting resource cpu=20m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2
Apr 27 17:14:52.332: INFO: Pod node-exporter-l2x79 requesting resource cpu=5m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r
Apr 27 17:14:52.332: INFO: Pod node-exporter-sq8cz requesting resource cpu=5m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2
Apr 27 17:14:52.332: INFO: Pod node-problem-detector-jtcdh requesting resource cpu=20m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2
Apr 27 17:14:52.332: INFO: Pod node-problem-detector-pd7fh requesting resource cpu=20m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r
Apr 27 17:14:52.332: INFO: Pod vpn-shoot-6df545ddcb-7js5s requesting resource cpu=100m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2
Apr 27 17:14:52.332: INFO: Pod dashboard-metrics-scraper-76c7b697bc-44kb6 requesting resource cpu=0m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2
Apr 27 17:14:52.332: INFO: Pod kubernetes-dashboard-6b586c4cb4-kgfwx requesting resource cpu=50m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2
STEP: Starting Pods to consume most of the cluster CPU.
Apr 27 17:14:52.332: INFO: Creating a pod which consumes cpu=714m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2
Apr 27 17:14:52.347: INFO: Creating a pod which consumes cpu=1137m on Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6995e75e-668d-4457-ab59-4c67b9be1a73.1609bc9523048cc7], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9874/filler-pod-6995e75e-668d-4457-ab59-4c67b9be1a73 to shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6995e75e-668d-4457-ab59-4c67b9be1a73.1609bc9569168fec], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6995e75e-668d-4457-ab59-4c67b9be1a73.1609bc957ffd73ce], Reason = [Created], Message = [Created container filler-pod-6995e75e-668d-4457-ab59-4c67b9be1a73]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6995e75e-668d-4457-ab59-4c67b9be1a73.1609bc9589ec92aa], Reason = [Started], Message = [Started container filler-pod-6995e75e-668d-4457-ab59-4c67b9be1a73]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-87682968-4812-4f34-86bf-461968b78837.1609bc9523b3501a], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9874/filler-pod-87682968-4812-4f34-86bf-461968b78837 to shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-87682968-4812-4f34-86bf-461968b78837.1609bc9567ff7a49], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-87682968-4812-4f34-86bf-461968b78837.1609bc957fb211f8], Reason = [Created], Message = [Created container filler-pod-87682968-4812-4f34-86bf-461968b78837]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-87682968-4812-4f34-86bf-461968b78837.1609bc95881a0a6a], Reason = [Started], Message = [Started container filler-pod-87682968-4812-4f34-86bf-461968b78837]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1609bc96175e4da6], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1609bc9617bd2ba6], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:57.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9874" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":277,"completed":253,"skipped":4392,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:57.565: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3236
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:14:57.750: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr 27 17:15:01.444: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3236 create -f -'
Apr 27 17:15:02.207: INFO: stderr: ""
Apr 27 17:15:02.207: INFO: stdout: "e2e-test-crd-publish-openapi-3877-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 27 17:15:02.207: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3236 delete e2e-test-crd-publish-openapi-3877-crds test-cr'
Apr 27 17:15:02.379: INFO: stderr: ""
Apr 27 17:15:02.379: INFO: stdout: "e2e-test-crd-publish-openapi-3877-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Apr 27 17:15:02.379: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3236 apply -f -'
Apr 27 17:15:02.688: INFO: stderr: ""
Apr 27 17:15:02.688: INFO: stdout: "e2e-test-crd-publish-openapi-3877-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 27 17:15:02.688: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3236 delete e2e-test-crd-publish-openapi-3877-crds test-cr'
Apr 27 17:15:02.816: INFO: stderr: ""
Apr 27 17:15:02.816: INFO: stdout: "e2e-test-crd-publish-openapi-3877-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Apr 27 17:15:02.816: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-3877-crds'
Apr 27 17:15:03.097: INFO: stderr: ""
Apr 27 17:15:03.097: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3877-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:15:06.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3236" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":277,"completed":254,"skipped":4395,"failed":0}
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:15:06.877: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4674
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-projected-zgjx
STEP: Creating a pod to test atomic-volume-subpath
Apr 27 17:15:07.108: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-zgjx" in namespace "subpath-4674" to be "Succeeded or Failed"
Apr 27 17:15:07.119: INFO: Pod "pod-subpath-test-projected-zgjx": Phase="Pending", Reason="", readiness=false. Elapsed: 10.384305ms
Apr 27 17:15:09.131: INFO: Pod "pod-subpath-test-projected-zgjx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022258778s
Apr 27 17:15:11.143: INFO: Pod "pod-subpath-test-projected-zgjx": Phase="Running", Reason="", readiness=true. Elapsed: 4.034636465s
Apr 27 17:15:13.155: INFO: Pod "pod-subpath-test-projected-zgjx": Phase="Running", Reason="", readiness=true. Elapsed: 6.046908903s
Apr 27 17:15:15.167: INFO: Pod "pod-subpath-test-projected-zgjx": Phase="Running", Reason="", readiness=true. Elapsed: 8.058865876s
Apr 27 17:15:17.179: INFO: Pod "pod-subpath-test-projected-zgjx": Phase="Running", Reason="", readiness=true. Elapsed: 10.070598875s
Apr 27 17:15:19.191: INFO: Pod "pod-subpath-test-projected-zgjx": Phase="Running", Reason="", readiness=true. Elapsed: 12.082940276s
Apr 27 17:15:21.204: INFO: Pod "pod-subpath-test-projected-zgjx": Phase="Running", Reason="", readiness=true. Elapsed: 14.095127665s
Apr 27 17:15:23.215: INFO: Pod "pod-subpath-test-projected-zgjx": Phase="Running", Reason="", readiness=true. Elapsed: 16.107092108s
Apr 27 17:15:25.227: INFO: Pod "pod-subpath-test-projected-zgjx": Phase="Running", Reason="", readiness=true. Elapsed: 18.118867326s
Apr 27 17:15:27.239: INFO: Pod "pod-subpath-test-projected-zgjx": Phase="Running", Reason="", readiness=true. Elapsed: 20.130618021s
Apr 27 17:15:29.250: INFO: Pod "pod-subpath-test-projected-zgjx": Phase="Running", Reason="", readiness=true. Elapsed: 22.141675083s
Apr 27 17:15:31.262: INFO: Pod "pod-subpath-test-projected-zgjx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.153799453s
STEP: Saw pod success
Apr 27 17:15:31.262: INFO: Pod "pod-subpath-test-projected-zgjx" satisfied condition "Succeeded or Failed"
Apr 27 17:15:31.274: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-subpath-test-projected-zgjx container test-container-subpath-projected-zgjx: <nil>
STEP: delete the pod
Apr 27 17:15:31.353: INFO: Waiting for pod pod-subpath-test-projected-zgjx to disappear
Apr 27 17:15:31.363: INFO: Pod pod-subpath-test-projected-zgjx no longer exists
STEP: Deleting pod pod-subpath-test-projected-zgjx
Apr 27 17:15:31.363: INFO: Deleting pod "pod-subpath-test-projected-zgjx" in namespace "subpath-4674"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:15:31.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4674" for this suite.
•{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [LinuxOnly] [Conformance]","total":277,"completed":255,"skipped":4400,"failed":0}
S
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:15:31.414: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9591
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:15:57.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9591" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":277,"completed":256,"skipped":4401,"failed":0}
SSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:15:57.205: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-406
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-406/configmap-test-009f9846-8221-4db5-a3dd-f242b58df7f0
STEP: Creating a pod to test consume configMaps
Apr 27 17:15:57.417: INFO: Waiting up to 5m0s for pod "pod-configmaps-dfd7ef75-25c4-42ba-a12d-4d2526286625" in namespace "configmap-406" to be "Succeeded or Failed"
Apr 27 17:15:57.427: INFO: Pod "pod-configmaps-dfd7ef75-25c4-42ba-a12d-4d2526286625": Phase="Pending", Reason="", readiness=false. Elapsed: 10.230294ms
Apr 27 17:15:59.439: INFO: Pod "pod-configmaps-dfd7ef75-25c4-42ba-a12d-4d2526286625": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021589949s
Apr 27 17:16:01.450: INFO: Pod "pod-configmaps-dfd7ef75-25c4-42ba-a12d-4d2526286625": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033333936s
STEP: Saw pod success
Apr 27 17:16:01.450: INFO: Pod "pod-configmaps-dfd7ef75-25c4-42ba-a12d-4d2526286625" satisfied condition "Succeeded or Failed"
Apr 27 17:16:01.461: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-configmaps-dfd7ef75-25c4-42ba-a12d-4d2526286625 container env-test: <nil>
STEP: delete the pod
Apr 27 17:16:01.499: INFO: Waiting for pod pod-configmaps-dfd7ef75-25c4-42ba-a12d-4d2526286625 to disappear
Apr 27 17:16:01.509: INFO: Pod pod-configmaps-dfd7ef75-25c4-42ba-a12d-4d2526286625 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:16:01.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-406" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":277,"completed":257,"skipped":4405,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:16:01.548: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9774
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Apr 27 17:16:02.381: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:16:02.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0427 17:16:02.381485    7292 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-9774" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":277,"completed":258,"skipped":4471,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:16:02.412: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2508
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-95f94003-96c6-4d49-a21c-41fc1f5caf37
STEP: Creating a pod to test consume configMaps
Apr 27 17:16:02.617: INFO: Waiting up to 5m0s for pod "pod-configmaps-a3751a10-2896-4099-8db1-949c57524548" in namespace "configmap-2508" to be "Succeeded or Failed"
Apr 27 17:16:02.628: INFO: Pod "pod-configmaps-a3751a10-2896-4099-8db1-949c57524548": Phase="Pending", Reason="", readiness=false. Elapsed: 10.426404ms
Apr 27 17:16:04.639: INFO: Pod "pod-configmaps-a3751a10-2896-4099-8db1-949c57524548": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022070347s
Apr 27 17:16:06.654: INFO: Pod "pod-configmaps-a3751a10-2896-4099-8db1-949c57524548": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036686702s
STEP: Saw pod success
Apr 27 17:16:06.654: INFO: Pod "pod-configmaps-a3751a10-2896-4099-8db1-949c57524548" satisfied condition "Succeeded or Failed"
Apr 27 17:16:06.664: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-configmaps-a3751a10-2896-4099-8db1-949c57524548 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 17:16:06.705: INFO: Waiting for pod pod-configmaps-a3751a10-2896-4099-8db1-949c57524548 to disappear
Apr 27 17:16:06.715: INFO: Pod pod-configmaps-a3751a10-2896-4099-8db1-949c57524548 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:16:06.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2508" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":259,"skipped":4514,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:16:06.746: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7609
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Apr 27 17:16:06.938: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Apr 27 17:16:21.048: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 17:16:24.924: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:16:39.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7609" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":277,"completed":260,"skipped":4520,"failed":0}
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:16:39.282: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6155
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Apr 27 17:16:39.470: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-6155'
Apr 27 17:16:39.761: INFO: stderr: ""
Apr 27 17:16:39.761: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Apr 27 17:16:40.773: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:16:40.773: INFO: Found 0 / 1
Apr 27 17:16:41.773: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:16:41.773: INFO: Found 0 / 1
Apr 27 17:16:42.773: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:16:42.773: INFO: Found 1 / 1
Apr 27 17:16:42.773: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Apr 27 17:16:42.784: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:16:42.784: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 27 17:16:42.784: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config patch pod agnhost-master-4tkdd --namespace=kubectl-6155 -p {"metadata":{"annotations":{"x":"y"}}}'
Apr 27 17:16:42.926: INFO: stderr: ""
Apr 27 17:16:42.926: INFO: stdout: "pod/agnhost-master-4tkdd patched\n"
STEP: checking annotations
Apr 27 17:16:42.937: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:16:42.937: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:16:42.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6155" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":277,"completed":261,"skipped":4528,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:16:42.969: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-155
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-secret-bb6v
STEP: Creating a pod to test atomic-volume-subpath
Apr 27 17:16:43.186: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-bb6v" in namespace "subpath-155" to be "Succeeded or Failed"
Apr 27 17:16:43.196: INFO: Pod "pod-subpath-test-secret-bb6v": Phase="Pending", Reason="", readiness=false. Elapsed: 10.358743ms
Apr 27 17:16:45.209: INFO: Pod "pod-subpath-test-secret-bb6v": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022599626s
Apr 27 17:16:47.221: INFO: Pod "pod-subpath-test-secret-bb6v": Phase="Running", Reason="", readiness=true. Elapsed: 4.034676418s
Apr 27 17:16:49.233: INFO: Pod "pod-subpath-test-secret-bb6v": Phase="Running", Reason="", readiness=true. Elapsed: 6.046756344s
Apr 27 17:16:51.245: INFO: Pod "pod-subpath-test-secret-bb6v": Phase="Running", Reason="", readiness=true. Elapsed: 8.05889827s
Apr 27 17:16:53.256: INFO: Pod "pod-subpath-test-secret-bb6v": Phase="Running", Reason="", readiness=true. Elapsed: 10.069900289s
Apr 27 17:16:55.268: INFO: Pod "pod-subpath-test-secret-bb6v": Phase="Running", Reason="", readiness=true. Elapsed: 12.081861888s
Apr 27 17:16:57.280: INFO: Pod "pod-subpath-test-secret-bb6v": Phase="Running", Reason="", readiness=true. Elapsed: 14.093559577s
Apr 27 17:16:59.292: INFO: Pod "pod-subpath-test-secret-bb6v": Phase="Running", Reason="", readiness=true. Elapsed: 16.105595034s
Apr 27 17:17:01.304: INFO: Pod "pod-subpath-test-secret-bb6v": Phase="Running", Reason="", readiness=true. Elapsed: 18.117603605s
Apr 27 17:17:03.316: INFO: Pod "pod-subpath-test-secret-bb6v": Phase="Running", Reason="", readiness=true. Elapsed: 20.130109436s
Apr 27 17:17:05.328: INFO: Pod "pod-subpath-test-secret-bb6v": Phase="Running", Reason="", readiness=true. Elapsed: 22.142148013s
Apr 27 17:17:07.341: INFO: Pod "pod-subpath-test-secret-bb6v": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.154662215s
STEP: Saw pod success
Apr 27 17:17:07.341: INFO: Pod "pod-subpath-test-secret-bb6v" satisfied condition "Succeeded or Failed"
Apr 27 17:17:07.352: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-subpath-test-secret-bb6v container test-container-subpath-secret-bb6v: <nil>
STEP: delete the pod
Apr 27 17:17:07.388: INFO: Waiting for pod pod-subpath-test-secret-bb6v to disappear
Apr 27 17:17:07.399: INFO: Pod pod-subpath-test-secret-bb6v no longer exists
STEP: Deleting pod pod-subpath-test-secret-bb6v
Apr 27 17:17:07.399: INFO: Deleting pod "pod-subpath-test-secret-bb6v" in namespace "subpath-155"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:17:07.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-155" for this suite.
•{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [LinuxOnly] [Conformance]","total":277,"completed":262,"skipped":4554,"failed":0}
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:17:07.443: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2765
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 27 17:17:07.723: INFO: Number of nodes with available pods: 0
Apr 27 17:17:07.723: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:17:08.754: INFO: Number of nodes with available pods: 0
Apr 27 17:17:08.754: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:17:09.755: INFO: Number of nodes with available pods: 0
Apr 27 17:17:09.755: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:17:10.755: INFO: Number of nodes with available pods: 2
Apr 27 17:17:10.755: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Apr 27 17:17:10.818: INFO: Number of nodes with available pods: 1
Apr 27 17:17:10.818: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:17:11.851: INFO: Number of nodes with available pods: 1
Apr 27 17:17:11.851: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:17:12.851: INFO: Number of nodes with available pods: 1
Apr 27 17:17:12.851: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:17:13.851: INFO: Number of nodes with available pods: 2
Apr 27 17:17:13.851: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2765, will wait for the garbage collector to delete the pods
Apr 27 17:17:13.946: INFO: Deleting DaemonSet.extensions daemon-set took: 13.493353ms
Apr 27 17:17:14.047: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.317548ms
Apr 27 17:17:27.358: INFO: Number of nodes with available pods: 0
Apr 27 17:17:27.358: INFO: Number of running nodes: 0, number of available pods: 0
Apr 27 17:17:27.384: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2765/daemonsets","resourceVersion":"33100"},"items":null}

Apr 27 17:17:27.394: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2765/pods","resourceVersion":"33100"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:17:27.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2765" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":277,"completed":263,"skipped":4556,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:17:27.462: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-995
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-projected-all-test-volume-04a6df22-106d-462f-a531-230f368920a1
STEP: Creating secret with name secret-projected-all-test-volume-91c735cb-77e8-4fbf-bd86-977e07945060
STEP: Creating a pod to test Check all projections for projected volume plugin
Apr 27 17:17:27.686: INFO: Waiting up to 5m0s for pod "projected-volume-9688f840-a021-4445-ae49-028d29da158a" in namespace "projected-995" to be "Succeeded or Failed"
Apr 27 17:17:27.696: INFO: Pod "projected-volume-9688f840-a021-4445-ae49-028d29da158a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.068852ms
Apr 27 17:17:29.708: INFO: Pod "projected-volume-9688f840-a021-4445-ae49-028d29da158a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021214961s
Apr 27 17:17:31.719: INFO: Pod "projected-volume-9688f840-a021-4445-ae49-028d29da158a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032824322s
STEP: Saw pod success
Apr 27 17:17:31.719: INFO: Pod "projected-volume-9688f840-a021-4445-ae49-028d29da158a" satisfied condition "Succeeded or Failed"
Apr 27 17:17:31.730: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod projected-volume-9688f840-a021-4445-ae49-028d29da158a container projected-all-volume-test: <nil>
STEP: delete the pod
Apr 27 17:17:31.767: INFO: Waiting for pod projected-volume-9688f840-a021-4445-ae49-028d29da158a to disappear
Apr 27 17:17:31.777: INFO: Pod projected-volume-9688f840-a021-4445-ae49-028d29da158a no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:17:31.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-995" for this suite.
•{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":277,"completed":264,"skipped":4562,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:17:31.809: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-7955
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:164
Apr 27 17:17:31.991: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 27 17:18:32.110: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:18:32.122: INFO: Starting informer...
STEP: Starting pod...
Apr 27 17:18:32.147: INFO: Pod is running on shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Apr 27 17:18:32.187: INFO: Pod wasn't evicted. Proceeding
Apr 27 17:18:32.187: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Apr 27 17:19:47.224: INFO: Pod wasn't evicted. Test successful
[AfterEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:19:47.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-7955" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":277,"completed":265,"skipped":4573,"failed":0}
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:19:47.258: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6728
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:19:47.462: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c02b2e4d-e64d-47bb-bfdf-b497d332b458" in namespace "downward-api-6728" to be "Succeeded or Failed"
Apr 27 17:19:47.472: INFO: Pod "downwardapi-volume-c02b2e4d-e64d-47bb-bfdf-b497d332b458": Phase="Pending", Reason="", readiness=false. Elapsed: 10.395112ms
Apr 27 17:19:49.483: INFO: Pod "downwardapi-volume-c02b2e4d-e64d-47bb-bfdf-b497d332b458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021693978s
Apr 27 17:19:51.495: INFO: Pod "downwardapi-volume-c02b2e4d-e64d-47bb-bfdf-b497d332b458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033490437s
STEP: Saw pod success
Apr 27 17:19:51.495: INFO: Pod "downwardapi-volume-c02b2e4d-e64d-47bb-bfdf-b497d332b458" satisfied condition "Succeeded or Failed"
Apr 27 17:19:51.506: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod downwardapi-volume-c02b2e4d-e64d-47bb-bfdf-b497d332b458 container client-container: <nil>
STEP: delete the pod
Apr 27 17:19:51.630: INFO: Waiting for pod downwardapi-volume-c02b2e4d-e64d-47bb-bfdf-b497d332b458 to disappear
Apr 27 17:19:51.641: INFO: Pod downwardapi-volume-c02b2e4d-e64d-47bb-bfdf-b497d332b458 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:19:51.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6728" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":266,"skipped":4577,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:19:51.674: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9392
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9392.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9392.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 17:19:56.475: INFO: DNS probes using dns-9392/dns-test-abe5073f-e970-45ab-846a-10a36431f6ee succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:19:56.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9392" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":277,"completed":267,"skipped":4596,"failed":0}
S
------------------------------
[k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:19:56.529: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-5052
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:345
Apr 27 17:19:56.717: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 27 17:20:56.833: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:20:56.844: INFO: Starting informer...
STEP: Starting pods...
Apr 27 17:20:56.880: INFO: Pod1 is running on shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r. Tainting Node
Apr 27 17:21:00.937: INFO: Pod2 is running on shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Apr 27 17:21:18.526: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Apr 27 17:21:38.527: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:21:38.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-5052" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":277,"completed":268,"skipped":4597,"failed":0}
SSSSSSS
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:21:38.589: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename limitrange
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in limitrange-1246
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
Apr 27 17:21:38.805: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
Apr 27 17:21:38.830: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr 27 17:21:38.830: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
Apr 27 17:21:38.853: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr 27 17:21:38.853: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
Apr 27 17:21:38.877: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Apr 27 17:21:38.877: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
Apr 27 17:21:45.968: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:21:45.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-1246" for this suite.
•{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":277,"completed":269,"skipped":4604,"failed":0}
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:21:46.017: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3404
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3404.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3404.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3404.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3404.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3404.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3404.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3404.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3404.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3404.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3404.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3404.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 200.101.104.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.104.101.200_udp@PTR;check="$$(dig +tcp +noall +answer +search 200.101.104.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.104.101.200_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3404.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3404.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3404.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3404.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3404.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3404.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3404.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3404.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3404.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3404.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3404.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 200.101.104.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.104.101.200_udp@PTR;check="$$(dig +tcp +noall +answer +search 200.101.104.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.104.101.200_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 17:21:50.395: INFO: Unable to read wheezy_udp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:21:50.438: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:21:50.450: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:21:50.463: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:21:50.898: INFO: Unable to read jessie_udp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:21:50.911: INFO: Unable to read jessie_tcp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:21:50.923: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:21:50.935: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:21:51.297: INFO: Lookups using dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c failed for: [wheezy_udp@dns-test-service.dns-3404.svc.cluster.local wheezy_tcp@dns-test-service.dns-3404.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local jessie_udp@dns-test-service.dns-3404.svc.cluster.local jessie_tcp@dns-test-service.dns-3404.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local]

Apr 27 17:21:56.311: INFO: Unable to read wheezy_udp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:21:56.354: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:21:56.367: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:21:56.379: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:21:56.774: INFO: Unable to read jessie_udp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:21:56.786: INFO: Unable to read jessie_tcp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:21:56.800: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:21:56.813: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:21:57.207: INFO: Lookups using dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c failed for: [wheezy_udp@dns-test-service.dns-3404.svc.cluster.local wheezy_tcp@dns-test-service.dns-3404.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local jessie_udp@dns-test-service.dns-3404.svc.cluster.local jessie_tcp@dns-test-service.dns-3404.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local]

Apr 27 17:22:01.310: INFO: Unable to read wheezy_udp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:01.354: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:01.367: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:01.380: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:01.772: INFO: Unable to read jessie_udp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:01.784: INFO: Unable to read jessie_tcp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:01.797: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:01.810: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:02.172: INFO: Lookups using dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c failed for: [wheezy_udp@dns-test-service.dns-3404.svc.cluster.local wheezy_tcp@dns-test-service.dns-3404.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local jessie_udp@dns-test-service.dns-3404.svc.cluster.local jessie_tcp@dns-test-service.dns-3404.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local]

Apr 27 17:22:06.311: INFO: Unable to read wheezy_udp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:06.325: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:06.338: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:06.356: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:06.791: INFO: Unable to read jessie_udp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:06.803: INFO: Unable to read jessie_tcp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:06.816: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:06.828: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:07.179: INFO: Lookups using dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c failed for: [wheezy_udp@dns-test-service.dns-3404.svc.cluster.local wheezy_tcp@dns-test-service.dns-3404.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local jessie_udp@dns-test-service.dns-3404.svc.cluster.local jessie_tcp@dns-test-service.dns-3404.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local]

Apr 27 17:22:11.311: INFO: Unable to read wheezy_udp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:11.324: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:11.337: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:11.350: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:11.742: INFO: Unable to read jessie_udp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:11.755: INFO: Unable to read jessie_tcp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:11.767: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:11.780: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:12.130: INFO: Lookups using dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c failed for: [wheezy_udp@dns-test-service.dns-3404.svc.cluster.local wheezy_tcp@dns-test-service.dns-3404.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local jessie_udp@dns-test-service.dns-3404.svc.cluster.local jessie_tcp@dns-test-service.dns-3404.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local]

Apr 27 17:22:16.312: INFO: Unable to read wheezy_udp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:16.325: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:16.338: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:16.351: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:16.744: INFO: Unable to read jessie_udp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:16.757: INFO: Unable to read jessie_tcp@dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:16.770: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:16.783: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local from pod dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c: the server could not find the requested resource (get pods dns-test-07cfe98c-8b39-4731-bc39-38830f55381c)
Apr 27 17:22:17.178: INFO: Lookups using dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c failed for: [wheezy_udp@dns-test-service.dns-3404.svc.cluster.local wheezy_tcp@dns-test-service.dns-3404.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local jessie_udp@dns-test-service.dns-3404.svc.cluster.local jessie_tcp@dns-test-service.dns-3404.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3404.svc.cluster.local]

Apr 27 17:22:22.536: INFO: DNS probes using dns-3404/dns-test-07cfe98c-8b39-4731-bc39-38830f55381c succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:22:22.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3404" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":277,"completed":270,"skipped":4608,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:22:22.643: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5150
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-bd6a4ecd-e927-44dd-9ac2-317c10b9f68c
STEP: Creating a pod to test consume configMaps
Apr 27 17:22:23.021: INFO: Waiting up to 5m0s for pod "pod-configmaps-de1976ed-1e89-44f3-94a7-af1c1b492d28" in namespace "configmap-5150" to be "Succeeded or Failed"
Apr 27 17:22:23.032: INFO: Pod "pod-configmaps-de1976ed-1e89-44f3-94a7-af1c1b492d28": Phase="Pending", Reason="", readiness=false. Elapsed: 10.302168ms
Apr 27 17:22:25.043: INFO: Pod "pod-configmaps-de1976ed-1e89-44f3-94a7-af1c1b492d28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021680251s
Apr 27 17:22:27.054: INFO: Pod "pod-configmaps-de1976ed-1e89-44f3-94a7-af1c1b492d28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032750408s
STEP: Saw pod success
Apr 27 17:22:27.054: INFO: Pod "pod-configmaps-de1976ed-1e89-44f3-94a7-af1c1b492d28" satisfied condition "Succeeded or Failed"
Apr 27 17:22:27.065: INFO: Trying to get logs from node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r pod pod-configmaps-de1976ed-1e89-44f3-94a7-af1c1b492d28 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 17:22:27.189: INFO: Waiting for pod pod-configmaps-de1976ed-1e89-44f3-94a7-af1c1b492d28 to disappear
Apr 27 17:22:27.200: INFO: Pod pod-configmaps-de1976ed-1e89-44f3-94a7-af1c1b492d28 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:22:27.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5150" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":271,"skipped":4617,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:22:27.233: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4616
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating all guestbook components
Apr 27 17:22:27.418: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-slave
  labels:
    app: agnhost
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: slave
    tier: backend

Apr 27 17:22:27.418: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-4616'
Apr 27 17:22:27.877: INFO: stderr: ""
Apr 27 17:22:27.877: INFO: stdout: "service/agnhost-slave created\n"
Apr 27 17:22:27.877: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-master
  labels:
    app: agnhost
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: master
    tier: backend

Apr 27 17:22:27.878: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-4616'
Apr 27 17:22:28.216: INFO: stderr: ""
Apr 27 17:22:28.216: INFO: stdout: "service/agnhost-master created\n"
Apr 27 17:22:28.216: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr 27 17:22:28.216: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-4616'
Apr 27 17:22:28.505: INFO: stderr: ""
Apr 27 17:22:28.505: INFO: stdout: "service/frontend created\n"
Apr 27 17:22:28.506: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Apr 27 17:22:28.506: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-4616'
Apr 27 17:22:28.769: INFO: stderr: ""
Apr 27 17:22:28.769: INFO: stdout: "deployment.apps/frontend created\n"
Apr 27 17:22:28.769: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 27 17:22:28.769: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-4616'
Apr 27 17:22:29.396: INFO: stderr: ""
Apr 27 17:22:29.396: INFO: stdout: "deployment.apps/agnhost-master created\n"
Apr 27 17:22:29.396: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--slaveof", "agnhost-master", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 27 17:22:29.396: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-4616'
Apr 27 17:22:29.616: INFO: stderr: ""
Apr 27 17:22:29.616: INFO: stdout: "deployment.apps/agnhost-slave created\n"
STEP: validating guestbook app
Apr 27 17:22:29.616: INFO: Waiting for all frontend pods to be Running.
Apr 27 17:22:34.667: INFO: Waiting for frontend to serve content.
Apr 27 17:22:34.764: INFO: Trying to add a new entry to the guestbook.
Apr 27 17:22:34.889: INFO: Verifying that added entry can be retrieved.
Apr 27 17:22:34.935: INFO: Failed to get response from guestbook. err: <nil>, response: {"data":""}
STEP: using delete to clean up resources
Apr 27 17:22:39.953: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-4616'
Apr 27 17:22:40.073: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 17:22:40.073: INFO: stdout: "service \"agnhost-slave\" force deleted\n"
STEP: using delete to clean up resources
Apr 27 17:22:40.073: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-4616'
Apr 27 17:22:40.191: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 17:22:40.191: INFO: stdout: "service \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 27 17:22:40.192: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-4616'
Apr 27 17:22:40.314: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 17:22:40.314: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 27 17:22:40.314: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-4616'
Apr 27 17:22:40.426: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 17:22:40.426: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 27 17:22:40.426: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-4616'
Apr 27 17:22:40.544: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 17:22:40.544: INFO: stdout: "deployment.apps \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 27 17:22:40.544: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmcuv-7tj.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-4616'
Apr 27 17:22:40.668: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 17:22:40.668: INFO: stdout: "deployment.apps \"agnhost-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:22:40.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4616" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":277,"completed":272,"skipped":4630,"failed":0}
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:22:40.702: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8768
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod test-webserver-c5c5de43-9953-4823-96ab-ce031bf3eba3 in namespace container-probe-8768
Apr 27 17:22:44.931: INFO: Started pod test-webserver-c5c5de43-9953-4823-96ab-ce031bf3eba3 in namespace container-probe-8768
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 17:22:44.942: INFO: Initial restart count of pod test-webserver-c5c5de43-9953-4823-96ab-ce031bf3eba3 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:26:46.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8768" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":277,"completed":273,"skipped":4634,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:26:46.443: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5892
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-91adaa7e-e2bd-496d-a075-e0168dfc952b
STEP: Creating secret with name s-test-opt-upd-6354eb98-4d54-4d99-a21d-ef37f58e86e9
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-91adaa7e-e2bd-496d-a075-e0168dfc952b
STEP: Updating secret s-test-opt-upd-6354eb98-4d54-4d99-a21d-ef37f58e86e9
STEP: Creating secret with name s-test-opt-create-04757583-eef0-4305-a960-92fd99c78e69
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:28:12.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5892" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":274,"skipped":4660,"failed":0}
SSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:28:12.105: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-7414
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Apr 27 17:28:16.354: INFO: &Pod{ObjectMeta:{send-events-41933b21-64cf-4cfc-9d89-af37d283a7ae  events-7414 /api/v1/namespaces/events-7414/pods/send-events-41933b21-64cf-4cfc-9d89-af37d283a7ae c11624d3-99a7-4522-868c-6c3976ecab12 36173 0 2020-04-27 17:28:12 +0000 UTC <nil> <nil> map[name:foo time:295991607] map[cni.projectcalico.org/podIP:100.64.1.96/32 cni.projectcalico.org/podIPs:100.64.1.96/32 kubernetes.io/psp:e2e-test-privileged-psp] [] []  [{e2e.test Update v1 2020-04-27 17:28:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 116 105 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 112 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 114 116 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 99 111 110 116 97 105 110 101 114 80 111 114 116 92 34 58 56 48 44 92 34 112 114 111 116 111 99 111 108 92 34 58 92 34 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 99 111 110 116 97 105 110 101 114 80 111 114 116 34 58 123 125 44 34 102 58 112 114 111 116 111 99 111 108 34 58 123 125 125 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:28:13 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:28:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 57 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-vrh56,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-vrh56,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-vrh56,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:28:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:28:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:28:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:28:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.1.96,StartTime:2020-04-27 17:28:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:28:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://ed05b2f6e41aedd04cf516ae0922d1fd1baae0a956afb39f91bf7786d25150d5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.96,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Apr 27 17:28:18.366: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Apr 27 17:28:20.377: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:28:20.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7414" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]","total":277,"completed":275,"skipped":4673,"failed":0}
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:28:20.423: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-439
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 27 17:28:20.721: INFO: Number of nodes with available pods: 0
Apr 27 17:28:20.721: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:28:21.753: INFO: Number of nodes with available pods: 0
Apr 27 17:28:21.753: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:28:22.757: INFO: Number of nodes with available pods: 0
Apr 27 17:28:22.757: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-5h4w2 is running more than one daemon pod
Apr 27 17:28:23.753: INFO: Number of nodes with available pods: 2
Apr 27 17:28:23.753: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Apr 27 17:28:23.818: INFO: Number of nodes with available pods: 1
Apr 27 17:28:23.818: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r is running more than one daemon pod
Apr 27 17:28:24.851: INFO: Number of nodes with available pods: 1
Apr 27 17:28:24.851: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r is running more than one daemon pod
Apr 27 17:28:25.851: INFO: Number of nodes with available pods: 1
Apr 27 17:28:25.851: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r is running more than one daemon pod
Apr 27 17:28:26.851: INFO: Number of nodes with available pods: 1
Apr 27 17:28:26.851: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r is running more than one daemon pod
Apr 27 17:28:27.851: INFO: Number of nodes with available pods: 1
Apr 27 17:28:27.851: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r is running more than one daemon pod
Apr 27 17:28:28.854: INFO: Number of nodes with available pods: 1
Apr 27 17:28:28.855: INFO: Node shoot--it--tmcuv-7tj-worker-1-584bbbcd45-pm97r is running more than one daemon pod
Apr 27 17:28:29.853: INFO: Number of nodes with available pods: 2
Apr 27 17:28:29.853: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-439, will wait for the garbage collector to delete the pods
Apr 27 17:28:29.939: INFO: Deleting DaemonSet.extensions daemon-set took: 14.008944ms
Apr 27 17:28:30.439: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.428374ms
Apr 27 17:28:38.551: INFO: Number of nodes with available pods: 0
Apr 27 17:28:38.551: INFO: Number of running nodes: 0, number of available pods: 0
Apr 27 17:28:38.562: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-439/daemonsets","resourceVersion":"36346"},"items":null}

Apr 27 17:28:38.572: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-439/pods","resourceVersion":"36346"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:28:38.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-439" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":277,"completed":276,"skipped":4676,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:28:38.787: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4598
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:28:39.786: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605319, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605319, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605319, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605319, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:28:41.797: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605319, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605319, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605319, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605319, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:28:44.828: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:28:45.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4598" for this suite.
STEP: Destroying namespace "webhook-4598-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":277,"completed":277,"skipped":4704,"failed":0}
SSSSSSSSSSSApr 27 17:28:45.221: INFO: Running AfterSuite actions on all nodes
Apr 27 17:28:45.221: INFO: Running AfterSuite actions on node 1
Apr 27 17:28:45.221: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/e2e/artifacts/1588003587/junit_01.xml
{"msg":"Test Suite completed","total":277,"completed":277,"skipped":4715,"failed":0}

Ran 277 of 4992 Specs in 4934.982 seconds
SUCCESS! -- 277 Passed | 0 Failed | 0 Flaked | 0 Pending | 4715 Skipped
PASS

Ginkgo ran 1 suite in 1h22m16.98377495s
Test Suite Passed
