Conformance test: not doing test setup.
I0427 16:19:23.975972    5439 test_context.go:423] Tolerating taints "node-role.kubernetes.io/master" when considering if nodes are ready
I0427 16:19:23.976087    5439 e2e.go:124] Starting e2e run "1c89e158-d4db-4fc9-b2a1-b6ea1e61f82a" on Ginkgo node 1
{"msg":"Test Suite starting","total":277,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1588004362 - Will randomize all specs
Will run 277 of 4992 specs

Apr 27 16:19:24.211: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:19:24.212: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr 27 16:19:24.235: INFO: Waiting up to 10m0s for all pods (need at least 1) in namespace 'kube-system' to be running and ready
Apr 27 16:19:24.281: INFO: 20 / 20 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr 27 16:19:24.281: INFO: expected 12 pod replicas in namespace 'kube-system', 12 are Running and Ready.
Apr 27 16:19:24.281: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr 27 16:19:24.293: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Apr 27 16:19:24.293: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Apr 27 16:19:24.293: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Apr 27 16:19:24.293: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-problem-detector' (0 seconds elapsed)
Apr 27 16:19:24.293: INFO: e2e test version: v1.18.2
Apr 27 16:19:24.295: INFO: kube-apiserver version: v1.18.2
Apr 27 16:19:24.295: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:19:24.300: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:19:24.301: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
Apr 27 16:19:24.346: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Apr 27 16:19:24.366: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-36
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0427 16:19:34.561315    5439 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 27 16:19:34.561: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:19:34.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-36" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":277,"completed":1,"skipped":14,"failed":0}
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:19:34.570: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9970
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:19:34.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9970" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":277,"completed":2,"skipped":15,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:19:34.754: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4535
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:19:34.908: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3d22d378-a49e-4ba2-8418-cde5ff3b71b4" in namespace "downward-api-4535" to be "Succeeded or Failed"
Apr 27 16:19:34.930: INFO: Pod "downwardapi-volume-3d22d378-a49e-4ba2-8418-cde5ff3b71b4": Phase="Pending", Reason="", readiness=false. Elapsed: 21.981481ms
Apr 27 16:19:36.936: INFO: Pod "downwardapi-volume-3d22d378-a49e-4ba2-8418-cde5ff3b71b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027084096s
Apr 27 16:19:38.940: INFO: Pod "downwardapi-volume-3d22d378-a49e-4ba2-8418-cde5ff3b71b4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031603162s
Apr 27 16:19:40.946: INFO: Pod "downwardapi-volume-3d22d378-a49e-4ba2-8418-cde5ff3b71b4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.037374466s
Apr 27 16:19:42.951: INFO: Pod "downwardapi-volume-3d22d378-a49e-4ba2-8418-cde5ff3b71b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.042851188s
STEP: Saw pod success
Apr 27 16:19:42.951: INFO: Pod "downwardapi-volume-3d22d378-a49e-4ba2-8418-cde5ff3b71b4" satisfied condition "Succeeded or Failed"
Apr 27 16:19:42.955: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downwardapi-volume-3d22d378-a49e-4ba2-8418-cde5ff3b71b4 container client-container: <nil>
STEP: delete the pod
Apr 27 16:19:43.064: INFO: Waiting for pod downwardapi-volume-3d22d378-a49e-4ba2-8418-cde5ff3b71b4 to disappear
Apr 27 16:19:43.067: INFO: Pod downwardapi-volume-3d22d378-a49e-4ba2-8418-cde5ff3b71b4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:19:43.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4535" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":3,"skipped":24,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:19:43.077: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-2739
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:19:44.177: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Apr 27 16:19:46.189: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601184, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601184, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601184, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601184, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:19:48.193: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601184, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601184, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601184, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601184, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:19:51.203: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:19:51.207: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:19:52.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-2739" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137
•{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":277,"completed":4,"skipped":46,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:19:52.988: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9373
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-gwq5
STEP: Creating a pod to test atomic-volume-subpath
Apr 27 16:19:53.167: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-gwq5" in namespace "subpath-9373" to be "Succeeded or Failed"
Apr 27 16:19:53.171: INFO: Pod "pod-subpath-test-configmap-gwq5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.475455ms
Apr 27 16:19:55.176: INFO: Pod "pod-subpath-test-configmap-gwq5": Phase="Running", Reason="", readiness=true. Elapsed: 2.008638145s
Apr 27 16:19:57.181: INFO: Pod "pod-subpath-test-configmap-gwq5": Phase="Running", Reason="", readiness=true. Elapsed: 4.013922414s
Apr 27 16:19:59.186: INFO: Pod "pod-subpath-test-configmap-gwq5": Phase="Running", Reason="", readiness=true. Elapsed: 6.019241332s
Apr 27 16:20:01.191: INFO: Pod "pod-subpath-test-configmap-gwq5": Phase="Running", Reason="", readiness=true. Elapsed: 8.024387761s
Apr 27 16:20:03.197: INFO: Pod "pod-subpath-test-configmap-gwq5": Phase="Running", Reason="", readiness=true. Elapsed: 10.029535286s
Apr 27 16:20:05.202: INFO: Pod "pod-subpath-test-configmap-gwq5": Phase="Running", Reason="", readiness=true. Elapsed: 12.035121199s
Apr 27 16:20:07.207: INFO: Pod "pod-subpath-test-configmap-gwq5": Phase="Running", Reason="", readiness=true. Elapsed: 14.039965724s
Apr 27 16:20:09.212: INFO: Pod "pod-subpath-test-configmap-gwq5": Phase="Running", Reason="", readiness=true. Elapsed: 16.044711445s
Apr 27 16:20:11.217: INFO: Pod "pod-subpath-test-configmap-gwq5": Phase="Running", Reason="", readiness=true. Elapsed: 18.0499729s
Apr 27 16:20:13.222: INFO: Pod "pod-subpath-test-configmap-gwq5": Phase="Running", Reason="", readiness=true. Elapsed: 20.055167644s
Apr 27 16:20:15.227: INFO: Pod "pod-subpath-test-configmap-gwq5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.06008508s
STEP: Saw pod success
Apr 27 16:20:15.227: INFO: Pod "pod-subpath-test-configmap-gwq5" satisfied condition "Succeeded or Failed"
Apr 27 16:20:15.231: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-subpath-test-configmap-gwq5 container test-container-subpath-configmap-gwq5: <nil>
STEP: delete the pod
Apr 27 16:20:15.254: INFO: Waiting for pod pod-subpath-test-configmap-gwq5 to disappear
Apr 27 16:20:15.259: INFO: Pod pod-subpath-test-configmap-gwq5 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-gwq5
Apr 27 16:20:15.259: INFO: Deleting pod "pod-subpath-test-configmap-gwq5" in namespace "subpath-9373"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:20:15.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9373" for this suite.
•{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [LinuxOnly] [Conformance]","total":277,"completed":5,"skipped":58,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:20:15.278: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-432
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a Namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nspatchtest-a8a2eef0-8f74-4a42-b229-8f2adc0e6946-520
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:20:15.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-432" for this suite.
STEP: Destroying namespace "nspatchtest-a8a2eef0-8f74-4a42-b229-8f2adc0e6946-520" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":277,"completed":6,"skipped":68,"failed":0}

------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:20:15.617: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5532
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-fb909b74-ff28-4a6c-9f9c-dac224b3d2cb in namespace container-probe-5532
Apr 27 16:20:17.782: INFO: Started pod liveness-fb909b74-ff28-4a6c-9f9c-dac224b3d2cb in namespace container-probe-5532
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 16:20:17.786: INFO: Initial restart count of pod liveness-fb909b74-ff28-4a6c-9f9c-dac224b3d2cb is 0
Apr 27 16:20:35.830: INFO: Restart count of pod container-probe-5532/liveness-fb909b74-ff28-4a6c-9f9c-dac224b3d2cb is now 1 (18.043896439s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:20:35.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5532" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":277,"completed":7,"skipped":68,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:20:35.852: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5173
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service endpoint-test2 in namespace services-5173
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5173 to expose endpoints map[]
Apr 27 16:20:36.026: INFO: Get endpoints failed (3.499242ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Apr 27 16:20:37.031: INFO: successfully validated that service endpoint-test2 in namespace services-5173 exposes endpoints map[] (1.00808749s elapsed)
STEP: Creating pod pod1 in namespace services-5173
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5173 to expose endpoints map[pod1:[80]]
Apr 27 16:20:39.063: INFO: successfully validated that service endpoint-test2 in namespace services-5173 exposes endpoints map[pod1:[80]] (2.024958468s elapsed)
STEP: Creating pod pod2 in namespace services-5173
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5173 to expose endpoints map[pod1:[80] pod2:[80]]
Apr 27 16:20:41.105: INFO: successfully validated that service endpoint-test2 in namespace services-5173 exposes endpoints map[pod1:[80] pod2:[80]] (2.03605049s elapsed)
STEP: Deleting pod pod1 in namespace services-5173
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5173 to expose endpoints map[pod2:[80]]
Apr 27 16:20:41.119: INFO: successfully validated that service endpoint-test2 in namespace services-5173 exposes endpoints map[pod2:[80]] (8.112987ms elapsed)
STEP: Deleting pod pod2 in namespace services-5173
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5173 to expose endpoints map[]
Apr 27 16:20:41.130: INFO: successfully validated that service endpoint-test2 in namespace services-5173 exposes endpoints map[] (6.326641ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:20:41.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5173" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":277,"completed":8,"skipped":91,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:20:41.160: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3226
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-secret-l2x6
STEP: Creating a pod to test atomic-volume-subpath
Apr 27 16:20:41.330: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-l2x6" in namespace "subpath-3226" to be "Succeeded or Failed"
Apr 27 16:20:41.333: INFO: Pod "pod-subpath-test-secret-l2x6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.019373ms
Apr 27 16:20:43.338: INFO: Pod "pod-subpath-test-secret-l2x6": Phase="Running", Reason="", readiness=true. Elapsed: 2.007894757s
Apr 27 16:20:45.343: INFO: Pod "pod-subpath-test-secret-l2x6": Phase="Running", Reason="", readiness=true. Elapsed: 4.013516788s
Apr 27 16:20:47.348: INFO: Pod "pod-subpath-test-secret-l2x6": Phase="Running", Reason="", readiness=true. Elapsed: 6.018520176s
Apr 27 16:20:49.353: INFO: Pod "pod-subpath-test-secret-l2x6": Phase="Running", Reason="", readiness=true. Elapsed: 8.023375897s
Apr 27 16:20:51.358: INFO: Pod "pod-subpath-test-secret-l2x6": Phase="Running", Reason="", readiness=true. Elapsed: 10.028443229s
Apr 27 16:20:53.363: INFO: Pod "pod-subpath-test-secret-l2x6": Phase="Running", Reason="", readiness=true. Elapsed: 12.033455847s
Apr 27 16:20:55.369: INFO: Pod "pod-subpath-test-secret-l2x6": Phase="Running", Reason="", readiness=true. Elapsed: 14.039152884s
Apr 27 16:20:57.373: INFO: Pod "pod-subpath-test-secret-l2x6": Phase="Running", Reason="", readiness=true. Elapsed: 16.04373124s
Apr 27 16:20:59.378: INFO: Pod "pod-subpath-test-secret-l2x6": Phase="Running", Reason="", readiness=true. Elapsed: 18.048617965s
Apr 27 16:21:01.383: INFO: Pod "pod-subpath-test-secret-l2x6": Phase="Running", Reason="", readiness=true. Elapsed: 20.05364021s
Apr 27 16:21:03.388: INFO: Pod "pod-subpath-test-secret-l2x6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.058479093s
STEP: Saw pod success
Apr 27 16:21:03.388: INFO: Pod "pod-subpath-test-secret-l2x6" satisfied condition "Succeeded or Failed"
Apr 27 16:21:03.392: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-subpath-test-secret-l2x6 container test-container-subpath-secret-l2x6: <nil>
STEP: delete the pod
Apr 27 16:21:03.455: INFO: Waiting for pod pod-subpath-test-secret-l2x6 to disappear
Apr 27 16:21:03.459: INFO: Pod pod-subpath-test-secret-l2x6 no longer exists
STEP: Deleting pod pod-subpath-test-secret-l2x6
Apr 27 16:21:03.459: INFO: Deleting pod "pod-subpath-test-secret-l2x6" in namespace "subpath-3226"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:21:03.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3226" for this suite.
•{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [LinuxOnly] [Conformance]","total":277,"completed":9,"skipped":118,"failed":0}
SS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:21:03.475: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-5889
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Apr 27 16:21:10.151: INFO: Successfully updated pod "adopt-release-k67d6"
STEP: Checking that the Job readopts the Pod
Apr 27 16:21:10.151: INFO: Waiting up to 15m0s for pod "adopt-release-k67d6" in namespace "job-5889" to be "adopted"
Apr 27 16:21:10.155: INFO: Pod "adopt-release-k67d6": Phase="Running", Reason="", readiness=true. Elapsed: 3.38252ms
Apr 27 16:21:12.159: INFO: Pod "adopt-release-k67d6": Phase="Running", Reason="", readiness=true. Elapsed: 2.00744558s
Apr 27 16:21:12.159: INFO: Pod "adopt-release-k67d6" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Apr 27 16:21:12.672: INFO: Successfully updated pod "adopt-release-k67d6"
STEP: Checking that the Job releases the Pod
Apr 27 16:21:12.672: INFO: Waiting up to 15m0s for pod "adopt-release-k67d6" in namespace "job-5889" to be "released"
Apr 27 16:21:12.675: INFO: Pod "adopt-release-k67d6": Phase="Running", Reason="", readiness=true. Elapsed: 3.384414ms
Apr 27 16:21:14.680: INFO: Pod "adopt-release-k67d6": Phase="Running", Reason="", readiness=true. Elapsed: 2.00830808s
Apr 27 16:21:14.680: INFO: Pod "adopt-release-k67d6" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:21:14.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5889" for this suite.
•{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":277,"completed":10,"skipped":120,"failed":0}
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:21:14.693: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-821
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl logs
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1288
STEP: creating an pod
Apr 27 16:21:14.842: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run logs-generator --image=us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 --namespace=kubectl-821 -- logs-generator --log-lines-total 100 --run-duration 20s'
Apr 27 16:21:14.953: INFO: stderr: ""
Apr 27 16:21:14.953: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Waiting for log generator to start.
Apr 27 16:21:14.953: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Apr 27 16:21:14.953: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-821" to be "running and ready, or succeeded"
Apr 27 16:21:14.957: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 3.613215ms
Apr 27 16:21:16.961: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.008509082s
Apr 27 16:21:16.962: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Apr 27 16:21:16.962: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Apr 27 16:21:16.962: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-821'
Apr 27 16:21:17.050: INFO: stderr: ""
Apr 27 16:21:17.050: INFO: stdout: "I0427 16:21:15.813491       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/2l8 522\nI0427 16:21:16.013566       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/k28l 526\nI0427 16:21:16.213603       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/kh7c 220\nI0427 16:21:16.413593       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/b2xx 460\nI0427 16:21:16.613578       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/7thz 365\nI0427 16:21:16.813569       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/66lv 536\nI0427 16:21:17.013577       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/ggt 422\n"
STEP: limiting log lines
Apr 27 16:21:17.050: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-821 --tail=1'
Apr 27 16:21:17.143: INFO: stderr: ""
Apr 27 16:21:17.144: INFO: stdout: "I0427 16:21:17.013577       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/ggt 422\n"
Apr 27 16:21:17.144: INFO: got output "I0427 16:21:17.013577       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/ggt 422\n"
STEP: limiting log bytes
Apr 27 16:21:17.144: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-821 --limit-bytes=1'
Apr 27 16:21:17.226: INFO: stderr: ""
Apr 27 16:21:17.226: INFO: stdout: "I"
Apr 27 16:21:17.226: INFO: got output "I"
STEP: exposing timestamps
Apr 27 16:21:17.227: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-821 --tail=1 --timestamps'
Apr 27 16:21:17.309: INFO: stderr: ""
Apr 27 16:21:17.309: INFO: stdout: "2020-04-27T16:21:17.213756591Z I0427 16:21:17.213574       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/cb22 389\n"
Apr 27 16:21:17.309: INFO: got output "2020-04-27T16:21:17.213756591Z I0427 16:21:17.213574       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/cb22 389\n"
STEP: restricting to a time range
Apr 27 16:21:19.810: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-821 --since=1s'
Apr 27 16:21:19.996: INFO: stderr: ""
Apr 27 16:21:19.996: INFO: stdout: "I0427 16:21:19.013573       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/twr 424\nI0427 16:21:19.213589       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/q79 233\nI0427 16:21:19.413579       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/h7c6 250\nI0427 16:21:19.613567       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/6qrg 271\nI0427 16:21:19.813573       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/qn9h 546\n"
Apr 27 16:21:19.996: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-821 --since=24h'
Apr 27 16:21:20.087: INFO: stderr: ""
Apr 27 16:21:20.087: INFO: stdout: "I0427 16:21:15.813491       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/2l8 522\nI0427 16:21:16.013566       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/k28l 526\nI0427 16:21:16.213603       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/kh7c 220\nI0427 16:21:16.413593       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/b2xx 460\nI0427 16:21:16.613578       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/7thz 365\nI0427 16:21:16.813569       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/66lv 536\nI0427 16:21:17.013577       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/ggt 422\nI0427 16:21:17.213574       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/cb22 389\nI0427 16:21:17.413590       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/247 562\nI0427 16:21:17.613576       1 logs_generator.go:76] 9 POST /api/v1/namespaces/kube-system/pods/6n9 369\nI0427 16:21:17.813576       1 logs_generator.go:76] 10 POST /api/v1/namespaces/kube-system/pods/n6j 451\nI0427 16:21:18.013582       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/wxj 361\nI0427 16:21:18.213574       1 logs_generator.go:76] 12 POST /api/v1/namespaces/ns/pods/mkwq 473\nI0427 16:21:18.413602       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/ns/pods/ztcq 272\nI0427 16:21:18.613635       1 logs_generator.go:76] 14 GET /api/v1/namespaces/default/pods/6l4k 224\nI0427 16:21:18.813626       1 logs_generator.go:76] 15 GET /api/v1/namespaces/default/pods/5qvj 366\nI0427 16:21:19.013573       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/twr 424\nI0427 16:21:19.213589       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/q79 233\nI0427 16:21:19.413579       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/h7c6 250\nI0427 16:21:19.613567       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/6qrg 271\nI0427 16:21:19.813573       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/qn9h 546\nI0427 16:21:20.013561       1 logs_generator.go:76] 21 GET /api/v1/namespaces/ns/pods/dp6t 329\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1294
Apr 27 16:21:20.087: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pod logs-generator --namespace=kubectl-821'
Apr 27 16:21:25.029: INFO: stderr: ""
Apr 27 16:21:25.029: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:21:25.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-821" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":277,"completed":11,"skipped":130,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:21:25.040: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9833
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 27 16:21:27.213: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:21:27.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9833" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":12,"skipped":146,"failed":0}
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:21:27.238: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-370
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:21:38.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-370" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":277,"completed":13,"skipped":149,"failed":0}
SSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:21:38.452: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-6535
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Apr 27 16:21:44.653: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6535 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:21:44.653: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:21:50.042: INFO: Exec stderr: ""
Apr 27 16:21:50.042: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6535 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:21:50.042: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:21:50.462: INFO: Exec stderr: ""
Apr 27 16:21:50.462: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6535 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:21:50.462: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:21:50.809: INFO: Exec stderr: ""
Apr 27 16:21:50.809: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6535 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:21:50.809: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:21:51.190: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Apr 27 16:21:51.190: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6535 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:21:51.190: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:21:51.635: INFO: Exec stderr: ""
Apr 27 16:21:51.635: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6535 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:21:51.635: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:21:52.044: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Apr 27 16:21:52.044: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6535 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:21:52.044: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:21:52.420: INFO: Exec stderr: ""
Apr 27 16:21:52.420: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6535 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:21:52.420: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:21:52.894: INFO: Exec stderr: ""
Apr 27 16:21:52.894: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6535 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:21:52.894: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:21:53.354: INFO: Exec stderr: ""
Apr 27 16:21:53.354: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6535 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:21:53.354: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:21:53.758: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:21:53.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-6535" for this suite.
•{"msg":"PASSED [k8s.io] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":14,"skipped":155,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:21:53.773: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-2611
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9237
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-373
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:22:00.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2611" for this suite.
STEP: Destroying namespace "nsdeletetest-9237" for this suite.
Apr 27 16:22:00.260: INFO: Namespace nsdeletetest-9237 was already deleted
STEP: Destroying namespace "nsdeletetest-373" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":277,"completed":15,"skipped":160,"failed":0}
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:22:00.268: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8055
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-26096d5e-eb71-4017-afdd-1681fbd86950 in namespace container-probe-8055
Apr 27 16:22:02.490: INFO: Started pod liveness-26096d5e-eb71-4017-afdd-1681fbd86950 in namespace container-probe-8055
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 16:22:02.494: INFO: Initial restart count of pod liveness-26096d5e-eb71-4017-afdd-1681fbd86950 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:26:03.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8055" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":277,"completed":16,"skipped":166,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:26:03.128: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-6774
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:26:11.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6774" for this suite.
•{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":277,"completed":17,"skipped":187,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:26:11.306: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2899
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-2899
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-2899
I0427 16:26:11.484311    5439 runners.go:190] Created replication controller with name: externalname-service, namespace: services-2899, replica count: 2
Apr 27 16:26:14.534: INFO: Creating new exec pod
I0427 16:26:14.534891    5439 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 27 16:26:19.557: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-2899 execpodf2xfn -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Apr 27 16:26:20.053: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 27 16:26:20.053: INFO: stdout: ""
Apr 27 16:26:20.054: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-2899 execpodf2xfn -- /bin/sh -x -c nc -zv -t -w 2 100.107.109.133 80'
Apr 27 16:26:20.489: INFO: stderr: "+ nc -zv -t -w 2 100.107.109.133 80\nConnection to 100.107.109.133 80 port [tcp/http] succeeded!\n"
Apr 27 16:26:20.489: INFO: stdout: ""
Apr 27 16:26:20.489: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-2899 execpodf2xfn -- /bin/sh -x -c nc -zv -t -w 2 10.250.0.4 32335'
Apr 27 16:26:25.959: INFO: stderr: "+ nc -zv -t -w 2 10.250.0.4 32335\nConnection to 10.250.0.4 32335 port [tcp/32335] succeeded!\n"
Apr 27 16:26:25.959: INFO: stdout: ""
Apr 27 16:26:25.959: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-2899 execpodf2xfn -- /bin/sh -x -c nc -zv -t -w 2 10.250.0.21 32335'
Apr 27 16:26:26.375: INFO: stderr: "+ nc -zv -t -w 2 10.250.0.21 32335\nConnection to 10.250.0.21 32335 port [tcp/32335] succeeded!\n"
Apr 27 16:26:26.375: INFO: stdout: ""
Apr 27 16:26:26.375: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:26:26.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2899" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":277,"completed":18,"skipped":201,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:26:26.408: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-3788
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Apr 27 16:26:26.560: INFO: PodSpec: initContainers in spec.initContainers
Apr 27 16:27:06.311: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-c0b4c09f-acbd-47ed-be09-2b0d8ee9d53b", GenerateName:"", Namespace:"init-container-3788", SelfLink:"/api/v1/namespaces/init-container-3788/pods/pod-init-c0b4c09f-acbd-47ed-be09-2b0d8ee9d53b", UID:"19e922ab-eb40-46f6-aea2-173d4ced96bc", ResourceVersion:"12225", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63723601586, loc:(*time.Location)(0x7b501e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"560518051"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.64.1.35/32", "cni.projectcalico.org/podIPs":"100.64.1.35/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc001ce92a0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001ce92e0)}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc001ce9300), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001ce9320)}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc001ce9340), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001ce93c0)}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-b4cbl", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002a90100), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-b4cbl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-b4cbl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.2", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-b4cbl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0006a1ef8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002e3c540), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0006a1f70)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0006a1f90)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0006a1f98), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0006a1f9c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601586, loc:(*time.Location)(0x7b501e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601586, loc:(*time.Location)(0x7b501e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601586, loc:(*time.Location)(0x7b501e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601586, loc:(*time.Location)(0x7b501e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.0.21", PodIP:"100.64.1.35", PodIPs:[]v1.PodIP{v1.PodIP{IP:"100.64.1.35"}}, StartTime:(*v1.Time)(0xc001ce9400), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002e3c620)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002e3c690)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://ee6e94cea7e875aa79eaf53d130ca7a0cb64b2aff7a20392d74334412bccfb15", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001ce9460), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001ce9420), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.2", ImageID:"", ContainerID:"", Started:(*bool)(0xc00155801f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:06.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3788" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":277,"completed":19,"skipped":238,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:06.323: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9540
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-projected-all-test-volume-ecdc8d68-df3d-4e2a-95b3-efefcfc86610
STEP: Creating secret with name secret-projected-all-test-volume-dac4470a-b378-476c-a61f-c6c7cd5ce470
STEP: Creating a pod to test Check all projections for projected volume plugin
Apr 27 16:27:06.496: INFO: Waiting up to 5m0s for pod "projected-volume-c1acbcc5-6d55-4910-a5fc-c3ec2cf8ef96" in namespace "projected-9540" to be "Succeeded or Failed"
Apr 27 16:27:06.499: INFO: Pod "projected-volume-c1acbcc5-6d55-4910-a5fc-c3ec2cf8ef96": Phase="Pending", Reason="", readiness=false. Elapsed: 3.055929ms
Apr 27 16:27:08.504: INFO: Pod "projected-volume-c1acbcc5-6d55-4910-a5fc-c3ec2cf8ef96": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008110747s
STEP: Saw pod success
Apr 27 16:27:08.504: INFO: Pod "projected-volume-c1acbcc5-6d55-4910-a5fc-c3ec2cf8ef96" satisfied condition "Succeeded or Failed"
Apr 27 16:27:08.508: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod projected-volume-c1acbcc5-6d55-4910-a5fc-c3ec2cf8ef96 container projected-all-volume-test: <nil>
STEP: delete the pod
Apr 27 16:27:08.619: INFO: Waiting for pod projected-volume-c1acbcc5-6d55-4910-a5fc-c3ec2cf8ef96 to disappear
Apr 27 16:27:08.622: INFO: Pod projected-volume-c1acbcc5-6d55-4910-a5fc-c3ec2cf8ef96 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:08.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9540" for this suite.
•{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":277,"completed":20,"skipped":244,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:08.633: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6648
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-4befcf6d-f0eb-45c2-8acb-9a230587ac1b
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-4befcf6d-f0eb-45c2-8acb-9a230587ac1b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:12.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6648" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":21,"skipped":265,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:12.932: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6972
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:30.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6972" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":277,"completed":22,"skipped":278,"failed":0}
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:30.136: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4232
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:32.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4232" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":23,"skipped":283,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:32.327: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5073
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:45.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5073" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":277,"completed":24,"skipped":299,"failed":0}
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:45.552: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8435
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-downwardapi-4qhd
STEP: Creating a pod to test atomic-volume-subpath
Apr 27 16:27:45.723: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-4qhd" in namespace "subpath-8435" to be "Succeeded or Failed"
Apr 27 16:27:45.727: INFO: Pod "pod-subpath-test-downwardapi-4qhd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.102484ms
Apr 27 16:27:47.731: INFO: Pod "pod-subpath-test-downwardapi-4qhd": Phase="Running", Reason="", readiness=true. Elapsed: 2.007738703s
Apr 27 16:27:49.736: INFO: Pod "pod-subpath-test-downwardapi-4qhd": Phase="Running", Reason="", readiness=true. Elapsed: 4.012674708s
Apr 27 16:27:51.740: INFO: Pod "pod-subpath-test-downwardapi-4qhd": Phase="Running", Reason="", readiness=true. Elapsed: 6.016867199s
Apr 27 16:27:53.744: INFO: Pod "pod-subpath-test-downwardapi-4qhd": Phase="Running", Reason="", readiness=true. Elapsed: 8.020870648s
Apr 27 16:27:55.750: INFO: Pod "pod-subpath-test-downwardapi-4qhd": Phase="Running", Reason="", readiness=true. Elapsed: 10.026010378s
Apr 27 16:27:57.755: INFO: Pod "pod-subpath-test-downwardapi-4qhd": Phase="Running", Reason="", readiness=true. Elapsed: 12.031981742s
Apr 27 16:27:59.760: INFO: Pod "pod-subpath-test-downwardapi-4qhd": Phase="Running", Reason="", readiness=true. Elapsed: 14.036937816s
Apr 27 16:28:01.765: INFO: Pod "pod-subpath-test-downwardapi-4qhd": Phase="Running", Reason="", readiness=true. Elapsed: 16.041667603s
Apr 27 16:28:03.771: INFO: Pod "pod-subpath-test-downwardapi-4qhd": Phase="Running", Reason="", readiness=true. Elapsed: 18.047677174s
Apr 27 16:28:05.776: INFO: Pod "pod-subpath-test-downwardapi-4qhd": Phase="Running", Reason="", readiness=true. Elapsed: 20.05287535s
Apr 27 16:28:07.782: INFO: Pod "pod-subpath-test-downwardapi-4qhd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.058432653s
STEP: Saw pod success
Apr 27 16:28:07.782: INFO: Pod "pod-subpath-test-downwardapi-4qhd" satisfied condition "Succeeded or Failed"
Apr 27 16:28:07.786: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-subpath-test-downwardapi-4qhd container test-container-subpath-downwardapi-4qhd: <nil>
STEP: delete the pod
Apr 27 16:28:07.807: INFO: Waiting for pod pod-subpath-test-downwardapi-4qhd to disappear
Apr 27 16:28:07.810: INFO: Pod pod-subpath-test-downwardapi-4qhd no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-4qhd
Apr 27 16:28:07.810: INFO: Deleting pod "pod-subpath-test-downwardapi-4qhd" in namespace "subpath-8435"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:28:07.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8435" for this suite.
•{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [LinuxOnly] [Conformance]","total":277,"completed":25,"skipped":303,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:28:07.826: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4062
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:28:13.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4062" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":277,"completed":26,"skipped":315,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:28:13.384: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8134
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Apr 27 16:28:13.542: INFO: Created pod &Pod{ObjectMeta:{dns-8134  dns-8134 /api/v1/namespaces/dns-8134/pods/dns-8134 a2688310-72f8-4d16-befd-64a7a19747a4 12757 0 2020-04-27 16:28:13 +0000 UTC <nil> <nil> map[] map[kubernetes.io/psp:e2e-test-privileged-psp] [] []  [{e2e.test Update v1 2020-04-27 16:28:13 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 67 111 110 102 105 103 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 115 101 114 118 101 114 115 34 58 123 125 44 34 102 58 115 101 97 114 99 104 101 115 34 58 123 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-82h5s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-82h5s,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-82h5s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:28:13.546: INFO: The status of Pod dns-8134 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:28:15.550: INFO: The status of Pod dns-8134 is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
Apr 27 16:28:15.551: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-8134 PodName:dns-8134 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:28:15.551: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Verifying customized DNS server is configured on pod...
Apr 27 16:28:20.994: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-8134 PodName:dns-8134 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:28:20.994: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:28:21.487: INFO: Deleting pod dns-8134...
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:28:21.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8134" for this suite.
•{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":277,"completed":27,"skipped":328,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:28:21.508: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2624
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:28:37.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2624" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":277,"completed":28,"skipped":372,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:28:37.753: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-460
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:28:37.904: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr 27 16:28:41.532: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-460 create -f -'
Apr 27 16:28:41.933: INFO: stderr: ""
Apr 27 16:28:41.933: INFO: stdout: "e2e-test-crd-publish-openapi-8738-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 27 16:28:41.933: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-460 delete e2e-test-crd-publish-openapi-8738-crds test-cr'
Apr 27 16:28:42.052: INFO: stderr: ""
Apr 27 16:28:42.052: INFO: stdout: "e2e-test-crd-publish-openapi-8738-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Apr 27 16:28:42.053: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-460 apply -f -'
Apr 27 16:28:42.205: INFO: stderr: ""
Apr 27 16:28:42.205: INFO: stdout: "e2e-test-crd-publish-openapi-8738-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 27 16:28:42.205: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-460 delete e2e-test-crd-publish-openapi-8738-crds test-cr'
Apr 27 16:28:42.283: INFO: stderr: ""
Apr 27 16:28:42.283: INFO: stdout: "e2e-test-crd-publish-openapi-8738-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Apr 27 16:28:42.283: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-8738-crds'
Apr 27 16:28:42.442: INFO: stderr: ""
Apr 27 16:28:42.442: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8738-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:28:46.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-460" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":277,"completed":29,"skipped":378,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:28:46.168: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7035
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Apr 27 16:28:46.328: INFO: Pod name pod-release: Found 0 pods out of 1
Apr 27 16:28:51.332: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:28:52.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7035" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":277,"completed":30,"skipped":402,"failed":0}
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:28:52.366: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2293
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Apr 27 16:28:52.526: INFO: Waiting up to 5m0s for pod "downward-api-5def1044-1fe3-481b-87d0-745349d969c7" in namespace "downward-api-2293" to be "Succeeded or Failed"
Apr 27 16:28:52.529: INFO: Pod "downward-api-5def1044-1fe3-481b-87d0-745349d969c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.937413ms
Apr 27 16:28:54.533: INFO: Pod "downward-api-5def1044-1fe3-481b-87d0-745349d969c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007076771s
STEP: Saw pod success
Apr 27 16:28:54.533: INFO: Pod "downward-api-5def1044-1fe3-481b-87d0-745349d969c7" satisfied condition "Succeeded or Failed"
Apr 27 16:28:54.536: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downward-api-5def1044-1fe3-481b-87d0-745349d969c7 container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:28:54.555: INFO: Waiting for pod downward-api-5def1044-1fe3-481b-87d0-745349d969c7 to disappear
Apr 27 16:28:54.558: INFO: Pod downward-api-5def1044-1fe3-481b-87d0-745349d969c7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:28:54.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2293" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":277,"completed":31,"skipped":408,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:28:54.568: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7799
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:28:54.726: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ebecb819-b1f2-4370-b6e5-9d43b301faf2" in namespace "downward-api-7799" to be "Succeeded or Failed"
Apr 27 16:28:54.729: INFO: Pod "downwardapi-volume-ebecb819-b1f2-4370-b6e5-9d43b301faf2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.130512ms
Apr 27 16:28:56.734: INFO: Pod "downwardapi-volume-ebecb819-b1f2-4370-b6e5-9d43b301faf2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007881796s
STEP: Saw pod success
Apr 27 16:28:56.734: INFO: Pod "downwardapi-volume-ebecb819-b1f2-4370-b6e5-9d43b301faf2" satisfied condition "Succeeded or Failed"
Apr 27 16:28:56.737: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downwardapi-volume-ebecb819-b1f2-4370-b6e5-9d43b301faf2 container client-container: <nil>
STEP: delete the pod
Apr 27 16:28:56.756: INFO: Waiting for pod downwardapi-volume-ebecb819-b1f2-4370-b6e5-9d43b301faf2 to disappear
Apr 27 16:28:56.759: INFO: Pod downwardapi-volume-ebecb819-b1f2-4370-b6e5-9d43b301faf2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:28:56.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7799" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":32,"skipped":429,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:28:56.769: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4265
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4265.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4265.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4265.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4265.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4265.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4265.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4265.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4265.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4265.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4265.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4265.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 37.169.109.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.109.169.37_udp@PTR;check="$$(dig +tcp +noall +answer +search 37.169.109.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.109.169.37_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4265.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4265.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4265.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4265.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4265.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4265.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4265.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4265.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4265.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4265.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4265.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 37.169.109.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.109.169.37_udp@PTR;check="$$(dig +tcp +noall +answer +search 37.169.109.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.109.169.37_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 16:29:07.046: INFO: Unable to read wheezy_udp@dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:07.089: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:07.095: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:07.100: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:07.530: INFO: Unable to read jessie_udp@dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:07.536: INFO: Unable to read jessie_tcp@dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:07.543: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:07.548: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:07.894: INFO: Lookups using dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32 failed for: [wheezy_udp@dns-test-service.dns-4265.svc.cluster.local wheezy_tcp@dns-test-service.dns-4265.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local jessie_udp@dns-test-service.dns-4265.svc.cluster.local jessie_tcp@dns-test-service.dns-4265.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local]

Apr 27 16:29:12.901: INFO: Unable to read wheezy_udp@dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:12.908: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:12.913: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:12.918: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:13.307: INFO: Unable to read jessie_udp@dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:13.313: INFO: Unable to read jessie_tcp@dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:13.318: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:13.323: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:13.710: INFO: Lookups using dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32 failed for: [wheezy_udp@dns-test-service.dns-4265.svc.cluster.local wheezy_tcp@dns-test-service.dns-4265.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local jessie_udp@dns-test-service.dns-4265.svc.cluster.local jessie_tcp@dns-test-service.dns-4265.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local]

Apr 27 16:29:17.900: INFO: Unable to read wheezy_udp@dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:17.943: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:17.949: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:17.954: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:18.388: INFO: Unable to read jessie_udp@dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:18.394: INFO: Unable to read jessie_tcp@dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:18.398: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:18.403: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:18.750: INFO: Lookups using dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32 failed for: [wheezy_udp@dns-test-service.dns-4265.svc.cluster.local wheezy_tcp@dns-test-service.dns-4265.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local jessie_udp@dns-test-service.dns-4265.svc.cluster.local jessie_tcp@dns-test-service.dns-4265.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local]

Apr 27 16:29:22.903: INFO: Unable to read wheezy_udp@dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:22.916: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:22.925: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:22.930: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:23.363: INFO: Unable to read jessie_udp@dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:23.369: INFO: Unable to read jessie_tcp@dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:23.374: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:23.379: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:23.726: INFO: Lookups using dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32 failed for: [wheezy_udp@dns-test-service.dns-4265.svc.cluster.local wheezy_tcp@dns-test-service.dns-4265.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local jessie_udp@dns-test-service.dns-4265.svc.cluster.local jessie_tcp@dns-test-service.dns-4265.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local]

Apr 27 16:29:27.902: INFO: Unable to read wheezy_udp@dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:27.908: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:27.913: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:27.920: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:28.353: INFO: Unable to read jessie_udp@dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:28.359: INFO: Unable to read jessie_tcp@dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:28.363: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:28.368: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local from pod dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32: the server could not find the requested resource (get pods dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32)
Apr 27 16:29:28.716: INFO: Lookups using dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32 failed for: [wheezy_udp@dns-test-service.dns-4265.svc.cluster.local wheezy_tcp@dns-test-service.dns-4265.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local jessie_udp@dns-test-service.dns-4265.svc.cluster.local jessie_tcp@dns-test-service.dns-4265.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4265.svc.cluster.local]

Apr 27 16:29:34.222: INFO: DNS probes using dns-4265/dns-test-cd4da40e-cf3c-42ac-9199-67b0af8fcb32 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:29:34.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4265" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":277,"completed":33,"skipped":460,"failed":0}
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:29:34.275: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-328
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override arguments
Apr 27 16:29:34.445: INFO: Waiting up to 5m0s for pod "client-containers-4320fdf4-be21-4251-89f5-0cbdac4a441a" in namespace "containers-328" to be "Succeeded or Failed"
Apr 27 16:29:34.448: INFO: Pod "client-containers-4320fdf4-be21-4251-89f5-0cbdac4a441a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.314743ms
Apr 27 16:29:36.453: INFO: Pod "client-containers-4320fdf4-be21-4251-89f5-0cbdac4a441a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008074506s
STEP: Saw pod success
Apr 27 16:29:36.453: INFO: Pod "client-containers-4320fdf4-be21-4251-89f5-0cbdac4a441a" satisfied condition "Succeeded or Failed"
Apr 27 16:29:36.456: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod client-containers-4320fdf4-be21-4251-89f5-0cbdac4a441a container test-container: <nil>
STEP: delete the pod
Apr 27 16:29:36.474: INFO: Waiting for pod client-containers-4320fdf4-be21-4251-89f5-0cbdac4a441a to disappear
Apr 27 16:29:36.477: INFO: Pod client-containers-4320fdf4-be21-4251-89f5-0cbdac4a441a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:29:36.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-328" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":277,"completed":34,"skipped":466,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:29:36.486: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8488
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-b7f42b45-c11f-4903-b44d-9484d1c0d8da
STEP: Creating a pod to test consume configMaps
Apr 27 16:29:36.647: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-57739caf-7a6c-41f0-af19-449ae72fd69a" in namespace "projected-8488" to be "Succeeded or Failed"
Apr 27 16:29:36.649: INFO: Pod "pod-projected-configmaps-57739caf-7a6c-41f0-af19-449ae72fd69a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.914143ms
Apr 27 16:29:38.654: INFO: Pod "pod-projected-configmaps-57739caf-7a6c-41f0-af19-449ae72fd69a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007443115s
STEP: Saw pod success
Apr 27 16:29:38.654: INFO: Pod "pod-projected-configmaps-57739caf-7a6c-41f0-af19-449ae72fd69a" satisfied condition "Succeeded or Failed"
Apr 27 16:29:38.657: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-projected-configmaps-57739caf-7a6c-41f0-af19-449ae72fd69a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:29:38.676: INFO: Waiting for pod pod-projected-configmaps-57739caf-7a6c-41f0-af19-449ae72fd69a to disappear
Apr 27 16:29:38.679: INFO: Pod pod-projected-configmaps-57739caf-7a6c-41f0-af19-449ae72fd69a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:29:38.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8488" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":35,"skipped":471,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:29:38.689: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8459
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Apr 27 16:29:38.848: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:29:55.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8459" for this suite.
•{"msg":"PASSED [k8s.io] Pods should be submitted and removed [NodeConformance] [Conformance]","total":277,"completed":36,"skipped":494,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:29:55.041: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4834
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-ff1affc5-ae1f-4a42-9c68-7f3ad126d588
STEP: Creating a pod to test consume configMaps
Apr 27 16:29:55.197: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-164836e8-a51f-42a0-887f-d44df158fdef" in namespace "projected-4834" to be "Succeeded or Failed"
Apr 27 16:29:55.202: INFO: Pod "pod-projected-configmaps-164836e8-a51f-42a0-887f-d44df158fdef": Phase="Pending", Reason="", readiness=false. Elapsed: 4.227541ms
Apr 27 16:29:57.206: INFO: Pod "pod-projected-configmaps-164836e8-a51f-42a0-887f-d44df158fdef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00878499s
STEP: Saw pod success
Apr 27 16:29:57.206: INFO: Pod "pod-projected-configmaps-164836e8-a51f-42a0-887f-d44df158fdef" satisfied condition "Succeeded or Failed"
Apr 27 16:29:57.210: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-projected-configmaps-164836e8-a51f-42a0-887f-d44df158fdef container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:29:57.228: INFO: Waiting for pod pod-projected-configmaps-164836e8-a51f-42a0-887f-d44df158fdef to disappear
Apr 27 16:29:57.231: INFO: Pod pod-projected-configmaps-164836e8-a51f-42a0-887f-d44df158fdef no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:29:57.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4834" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":37,"skipped":528,"failed":0}
SSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:29:57.240: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5279
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-5279
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-5279
STEP: creating replication controller externalsvc in namespace services-5279
I0427 16:29:57.415639    5439 runners.go:190] Created replication controller with name: externalsvc, namespace: services-5279, replica count: 2
I0427 16:30:00.466098    5439 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Apr 27 16:30:00.486: INFO: Creating new exec pod
Apr 27 16:30:02.499: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-5279 execpodtwdks -- /bin/sh -x -c nslookup clusterip-service'
Apr 27 16:30:03.047: INFO: stderr: "+ nslookup clusterip-service\n"
Apr 27 16:30:03.047: INFO: stdout: "Server:\t\t100.104.0.10\nAddress:\t100.104.0.10#53\n\nclusterip-service.services-5279.svc.cluster.local\tcanonical name = externalsvc.services-5279.svc.cluster.local.\nName:\texternalsvc.services-5279.svc.cluster.local\nAddress: 100.110.119.160\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-5279, will wait for the garbage collector to delete the pods
Apr 27 16:30:03.108: INFO: Deleting ReplicationController externalsvc took: 6.978381ms
Apr 27 16:30:03.608: INFO: Terminating ReplicationController externalsvc pods took: 500.2052ms
Apr 27 16:30:15.126: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:15.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5279" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":277,"completed":38,"skipped":531,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:15.151: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7611
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7611.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-7611.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7611.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7611.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-7611.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7611.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 16:30:17.906: INFO: DNS probes using dns-7611/dns-test-26435edb-3249-4179-9426-353958ed9196 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:17.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7611" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":277,"completed":39,"skipped":542,"failed":0}
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:17.927: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2371
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-c83be32b-8711-426d-8fda-5fed72db65f9
STEP: Creating a pod to test consume secrets
Apr 27 16:30:18.089: INFO: Waiting up to 5m0s for pod "pod-secrets-a83a5ce5-5445-4ab4-a96b-d84617f7016e" in namespace "secrets-2371" to be "Succeeded or Failed"
Apr 27 16:30:18.091: INFO: Pod "pod-secrets-a83a5ce5-5445-4ab4-a96b-d84617f7016e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.815932ms
Apr 27 16:30:20.096: INFO: Pod "pod-secrets-a83a5ce5-5445-4ab4-a96b-d84617f7016e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007440907s
STEP: Saw pod success
Apr 27 16:30:20.096: INFO: Pod "pod-secrets-a83a5ce5-5445-4ab4-a96b-d84617f7016e" satisfied condition "Succeeded or Failed"
Apr 27 16:30:20.099: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-secrets-a83a5ce5-5445-4ab4-a96b-d84617f7016e container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:30:20.117: INFO: Waiting for pod pod-secrets-a83a5ce5-5445-4ab4-a96b-d84617f7016e to disappear
Apr 27 16:30:20.120: INFO: Pod pod-secrets-a83a5ce5-5445-4ab4-a96b-d84617f7016e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:20.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2371" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":40,"skipped":545,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:20.158: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5014
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 27 16:30:24.361: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 16:30:24.365: INFO: Pod pod-with-poststart-http-hook still exists
Apr 27 16:30:26.365: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 16:30:26.371: INFO: Pod pod-with-poststart-http-hook still exists
Apr 27 16:30:28.365: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 16:30:28.370: INFO: Pod pod-with-poststart-http-hook still exists
Apr 27 16:30:30.365: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 16:30:30.370: INFO: Pod pod-with-poststart-http-hook still exists
Apr 27 16:30:32.365: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 16:30:32.371: INFO: Pod pod-with-poststart-http-hook still exists
Apr 27 16:30:34.365: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 16:30:34.370: INFO: Pod pod-with-poststart-http-hook still exists
Apr 27 16:30:36.365: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 16:30:36.370: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:36.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5014" for this suite.
•{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":277,"completed":41,"skipped":565,"failed":0}
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:36.382: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8130
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Apr 27 16:30:36.535: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:39.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8130" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":277,"completed":42,"skipped":567,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:39.350: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5151
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap that has name configmap-test-emptyKey-f57194ad-0920-45f9-b180-de8a47087d02
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:39.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5151" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":277,"completed":43,"skipped":599,"failed":0}
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:39.511: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7979
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Apr 27 16:30:39.657: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 27 16:30:39.669: INFO: Waiting for terminating namespaces to be deleted...
Apr 27 16:30:39.672: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp before test
Apr 27 16:30:39.697: INFO: dashboard-metrics-scraper-76c7b697bc-l2z4c from kubernetes-dashboard started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.697: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 27 16:30:39.698: INFO: coredns-5cb857d789-s8ws2 from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.698: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:30:39.698: INFO: node-exporter-9pkd5 from kube-system started at 2020-04-27 16:07:11 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.698: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:30:39.698: INFO: metrics-server-5f76b49bb-ktlbv from kube-system started at 2020-04-27 16:07:31 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.698: INFO: 	Container metrics-server ready: true, restart count 0
Apr 27 16:30:39.698: INFO: node-problem-detector-tq7hl from kube-system started at 2020-04-27 16:07:11 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.698: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 16:30:39.698: INFO: vpn-shoot-5b5f49b4bf-trqr9 from kube-system started at 2020-04-27 16:07:31 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.698: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 27 16:30:39.698: INFO: calico-typha-vertical-autoscaler-5b477c88cf-k2f8l from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.698: INFO: 	Container autoscaler ready: true, restart count 6
Apr 27 16:30:39.698: INFO: calico-typha-horizontal-autoscaler-6fdd5d8746-hv92s from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.698: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 16:30:39.698: INFO: calico-typha-deploy-784665cc66-9ngtv from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.698: INFO: 	Container calico-typha ready: true, restart count 0
Apr 27 16:30:39.698: INFO: kubernetes-dashboard-6b586c4cb4-9c2rc from kubernetes-dashboard started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.698: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
Apr 27 16:30:39.698: INFO: blackbox-exporter-5dc75b79b7-7xcjk from kube-system started at 2020-04-27 16:07:11 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.698: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 27 16:30:39.698: INFO: kube-proxy-h2cx7 from kube-system started at 2020-04-27 16:07:11 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.698: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:30:39.698: INFO: addons-nginx-ingress-controller-6cf77756b5-rw99m from kube-system started at 2020-04-27 16:07:33 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.698: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 27 16:30:39.698: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-q52mz from kube-system started at 2020-04-27 16:07:41 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.698: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr 27 16:30:39.698: INFO: calico-kube-controllers-77dcb8f688-7jxx4 from kube-system started at 2020-04-27 16:07:33 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.698: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 27 16:30:39.698: INFO: calico-node-xphhz from kube-system started at 2020-04-27 16:15:29 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.698: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:30:39.698: INFO: coredns-5cb857d789-lrv9m from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.698: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:30:39.698: INFO: calico-node-vertical-autoscaler-74d4897db8-h9n8r from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.698: INFO: 	Container autoscaler ready: true, restart count 6
Apr 27 16:30:39.698: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 before test
Apr 27 16:30:39.715: INFO: kube-proxy-jm5m6 from kube-system started at 2020-04-27 16:07:18 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.715: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:30:39.715: INFO: pod-handle-http-request from container-lifecycle-hook-5014 started at 2020-04-27 16:30:20 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.715: INFO: 	Container pod-handle-http-request ready: true, restart count 0
Apr 27 16:30:39.715: INFO: calico-node-ld4x7 from kube-system started at 2020-04-27 16:15:20 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.715: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:30:39.715: INFO: node-exporter-srfgn from kube-system started at 2020-04-27 16:07:18 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.715: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:30:39.715: INFO: node-problem-detector-9thlx from kube-system started at 2020-04-27 16:07:18 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.715: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 16:30:39.715: INFO: pod-init-30a92d80-c11f-457e-9124-f158de458546 from init-container-8130 started at 2020-04-27 16:30:36 +0000 UTC (1 container statuses recorded)
Apr 27 16:30:39.715: INFO: 	Container run1 ready: false, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-28624691-c7fd-493e-9aa3-95d78a036863 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-28624691-c7fd-493e-9aa3-95d78a036863 off the node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9
STEP: verifying the node doesn't have the label kubernetes.io/e2e-28624691-c7fd-493e-9aa3-95d78a036863
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:35:43.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7979" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:304.297 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":277,"completed":44,"skipped":605,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:35:43.808: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1117
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-1117
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 27 16:35:43.955: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 27 16:35:43.979: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:35:45.984: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:35:47.985: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:35:49.984: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:35:51.984: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:35:53.984: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:35:55.983: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:35:57.984: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:35:59.984: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:36:01.984: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:36:03.984: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:36:05.985: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:36:07.984: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr 27 16:36:07.991: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Apr 27 16:36:10.015: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.63:8080/dial?request=hostname&protocol=http&host=100.64.0.18&port=8080&tries=1'] Namespace:pod-network-test-1117 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:36:10.015: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:36:10.448: INFO: Waiting for responses: map[]
Apr 27 16:36:10.452: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.63:8080/dial?request=hostname&protocol=http&host=100.64.1.62&port=8080&tries=1'] Namespace:pod-network-test-1117 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:36:10.452: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:36:10.845: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:10.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1117" for this suite.
•{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":277,"completed":45,"skipped":625,"failed":0}

------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:10.857: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7707
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Apr 27 16:36:11.017: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-7707'
Apr 27 16:36:11.262: INFO: stderr: ""
Apr 27 16:36:11.262: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 27 16:36:11.262: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7707'
Apr 27 16:36:11.372: INFO: stderr: ""
Apr 27 16:36:11.372: INFO: stdout: "update-demo-nautilus-7zrpv update-demo-nautilus-n8w8q "
Apr 27 16:36:11.372: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-7zrpv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7707'
Apr 27 16:36:11.442: INFO: stderr: ""
Apr 27 16:36:11.442: INFO: stdout: ""
Apr 27 16:36:11.442: INFO: update-demo-nautilus-7zrpv is created but not running
Apr 27 16:36:16.442: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7707'
Apr 27 16:36:16.520: INFO: stderr: ""
Apr 27 16:36:16.520: INFO: stdout: "update-demo-nautilus-7zrpv update-demo-nautilus-n8w8q "
Apr 27 16:36:16.520: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-7zrpv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7707'
Apr 27 16:36:16.595: INFO: stderr: ""
Apr 27 16:36:16.595: INFO: stdout: "true"
Apr 27 16:36:16.595: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-7zrpv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7707'
Apr 27 16:36:16.671: INFO: stderr: ""
Apr 27 16:36:16.671: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:36:16.671: INFO: validating pod update-demo-nautilus-7zrpv
Apr 27 16:36:16.761: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:36:16.762: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:36:16.762: INFO: update-demo-nautilus-7zrpv is verified up and running
Apr 27 16:36:16.762: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-n8w8q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7707'
Apr 27 16:36:16.839: INFO: stderr: ""
Apr 27 16:36:16.839: INFO: stdout: "true"
Apr 27 16:36:16.839: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-n8w8q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7707'
Apr 27 16:36:16.913: INFO: stderr: ""
Apr 27 16:36:16.913: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:36:16.913: INFO: validating pod update-demo-nautilus-n8w8q
Apr 27 16:36:17.005: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:36:17.005: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:36:17.005: INFO: update-demo-nautilus-n8w8q is verified up and running
STEP: using delete to clean up resources
Apr 27 16:36:17.005: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-7707'
Apr 27 16:36:17.082: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 16:36:17.082: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 27 16:36:17.082: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7707'
Apr 27 16:36:17.162: INFO: stderr: "No resources found in kubectl-7707 namespace.\n"
Apr 27 16:36:17.162: INFO: stdout: ""
Apr 27 16:36:17.162: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-7707 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 27 16:36:17.235: INFO: stderr: ""
Apr 27 16:36:17.235: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:17.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7707" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":277,"completed":46,"skipped":625,"failed":0}

------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:17.247: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3805
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-43c5475a-7187-4c3f-9cfe-85d4203b8562
STEP: Creating a pod to test consume secrets
Apr 27 16:36:17.409: INFO: Waiting up to 5m0s for pod "pod-secrets-8e7a7097-edd9-4f83-929a-fee71eea78dd" in namespace "secrets-3805" to be "Succeeded or Failed"
Apr 27 16:36:17.412: INFO: Pod "pod-secrets-8e7a7097-edd9-4f83-929a-fee71eea78dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.942116ms
Apr 27 16:36:19.416: INFO: Pod "pod-secrets-8e7a7097-edd9-4f83-929a-fee71eea78dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007117548s
STEP: Saw pod success
Apr 27 16:36:19.416: INFO: Pod "pod-secrets-8e7a7097-edd9-4f83-929a-fee71eea78dd" satisfied condition "Succeeded or Failed"
Apr 27 16:36:19.419: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-secrets-8e7a7097-edd9-4f83-929a-fee71eea78dd container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:36:19.528: INFO: Waiting for pod pod-secrets-8e7a7097-edd9-4f83-929a-fee71eea78dd to disappear
Apr 27 16:36:19.531: INFO: Pod pod-secrets-8e7a7097-edd9-4f83-929a-fee71eea78dd no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:19.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3805" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":47,"skipped":625,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:19.542: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3884
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-166ea0b4-ef1f-4d60-8490-3ce528a76a9e
STEP: Creating secret with name s-test-opt-upd-54c27428-a501-4275-88ac-efbe243dd957
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-166ea0b4-ef1f-4d60-8490-3ce528a76a9e
STEP: Updating secret s-test-opt-upd-54c27428-a501-4275-88ac-efbe243dd957
STEP: Creating secret with name s-test-opt-create-ef98a506-227e-48e6-ba27-4781730471d4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:26.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3884" for this suite.
•{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":48,"skipped":643,"failed":0}

------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:26.116: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-277
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 27 16:36:28.296: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:36:28.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-277" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":49,"skipped":643,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:36:28.320: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-357
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:345
Apr 27 16:36:28.467: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 27 16:37:28.496: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:37:28.499: INFO: Starting informer...
STEP: Starting pods...
Apr 27 16:37:28.716: INFO: Pod1 is running on shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9. Tainting Node
Apr 27 16:37:30.937: INFO: Pod2 is running on shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Apr 27 16:37:37.548: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Apr 27 16:37:57.665: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:37:57.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-357" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":277,"completed":50,"skipped":658,"failed":0}
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:37:57.693: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-915
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-fb5b78d2-05cf-480c-bb2b-c2c939a10158
STEP: Creating a pod to test consume secrets
Apr 27 16:37:57.852: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4ea561e9-a30a-41e3-a2e9-629f4bddfe25" in namespace "projected-915" to be "Succeeded or Failed"
Apr 27 16:37:57.854: INFO: Pod "pod-projected-secrets-4ea561e9-a30a-41e3-a2e9-629f4bddfe25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.817247ms
Apr 27 16:37:59.860: INFO: Pod "pod-projected-secrets-4ea561e9-a30a-41e3-a2e9-629f4bddfe25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008778488s
STEP: Saw pod success
Apr 27 16:37:59.860: INFO: Pod "pod-projected-secrets-4ea561e9-a30a-41e3-a2e9-629f4bddfe25" satisfied condition "Succeeded or Failed"
Apr 27 16:37:59.864: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-projected-secrets-4ea561e9-a30a-41e3-a2e9-629f4bddfe25 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:37:59.978: INFO: Waiting for pod pod-projected-secrets-4ea561e9-a30a-41e3-a2e9-629f4bddfe25 to disappear
Apr 27 16:37:59.980: INFO: Pod pod-projected-secrets-4ea561e9-a30a-41e3-a2e9-629f4bddfe25 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:37:59.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-915" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":51,"skipped":662,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:37:59.990: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-221
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:38:00.143: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3fe973f0-d0f0-4301-9908-ebda1eaca4dd" in namespace "projected-221" to be "Succeeded or Failed"
Apr 27 16:38:00.147: INFO: Pod "downwardapi-volume-3fe973f0-d0f0-4301-9908-ebda1eaca4dd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.612435ms
Apr 27 16:38:02.154: INFO: Pod "downwardapi-volume-3fe973f0-d0f0-4301-9908-ebda1eaca4dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010392534s
STEP: Saw pod success
Apr 27 16:38:02.154: INFO: Pod "downwardapi-volume-3fe973f0-d0f0-4301-9908-ebda1eaca4dd" satisfied condition "Succeeded or Failed"
Apr 27 16:38:02.158: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downwardapi-volume-3fe973f0-d0f0-4301-9908-ebda1eaca4dd container client-container: <nil>
STEP: delete the pod
Apr 27 16:38:02.182: INFO: Waiting for pod downwardapi-volume-3fe973f0-d0f0-4301-9908-ebda1eaca4dd to disappear
Apr 27 16:38:02.185: INFO: Pod downwardapi-volume-3fe973f0-d0f0-4301-9908-ebda1eaca4dd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:02.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-221" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":52,"skipped":673,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:02.197: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2384
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:38:02.339: INFO: Creating deployment "test-recreate-deployment"
Apr 27 16:38:02.347: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr 27 16:38:02.352: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Apr 27 16:38:04.359: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr 27 16:38:04.362: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr 27 16:38:04.370: INFO: Updating deployment test-recreate-deployment
Apr 27 16:38:04.370: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Apr 27 16:38:04.412: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-2384 /apis/apps/v1/namespaces/deployment-2384/deployments/test-recreate-deployment e9f3dc67-d245-4d97-b969-4d03424b7358 15955 2 2020-04-27 16:38:02 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-04-27 16:38:04 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 16:38:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0029e80c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-04-27 16:38:04 +0000 UTC,LastTransitionTime:2020-04-27 16:38:04 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-d5667d9c7" is progressing.,LastUpdateTime:2020-04-27 16:38:04 +0000 UTC,LastTransitionTime:2020-04-27 16:38:02 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Apr 27 16:38:04.415: INFO: New ReplicaSet "test-recreate-deployment-d5667d9c7" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-d5667d9c7  deployment-2384 /apis/apps/v1/namespaces/deployment-2384/replicasets/test-recreate-deployment-d5667d9c7 9f27a5b9-9e95-4d16-9db6-192011006125 15954 1 2020-04-27 16:38:04 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment e9f3dc67-d245-4d97-b969-4d03424b7358 0xc0029e85f0 0xc0029e85f1}] []  [{kube-controller-manager Update apps/v1 2020-04-27 16:38:04 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 57 102 51 100 99 54 55 45 100 50 52 53 45 52 100 57 55 45 98 57 54 57 45 52 100 48 51 52 50 52 98 55 51 53 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: d5667d9c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0029e8668 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:38:04.415: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr 27 16:38:04.416: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-74d98b5f7c  deployment-2384 /apis/apps/v1/namespaces/deployment-2384/replicasets/test-recreate-deployment-74d98b5f7c 1a72ea49-9d49-4c08-9585-e35e0d5068e7 15947 2 2020-04-27 16:38:02 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment e9f3dc67-d245-4d97-b969-4d03424b7358 0xc0029e84f7 0xc0029e84f8}] []  [{kube-controller-manager Update apps/v1 2020-04-27 16:38:04 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 57 102 51 100 99 54 55 45 100 50 52 53 45 52 100 57 55 45 98 57 54 57 45 52 100 48 51 52 50 52 98 55 51 53 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 74d98b5f7c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0029e8588 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:38:04.419: INFO: Pod "test-recreate-deployment-d5667d9c7-gc7zq" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-d5667d9c7-gc7zq test-recreate-deployment-d5667d9c7- deployment-2384 /api/v1/namespaces/deployment-2384/pods/test-recreate-deployment-d5667d9c7-gc7zq 5bdf5b25-c1a4-4821-ad42-a2a8ab645bf7 15956 0 2020-04-27 16:38:04 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-recreate-deployment-d5667d9c7 9f27a5b9-9e95-4d16-9db6-192011006125 0xc002ccb540 0xc002ccb541}] []  [{kube-controller-manager Update v1 2020-04-27 16:38:04 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 102 50 55 97 53 98 57 45 57 101 57 53 45 52 100 49 54 45 57 100 98 54 45 49 57 50 48 49 49 48 48 54 49 50 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:38:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-xjfcv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-xjfcv,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-xjfcv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:38:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:38:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:38:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:38:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.21,PodIP:,StartTime:2020-04-27 16:38:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:04.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2384" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":277,"completed":53,"skipped":686,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:04.428: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9564
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:38:05.200: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 27 16:38:07.211: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602285, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602285, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602285, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602285, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:38:10.226: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:10.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9564" for this suite.
STEP: Destroying namespace "webhook-9564-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":277,"completed":54,"skipped":693,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:10.526: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-6246
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:38:10.699: INFO: (0) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 19.809759ms)
Apr 27 16:38:10.742: INFO: (1) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.652348ms)
Apr 27 16:38:10.748: INFO: (2) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.573657ms)
Apr 27 16:38:10.753: INFO: (3) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.765101ms)
Apr 27 16:38:10.758: INFO: (4) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.819259ms)
Apr 27 16:38:10.762: INFO: (5) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.649686ms)
Apr 27 16:38:10.767: INFO: (6) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.499915ms)
Apr 27 16:38:10.771: INFO: (7) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.438824ms)
Apr 27 16:38:10.776: INFO: (8) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.946366ms)
Apr 27 16:38:10.782: INFO: (9) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.388839ms)
Apr 27 16:38:10.787: INFO: (10) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.168357ms)
Apr 27 16:38:10.792: INFO: (11) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.039539ms)
Apr 27 16:38:10.796: INFO: (12) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.520925ms)
Apr 27 16:38:10.802: INFO: (13) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.106623ms)
Apr 27 16:38:10.807: INFO: (14) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.015523ms)
Apr 27 16:38:10.811: INFO: (15) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.551785ms)
Apr 27 16:38:10.816: INFO: (16) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.896014ms)
Apr 27 16:38:10.821: INFO: (17) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.8689ms)
Apr 27 16:38:10.826: INFO: (18) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.944379ms)
Apr 27 16:38:10.831: INFO: (19) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.822065ms)
[AfterEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:10.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6246" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]","total":277,"completed":55,"skipped":745,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:10.840: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5808
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:38:10.988: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-5808'
Apr 27 16:38:11.239: INFO: stderr: ""
Apr 27 16:38:11.239: INFO: stdout: "replicationcontroller/agnhost-master created\n"
Apr 27 16:38:11.239: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-5808'
Apr 27 16:38:11.482: INFO: stderr: ""
Apr 27 16:38:11.482: INFO: stdout: "service/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Apr 27 16:38:12.488: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 16:38:12.488: INFO: Found 0 / 1
Apr 27 16:38:13.487: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 16:38:13.487: INFO: Found 1 / 1
Apr 27 16:38:13.487: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 27 16:38:13.490: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 16:38:13.490: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 27 16:38:13.490: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe pod agnhost-master-qg46z --namespace=kubectl-5808'
Apr 27 16:38:13.577: INFO: stderr: ""
Apr 27 16:38:13.577: INFO: stdout: "Name:         agnhost-master-qg46z\nNamespace:    kubectl-5808\nPriority:     0\nNode:         shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9/10.250.0.21\nStart Time:   Mon, 27 Apr 2020 16:38:11 +0000\nLabels:       app=agnhost\n              role=master\nAnnotations:  cni.projectcalico.org/podIP: 100.64.1.76/32\n              cni.projectcalico.org/podIPs: 100.64.1.76/32\n              kubernetes.io/psp: e2e-test-privileged-psp\nStatus:       Running\nIP:           100.64.1.76\nIPs:\n  IP:           100.64.1.76\nControlled By:  ReplicationController/agnhost-master\nContainers:\n  agnhost-master:\n    Container ID:   docker://507d2f179cc190b9099dec13f26cb88f895a3fd71ddaad959b09e23400031d09\n    Image:          us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Image ID:       docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 27 Apr 2020 16:38:12 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-2q2wz (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-2q2wz:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-2q2wz\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                                                        Message\n  ----    ------     ----       ----                                                        -------\n  Normal  Scheduled  <unknown>  default-scheduler                                           Successfully assigned kubectl-5808/agnhost-master-qg46z to shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9\n  Normal  Pulled     2s         kubelet, shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Container image \"us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\" already present on machine\n  Normal  Created    2s         kubelet, shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Created container agnhost-master\n  Normal  Started    1s         kubelet, shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Started container agnhost-master\n"
Apr 27 16:38:13.577: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe rc agnhost-master --namespace=kubectl-5808'
Apr 27 16:38:13.679: INFO: stderr: ""
Apr 27 16:38:13.679: INFO: stdout: "Name:         agnhost-master\nNamespace:    kubectl-5808\nSelector:     app=agnhost,role=master\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=master\n  Containers:\n   agnhost-master:\n    Image:        us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-master-qg46z\n"
Apr 27 16:38:13.679: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe service agnhost-master --namespace=kubectl-5808'
Apr 27 16:38:13.763: INFO: stderr: ""
Apr 27 16:38:13.763: INFO: stdout: "Name:              agnhost-master\nNamespace:         kubectl-5808\nLabels:            app=agnhost\n                   role=master\nAnnotations:       <none>\nSelector:          app=agnhost,role=master\nType:              ClusterIP\nIP:                100.108.107.229\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         100.64.1.76:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr 27 16:38:13.770: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp'
Apr 27 16:38:13.900: INFO: stderr: ""
Apr 27 16:38:13.901: INFO: stdout: "Name:               shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=22\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/zone=eu-nl-1a\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/instance-type=22\n                    node.kubernetes.io/role=node\n                    topology.kubernetes.io/zone=eu-nl-1a\n                    worker.garden.sapcloud.io/group=worker-1\n                    worker.gardener.cloud/pool=worker-1\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    node.machine.sapcloud.io/last-applied-anno-labels-taints:\n                      {\"metadata\":{\"creationTimestamp\":null,\"labels\":{\"node.kubernetes.io/role\":\"node\",\"worker.garden.sapcloud.io/group\":\"worker-1\",\"worker.gard...\n                    projectcalico.org/IPv4Address: 10.250.0.4/19\n                    projectcalico.org/IPv4IPIPTunnelAddr: 100.64.0.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 27 Apr 2020 16:07:11 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp\n  AcquireTime:     <unset>\n  RenewTime:       Mon, 27 Apr 2020 16:38:11 +0000\nConditions:\n  Type                          Status  LastHeartbeatTime                 LastTransitionTime                Reason                          Message\n  ----                          ------  -----------------                 ------------------                ------                          -------\n  FrequentKubeletRestart        False   Mon, 27 Apr 2020 16:37:24 +0000   Mon, 27 Apr 2020 16:08:04 +0000   NoFrequentKubeletRestart        kubelet is functioning properly\n  FrequentDockerRestart         False   Mon, 27 Apr 2020 16:37:24 +0000   Mon, 27 Apr 2020 16:08:04 +0000   NoFrequentDockerRestart         docker is functioning properly\n  FrequentContainerdRestart     False   Mon, 27 Apr 2020 16:37:24 +0000   Mon, 27 Apr 2020 16:08:04 +0000   NoFrequentContainerdRestart     containerd is functioning properly\n  KernelDeadlock                False   Mon, 27 Apr 2020 16:37:24 +0000   Mon, 27 Apr 2020 16:08:04 +0000   KernelHasNoDeadlock             kernel has no deadlock\n  ReadonlyFilesystem            False   Mon, 27 Apr 2020 16:37:24 +0000   Mon, 27 Apr 2020 16:08:04 +0000   FilesystemIsNotReadOnly         Filesystem is not read-only\n  FrequentUnregisterNetDevice   False   Mon, 27 Apr 2020 16:37:24 +0000   Mon, 27 Apr 2020 16:08:04 +0000   NoFrequentUnregisterNetDevice   node is functioning properly\n  CorruptDockerOverlay2         False   Mon, 27 Apr 2020 16:37:24 +0000   Mon, 27 Apr 2020 16:08:04 +0000   NoCorruptDockerOverlay2         docker overlay2 is functioning properly\n  NetworkUnavailable            False   Mon, 27 Apr 2020 16:15:32 +0000   Mon, 27 Apr 2020 16:15:32 +0000   CalicoIsUp                      Calico is running on this node\n  MemoryPressure                False   Mon, 27 Apr 2020 16:38:04 +0000   Mon, 27 Apr 2020 16:07:11 +0000   KubeletHasSufficientMemory      kubelet has sufficient memory available\n  DiskPressure                  False   Mon, 27 Apr 2020 16:38:04 +0000   Mon, 27 Apr 2020 16:07:11 +0000   KubeletHasNoDiskPressure        kubelet has no disk pressure\n  PIDPressure                   False   Mon, 27 Apr 2020 16:38:04 +0000   Mon, 27 Apr 2020 16:07:11 +0000   KubeletHasSufficientPID         kubelet has sufficient PID available\n  Ready                         True    Mon, 27 Apr 2020 16:38:04 +0000   Mon, 27 Apr 2020 16:07:31 +0000   KubeletReady                    kubelet is posting ready status\nAddresses:\n  InternalIP:  10.250.0.4\nCapacity:\n  attachable-volumes-cinder:  256\n  cpu:                        2\n  ephemeral-storage:          30088688Ki\n  hugepages-1Gi:              0\n  hugepages-2Mi:              0\n  memory:                     4024308Ki\n  pods:                       110\nAllocatable:\n  attachable-volumes-cinder:  256\n  cpu:                        1920m\n  ephemeral-storage:          29270275664\n  hugepages-1Gi:              0\n  hugepages-2Mi:              0\n  memory:                     2841104996\n  pods:                       110\nSystem Info:\n  Machine ID:                 a0b3e3cb23a54c65ae3ca32d59d5c4fe\n  System UUID:                99cf1e42-ee18-3460-934a-7787dccf72e9\n  Boot ID:                    1b5d4392-e210-4327-927f-8a02661d1eb8\n  Kernel Version:             4.19.106-coreos\n  OS Image:                   Container Linux by CoreOS 2345.3.0 (Rhyolite)\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://18.6.3\n  Kubelet Version:            v1.18.2\n  Kube-Proxy Version:         v1.18.2\nPodCIDR:                      100.64.0.0/24\nPodCIDRs:                     100.64.0.0/24\nProviderID:                   openstack:///dca19732-9cb1-4ec2-9097-c772aae73382\nNon-terminated Pods:          (18 in total)\n  Namespace                   Name                                                               CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                   ----                                                               ------------  ----------  ---------------  -------------  ---\n  kube-system                 addons-nginx-ingress-controller-6cf77756b5-rw99m                   100m (5%)     2 (104%)    100Mi (3%)       1Gi (37%)      56m\n  kube-system                 addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-q52mz    0 (0%)        0 (0%)      0 (0%)           0 (0%)         56m\n  kube-system                 blackbox-exporter-5dc75b79b7-7xcjk                                 5m (0%)       10m (0%)    5Mi (0%)         35Mi (1%)      56m\n  kube-system                 calico-kube-controllers-77dcb8f688-7jxx4                           10m (0%)      50m (2%)    50Mi (1%)        100Mi (3%)     56m\n  kube-system                 calico-node-vertical-autoscaler-74d4897db8-h9n8r                   10m (0%)      10m (0%)    50Mi (1%)        50Mi (1%)      56m\n  kube-system                 calico-node-xphhz                                                  250m (13%)    800m (41%)  100Mi (3%)       700Mi (25%)    22m\n  kube-system                 calico-typha-deploy-784665cc66-9ngtv                               200m (10%)    500m (26%)  100Mi (3%)       700Mi (25%)    56m\n  kube-system                 calico-typha-horizontal-autoscaler-6fdd5d8746-hv92s                10m (0%)      10m (0%)    50Mi (1%)        50Mi (1%)      56m\n  kube-system                 calico-typha-vertical-autoscaler-5b477c88cf-k2f8l                  10m (0%)      10m (0%)    50Mi (1%)        50Mi (1%)      56m\n  kube-system                 coredns-5cb857d789-lrv9m                                           50m (2%)      100m (5%)   15Mi (0%)        100Mi (3%)     55m\n  kube-system                 coredns-5cb857d789-s8ws2                                           50m (2%)      100m (5%)   15Mi (0%)        100Mi (3%)     56m\n  kube-system                 kube-proxy-h2cx7                                                   20m (1%)      0 (0%)      64Mi (2%)        0 (0%)         31m\n  kube-system                 metrics-server-5f76b49bb-ktlbv                                     20m (1%)      100m (5%)   100Mi (3%)       1Gi (37%)      56m\n  kube-system                 node-exporter-9pkd5                                                5m (0%)       25m (1%)    10Mi (0%)        100Mi (3%)     31m\n  kube-system                 node-problem-detector-tq7hl                                        20m (1%)      200m (10%)  20Mi (0%)        100Mi (3%)     31m\n  kube-system                 vpn-shoot-5b5f49b4bf-trqr9                                         100m (5%)     1 (52%)     100Mi (3%)       1000Mi (36%)   56m\n  kubernetes-dashboard        dashboard-metrics-scraper-76c7b697bc-l2z4c                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         56m\n  kubernetes-dashboard        kubernetes-dashboard-6b586c4cb4-9c2rc                              50m (2%)      100m (5%)   50Mi (1%)        256Mi (9%)     56m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                   Requests     Limits\n  --------                   --------     ------\n  cpu                        910m (47%)   5015m (261%)\n  memory                     879Mi (32%)  5389Mi (198%)\n  ephemeral-storage          0 (0%)       0 (0%)\n  hugepages-1Gi              0 (0%)       0 (0%)\n  hugepages-2Mi              0 (0%)       0 (0%)\n  attachable-volumes-cinder  0            0\nEvents:\n  Type     Reason                   Age                From                                                                Message\n  ----     ------                   ----               ----                                                                -------\n  Normal   Starting                 31m                kubelet, shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp          Starting kubelet.\n  Normal   NodeAllocatableEnforced  31m                kubelet, shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientMemory  31m (x2 over 31m)  kubelet, shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp          Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    31m (x2 over 31m)  kubelet, shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp          Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     31m (x2 over 31m)  kubelet, shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp          Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp status is now: NodeHasSufficientPID\n  Normal   Starting                 30m                kube-proxy, shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp       Starting kube-proxy.\n  Normal   NodeReady                30m                kubelet, shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp          Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp status is now: NodeReady\n  Warning  DockerStart              30m (x2 over 30m)  systemd-monitor, shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp  Starting Docker Application Container Engine...\n"
Apr 27 16:38:13.901: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe namespace kubectl-5808'
Apr 27 16:38:13.981: INFO: stderr: ""
Apr 27 16:38:13.981: INFO: stdout: "Name:         kubectl-5808\nLabels:       e2e-framework=kubectl\n              e2e-run=1c89e158-d4db-4fc9-b2a1-b6ea1e61f82a\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:13.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5808" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":277,"completed":56,"skipped":790,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:13.993: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3809
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:38:14.171: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr 27 16:38:14.180: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 27 16:38:19.185: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 27 16:38:19.185: INFO: Creating deployment "test-rolling-update-deployment"
Apr 27 16:38:19.189: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr 27 16:38:19.195: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Apr 27 16:38:21.203: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr 27 16:38:21.207: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Apr 27 16:38:21.217: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-3809 /apis/apps/v1/namespaces/deployment-3809/deployments/test-rolling-update-deployment b7734c42-f4b4-4ae0-98f4-5c42499857c1 16185 1 2020-04-27 16:38:19 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2020-04-27 16:38:19 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 16:38:20 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0033b02d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-04-27 16:38:19 +0000 UTC,LastTransitionTime:2020-04-27 16:38:19 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-59d5cb45c7" has successfully progressed.,LastUpdateTime:2020-04-27 16:38:20 +0000 UTC,LastTransitionTime:2020-04-27 16:38:19 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 27 16:38:21.221: INFO: New ReplicaSet "test-rolling-update-deployment-59d5cb45c7" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7  deployment-3809 /apis/apps/v1/namespaces/deployment-3809/replicasets/test-rolling-update-deployment-59d5cb45c7 88b9d929-2142-42ec-8d7b-bfde08677333 16177 1 2020-04-27 16:38:19 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment b7734c42-f4b4-4ae0-98f4-5c42499857c1 0xc00071cf77 0xc00071cf78}] []  [{kube-controller-manager Update apps/v1 2020-04-27 16:38:20 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 98 55 55 51 52 99 52 50 45 102 52 98 52 45 52 97 101 48 45 57 56 102 52 45 53 99 52 50 52 57 57 56 53 55 99 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 59d5cb45c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00071d008 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:38:21.221: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr 27 16:38:21.221: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-3809 /apis/apps/v1/namespaces/deployment-3809/replicasets/test-rolling-update-controller 4f4af4d6-6a21-4e4e-ab84-413a03d51974 16184 2 2020-04-27 16:38:14 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment b7734c42-f4b4-4ae0-98f4-5c42499857c1 0xc00071ce67 0xc00071ce68}] []  [{e2e.test Update apps/v1 2020-04-27 16:38:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 16:38:20 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 98 55 55 51 52 99 52 50 45 102 52 98 52 45 52 97 101 48 45 57 56 102 52 45 53 99 52 50 52 57 57 56 53 55 99 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00071cf08 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:38:21.224: INFO: Pod "test-rolling-update-deployment-59d5cb45c7-mthq7" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7-mthq7 test-rolling-update-deployment-59d5cb45c7- deployment-3809 /api/v1/namespaces/deployment-3809/pods/test-rolling-update-deployment-59d5cb45c7-mthq7 dd17b30f-b437-4170-a4f4-b1dd91488eb6 16176 0 2020-04-27 16:38:19 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[cni.projectcalico.org/podIP:100.64.1.78/32 cni.projectcalico.org/podIPs:100.64.1.78/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rolling-update-deployment-59d5cb45c7 88b9d929-2142-42ec-8d7b-bfde08677333 0xc00071d507 0xc00071d508}] []  [{calico Update v1 2020-04-27 16:38:19 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kube-controller-manager Update v1 2020-04-27 16:38:19 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 56 56 98 57 100 57 50 57 45 50 49 52 50 45 52 50 101 99 45 56 100 55 98 45 98 102 100 101 48 56 54 55 55 51 51 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:38:20 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 55 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ws48v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ws48v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ws48v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:38:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:38:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:38:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:38:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.21,PodIP:100.64.1.78,StartTime:2020-04-27 16:38:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:38:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://61590a978c197d1168f25a7be61bfeb131ea9a8789c9c1c66a29be8d0b82c115,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.78,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:21.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3809" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":277,"completed":57,"skipped":798,"failed":0}
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:21.234: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7394
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 27 16:38:21.391: INFO: Waiting up to 5m0s for pod "pod-c961cff8-2d78-4e0f-9640-5eaeaefb1948" in namespace "emptydir-7394" to be "Succeeded or Failed"
Apr 27 16:38:21.394: INFO: Pod "pod-c961cff8-2d78-4e0f-9640-5eaeaefb1948": Phase="Pending", Reason="", readiness=false. Elapsed: 3.468747ms
Apr 27 16:38:23.399: INFO: Pod "pod-c961cff8-2d78-4e0f-9640-5eaeaefb1948": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008113709s
STEP: Saw pod success
Apr 27 16:38:23.399: INFO: Pod "pod-c961cff8-2d78-4e0f-9640-5eaeaefb1948" satisfied condition "Succeeded or Failed"
Apr 27 16:38:23.403: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-c961cff8-2d78-4e0f-9640-5eaeaefb1948 container test-container: <nil>
STEP: delete the pod
Apr 27 16:38:23.423: INFO: Waiting for pod pod-c961cff8-2d78-4e0f-9640-5eaeaefb1948 to disappear
Apr 27 16:38:23.430: INFO: Pod pod-c961cff8-2d78-4e0f-9640-5eaeaefb1948 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:23.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7394" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":58,"skipped":804,"failed":0}
SSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:23.440: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7778
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:23.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7778" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":277,"completed":59,"skipped":811,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:23.602: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-1491
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:38:23.755: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating replication controller svc-latency-rc in namespace svc-latency-1491
I0427 16:38:23.768517    5439 runners.go:190] Created replication controller with name: svc-latency-rc, namespace: svc-latency-1491, replica count: 1
I0427 16:38:24.819031    5439 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0427 16:38:25.819256    5439 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 27 16:38:25.934: INFO: Created: latency-svc-4pxg8
Apr 27 16:38:25.941: INFO: Got endpoints: latency-svc-4pxg8 [22.263325ms]
Apr 27 16:38:25.952: INFO: Created: latency-svc-bg6sf
Apr 27 16:38:25.957: INFO: Got endpoints: latency-svc-bg6sf [15.57304ms]
Apr 27 16:38:25.958: INFO: Created: latency-svc-mtv2l
Apr 27 16:38:25.961: INFO: Got endpoints: latency-svc-mtv2l [19.124954ms]
Apr 27 16:38:25.966: INFO: Created: latency-svc-cphdf
Apr 27 16:38:25.969: INFO: Got endpoints: latency-svc-cphdf [26.924228ms]
Apr 27 16:38:25.971: INFO: Created: latency-svc-b8h4f
Apr 27 16:38:25.974: INFO: Got endpoints: latency-svc-b8h4f [31.779483ms]
Apr 27 16:38:25.977: INFO: Created: latency-svc-hdzbs
Apr 27 16:38:25.981: INFO: Got endpoints: latency-svc-hdzbs [39.343497ms]
Apr 27 16:38:25.985: INFO: Created: latency-svc-dqw88
Apr 27 16:38:25.990: INFO: Got endpoints: latency-svc-dqw88 [48.481824ms]
Apr 27 16:38:25.991: INFO: Created: latency-svc-2rzxb
Apr 27 16:38:25.994: INFO: Got endpoints: latency-svc-2rzxb [51.845584ms]
Apr 27 16:38:25.998: INFO: Created: latency-svc-t24kf
Apr 27 16:38:26.001: INFO: Got endpoints: latency-svc-t24kf [58.677505ms]
Apr 27 16:38:26.005: INFO: Created: latency-svc-j9phb
Apr 27 16:38:26.009: INFO: Got endpoints: latency-svc-j9phb [66.609057ms]
Apr 27 16:38:26.009: INFO: Created: latency-svc-wbdzf
Apr 27 16:38:26.015: INFO: Created: latency-svc-nz2l5
Apr 27 16:38:26.016: INFO: Got endpoints: latency-svc-wbdzf [73.423008ms]
Apr 27 16:38:26.018: INFO: Got endpoints: latency-svc-nz2l5 [76.192689ms]
Apr 27 16:38:26.023: INFO: Created: latency-svc-d5wzz
Apr 27 16:38:26.026: INFO: Got endpoints: latency-svc-d5wzz [84.033756ms]
Apr 27 16:38:26.031: INFO: Created: latency-svc-t8m6s
Apr 27 16:38:26.035: INFO: Created: latency-svc-9c6bh
Apr 27 16:38:26.064: INFO: Got endpoints: latency-svc-9c6bh [122.243262ms]
Apr 27 16:38:26.065: INFO: Got endpoints: latency-svc-t8m6s [46.312869ms]
Apr 27 16:38:26.065: INFO: Created: latency-svc-zznhn
Apr 27 16:38:26.067: INFO: Got endpoints: latency-svc-zznhn [124.559402ms]
Apr 27 16:38:26.086: INFO: Created: latency-svc-ll75q
Apr 27 16:38:26.090: INFO: Got endpoints: latency-svc-ll75q [148.190121ms]
Apr 27 16:38:26.091: INFO: Created: latency-svc-7zh9z
Apr 27 16:38:26.093: INFO: Got endpoints: latency-svc-7zh9z [136.036149ms]
Apr 27 16:38:26.097: INFO: Created: latency-svc-t2lhc
Apr 27 16:38:26.100: INFO: Got endpoints: latency-svc-t2lhc [138.969598ms]
Apr 27 16:38:26.102: INFO: Created: latency-svc-6cwpr
Apr 27 16:38:26.105: INFO: Got endpoints: latency-svc-6cwpr [135.899883ms]
Apr 27 16:38:26.107: INFO: Created: latency-svc-fn82d
Apr 27 16:38:26.112: INFO: Got endpoints: latency-svc-fn82d [137.921722ms]
Apr 27 16:38:26.131: INFO: Created: latency-svc-gsbk9
Apr 27 16:38:26.137: INFO: Got endpoints: latency-svc-gsbk9 [155.340447ms]
Apr 27 16:38:26.165: INFO: Created: latency-svc-ctv4t
Apr 27 16:38:26.173: INFO: Got endpoints: latency-svc-ctv4t [182.365757ms]
Apr 27 16:38:26.173: INFO: Created: latency-svc-9hqbt
Apr 27 16:38:26.185: INFO: Got endpoints: latency-svc-9hqbt [190.669338ms]
Apr 27 16:38:26.187: INFO: Created: latency-svc-qr9jc
Apr 27 16:38:26.192: INFO: Got endpoints: latency-svc-qr9jc [190.809671ms]
Apr 27 16:38:26.195: INFO: Created: latency-svc-6rbj8
Apr 27 16:38:26.198: INFO: Got endpoints: latency-svc-6rbj8 [188.960725ms]
Apr 27 16:38:26.202: INFO: Created: latency-svc-qh6h5
Apr 27 16:38:26.205: INFO: Got endpoints: latency-svc-qh6h5 [189.165256ms]
Apr 27 16:38:26.264: INFO: Created: latency-svc-974sc
Apr 27 16:38:26.266: INFO: Created: latency-svc-ft84v
Apr 27 16:38:26.268: INFO: Got endpoints: latency-svc-974sc [241.836722ms]
Apr 27 16:38:26.273: INFO: Got endpoints: latency-svc-ft84v [208.298738ms]
Apr 27 16:38:26.273: INFO: Created: latency-svc-zhh5r
Apr 27 16:38:26.279: INFO: Got endpoints: latency-svc-zhh5r [214.344517ms]
Apr 27 16:38:26.288: INFO: Created: latency-svc-hrvkr
Apr 27 16:38:26.365: INFO: Created: latency-svc-zl22s
Apr 27 16:38:26.365: INFO: Got endpoints: latency-svc-zl22s [297.842104ms]
Apr 27 16:38:26.367: INFO: Got endpoints: latency-svc-hrvkr [276.593834ms]
Apr 27 16:38:26.371: INFO: Created: latency-svc-5tjm5
Apr 27 16:38:26.375: INFO: Got endpoints: latency-svc-5tjm5 [281.619204ms]
Apr 27 16:38:26.380: INFO: Created: latency-svc-4lj77
Apr 27 16:38:26.382: INFO: Got endpoints: latency-svc-4lj77 [282.047519ms]
Apr 27 16:38:26.385: INFO: Created: latency-svc-bcn9k
Apr 27 16:38:26.390: INFO: Got endpoints: latency-svc-bcn9k [285.010932ms]
Apr 27 16:38:26.390: INFO: Created: latency-svc-qfvl9
Apr 27 16:38:26.392: INFO: Got endpoints: latency-svc-qfvl9 [280.282591ms]
Apr 27 16:38:26.397: INFO: Created: latency-svc-fwds8
Apr 27 16:38:26.403: INFO: Created: latency-svc-gkgh2
Apr 27 16:38:26.403: INFO: Got endpoints: latency-svc-fwds8 [266.081684ms]
Apr 27 16:38:26.467: INFO: Got endpoints: latency-svc-gkgh2 [294.060732ms]
Apr 27 16:38:26.477: INFO: Created: latency-svc-zd8qb
Apr 27 16:38:26.481: INFO: Got endpoints: latency-svc-zd8qb [296.761556ms]
Apr 27 16:38:26.482: INFO: Created: latency-svc-6jq6n
Apr 27 16:38:26.485: INFO: Got endpoints: latency-svc-6jq6n [293.527818ms]
Apr 27 16:38:26.490: INFO: Created: latency-svc-8qcwg
Apr 27 16:38:26.493: INFO: Got endpoints: latency-svc-8qcwg [295.389617ms]
Apr 27 16:38:26.496: INFO: Created: latency-svc-tvt9h
Apr 27 16:38:26.502: INFO: Created: latency-svc-z8m5m
Apr 27 16:38:26.508: INFO: Created: latency-svc-9rmq5
Apr 27 16:38:26.515: INFO: Created: latency-svc-nxlrh
Apr 27 16:38:26.524: INFO: Created: latency-svc-jcl54
Apr 27 16:38:26.566: INFO: Got endpoints: latency-svc-tvt9h [360.723151ms]
Apr 27 16:38:26.569: INFO: Created: latency-svc-gh7kk
Apr 27 16:38:26.589: INFO: Created: latency-svc-rgrpn
Apr 27 16:38:26.589: INFO: Got endpoints: latency-svc-z8m5m [320.599484ms]
Apr 27 16:38:26.593: INFO: Created: latency-svc-998pr
Apr 27 16:38:26.600: INFO: Created: latency-svc-8wzqd
Apr 27 16:38:26.604: INFO: Created: latency-svc-5grr4
Apr 27 16:38:26.608: INFO: Created: latency-svc-m5fxb
Apr 27 16:38:26.614: INFO: Created: latency-svc-vwkqs
Apr 27 16:38:26.620: INFO: Created: latency-svc-brfd4
Apr 27 16:38:26.626: INFO: Created: latency-svc-2pdk5
Apr 27 16:38:26.630: INFO: Created: latency-svc-pzdxr
Apr 27 16:38:26.636: INFO: Created: latency-svc-thblp
Apr 27 16:38:26.640: INFO: Got endpoints: latency-svc-9rmq5 [366.697488ms]
Apr 27 16:38:26.640: INFO: Created: latency-svc-xzn4w
Apr 27 16:38:26.664: INFO: Created: latency-svc-smxnl
Apr 27 16:38:26.694: INFO: Got endpoints: latency-svc-nxlrh [414.903104ms]
Apr 27 16:38:26.702: INFO: Created: latency-svc-bprd6
Apr 27 16:38:26.739: INFO: Got endpoints: latency-svc-jcl54 [373.990141ms]
Apr 27 16:38:26.747: INFO: Created: latency-svc-cvbs2
Apr 27 16:38:26.790: INFO: Got endpoints: latency-svc-gh7kk [422.658433ms]
Apr 27 16:38:26.801: INFO: Created: latency-svc-6jw9r
Apr 27 16:38:26.839: INFO: Got endpoints: latency-svc-rgrpn [463.878202ms]
Apr 27 16:38:26.848: INFO: Created: latency-svc-2bt97
Apr 27 16:38:26.890: INFO: Got endpoints: latency-svc-998pr [507.998384ms]
Apr 27 16:38:26.900: INFO: Created: latency-svc-g2gmg
Apr 27 16:38:26.938: INFO: Got endpoints: latency-svc-8wzqd [548.668124ms]
Apr 27 16:38:26.947: INFO: Created: latency-svc-7f4ns
Apr 27 16:38:26.988: INFO: Got endpoints: latency-svc-5grr4 [596.376956ms]
Apr 27 16:38:26.998: INFO: Created: latency-svc-lb6zs
Apr 27 16:38:27.039: INFO: Got endpoints: latency-svc-m5fxb [635.889368ms]
Apr 27 16:38:27.048: INFO: Created: latency-svc-pjnwv
Apr 27 16:38:27.089: INFO: Got endpoints: latency-svc-vwkqs [622.56282ms]
Apr 27 16:38:27.099: INFO: Created: latency-svc-pm5kh
Apr 27 16:38:27.141: INFO: Got endpoints: latency-svc-brfd4 [659.280871ms]
Apr 27 16:38:27.151: INFO: Created: latency-svc-5wqlx
Apr 27 16:38:27.189: INFO: Got endpoints: latency-svc-2pdk5 [703.79565ms]
Apr 27 16:38:27.198: INFO: Created: latency-svc-m2lrl
Apr 27 16:38:27.240: INFO: Got endpoints: latency-svc-pzdxr [747.298417ms]
Apr 27 16:38:27.249: INFO: Created: latency-svc-pqc6t
Apr 27 16:38:27.289: INFO: Got endpoints: latency-svc-thblp [723.466733ms]
Apr 27 16:38:27.298: INFO: Created: latency-svc-2kgwk
Apr 27 16:38:27.342: INFO: Got endpoints: latency-svc-xzn4w [753.095901ms]
Apr 27 16:38:27.353: INFO: Created: latency-svc-2fhdn
Apr 27 16:38:27.389: INFO: Got endpoints: latency-svc-smxnl [749.33721ms]
Apr 27 16:38:27.404: INFO: Created: latency-svc-fssfh
Apr 27 16:38:27.439: INFO: Got endpoints: latency-svc-bprd6 [745.166902ms]
Apr 27 16:38:27.448: INFO: Created: latency-svc-k4pd5
Apr 27 16:38:27.489: INFO: Got endpoints: latency-svc-cvbs2 [750.260101ms]
Apr 27 16:38:27.498: INFO: Created: latency-svc-9b2zd
Apr 27 16:38:27.539: INFO: Got endpoints: latency-svc-6jw9r [749.474806ms]
Apr 27 16:38:27.550: INFO: Created: latency-svc-2jfsp
Apr 27 16:38:27.591: INFO: Got endpoints: latency-svc-2bt97 [752.154139ms]
Apr 27 16:38:27.600: INFO: Created: latency-svc-hq4ln
Apr 27 16:38:27.641: INFO: Got endpoints: latency-svc-g2gmg [750.393953ms]
Apr 27 16:38:27.650: INFO: Created: latency-svc-z2p2k
Apr 27 16:38:27.689: INFO: Got endpoints: latency-svc-7f4ns [750.464717ms]
Apr 27 16:38:27.699: INFO: Created: latency-svc-546rx
Apr 27 16:38:27.740: INFO: Got endpoints: latency-svc-lb6zs [750.991782ms]
Apr 27 16:38:27.749: INFO: Created: latency-svc-9zqh2
Apr 27 16:38:27.793: INFO: Got endpoints: latency-svc-pjnwv [754.165961ms]
Apr 27 16:38:27.804: INFO: Created: latency-svc-2gxz9
Apr 27 16:38:27.840: INFO: Got endpoints: latency-svc-pm5kh [750.468847ms]
Apr 27 16:38:27.850: INFO: Created: latency-svc-2f57n
Apr 27 16:38:27.889: INFO: Got endpoints: latency-svc-5wqlx [748.149128ms]
Apr 27 16:38:27.909: INFO: Created: latency-svc-64qv2
Apr 27 16:38:27.939: INFO: Got endpoints: latency-svc-m2lrl [749.860722ms]
Apr 27 16:38:27.949: INFO: Created: latency-svc-sdtlk
Apr 27 16:38:27.990: INFO: Got endpoints: latency-svc-pqc6t [749.277826ms]
Apr 27 16:38:27.999: INFO: Created: latency-svc-s72l8
Apr 27 16:38:28.041: INFO: Got endpoints: latency-svc-2kgwk [751.403208ms]
Apr 27 16:38:28.051: INFO: Created: latency-svc-bmclw
Apr 27 16:38:28.091: INFO: Got endpoints: latency-svc-2fhdn [748.808926ms]
Apr 27 16:38:28.101: INFO: Created: latency-svc-s9l45
Apr 27 16:38:28.143: INFO: Got endpoints: latency-svc-fssfh [753.669631ms]
Apr 27 16:38:28.154: INFO: Created: latency-svc-jjt99
Apr 27 16:38:28.195: INFO: Got endpoints: latency-svc-k4pd5 [756.198499ms]
Apr 27 16:38:28.205: INFO: Created: latency-svc-w4nss
Apr 27 16:38:28.239: INFO: Got endpoints: latency-svc-9b2zd [749.596513ms]
Apr 27 16:38:28.252: INFO: Created: latency-svc-5knxd
Apr 27 16:38:28.290: INFO: Got endpoints: latency-svc-2jfsp [750.192848ms]
Apr 27 16:38:28.302: INFO: Created: latency-svc-86jxz
Apr 27 16:38:28.339: INFO: Got endpoints: latency-svc-hq4ln [747.931649ms]
Apr 27 16:38:28.353: INFO: Created: latency-svc-r6qjp
Apr 27 16:38:28.394: INFO: Got endpoints: latency-svc-z2p2k [753.675313ms]
Apr 27 16:38:28.410: INFO: Created: latency-svc-kfnj9
Apr 27 16:38:28.439: INFO: Got endpoints: latency-svc-546rx [749.662956ms]
Apr 27 16:38:28.448: INFO: Created: latency-svc-d2frc
Apr 27 16:38:28.488: INFO: Got endpoints: latency-svc-9zqh2 [748.263992ms]
Apr 27 16:38:28.497: INFO: Created: latency-svc-tx76l
Apr 27 16:38:28.538: INFO: Got endpoints: latency-svc-2gxz9 [744.794957ms]
Apr 27 16:38:28.547: INFO: Created: latency-svc-zn5bl
Apr 27 16:38:28.592: INFO: Got endpoints: latency-svc-2f57n [751.704166ms]
Apr 27 16:38:28.600: INFO: Created: latency-svc-252jf
Apr 27 16:38:28.638: INFO: Got endpoints: latency-svc-64qv2 [749.520985ms]
Apr 27 16:38:28.649: INFO: Created: latency-svc-xk6j8
Apr 27 16:38:28.688: INFO: Got endpoints: latency-svc-sdtlk [748.859245ms]
Apr 27 16:38:28.698: INFO: Created: latency-svc-t47cv
Apr 27 16:38:28.739: INFO: Got endpoints: latency-svc-s72l8 [749.300635ms]
Apr 27 16:38:28.750: INFO: Created: latency-svc-xv6vd
Apr 27 16:38:28.804: INFO: Got endpoints: latency-svc-bmclw [763.46981ms]
Apr 27 16:38:28.813: INFO: Created: latency-svc-vql2v
Apr 27 16:38:28.838: INFO: Got endpoints: latency-svc-s9l45 [747.096462ms]
Apr 27 16:38:28.848: INFO: Created: latency-svc-8j6mn
Apr 27 16:38:28.890: INFO: Got endpoints: latency-svc-jjt99 [746.817092ms]
Apr 27 16:38:28.898: INFO: Created: latency-svc-5z2jp
Apr 27 16:38:28.939: INFO: Got endpoints: latency-svc-w4nss [743.803021ms]
Apr 27 16:38:28.949: INFO: Created: latency-svc-52x5f
Apr 27 16:38:28.991: INFO: Got endpoints: latency-svc-5knxd [752.410573ms]
Apr 27 16:38:29.002: INFO: Created: latency-svc-7pc2h
Apr 27 16:38:29.040: INFO: Got endpoints: latency-svc-86jxz [749.833255ms]
Apr 27 16:38:29.051: INFO: Created: latency-svc-t24cn
Apr 27 16:38:29.089: INFO: Got endpoints: latency-svc-r6qjp [749.699241ms]
Apr 27 16:38:29.100: INFO: Created: latency-svc-7lrcg
Apr 27 16:38:29.139: INFO: Got endpoints: latency-svc-kfnj9 [744.979124ms]
Apr 27 16:38:29.151: INFO: Created: latency-svc-w5trx
Apr 27 16:38:29.189: INFO: Got endpoints: latency-svc-d2frc [750.240763ms]
Apr 27 16:38:29.198: INFO: Created: latency-svc-k82kw
Apr 27 16:38:29.239: INFO: Got endpoints: latency-svc-tx76l [751.075442ms]
Apr 27 16:38:29.250: INFO: Created: latency-svc-7xsjf
Apr 27 16:38:29.289: INFO: Got endpoints: latency-svc-zn5bl [750.787333ms]
Apr 27 16:38:29.299: INFO: Created: latency-svc-zg5mn
Apr 27 16:38:29.341: INFO: Got endpoints: latency-svc-252jf [749.10493ms]
Apr 27 16:38:29.351: INFO: Created: latency-svc-zgstb
Apr 27 16:38:29.390: INFO: Got endpoints: latency-svc-xk6j8 [751.941285ms]
Apr 27 16:38:29.401: INFO: Created: latency-svc-ppl5d
Apr 27 16:38:29.441: INFO: Got endpoints: latency-svc-t47cv [753.040062ms]
Apr 27 16:38:29.451: INFO: Created: latency-svc-6xj2q
Apr 27 16:38:29.488: INFO: Got endpoints: latency-svc-xv6vd [748.989367ms]
Apr 27 16:38:29.501: INFO: Created: latency-svc-xkpd6
Apr 27 16:38:29.539: INFO: Got endpoints: latency-svc-vql2v [734.609437ms]
Apr 27 16:38:29.549: INFO: Created: latency-svc-kcl6t
Apr 27 16:38:29.589: INFO: Got endpoints: latency-svc-8j6mn [750.922678ms]
Apr 27 16:38:29.666: INFO: Created: latency-svc-q64db
Apr 27 16:38:29.677: INFO: Got endpoints: latency-svc-5z2jp [787.675096ms]
Apr 27 16:38:29.766: INFO: Got endpoints: latency-svc-52x5f [826.911588ms]
Apr 27 16:38:29.769: INFO: Got endpoints: latency-svc-7pc2h [778.12013ms]
Apr 27 16:38:29.773: INFO: Created: latency-svc-x895m
Apr 27 16:38:29.866: INFO: Created: latency-svc-tbq8f
Apr 27 16:38:29.867: INFO: Got endpoints: latency-svc-t24cn [827.01295ms]
Apr 27 16:38:29.869: INFO: Got endpoints: latency-svc-7lrcg [780.480716ms]
Apr 27 16:38:29.871: INFO: Created: latency-svc-v4p67
Apr 27 16:38:29.881: INFO: Created: latency-svc-jnf8w
Apr 27 16:38:29.888: INFO: Got endpoints: latency-svc-w5trx [748.653469ms]
Apr 27 16:38:29.889: INFO: Created: latency-svc-5vlfz
Apr 27 16:38:29.898: INFO: Created: latency-svc-lsrd8
Apr 27 16:38:29.939: INFO: Got endpoints: latency-svc-k82kw [749.984019ms]
Apr 27 16:38:29.948: INFO: Created: latency-svc-wrcsz
Apr 27 16:38:29.989: INFO: Got endpoints: latency-svc-7xsjf [749.828563ms]
Apr 27 16:38:29.998: INFO: Created: latency-svc-kjx7z
Apr 27 16:38:30.039: INFO: Got endpoints: latency-svc-zg5mn [750.11126ms]
Apr 27 16:38:30.048: INFO: Created: latency-svc-zmjkl
Apr 27 16:38:30.089: INFO: Got endpoints: latency-svc-zgstb [748.302215ms]
Apr 27 16:38:30.098: INFO: Created: latency-svc-gwgr9
Apr 27 16:38:30.141: INFO: Got endpoints: latency-svc-ppl5d [750.391697ms]
Apr 27 16:38:30.153: INFO: Created: latency-svc-9zf4p
Apr 27 16:38:30.189: INFO: Got endpoints: latency-svc-6xj2q [748.356981ms]
Apr 27 16:38:30.200: INFO: Created: latency-svc-bbtgm
Apr 27 16:38:30.240: INFO: Got endpoints: latency-svc-xkpd6 [751.848497ms]
Apr 27 16:38:30.249: INFO: Created: latency-svc-kzfj7
Apr 27 16:38:30.291: INFO: Got endpoints: latency-svc-kcl6t [752.132589ms]
Apr 27 16:38:30.302: INFO: Created: latency-svc-tc8v5
Apr 27 16:38:30.340: INFO: Got endpoints: latency-svc-q64db [751.005494ms]
Apr 27 16:38:30.350: INFO: Created: latency-svc-xfcjt
Apr 27 16:38:30.390: INFO: Got endpoints: latency-svc-x895m [712.486533ms]
Apr 27 16:38:30.401: INFO: Created: latency-svc-xqzxj
Apr 27 16:38:30.450: INFO: Got endpoints: latency-svc-tbq8f [684.252604ms]
Apr 27 16:38:30.461: INFO: Created: latency-svc-dkbxm
Apr 27 16:38:30.491: INFO: Got endpoints: latency-svc-v4p67 [721.443442ms]
Apr 27 16:38:30.512: INFO: Created: latency-svc-xkx8n
Apr 27 16:38:30.544: INFO: Got endpoints: latency-svc-jnf8w [676.992499ms]
Apr 27 16:38:30.554: INFO: Created: latency-svc-rwcqf
Apr 27 16:38:30.598: INFO: Got endpoints: latency-svc-5vlfz [728.729547ms]
Apr 27 16:38:30.613: INFO: Created: latency-svc-pnxl4
Apr 27 16:38:30.640: INFO: Got endpoints: latency-svc-lsrd8 [751.558983ms]
Apr 27 16:38:30.652: INFO: Created: latency-svc-mqzfm
Apr 27 16:38:30.690: INFO: Got endpoints: latency-svc-wrcsz [750.969429ms]
Apr 27 16:38:30.700: INFO: Created: latency-svc-2lx4b
Apr 27 16:38:30.740: INFO: Got endpoints: latency-svc-kjx7z [751.026465ms]
Apr 27 16:38:30.749: INFO: Created: latency-svc-pjhp5
Apr 27 16:38:30.792: INFO: Got endpoints: latency-svc-zmjkl [753.10218ms]
Apr 27 16:38:30.801: INFO: Created: latency-svc-8wggh
Apr 27 16:38:30.842: INFO: Got endpoints: latency-svc-gwgr9 [752.925897ms]
Apr 27 16:38:30.853: INFO: Created: latency-svc-xn8lk
Apr 27 16:38:30.890: INFO: Got endpoints: latency-svc-9zf4p [749.169211ms]
Apr 27 16:38:30.900: INFO: Created: latency-svc-cf955
Apr 27 16:38:30.952: INFO: Got endpoints: latency-svc-bbtgm [762.812761ms]
Apr 27 16:38:30.963: INFO: Created: latency-svc-wkd96
Apr 27 16:38:30.998: INFO: Got endpoints: latency-svc-kzfj7 [757.518431ms]
Apr 27 16:38:31.008: INFO: Created: latency-svc-dnvvh
Apr 27 16:38:31.041: INFO: Got endpoints: latency-svc-tc8v5 [750.422145ms]
Apr 27 16:38:31.055: INFO: Created: latency-svc-nhmv2
Apr 27 16:38:31.093: INFO: Got endpoints: latency-svc-xfcjt [753.184582ms]
Apr 27 16:38:31.103: INFO: Created: latency-svc-pchrj
Apr 27 16:38:31.140: INFO: Got endpoints: latency-svc-xqzxj [749.891977ms]
Apr 27 16:38:31.154: INFO: Created: latency-svc-hbjjj
Apr 27 16:38:31.189: INFO: Got endpoints: latency-svc-dkbxm [739.063357ms]
Apr 27 16:38:31.199: INFO: Created: latency-svc-5h7jm
Apr 27 16:38:31.240: INFO: Got endpoints: latency-svc-xkx8n [749.122788ms]
Apr 27 16:38:31.250: INFO: Created: latency-svc-c755t
Apr 27 16:38:31.289: INFO: Got endpoints: latency-svc-rwcqf [745.841432ms]
Apr 27 16:38:31.299: INFO: Created: latency-svc-bc9fc
Apr 27 16:38:31.340: INFO: Got endpoints: latency-svc-pnxl4 [742.138669ms]
Apr 27 16:38:31.350: INFO: Created: latency-svc-ghhhx
Apr 27 16:38:31.391: INFO: Got endpoints: latency-svc-mqzfm [751.029885ms]
Apr 27 16:38:31.402: INFO: Created: latency-svc-wzccz
Apr 27 16:38:31.440: INFO: Got endpoints: latency-svc-2lx4b [749.683028ms]
Apr 27 16:38:31.450: INFO: Created: latency-svc-n22r2
Apr 27 16:38:31.489: INFO: Got endpoints: latency-svc-pjhp5 [749.033052ms]
Apr 27 16:38:31.501: INFO: Created: latency-svc-hjj85
Apr 27 16:38:31.540: INFO: Got endpoints: latency-svc-8wggh [747.62671ms]
Apr 27 16:38:31.550: INFO: Created: latency-svc-slhb9
Apr 27 16:38:31.595: INFO: Got endpoints: latency-svc-xn8lk [752.317198ms]
Apr 27 16:38:31.606: INFO: Created: latency-svc-mwtfk
Apr 27 16:38:31.641: INFO: Got endpoints: latency-svc-cf955 [751.144737ms]
Apr 27 16:38:31.652: INFO: Created: latency-svc-d7rqx
Apr 27 16:38:31.690: INFO: Got endpoints: latency-svc-wkd96 [737.743596ms]
Apr 27 16:38:31.699: INFO: Created: latency-svc-snslb
Apr 27 16:38:31.739: INFO: Got endpoints: latency-svc-dnvvh [741.129733ms]
Apr 27 16:38:31.749: INFO: Created: latency-svc-cr8rp
Apr 27 16:38:31.790: INFO: Got endpoints: latency-svc-nhmv2 [748.652387ms]
Apr 27 16:38:31.801: INFO: Created: latency-svc-trgck
Apr 27 16:38:31.840: INFO: Got endpoints: latency-svc-pchrj [746.649634ms]
Apr 27 16:38:31.851: INFO: Created: latency-svc-cjww7
Apr 27 16:38:31.891: INFO: Got endpoints: latency-svc-hbjjj [750.629266ms]
Apr 27 16:38:31.900: INFO: Created: latency-svc-ccndn
Apr 27 16:38:31.939: INFO: Got endpoints: latency-svc-5h7jm [749.733593ms]
Apr 27 16:38:31.949: INFO: Created: latency-svc-hbwwd
Apr 27 16:38:31.989: INFO: Got endpoints: latency-svc-c755t [749.384888ms]
Apr 27 16:38:32.000: INFO: Created: latency-svc-wtcjt
Apr 27 16:38:32.040: INFO: Got endpoints: latency-svc-bc9fc [750.036266ms]
Apr 27 16:38:32.049: INFO: Created: latency-svc-v2lpq
Apr 27 16:38:32.092: INFO: Got endpoints: latency-svc-ghhhx [751.917646ms]
Apr 27 16:38:32.103: INFO: Created: latency-svc-9whsl
Apr 27 16:38:32.141: INFO: Got endpoints: latency-svc-wzccz [750.041231ms]
Apr 27 16:38:32.153: INFO: Created: latency-svc-kbckm
Apr 27 16:38:32.190: INFO: Got endpoints: latency-svc-n22r2 [750.284286ms]
Apr 27 16:38:32.201: INFO: Created: latency-svc-8wljd
Apr 27 16:38:32.240: INFO: Got endpoints: latency-svc-hjj85 [750.860834ms]
Apr 27 16:38:32.249: INFO: Created: latency-svc-x9zbv
Apr 27 16:38:32.293: INFO: Got endpoints: latency-svc-slhb9 [752.960558ms]
Apr 27 16:38:32.318: INFO: Created: latency-svc-q2lzn
Apr 27 16:38:32.339: INFO: Got endpoints: latency-svc-mwtfk [743.905579ms]
Apr 27 16:38:32.357: INFO: Created: latency-svc-2z4lf
Apr 27 16:38:32.398: INFO: Got endpoints: latency-svc-d7rqx [756.347857ms]
Apr 27 16:38:32.418: INFO: Created: latency-svc-svst7
Apr 27 16:38:32.438: INFO: Got endpoints: latency-svc-snslb [748.360445ms]
Apr 27 16:38:32.460: INFO: Created: latency-svc-52x7p
Apr 27 16:38:32.489: INFO: Got endpoints: latency-svc-cr8rp [750.150731ms]
Apr 27 16:38:32.500: INFO: Created: latency-svc-pbd2f
Apr 27 16:38:32.541: INFO: Got endpoints: latency-svc-trgck [750.631827ms]
Apr 27 16:38:32.551: INFO: Created: latency-svc-mlvd2
Apr 27 16:38:32.590: INFO: Got endpoints: latency-svc-cjww7 [749.905412ms]
Apr 27 16:38:32.600: INFO: Created: latency-svc-tj6cr
Apr 27 16:38:32.640: INFO: Got endpoints: latency-svc-ccndn [748.672853ms]
Apr 27 16:38:32.650: INFO: Created: latency-svc-l9cp2
Apr 27 16:38:32.689: INFO: Got endpoints: latency-svc-hbwwd [750.100075ms]
Apr 27 16:38:32.699: INFO: Created: latency-svc-2vzbj
Apr 27 16:38:32.739: INFO: Got endpoints: latency-svc-wtcjt [749.586241ms]
Apr 27 16:38:32.749: INFO: Created: latency-svc-ckrr9
Apr 27 16:38:32.789: INFO: Got endpoints: latency-svc-v2lpq [748.904011ms]
Apr 27 16:38:32.797: INFO: Created: latency-svc-wsbmd
Apr 27 16:38:32.839: INFO: Got endpoints: latency-svc-9whsl [747.197148ms]
Apr 27 16:38:32.849: INFO: Created: latency-svc-xd75d
Apr 27 16:38:32.892: INFO: Got endpoints: latency-svc-kbckm [750.67167ms]
Apr 27 16:38:32.903: INFO: Created: latency-svc-9q8rb
Apr 27 16:38:32.940: INFO: Got endpoints: latency-svc-8wljd [749.250513ms]
Apr 27 16:38:32.950: INFO: Created: latency-svc-pbb8b
Apr 27 16:38:32.990: INFO: Got endpoints: latency-svc-x9zbv [749.563414ms]
Apr 27 16:38:32.999: INFO: Created: latency-svc-frd45
Apr 27 16:38:33.041: INFO: Got endpoints: latency-svc-q2lzn [748.028492ms]
Apr 27 16:38:33.052: INFO: Created: latency-svc-d8brd
Apr 27 16:38:33.088: INFO: Got endpoints: latency-svc-2z4lf [749.218604ms]
Apr 27 16:38:33.096: INFO: Created: latency-svc-94rb6
Apr 27 16:38:33.139: INFO: Got endpoints: latency-svc-svst7 [741.061184ms]
Apr 27 16:38:33.161: INFO: Created: latency-svc-rzw4b
Apr 27 16:38:33.193: INFO: Got endpoints: latency-svc-52x7p [753.992301ms]
Apr 27 16:38:33.202: INFO: Created: latency-svc-64hnx
Apr 27 16:38:33.242: INFO: Got endpoints: latency-svc-pbd2f [752.683598ms]
Apr 27 16:38:33.252: INFO: Created: latency-svc-t92p9
Apr 27 16:38:33.289: INFO: Got endpoints: latency-svc-mlvd2 [748.380081ms]
Apr 27 16:38:33.299: INFO: Created: latency-svc-79ch2
Apr 27 16:38:33.339: INFO: Got endpoints: latency-svc-tj6cr [749.361917ms]
Apr 27 16:38:33.350: INFO: Created: latency-svc-g286w
Apr 27 16:38:33.389: INFO: Got endpoints: latency-svc-l9cp2 [748.7808ms]
Apr 27 16:38:33.398: INFO: Created: latency-svc-qzwgq
Apr 27 16:38:33.439: INFO: Got endpoints: latency-svc-2vzbj [749.286849ms]
Apr 27 16:38:33.448: INFO: Created: latency-svc-qb99t
Apr 27 16:38:33.488: INFO: Got endpoints: latency-svc-ckrr9 [749.140166ms]
Apr 27 16:38:33.497: INFO: Created: latency-svc-scrhf
Apr 27 16:38:33.539: INFO: Got endpoints: latency-svc-wsbmd [750.800413ms]
Apr 27 16:38:33.549: INFO: Created: latency-svc-5ldff
Apr 27 16:38:33.590: INFO: Got endpoints: latency-svc-xd75d [750.974418ms]
Apr 27 16:38:33.599: INFO: Created: latency-svc-gs77p
Apr 27 16:38:33.639: INFO: Got endpoints: latency-svc-9q8rb [747.764444ms]
Apr 27 16:38:33.649: INFO: Created: latency-svc-794k9
Apr 27 16:38:33.691: INFO: Got endpoints: latency-svc-pbb8b [751.616975ms]
Apr 27 16:38:33.701: INFO: Created: latency-svc-29lqf
Apr 27 16:38:33.741: INFO: Got endpoints: latency-svc-frd45 [750.966417ms]
Apr 27 16:38:33.751: INFO: Created: latency-svc-h6ktn
Apr 27 16:38:33.790: INFO: Got endpoints: latency-svc-d8brd [749.051577ms]
Apr 27 16:38:33.839: INFO: Got endpoints: latency-svc-94rb6 [751.401417ms]
Apr 27 16:38:33.889: INFO: Got endpoints: latency-svc-rzw4b [750.378022ms]
Apr 27 16:38:33.940: INFO: Got endpoints: latency-svc-64hnx [747.489613ms]
Apr 27 16:38:33.990: INFO: Got endpoints: latency-svc-t92p9 [748.227958ms]
Apr 27 16:38:34.040: INFO: Got endpoints: latency-svc-79ch2 [750.129336ms]
Apr 27 16:38:34.092: INFO: Got endpoints: latency-svc-g286w [753.001329ms]
Apr 27 16:38:34.140: INFO: Got endpoints: latency-svc-qzwgq [750.913138ms]
Apr 27 16:38:34.191: INFO: Got endpoints: latency-svc-qb99t [752.433443ms]
Apr 27 16:38:34.241: INFO: Got endpoints: latency-svc-scrhf [752.492911ms]
Apr 27 16:38:34.290: INFO: Got endpoints: latency-svc-5ldff [750.278128ms]
Apr 27 16:38:34.340: INFO: Got endpoints: latency-svc-gs77p [749.645401ms]
Apr 27 16:38:34.389: INFO: Got endpoints: latency-svc-794k9 [749.577078ms]
Apr 27 16:38:34.441: INFO: Got endpoints: latency-svc-29lqf [749.437245ms]
Apr 27 16:38:34.489: INFO: Got endpoints: latency-svc-h6ktn [748.23446ms]
Apr 27 16:38:34.489: INFO: Latencies: [15.57304ms 19.124954ms 26.924228ms 31.779483ms 39.343497ms 46.312869ms 48.481824ms 51.845584ms 58.677505ms 66.609057ms 73.423008ms 76.192689ms 84.033756ms 122.243262ms 124.559402ms 135.899883ms 136.036149ms 137.921722ms 138.969598ms 148.190121ms 155.340447ms 182.365757ms 188.960725ms 189.165256ms 190.669338ms 190.809671ms 208.298738ms 214.344517ms 241.836722ms 266.081684ms 276.593834ms 280.282591ms 281.619204ms 282.047519ms 285.010932ms 293.527818ms 294.060732ms 295.389617ms 296.761556ms 297.842104ms 320.599484ms 360.723151ms 366.697488ms 373.990141ms 414.903104ms 422.658433ms 463.878202ms 507.998384ms 548.668124ms 596.376956ms 622.56282ms 635.889368ms 659.280871ms 676.992499ms 684.252604ms 703.79565ms 712.486533ms 721.443442ms 723.466733ms 728.729547ms 734.609437ms 737.743596ms 739.063357ms 741.061184ms 741.129733ms 742.138669ms 743.803021ms 743.905579ms 744.794957ms 744.979124ms 745.166902ms 745.841432ms 746.649634ms 746.817092ms 747.096462ms 747.197148ms 747.298417ms 747.489613ms 747.62671ms 747.764444ms 747.931649ms 748.028492ms 748.149128ms 748.227958ms 748.23446ms 748.263992ms 748.302215ms 748.356981ms 748.360445ms 748.380081ms 748.652387ms 748.653469ms 748.672853ms 748.7808ms 748.808926ms 748.859245ms 748.904011ms 748.989367ms 749.033052ms 749.051577ms 749.10493ms 749.122788ms 749.140166ms 749.169211ms 749.218604ms 749.250513ms 749.277826ms 749.286849ms 749.300635ms 749.33721ms 749.361917ms 749.384888ms 749.437245ms 749.474806ms 749.520985ms 749.563414ms 749.577078ms 749.586241ms 749.596513ms 749.645401ms 749.662956ms 749.683028ms 749.699241ms 749.733593ms 749.828563ms 749.833255ms 749.860722ms 749.891977ms 749.905412ms 749.984019ms 750.036266ms 750.041231ms 750.100075ms 750.11126ms 750.129336ms 750.150731ms 750.192848ms 750.240763ms 750.260101ms 750.278128ms 750.284286ms 750.378022ms 750.391697ms 750.393953ms 750.422145ms 750.464717ms 750.468847ms 750.629266ms 750.631827ms 750.67167ms 750.787333ms 750.800413ms 750.860834ms 750.913138ms 750.922678ms 750.966417ms 750.969429ms 750.974418ms 750.991782ms 751.005494ms 751.026465ms 751.029885ms 751.075442ms 751.144737ms 751.401417ms 751.403208ms 751.558983ms 751.616975ms 751.704166ms 751.848497ms 751.917646ms 751.941285ms 752.132589ms 752.154139ms 752.317198ms 752.410573ms 752.433443ms 752.492911ms 752.683598ms 752.925897ms 752.960558ms 753.001329ms 753.040062ms 753.095901ms 753.10218ms 753.184582ms 753.669631ms 753.675313ms 753.992301ms 754.165961ms 756.198499ms 756.347857ms 757.518431ms 762.812761ms 763.46981ms 778.12013ms 780.480716ms 787.675096ms 826.911588ms 827.01295ms]
Apr 27 16:38:34.489: INFO: 50 %ile: 749.10493ms
Apr 27 16:38:34.489: INFO: 90 %ile: 752.960558ms
Apr 27 16:38:34.489: INFO: 99 %ile: 826.911588ms
Apr 27 16:38:34.489: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:34.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-1491" for this suite.
•{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":277,"completed":60,"skipped":842,"failed":0}
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:34.502: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7360
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:38:34.670: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Apr 27 16:38:34.680: INFO: Number of nodes with available pods: 0
Apr 27 16:38:34.680: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Apr 27 16:38:34.701: INFO: Number of nodes with available pods: 0
Apr 27 16:38:34.701: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:38:35.708: INFO: Number of nodes with available pods: 0
Apr 27 16:38:35.708: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:38:36.706: INFO: Number of nodes with available pods: 0
Apr 27 16:38:36.706: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:38:37.706: INFO: Number of nodes with available pods: 0
Apr 27 16:38:37.706: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:38:38.708: INFO: Number of nodes with available pods: 0
Apr 27 16:38:38.709: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:38:39.705: INFO: Number of nodes with available pods: 0
Apr 27 16:38:39.705: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:38:40.706: INFO: Number of nodes with available pods: 0
Apr 27 16:38:40.706: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:38:41.705: INFO: Number of nodes with available pods: 0
Apr 27 16:38:41.705: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:38:42.705: INFO: Number of nodes with available pods: 0
Apr 27 16:38:42.706: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:38:43.766: INFO: Number of nodes with available pods: 1
Apr 27 16:38:43.766: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Apr 27 16:38:43.785: INFO: Number of nodes with available pods: 1
Apr 27 16:38:43.785: INFO: Number of running nodes: 0, number of available pods: 1
Apr 27 16:38:44.788: INFO: Number of nodes with available pods: 0
Apr 27 16:38:44.788: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Apr 27 16:38:44.797: INFO: Number of nodes with available pods: 0
Apr 27 16:38:44.797: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:38:45.800: INFO: Number of nodes with available pods: 0
Apr 27 16:38:45.801: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:38:46.802: INFO: Number of nodes with available pods: 0
Apr 27 16:38:46.802: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:38:47.801: INFO: Number of nodes with available pods: 0
Apr 27 16:38:47.801: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:38:48.801: INFO: Number of nodes with available pods: 0
Apr 27 16:38:48.801: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:38:49.801: INFO: Number of nodes with available pods: 0
Apr 27 16:38:49.801: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:38:50.800: INFO: Number of nodes with available pods: 0
Apr 27 16:38:50.800: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:38:51.801: INFO: Number of nodes with available pods: 0
Apr 27 16:38:51.801: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:38:52.802: INFO: Number of nodes with available pods: 1
Apr 27 16:38:52.802: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7360, will wait for the garbage collector to delete the pods
Apr 27 16:38:52.868: INFO: Deleting DaemonSet.extensions daemon-set took: 7.299629ms
Apr 27 16:38:53.369: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.274064ms
Apr 27 16:39:00.074: INFO: Number of nodes with available pods: 0
Apr 27 16:39:00.074: INFO: Number of running nodes: 0, number of available pods: 0
Apr 27 16:39:00.077: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7360/daemonsets","resourceVersion":"18079"},"items":null}

Apr 27 16:39:00.081: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7360/pods","resourceVersion":"18079"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:39:00.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7360" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":277,"completed":61,"skipped":846,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:39:00.110: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3772
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-91e0b8fb-0bf4-4b1f-bfaf-a7357182b9e3
STEP: Creating a pod to test consume configMaps
Apr 27 16:39:00.273: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d6592ab5-d877-4fcc-94cd-84c2ec66bb8b" in namespace "projected-3772" to be "Succeeded or Failed"
Apr 27 16:39:00.276: INFO: Pod "pod-projected-configmaps-d6592ab5-d877-4fcc-94cd-84c2ec66bb8b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.997438ms
Apr 27 16:39:02.280: INFO: Pod "pod-projected-configmaps-d6592ab5-d877-4fcc-94cd-84c2ec66bb8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007288593s
STEP: Saw pod success
Apr 27 16:39:02.280: INFO: Pod "pod-projected-configmaps-d6592ab5-d877-4fcc-94cd-84c2ec66bb8b" satisfied condition "Succeeded or Failed"
Apr 27 16:39:02.283: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-projected-configmaps-d6592ab5-d877-4fcc-94cd-84c2ec66bb8b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:39:02.312: INFO: Waiting for pod pod-projected-configmaps-d6592ab5-d877-4fcc-94cd-84c2ec66bb8b to disappear
Apr 27 16:39:02.315: INFO: Pod pod-projected-configmaps-d6592ab5-d877-4fcc-94cd-84c2ec66bb8b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:39:02.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3772" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":62,"skipped":867,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:39:02.326: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5992
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 27 16:39:02.484: INFO: Waiting up to 5m0s for pod "pod-2c5dada5-218b-4f31-aee3-c57035c47e34" in namespace "emptydir-5992" to be "Succeeded or Failed"
Apr 27 16:39:02.488: INFO: Pod "pod-2c5dada5-218b-4f31-aee3-c57035c47e34": Phase="Pending", Reason="", readiness=false. Elapsed: 3.385878ms
Apr 27 16:39:04.492: INFO: Pod "pod-2c5dada5-218b-4f31-aee3-c57035c47e34": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007354081s
STEP: Saw pod success
Apr 27 16:39:04.492: INFO: Pod "pod-2c5dada5-218b-4f31-aee3-c57035c47e34" satisfied condition "Succeeded or Failed"
Apr 27 16:39:04.495: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-2c5dada5-218b-4f31-aee3-c57035c47e34 container test-container: <nil>
STEP: delete the pod
Apr 27 16:39:04.512: INFO: Waiting for pod pod-2c5dada5-218b-4f31-aee3-c57035c47e34 to disappear
Apr 27 16:39:04.514: INFO: Pod pod-2c5dada5-218b-4f31-aee3-c57035c47e34 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:39:04.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5992" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":63,"skipped":909,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:39:04.523: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-425
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:39:06.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-425" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":277,"completed":64,"skipped":929,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:39:06.704: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6239
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Apr 27 16:39:06.864: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6239 /api/v1/namespaces/watch-6239/configmaps/e2e-watch-test-configmap-a 189b6fc1-0830-4af5-b4a0-4bc02d22d491 18159 0 2020-04-27 16:39:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:39:06 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:39:06.864: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6239 /api/v1/namespaces/watch-6239/configmaps/e2e-watch-test-configmap-a 189b6fc1-0830-4af5-b4a0-4bc02d22d491 18159 0 2020-04-27 16:39:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:39:06 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Apr 27 16:39:16.871: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6239 /api/v1/namespaces/watch-6239/configmaps/e2e-watch-test-configmap-a 189b6fc1-0830-4af5-b4a0-4bc02d22d491 18218 0 2020-04-27 16:39:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:39:16 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:39:16.871: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6239 /api/v1/namespaces/watch-6239/configmaps/e2e-watch-test-configmap-a 189b6fc1-0830-4af5-b4a0-4bc02d22d491 18218 0 2020-04-27 16:39:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:39:16 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Apr 27 16:39:26.879: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6239 /api/v1/namespaces/watch-6239/configmaps/e2e-watch-test-configmap-a 189b6fc1-0830-4af5-b4a0-4bc02d22d491 18277 0 2020-04-27 16:39:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:39:26 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:39:26.879: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6239 /api/v1/namespaces/watch-6239/configmaps/e2e-watch-test-configmap-a 189b6fc1-0830-4af5-b4a0-4bc02d22d491 18277 0 2020-04-27 16:39:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:39:26 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Apr 27 16:39:36.887: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6239 /api/v1/namespaces/watch-6239/configmaps/e2e-watch-test-configmap-a 189b6fc1-0830-4af5-b4a0-4bc02d22d491 18315 0 2020-04-27 16:39:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:39:26 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:39:36.887: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6239 /api/v1/namespaces/watch-6239/configmaps/e2e-watch-test-configmap-a 189b6fc1-0830-4af5-b4a0-4bc02d22d491 18315 0 2020-04-27 16:39:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:39:26 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Apr 27 16:39:46.894: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6239 /api/v1/namespaces/watch-6239/configmaps/e2e-watch-test-configmap-b b62880ed-dbd2-45b3-9e47-83e82baf375b 18354 0 2020-04-27 16:39:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-04-27 16:39:46 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:39:46.894: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6239 /api/v1/namespaces/watch-6239/configmaps/e2e-watch-test-configmap-b b62880ed-dbd2-45b3-9e47-83e82baf375b 18354 0 2020-04-27 16:39:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-04-27 16:39:46 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Apr 27 16:39:56.902: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6239 /api/v1/namespaces/watch-6239/configmaps/e2e-watch-test-configmap-b b62880ed-dbd2-45b3-9e47-83e82baf375b 18394 0 2020-04-27 16:39:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-04-27 16:39:46 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:39:56.902: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6239 /api/v1/namespaces/watch-6239/configmaps/e2e-watch-test-configmap-b b62880ed-dbd2-45b3-9e47-83e82baf375b 18394 0 2020-04-27 16:39:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-04-27 16:39:46 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:40:06.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6239" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":277,"completed":65,"skipped":945,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:40:06.915: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7319
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-7319
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 27 16:40:07.065: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 27 16:40:07.092: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:40:09.096: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:40:11.098: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:40:13.096: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:40:15.096: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:40:17.096: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:40:19.096: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:40:21.096: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:40:23.096: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr 27 16:40:23.103: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Apr 27 16:40:27.138: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.0.21:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7319 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:40:27.138: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:40:27.483: INFO: Found all expected endpoints: [netserver-0]
Apr 27 16:40:27.494: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.1.84:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7319 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:40:27.494: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:40:27.868: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:40:27.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7319" for this suite.
•{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":66,"skipped":957,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:40:27.880: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7358
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on tmpfs
Apr 27 16:40:28.051: INFO: Waiting up to 5m0s for pod "pod-533d3210-89ce-42a6-9c42-9638c078931b" in namespace "emptydir-7358" to be "Succeeded or Failed"
Apr 27 16:40:28.054: INFO: Pod "pod-533d3210-89ce-42a6-9c42-9638c078931b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.885094ms
Apr 27 16:40:30.058: INFO: Pod "pod-533d3210-89ce-42a6-9c42-9638c078931b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006919742s
STEP: Saw pod success
Apr 27 16:40:30.058: INFO: Pod "pod-533d3210-89ce-42a6-9c42-9638c078931b" satisfied condition "Succeeded or Failed"
Apr 27 16:40:30.061: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-533d3210-89ce-42a6-9c42-9638c078931b container test-container: <nil>
STEP: delete the pod
Apr 27 16:40:30.079: INFO: Waiting for pod pod-533d3210-89ce-42a6-9c42-9638c078931b to disappear
Apr 27 16:40:30.081: INFO: Pod pod-533d3210-89ce-42a6-9c42-9638c078931b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:40:30.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7358" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":67,"skipped":966,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:40:30.092: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5235
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Apr 27 16:40:30.248: INFO: Waiting up to 5m0s for pod "downward-api-0672f510-2d1b-4f94-97bd-9c387e779845" in namespace "downward-api-5235" to be "Succeeded or Failed"
Apr 27 16:40:30.251: INFO: Pod "downward-api-0672f510-2d1b-4f94-97bd-9c387e779845": Phase="Pending", Reason="", readiness=false. Elapsed: 2.866962ms
Apr 27 16:40:32.255: INFO: Pod "downward-api-0672f510-2d1b-4f94-97bd-9c387e779845": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007089331s
STEP: Saw pod success
Apr 27 16:40:32.255: INFO: Pod "downward-api-0672f510-2d1b-4f94-97bd-9c387e779845" satisfied condition "Succeeded or Failed"
Apr 27 16:40:32.258: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downward-api-0672f510-2d1b-4f94-97bd-9c387e779845 container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:40:32.279: INFO: Waiting for pod downward-api-0672f510-2d1b-4f94-97bd-9c387e779845 to disappear
Apr 27 16:40:32.282: INFO: Pod downward-api-0672f510-2d1b-4f94-97bd-9c387e779845 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:40:32.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5235" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":277,"completed":68,"skipped":1006,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:40:32.293: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6889
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 27 16:40:32.454: INFO: Waiting up to 5m0s for pod "pod-b2a25dbb-d0c9-4593-b123-a744afab342c" in namespace "emptydir-6889" to be "Succeeded or Failed"
Apr 27 16:40:32.457: INFO: Pod "pod-b2a25dbb-d0c9-4593-b123-a744afab342c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.803994ms
Apr 27 16:40:34.461: INFO: Pod "pod-b2a25dbb-d0c9-4593-b123-a744afab342c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007368445s
STEP: Saw pod success
Apr 27 16:40:34.461: INFO: Pod "pod-b2a25dbb-d0c9-4593-b123-a744afab342c" satisfied condition "Succeeded or Failed"
Apr 27 16:40:34.465: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-b2a25dbb-d0c9-4593-b123-a744afab342c container test-container: <nil>
STEP: delete the pod
Apr 27 16:40:34.481: INFO: Waiting for pod pod-b2a25dbb-d0c9-4593-b123-a744afab342c to disappear
Apr 27 16:40:34.484: INFO: Pod pod-b2a25dbb-d0c9-4593-b123-a744afab342c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:40:34.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6889" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":69,"skipped":1017,"failed":0}
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:40:34.493: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-790
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-2330f130-aa6c-411f-be85-e1d38c749013 in namespace container-probe-790
Apr 27 16:40:36.658: INFO: Started pod busybox-2330f130-aa6c-411f-be85-e1d38c749013 in namespace container-probe-790
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 16:40:36.661: INFO: Initial restart count of pod busybox-2330f130-aa6c-411f-be85-e1d38c749013 is 0
Apr 27 16:41:28.788: INFO: Restart count of pod container-probe-790/busybox-2330f130-aa6c-411f-be85-e1d38c749013 is now 1 (52.127313441s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:28.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-790" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":277,"completed":70,"skipped":1027,"failed":0}
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:28.805: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6052
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-6052
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Apr 27 16:41:28.966: INFO: Found 0 stateful pods, waiting for 3
Apr 27 16:41:38.971: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:41:38.972: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:41:38.972: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:41:38.982: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-6052 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:41:39.575: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:41:39.575: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:41:39.575: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Apr 27 16:41:49.609: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Apr 27 16:41:59.628: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-6052 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:42:00.087: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 16:42:00.087: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:42:00.087: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:42:10.107: INFO: Waiting for StatefulSet statefulset-6052/ss2 to complete update
Apr 27 16:42:10.107: INFO: Waiting for Pod statefulset-6052/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 27 16:42:10.107: INFO: Waiting for Pod statefulset-6052/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 27 16:42:10.107: INFO: Waiting for Pod statefulset-6052/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 27 16:42:20.116: INFO: Waiting for StatefulSet statefulset-6052/ss2 to complete update
Apr 27 16:42:20.116: INFO: Waiting for Pod statefulset-6052/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 27 16:42:20.116: INFO: Waiting for Pod statefulset-6052/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 27 16:42:30.115: INFO: Waiting for StatefulSet statefulset-6052/ss2 to complete update
Apr 27 16:42:30.115: INFO: Waiting for Pod statefulset-6052/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 27 16:42:30.115: INFO: Waiting for Pod statefulset-6052/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 27 16:42:40.116: INFO: Waiting for StatefulSet statefulset-6052/ss2 to complete update
Apr 27 16:42:40.116: INFO: Waiting for Pod statefulset-6052/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Apr 27 16:42:50.116: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-6052 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:42:55.593: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:42:55.593: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:42:55.593: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:43:05.628: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Apr 27 16:43:15.649: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-6052 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:43:16.075: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 16:43:16.075: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:43:16.075: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:43:26.172: INFO: Waiting for StatefulSet statefulset-6052/ss2 to complete update
Apr 27 16:43:26.172: INFO: Waiting for Pod statefulset-6052/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Apr 27 16:43:26.172: INFO: Waiting for Pod statefulset-6052/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Apr 27 16:43:36.180: INFO: Waiting for StatefulSet statefulset-6052/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 16:43:46.180: INFO: Deleting all statefulset in ns statefulset-6052
Apr 27 16:43:46.183: INFO: Scaling statefulset ss2 to 0
Apr 27 16:44:06.198: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:44:06.201: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:06.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6052" for this suite.
•{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":277,"completed":71,"skipped":1033,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:06.223: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3399
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Apr 27 16:44:06.396: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:26.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3399" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":277,"completed":72,"skipped":1038,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:26.480: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8687
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:44:27.024: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:44:30.045: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:30.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8687" for this suite.
STEP: Destroying namespace "webhook-8687-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":277,"completed":73,"skipped":1070,"failed":0}
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:30.298: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9973
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:44:30.452: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7b4c2744-a3f1-42bf-9bd7-dd7d3eb1f4ce" in namespace "downward-api-9973" to be "Succeeded or Failed"
Apr 27 16:44:30.455: INFO: Pod "downwardapi-volume-7b4c2744-a3f1-42bf-9bd7-dd7d3eb1f4ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.970427ms
Apr 27 16:44:32.459: INFO: Pod "downwardapi-volume-7b4c2744-a3f1-42bf-9bd7-dd7d3eb1f4ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007279054s
Apr 27 16:44:34.464: INFO: Pod "downwardapi-volume-7b4c2744-a3f1-42bf-9bd7-dd7d3eb1f4ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012079606s
STEP: Saw pod success
Apr 27 16:44:34.464: INFO: Pod "downwardapi-volume-7b4c2744-a3f1-42bf-9bd7-dd7d3eb1f4ce" satisfied condition "Succeeded or Failed"
Apr 27 16:44:34.467: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downwardapi-volume-7b4c2744-a3f1-42bf-9bd7-dd7d3eb1f4ce container client-container: <nil>
STEP: delete the pod
Apr 27 16:44:34.581: INFO: Waiting for pod downwardapi-volume-7b4c2744-a3f1-42bf-9bd7-dd7d3eb1f4ce to disappear
Apr 27 16:44:34.584: INFO: Pod downwardapi-volume-7b4c2744-a3f1-42bf-9bd7-dd7d3eb1f4ce no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:34.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9973" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":277,"completed":74,"skipped":1074,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:34.594: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-879
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:44:34.752: INFO: Waiting up to 5m0s for pod "downwardapi-volume-251875f1-4c0f-44f6-8462-d5446fb45a99" in namespace "projected-879" to be "Succeeded or Failed"
Apr 27 16:44:34.755: INFO: Pod "downwardapi-volume-251875f1-4c0f-44f6-8462-d5446fb45a99": Phase="Pending", Reason="", readiness=false. Elapsed: 3.23184ms
Apr 27 16:44:36.760: INFO: Pod "downwardapi-volume-251875f1-4c0f-44f6-8462-d5446fb45a99": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007908935s
STEP: Saw pod success
Apr 27 16:44:36.760: INFO: Pod "downwardapi-volume-251875f1-4c0f-44f6-8462-d5446fb45a99" satisfied condition "Succeeded or Failed"
Apr 27 16:44:36.764: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downwardapi-volume-251875f1-4c0f-44f6-8462-d5446fb45a99 container client-container: <nil>
STEP: delete the pod
Apr 27 16:44:36.788: INFO: Waiting for pod downwardapi-volume-251875f1-4c0f-44f6-8462-d5446fb45a99 to disappear
Apr 27 16:44:36.790: INFO: Pod downwardapi-volume-251875f1-4c0f-44f6-8462-d5446fb45a99 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:36.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-879" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":277,"completed":75,"skipped":1108,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:36.800: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4840
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:44:36.965: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Apr 27 16:44:36.978: INFO: Number of nodes with available pods: 0
Apr 27 16:44:36.978: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:44:37.989: INFO: Number of nodes with available pods: 0
Apr 27 16:44:37.989: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:44:38.989: INFO: Number of nodes with available pods: 2
Apr 27 16:44:38.989: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Apr 27 16:44:39.021: INFO: Wrong image for pod: daemon-set-mslsn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:44:39.021: INFO: Wrong image for pod: daemon-set-xm54w. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:44:40.031: INFO: Wrong image for pod: daemon-set-mslsn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:44:40.031: INFO: Wrong image for pod: daemon-set-xm54w. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:44:41.046: INFO: Wrong image for pod: daemon-set-mslsn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:44:41.046: INFO: Wrong image for pod: daemon-set-xm54w. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:44:42.030: INFO: Wrong image for pod: daemon-set-mslsn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:44:42.031: INFO: Wrong image for pod: daemon-set-xm54w. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:44:42.031: INFO: Pod daemon-set-xm54w is not available
Apr 27 16:44:43.031: INFO: Wrong image for pod: daemon-set-mslsn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:44:43.031: INFO: Pod daemon-set-xjslg is not available
Apr 27 16:44:44.031: INFO: Wrong image for pod: daemon-set-mslsn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:44:44.031: INFO: Pod daemon-set-mslsn is not available
Apr 27 16:44:45.031: INFO: Wrong image for pod: daemon-set-mslsn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:44:45.031: INFO: Pod daemon-set-mslsn is not available
Apr 27 16:44:46.030: INFO: Wrong image for pod: daemon-set-mslsn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:44:46.030: INFO: Pod daemon-set-mslsn is not available
Apr 27 16:44:47.031: INFO: Wrong image for pod: daemon-set-mslsn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:44:47.031: INFO: Pod daemon-set-mslsn is not available
Apr 27 16:44:48.031: INFO: Wrong image for pod: daemon-set-mslsn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:44:48.031: INFO: Pod daemon-set-mslsn is not available
Apr 27 16:44:49.031: INFO: Wrong image for pod: daemon-set-mslsn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:44:49.031: INFO: Pod daemon-set-mslsn is not available
Apr 27 16:44:50.030: INFO: Wrong image for pod: daemon-set-mslsn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:44:50.030: INFO: Pod daemon-set-mslsn is not available
Apr 27 16:44:51.032: INFO: Wrong image for pod: daemon-set-mslsn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:44:51.032: INFO: Pod daemon-set-mslsn is not available
Apr 27 16:44:52.030: INFO: Wrong image for pod: daemon-set-mslsn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:44:52.030: INFO: Pod daemon-set-mslsn is not available
Apr 27 16:44:53.031: INFO: Wrong image for pod: daemon-set-mslsn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:44:53.031: INFO: Pod daemon-set-mslsn is not available
Apr 27 16:44:54.031: INFO: Wrong image for pod: daemon-set-mslsn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:44:54.031: INFO: Pod daemon-set-mslsn is not available
Apr 27 16:44:55.030: INFO: Wrong image for pod: daemon-set-mslsn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 16:44:55.030: INFO: Pod daemon-set-mslsn is not available
Apr 27 16:44:56.031: INFO: Pod daemon-set-qd4sq is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Apr 27 16:44:56.045: INFO: Number of nodes with available pods: 1
Apr 27 16:44:56.045: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 is running more than one daemon pod
Apr 27 16:44:57.075: INFO: Number of nodes with available pods: 2
Apr 27 16:44:57.075: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4840, will wait for the garbage collector to delete the pods
Apr 27 16:44:57.154: INFO: Deleting DaemonSet.extensions daemon-set took: 6.242897ms
Apr 27 16:44:57.654: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.1958ms
Apr 27 16:45:10.058: INFO: Number of nodes with available pods: 0
Apr 27 16:45:10.058: INFO: Number of running nodes: 0, number of available pods: 0
Apr 27 16:45:10.061: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4840/daemonsets","resourceVersion":"20240"},"items":null}

Apr 27 16:45:10.065: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4840/pods","resourceVersion":"20240"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:45:10.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4840" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":277,"completed":76,"skipped":1130,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:45:10.086: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4726
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1418
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Apr 27 16:45:10.237: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-pod --restart=Never --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-4726'
Apr 27 16:45:15.389: INFO: stderr: ""
Apr 27 16:45:15.389: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1423
Apr 27 16:45:15.392: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pods e2e-test-httpd-pod --namespace=kubectl-4726'
Apr 27 16:45:25.033: INFO: stderr: ""
Apr 27 16:45:25.033: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:45:25.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4726" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":277,"completed":77,"skipped":1264,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:45:25.043: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-3311
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:45:25.192: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:45:25.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3311" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":277,"completed":78,"skipped":1299,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:45:25.736: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5773
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:45:26.017: INFO: Create a RollingUpdate DaemonSet
Apr 27 16:45:26.021: INFO: Check that daemon pods launch on every node of the cluster
Apr 27 16:45:26.029: INFO: Number of nodes with available pods: 0
Apr 27 16:45:26.029: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:45:27.043: INFO: Number of nodes with available pods: 0
Apr 27 16:45:27.043: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:45:28.064: INFO: Number of nodes with available pods: 1
Apr 27 16:45:28.064: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 is running more than one daemon pod
Apr 27 16:45:29.041: INFO: Number of nodes with available pods: 2
Apr 27 16:45:29.041: INFO: Number of running nodes: 2, number of available pods: 2
Apr 27 16:45:29.041: INFO: Update the DaemonSet to trigger a rollout
Apr 27 16:45:29.048: INFO: Updating DaemonSet daemon-set
Apr 27 16:45:35.070: INFO: Roll back the DaemonSet before rollout is complete
Apr 27 16:45:35.078: INFO: Updating DaemonSet daemon-set
Apr 27 16:45:35.078: INFO: Make sure DaemonSet rollback is complete
Apr 27 16:45:35.081: INFO: Wrong image for pod: daemon-set-7rzvc. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Apr 27 16:45:35.081: INFO: Pod daemon-set-7rzvc is not available
Apr 27 16:45:36.090: INFO: Wrong image for pod: daemon-set-7rzvc. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Apr 27 16:45:36.090: INFO: Pod daemon-set-7rzvc is not available
Apr 27 16:45:37.090: INFO: Wrong image for pod: daemon-set-7rzvc. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Apr 27 16:45:37.090: INFO: Pod daemon-set-7rzvc is not available
Apr 27 16:45:38.089: INFO: Wrong image for pod: daemon-set-7rzvc. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Apr 27 16:45:38.089: INFO: Pod daemon-set-7rzvc is not available
Apr 27 16:45:39.089: INFO: Wrong image for pod: daemon-set-7rzvc. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Apr 27 16:45:39.089: INFO: Pod daemon-set-7rzvc is not available
Apr 27 16:45:40.090: INFO: Pod daemon-set-wqx27 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5773, will wait for the garbage collector to delete the pods
Apr 27 16:45:40.161: INFO: Deleting DaemonSet.extensions daemon-set took: 6.556944ms
Apr 27 16:45:40.661: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.190672ms
Apr 27 16:45:55.065: INFO: Number of nodes with available pods: 0
Apr 27 16:45:55.065: INFO: Number of running nodes: 0, number of available pods: 0
Apr 27 16:45:55.069: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5773/daemonsets","resourceVersion":"20536"},"items":null}

Apr 27 16:45:55.071: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5773/pods","resourceVersion":"20536"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:45:55.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5773" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":277,"completed":79,"skipped":1337,"failed":0}
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:45:55.092: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7060
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-projected-cnfb
STEP: Creating a pod to test atomic-volume-subpath
Apr 27 16:45:55.257: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-cnfb" in namespace "subpath-7060" to be "Succeeded or Failed"
Apr 27 16:45:55.260: INFO: Pod "pod-subpath-test-projected-cnfb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.108223ms
Apr 27 16:45:57.264: INFO: Pod "pod-subpath-test-projected-cnfb": Phase="Running", Reason="", readiness=true. Elapsed: 2.007520777s
Apr 27 16:45:59.268: INFO: Pod "pod-subpath-test-projected-cnfb": Phase="Running", Reason="", readiness=true. Elapsed: 4.01140362s
Apr 27 16:46:01.288: INFO: Pod "pod-subpath-test-projected-cnfb": Phase="Running", Reason="", readiness=true. Elapsed: 6.031419599s
Apr 27 16:46:03.293: INFO: Pod "pod-subpath-test-projected-cnfb": Phase="Running", Reason="", readiness=true. Elapsed: 8.035711062s
Apr 27 16:46:05.297: INFO: Pod "pod-subpath-test-projected-cnfb": Phase="Running", Reason="", readiness=true. Elapsed: 10.040577705s
Apr 27 16:46:07.302: INFO: Pod "pod-subpath-test-projected-cnfb": Phase="Running", Reason="", readiness=true. Elapsed: 12.044759672s
Apr 27 16:46:09.306: INFO: Pod "pod-subpath-test-projected-cnfb": Phase="Running", Reason="", readiness=true. Elapsed: 14.049075497s
Apr 27 16:46:11.310: INFO: Pod "pod-subpath-test-projected-cnfb": Phase="Running", Reason="", readiness=true. Elapsed: 16.053425461s
Apr 27 16:46:13.314: INFO: Pod "pod-subpath-test-projected-cnfb": Phase="Running", Reason="", readiness=true. Elapsed: 18.057624549s
Apr 27 16:46:15.319: INFO: Pod "pod-subpath-test-projected-cnfb": Phase="Running", Reason="", readiness=true. Elapsed: 20.062258082s
Apr 27 16:46:17.324: INFO: Pod "pod-subpath-test-projected-cnfb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.066807344s
STEP: Saw pod success
Apr 27 16:46:17.324: INFO: Pod "pod-subpath-test-projected-cnfb" satisfied condition "Succeeded or Failed"
Apr 27 16:46:17.327: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-subpath-test-projected-cnfb container test-container-subpath-projected-cnfb: <nil>
STEP: delete the pod
Apr 27 16:46:17.406: INFO: Waiting for pod pod-subpath-test-projected-cnfb to disappear
Apr 27 16:46:17.409: INFO: Pod pod-subpath-test-projected-cnfb no longer exists
STEP: Deleting pod pod-subpath-test-projected-cnfb
Apr 27 16:46:17.409: INFO: Deleting pod "pod-subpath-test-projected-cnfb" in namespace "subpath-7060"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:17.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7060" for this suite.
•{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [LinuxOnly] [Conformance]","total":277,"completed":80,"skipped":1343,"failed":0}
S
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:17.421: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-6438
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's command
Apr 27 16:46:17.582: INFO: Waiting up to 5m0s for pod "var-expansion-ae3e37c2-078a-47e6-92a3-9c9fc28685c6" in namespace "var-expansion-6438" to be "Succeeded or Failed"
Apr 27 16:46:17.585: INFO: Pod "var-expansion-ae3e37c2-078a-47e6-92a3-9c9fc28685c6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.083449ms
Apr 27 16:46:19.590: INFO: Pod "var-expansion-ae3e37c2-078a-47e6-92a3-9c9fc28685c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007515917s
STEP: Saw pod success
Apr 27 16:46:19.590: INFO: Pod "var-expansion-ae3e37c2-078a-47e6-92a3-9c9fc28685c6" satisfied condition "Succeeded or Failed"
Apr 27 16:46:19.593: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod var-expansion-ae3e37c2-078a-47e6-92a3-9c9fc28685c6 container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:46:19.611: INFO: Waiting for pod var-expansion-ae3e37c2-078a-47e6-92a3-9c9fc28685c6 to disappear
Apr 27 16:46:19.614: INFO: Pod var-expansion-ae3e37c2-078a-47e6-92a3-9c9fc28685c6 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:19.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6438" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":277,"completed":81,"skipped":1344,"failed":0}

------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:19.625: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8107
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:46:19.771: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Apr 27 16:46:21.801: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:21.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8107" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":277,"completed":82,"skipped":1344,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:21.818: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7743
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Apr 27 16:46:21.961: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 27 16:46:21.973: INFO: Waiting for terminating namespaces to be deleted...
Apr 27 16:46:21.976: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp before test
Apr 27 16:46:22.054: INFO: coredns-5cb857d789-lrv9m from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.054: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:46:22.054: INFO: calico-node-vertical-autoscaler-74d4897db8-h9n8r from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.054: INFO: 	Container autoscaler ready: true, restart count 6
Apr 27 16:46:22.054: INFO: dashboard-metrics-scraper-76c7b697bc-l2z4c from kubernetes-dashboard started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.054: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 27 16:46:22.054: INFO: coredns-5cb857d789-s8ws2 from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.054: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:46:22.054: INFO: node-exporter-9pkd5 from kube-system started at 2020-04-27 16:07:11 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.054: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:46:22.054: INFO: metrics-server-5f76b49bb-ktlbv from kube-system started at 2020-04-27 16:07:31 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.054: INFO: 	Container metrics-server ready: true, restart count 0
Apr 27 16:46:22.054: INFO: node-problem-detector-tq7hl from kube-system started at 2020-04-27 16:07:11 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.054: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 16:46:22.054: INFO: vpn-shoot-5b5f49b4bf-trqr9 from kube-system started at 2020-04-27 16:07:31 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.054: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 27 16:46:22.054: INFO: calico-typha-vertical-autoscaler-5b477c88cf-k2f8l from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.054: INFO: 	Container autoscaler ready: true, restart count 6
Apr 27 16:46:22.054: INFO: calico-typha-horizontal-autoscaler-6fdd5d8746-hv92s from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.054: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 16:46:22.054: INFO: calico-typha-deploy-784665cc66-9ngtv from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.054: INFO: 	Container calico-typha ready: true, restart count 0
Apr 27 16:46:22.054: INFO: kubernetes-dashboard-6b586c4cb4-9c2rc from kubernetes-dashboard started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.054: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
Apr 27 16:46:22.054: INFO: blackbox-exporter-5dc75b79b7-7xcjk from kube-system started at 2020-04-27 16:07:11 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.054: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 27 16:46:22.054: INFO: kube-proxy-h2cx7 from kube-system started at 2020-04-27 16:07:11 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.054: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:46:22.054: INFO: addons-nginx-ingress-controller-6cf77756b5-rw99m from kube-system started at 2020-04-27 16:07:33 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.054: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 27 16:46:22.054: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-q52mz from kube-system started at 2020-04-27 16:07:41 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.054: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr 27 16:46:22.054: INFO: calico-kube-controllers-77dcb8f688-7jxx4 from kube-system started at 2020-04-27 16:07:33 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.054: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 27 16:46:22.054: INFO: calico-node-xphhz from kube-system started at 2020-04-27 16:15:29 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.054: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:46:22.054: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 before test
Apr 27 16:46:22.103: INFO: kube-proxy-jm5m6 from kube-system started at 2020-04-27 16:07:18 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.103: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:46:22.103: INFO: calico-node-ld4x7 from kube-system started at 2020-04-27 16:15:20 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.103: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:46:22.103: INFO: node-exporter-srfgn from kube-system started at 2020-04-27 16:07:18 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.103: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:46:22.104: INFO: node-problem-detector-9thlx from kube-system started at 2020-04-27 16:07:18 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.104: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 16:46:22.104: INFO: condition-test-hfql8 from replication-controller-8107 started at 2020-04-27 16:46:20 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.104: INFO: 	Container httpd ready: false, restart count 0
Apr 27 16:46:22.104: INFO: condition-test-n6vsz from replication-controller-8107 started at 2020-04-27 16:46:20 +0000 UTC (1 container statuses recorded)
Apr 27 16:46:22.104: INFO: 	Container httpd ready: false, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: verifying the node has the label node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp
STEP: verifying the node has the label node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9
Apr 27 16:46:22.152: INFO: Pod addons-nginx-ingress-controller-6cf77756b5-rw99m requesting resource cpu=100m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp
Apr 27 16:46:22.152: INFO: Pod addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-q52mz requesting resource cpu=0m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp
Apr 27 16:46:22.152: INFO: Pod blackbox-exporter-5dc75b79b7-7xcjk requesting resource cpu=5m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp
Apr 27 16:46:22.152: INFO: Pod calico-kube-controllers-77dcb8f688-7jxx4 requesting resource cpu=10m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp
Apr 27 16:46:22.152: INFO: Pod calico-node-ld4x7 requesting resource cpu=250m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9
Apr 27 16:46:22.152: INFO: Pod calico-node-vertical-autoscaler-74d4897db8-h9n8r requesting resource cpu=10m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp
Apr 27 16:46:22.152: INFO: Pod calico-node-xphhz requesting resource cpu=250m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp
Apr 27 16:46:22.152: INFO: Pod calico-typha-deploy-784665cc66-9ngtv requesting resource cpu=200m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp
Apr 27 16:46:22.152: INFO: Pod calico-typha-horizontal-autoscaler-6fdd5d8746-hv92s requesting resource cpu=10m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp
Apr 27 16:46:22.152: INFO: Pod calico-typha-vertical-autoscaler-5b477c88cf-k2f8l requesting resource cpu=10m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp
Apr 27 16:46:22.152: INFO: Pod coredns-5cb857d789-lrv9m requesting resource cpu=50m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp
Apr 27 16:46:22.152: INFO: Pod coredns-5cb857d789-s8ws2 requesting resource cpu=50m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp
Apr 27 16:46:22.152: INFO: Pod kube-proxy-h2cx7 requesting resource cpu=20m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp
Apr 27 16:46:22.152: INFO: Pod kube-proxy-jm5m6 requesting resource cpu=20m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9
Apr 27 16:46:22.152: INFO: Pod metrics-server-5f76b49bb-ktlbv requesting resource cpu=20m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp
Apr 27 16:46:22.152: INFO: Pod node-exporter-9pkd5 requesting resource cpu=5m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp
Apr 27 16:46:22.152: INFO: Pod node-exporter-srfgn requesting resource cpu=5m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9
Apr 27 16:46:22.152: INFO: Pod node-problem-detector-9thlx requesting resource cpu=20m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9
Apr 27 16:46:22.152: INFO: Pod node-problem-detector-tq7hl requesting resource cpu=20m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp
Apr 27 16:46:22.152: INFO: Pod vpn-shoot-5b5f49b4bf-trqr9 requesting resource cpu=100m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp
Apr 27 16:46:22.152: INFO: Pod dashboard-metrics-scraper-76c7b697bc-l2z4c requesting resource cpu=0m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp
Apr 27 16:46:22.152: INFO: Pod kubernetes-dashboard-6b586c4cb4-9c2rc requesting resource cpu=50m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp
Apr 27 16:46:22.152: INFO: Pod condition-test-hfql8 requesting resource cpu=0m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9
Apr 27 16:46:22.152: INFO: Pod condition-test-n6vsz requesting resource cpu=0m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9
STEP: Starting Pods to consume most of the cluster CPU.
Apr 27 16:46:22.152: INFO: Creating a pod which consumes cpu=707m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp
Apr 27 16:46:22.161: INFO: Creating a pod which consumes cpu=1137m on Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5b081beb-7214-4e76-a2f9-4cf73257df79.1609bb06f4f4adf5], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7743/filler-pod-5b081beb-7214-4e76-a2f9-4cf73257df79 to shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5b081beb-7214-4e76-a2f9-4cf73257df79.1609bb07203da387], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.2"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5b081beb-7214-4e76-a2f9-4cf73257df79.1609bb0745127154], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.2"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5b081beb-7214-4e76-a2f9-4cf73257df79.1609bb07482065a8], Reason = [Created], Message = [Created container filler-pod-5b081beb-7214-4e76-a2f9-4cf73257df79]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5b081beb-7214-4e76-a2f9-4cf73257df79.1609bb074f714feb], Reason = [Started], Message = [Started container filler-pod-5b081beb-7214-4e76-a2f9-4cf73257df79]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f408ad56-9c5b-43ed-a442-8fd306756903.1609bb06f500a9ac], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7743/filler-pod-f408ad56-9c5b-43ed-a442-8fd306756903 to shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f408ad56-9c5b-43ed-a442-8fd306756903.1609bb071e55d895], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f408ad56-9c5b-43ed-a442-8fd306756903.1609bb07217aa7dd], Reason = [Created], Message = [Created container filler-pod-f408ad56-9c5b-43ed-a442-8fd306756903]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f408ad56-9c5b-43ed-a442-8fd306756903.1609bb0728b5310c], Reason = [Started], Message = [Started container filler-pod-f408ad56-9c5b-43ed-a442-8fd306756903]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1609bb076d22af2d], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1609bb076d8c42c7], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:25.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7743" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":277,"completed":83,"skipped":1355,"failed":0}
SSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:25.229: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8857
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-785
STEP: Creating secret with name secret-test-e29b7268-3640-4d0b-9d12-e7c8b1d1df17
STEP: Creating a pod to test consume secrets
Apr 27 16:46:25.535: INFO: Waiting up to 5m0s for pod "pod-secrets-2474591b-44e1-418a-950c-c1e714045e03" in namespace "secrets-8857" to be "Succeeded or Failed"
Apr 27 16:46:25.538: INFO: Pod "pod-secrets-2474591b-44e1-418a-950c-c1e714045e03": Phase="Pending", Reason="", readiness=false. Elapsed: 2.81091ms
Apr 27 16:46:27.542: INFO: Pod "pod-secrets-2474591b-44e1-418a-950c-c1e714045e03": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007052303s
STEP: Saw pod success
Apr 27 16:46:27.542: INFO: Pod "pod-secrets-2474591b-44e1-418a-950c-c1e714045e03" satisfied condition "Succeeded or Failed"
Apr 27 16:46:27.546: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-secrets-2474591b-44e1-418a-950c-c1e714045e03 container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:46:27.565: INFO: Waiting for pod pod-secrets-2474591b-44e1-418a-950c-c1e714045e03 to disappear
Apr 27 16:46:27.568: INFO: Pod pod-secrets-2474591b-44e1-418a-950c-c1e714045e03 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:27.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8857" for this suite.
STEP: Destroying namespace "secret-namespace-785" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":277,"completed":84,"skipped":1360,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:27.584: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3803
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-3803
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating statefulset ss in namespace statefulset-3803
Apr 27 16:46:27.744: INFO: Found 0 stateful pods, waiting for 1
Apr 27 16:46:37.749: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 16:46:37.766: INFO: Deleting all statefulset in ns statefulset-3803
Apr 27 16:46:37.769: INFO: Scaling statefulset ss to 0
Apr 27 16:46:47.796: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:46:47.799: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:47.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3803" for this suite.
•{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":277,"completed":85,"skipped":1419,"failed":0}

------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:47.821: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7119
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service nodeport-test with type=NodePort in namespace services-7119
STEP: creating replication controller nodeport-test in namespace services-7119
I0427 16:46:47.992173    5439 runners.go:190] Created replication controller with name: nodeport-test, namespace: services-7119, replica count: 2
I0427 16:46:51.042569    5439 runners.go:190] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 27 16:46:51.042: INFO: Creating new exec pod
Apr 27 16:46:56.061: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-7119 execpodtrdfb -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Apr 27 16:47:01.557: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Apr 27 16:47:01.557: INFO: stdout: ""
Apr 27 16:47:01.558: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-7119 execpodtrdfb -- /bin/sh -x -c nc -zv -t -w 2 100.107.88.150 80'
Apr 27 16:47:02.039: INFO: stderr: "+ nc -zv -t -w 2 100.107.88.150 80\nConnection to 100.107.88.150 80 port [tcp/http] succeeded!\n"
Apr 27 16:47:02.039: INFO: stdout: ""
Apr 27 16:47:02.039: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-7119 execpodtrdfb -- /bin/sh -x -c nc -zv -t -w 2 10.250.0.4 31185'
Apr 27 16:47:02.467: INFO: stderr: "+ nc -zv -t -w 2 10.250.0.4 31185\nConnection to 10.250.0.4 31185 port [tcp/31185] succeeded!\n"
Apr 27 16:47:02.467: INFO: stdout: ""
Apr 27 16:47:02.467: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-7119 execpodtrdfb -- /bin/sh -x -c nc -zv -t -w 2 10.250.0.21 31185'
Apr 27 16:47:02.928: INFO: stderr: "+ nc -zv -t -w 2 10.250.0.21 31185\nConnection to 10.250.0.21 31185 port [tcp/31185] succeeded!\n"
Apr 27 16:47:02.928: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:47:02.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7119" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":277,"completed":86,"skipped":1419,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:47:02.939: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7426
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:47:03.095: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8094f55a-fbde-4ca9-a533-81a0bd4d6531" in namespace "projected-7426" to be "Succeeded or Failed"
Apr 27 16:47:03.098: INFO: Pod "downwardapi-volume-8094f55a-fbde-4ca9-a533-81a0bd4d6531": Phase="Pending", Reason="", readiness=false. Elapsed: 2.950908ms
Apr 27 16:47:05.102: INFO: Pod "downwardapi-volume-8094f55a-fbde-4ca9-a533-81a0bd4d6531": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007171612s
STEP: Saw pod success
Apr 27 16:47:05.102: INFO: Pod "downwardapi-volume-8094f55a-fbde-4ca9-a533-81a0bd4d6531" satisfied condition "Succeeded or Failed"
Apr 27 16:47:05.106: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downwardapi-volume-8094f55a-fbde-4ca9-a533-81a0bd4d6531 container client-container: <nil>
STEP: delete the pod
Apr 27 16:47:05.124: INFO: Waiting for pod downwardapi-volume-8094f55a-fbde-4ca9-a533-81a0bd4d6531 to disappear
Apr 27 16:47:05.126: INFO: Pod downwardapi-volume-8094f55a-fbde-4ca9-a533-81a0bd4d6531 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:47:05.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7426" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":277,"completed":87,"skipped":1424,"failed":0}
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:47:05.136: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-590
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8360
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2490
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:47:34.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-590" for this suite.
STEP: Destroying namespace "nsdeletetest-8360" for this suite.
Apr 27 16:47:34.616: INFO: Namespace nsdeletetest-8360 was already deleted
STEP: Destroying namespace "nsdeletetest-2490" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":277,"completed":88,"skipped":1428,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:47:34.620: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5437
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override all
Apr 27 16:47:34.772: INFO: Waiting up to 5m0s for pod "client-containers-8fda8b0c-ccf7-4d4d-a161-0ca0e0e4a820" in namespace "containers-5437" to be "Succeeded or Failed"
Apr 27 16:47:34.775: INFO: Pod "client-containers-8fda8b0c-ccf7-4d4d-a161-0ca0e0e4a820": Phase="Pending", Reason="", readiness=false. Elapsed: 2.623504ms
Apr 27 16:47:36.779: INFO: Pod "client-containers-8fda8b0c-ccf7-4d4d-a161-0ca0e0e4a820": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006410283s
STEP: Saw pod success
Apr 27 16:47:36.779: INFO: Pod "client-containers-8fda8b0c-ccf7-4d4d-a161-0ca0e0e4a820" satisfied condition "Succeeded or Failed"
Apr 27 16:47:36.782: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod client-containers-8fda8b0c-ccf7-4d4d-a161-0ca0e0e4a820 container test-container: <nil>
STEP: delete the pod
Apr 27 16:47:36.798: INFO: Waiting for pod client-containers-8fda8b0c-ccf7-4d4d-a161-0ca0e0e4a820 to disappear
Apr 27 16:47:36.801: INFO: Pod client-containers-8fda8b0c-ccf7-4d4d-a161-0ca0e0e4a820 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:47:36.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5437" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":277,"completed":89,"skipped":1440,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:47:36.814: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3461
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 27 16:47:36.966: INFO: Waiting up to 5m0s for pod "pod-03d503b5-6233-478d-b2c0-19ee01eee2c7" in namespace "emptydir-3461" to be "Succeeded or Failed"
Apr 27 16:47:36.969: INFO: Pod "pod-03d503b5-6233-478d-b2c0-19ee01eee2c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.833053ms
Apr 27 16:47:38.973: INFO: Pod "pod-03d503b5-6233-478d-b2c0-19ee01eee2c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007043264s
STEP: Saw pod success
Apr 27 16:47:38.974: INFO: Pod "pod-03d503b5-6233-478d-b2c0-19ee01eee2c7" satisfied condition "Succeeded or Failed"
Apr 27 16:47:38.977: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-03d503b5-6233-478d-b2c0-19ee01eee2c7 container test-container: <nil>
STEP: delete the pod
Apr 27 16:47:38.998: INFO: Waiting for pod pod-03d503b5-6233-478d-b2c0-19ee01eee2c7 to disappear
Apr 27 16:47:39.001: INFO: Pod pod-03d503b5-6233-478d-b2c0-19ee01eee2c7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:47:39.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3461" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":90,"skipped":1450,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:47:39.016: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9975
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:48:39.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9975" for this suite.
•{"msg":"PASSED [k8s.io] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":277,"completed":91,"skipped":1464,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:48:39.248: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-5101
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:48:39.394: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:48:40.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5101" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":277,"completed":92,"skipped":1467,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:48:40.427: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1434
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Apr 27 16:48:40.590: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1434 /api/v1/namespaces/watch-1434/configmaps/e2e-watch-test-label-changed 18187b61-2b92-4e00-a60c-c5afc5a3dabf 21630 0 2020-04-27 16:48:40 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:48:40 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:48:40.591: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1434 /api/v1/namespaces/watch-1434/configmaps/e2e-watch-test-label-changed 18187b61-2b92-4e00-a60c-c5afc5a3dabf 21631 0 2020-04-27 16:48:40 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:48:40 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:48:40.591: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1434 /api/v1/namespaces/watch-1434/configmaps/e2e-watch-test-label-changed 18187b61-2b92-4e00-a60c-c5afc5a3dabf 21632 0 2020-04-27 16:48:40 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:48:40 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Apr 27 16:48:50.617: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1434 /api/v1/namespaces/watch-1434/configmaps/e2e-watch-test-label-changed 18187b61-2b92-4e00-a60c-c5afc5a3dabf 21686 0 2020-04-27 16:48:40 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:48:50 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:48:50.617: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1434 /api/v1/namespaces/watch-1434/configmaps/e2e-watch-test-label-changed 18187b61-2b92-4e00-a60c-c5afc5a3dabf 21687 0 2020-04-27 16:48:40 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:48:50 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:48:50.617: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1434 /api/v1/namespaces/watch-1434/configmaps/e2e-watch-test-label-changed 18187b61-2b92-4e00-a60c-c5afc5a3dabf 21688 0 2020-04-27 16:48:40 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:48:50 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:48:50.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1434" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":277,"completed":93,"skipped":1481,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:48:50.627: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1996
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:48:51.251: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:48:54.273: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:49:06.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1996" for this suite.
STEP: Destroying namespace "webhook-1996-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":277,"completed":94,"skipped":1522,"failed":0}
SSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:49:06.798: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-1706
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:171
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating server pod server in namespace prestop-1706
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-1706
STEP: Deleting pre-stop pod
Apr 27 16:49:16.075: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:49:16.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-1706" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":277,"completed":95,"skipped":1528,"failed":0}
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:49:16.096: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3023
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0427 16:49:22.274943    5439 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 27 16:49:22.275: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:49:22.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3023" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":277,"completed":96,"skipped":1530,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:49:22.286: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5884
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:49:23.061: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Apr 27 16:49:25.072: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602963, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602963, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602963, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602963, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:49:28.089: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Apr 27 16:49:30.219: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config attach --namespace=webhook-5884 to-be-attached-pod -i -c=container1'
Apr 27 16:49:30.465: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:49:30.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5884" for this suite.
STEP: Destroying namespace "webhook-5884-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":277,"completed":97,"skipped":1575,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:49:30.523: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7697
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:49:37.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7697" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":277,"completed":98,"skipped":1601,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:49:37.702: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2474
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test env composition
Apr 27 16:49:37.857: INFO: Waiting up to 5m0s for pod "var-expansion-583b1c90-3f12-469c-be2a-47e65934805f" in namespace "var-expansion-2474" to be "Succeeded or Failed"
Apr 27 16:49:37.860: INFO: Pod "var-expansion-583b1c90-3f12-469c-be2a-47e65934805f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.707351ms
Apr 27 16:49:39.864: INFO: Pod "var-expansion-583b1c90-3f12-469c-be2a-47e65934805f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005977014s
STEP: Saw pod success
Apr 27 16:49:39.864: INFO: Pod "var-expansion-583b1c90-3f12-469c-be2a-47e65934805f" satisfied condition "Succeeded or Failed"
Apr 27 16:49:39.867: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod var-expansion-583b1c90-3f12-469c-be2a-47e65934805f container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:49:39.983: INFO: Waiting for pod var-expansion-583b1c90-3f12-469c-be2a-47e65934805f to disappear
Apr 27 16:49:39.987: INFO: Pod var-expansion-583b1c90-3f12-469c-be2a-47e65934805f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:49:39.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2474" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":277,"completed":99,"skipped":1619,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:49:39.996: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7552
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:49:40.153: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cdba32fa-55e1-4bf0-a0d6-032f7a87eeb4" in namespace "projected-7552" to be "Succeeded or Failed"
Apr 27 16:49:40.155: INFO: Pod "downwardapi-volume-cdba32fa-55e1-4bf0-a0d6-032f7a87eeb4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.917932ms
Apr 27 16:49:42.160: INFO: Pod "downwardapi-volume-cdba32fa-55e1-4bf0-a0d6-032f7a87eeb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007801996s
STEP: Saw pod success
Apr 27 16:49:42.160: INFO: Pod "downwardapi-volume-cdba32fa-55e1-4bf0-a0d6-032f7a87eeb4" satisfied condition "Succeeded or Failed"
Apr 27 16:49:42.164: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downwardapi-volume-cdba32fa-55e1-4bf0-a0d6-032f7a87eeb4 container client-container: <nil>
STEP: delete the pod
Apr 27 16:49:42.183: INFO: Waiting for pod downwardapi-volume-cdba32fa-55e1-4bf0-a0d6-032f7a87eeb4 to disappear
Apr 27 16:49:42.187: INFO: Pod downwardapi-volume-cdba32fa-55e1-4bf0-a0d6-032f7a87eeb4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:49:42.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7552" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":277,"completed":100,"skipped":1628,"failed":0}

------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:49:42.199: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9293
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:49:42.940: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:49:45.961: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:49:45.965: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:49:47.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9293" for this suite.
STEP: Destroying namespace "webhook-9293-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":277,"completed":101,"skipped":1628,"failed":0}
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:49:47.889: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2815
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-2815
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-2815
STEP: Creating statefulset with conflicting port in namespace statefulset-2815
STEP: Waiting until pod test-pod will start running in namespace statefulset-2815
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-2815
Apr 27 16:49:50.188: INFO: Observed stateful pod in namespace: statefulset-2815, name: ss-0, uid: bdfa3853-2df8-402b-b659-b12eedabb87a, status phase: Pending. Waiting for statefulset controller to delete.
Apr 27 16:49:50.206: INFO: Observed stateful pod in namespace: statefulset-2815, name: ss-0, uid: bdfa3853-2df8-402b-b659-b12eedabb87a, status phase: Failed. Waiting for statefulset controller to delete.
Apr 27 16:49:50.211: INFO: Observed stateful pod in namespace: statefulset-2815, name: ss-0, uid: bdfa3853-2df8-402b-b659-b12eedabb87a, status phase: Failed. Waiting for statefulset controller to delete.
Apr 27 16:49:50.214: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-2815
STEP: Removing pod with conflicting port in namespace statefulset-2815
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-2815 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 16:49:52.281: INFO: Deleting all statefulset in ns statefulset-2815
Apr 27 16:49:52.284: INFO: Scaling statefulset ss to 0
Apr 27 16:50:02.300: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:50:02.303: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:50:02.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2815" for this suite.
•{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":277,"completed":102,"skipped":1635,"failed":0}

------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:50:02.328: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2984
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:50:02.497: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f601ae68-d08c-4ad0-ac7d-f6dfd11e52d9" in namespace "projected-2984" to be "Succeeded or Failed"
Apr 27 16:50:02.500: INFO: Pod "downwardapi-volume-f601ae68-d08c-4ad0-ac7d-f6dfd11e52d9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.009686ms
Apr 27 16:50:04.567: INFO: Pod "downwardapi-volume-f601ae68-d08c-4ad0-ac7d-f6dfd11e52d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.06997513s
STEP: Saw pod success
Apr 27 16:50:04.567: INFO: Pod "downwardapi-volume-f601ae68-d08c-4ad0-ac7d-f6dfd11e52d9" satisfied condition "Succeeded or Failed"
Apr 27 16:50:04.578: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downwardapi-volume-f601ae68-d08c-4ad0-ac7d-f6dfd11e52d9 container client-container: <nil>
STEP: delete the pod
Apr 27 16:50:04.603: INFO: Waiting for pod downwardapi-volume-f601ae68-d08c-4ad0-ac7d-f6dfd11e52d9 to disappear
Apr 27 16:50:04.605: INFO: Pod downwardapi-volume-f601ae68-d08c-4ad0-ac7d-f6dfd11e52d9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:50:04.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2984" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":103,"skipped":1635,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:50:04.616: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6120
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-9d6e9233-f2d4-48f8-b7c7-0b273c11933d
STEP: Creating a pod to test consume configMaps
Apr 27 16:50:04.777: INFO: Waiting up to 5m0s for pod "pod-configmaps-299d6198-307a-4d13-89ef-09dcb6a2c3fb" in namespace "configmap-6120" to be "Succeeded or Failed"
Apr 27 16:50:04.781: INFO: Pod "pod-configmaps-299d6198-307a-4d13-89ef-09dcb6a2c3fb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.50375ms
Apr 27 16:50:06.786: INFO: Pod "pod-configmaps-299d6198-307a-4d13-89ef-09dcb6a2c3fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008381284s
STEP: Saw pod success
Apr 27 16:50:06.786: INFO: Pod "pod-configmaps-299d6198-307a-4d13-89ef-09dcb6a2c3fb" satisfied condition "Succeeded or Failed"
Apr 27 16:50:06.789: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-configmaps-299d6198-307a-4d13-89ef-09dcb6a2c3fb container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:50:06.813: INFO: Waiting for pod pod-configmaps-299d6198-307a-4d13-89ef-09dcb6a2c3fb to disappear
Apr 27 16:50:06.817: INFO: Pod pod-configmaps-299d6198-307a-4d13-89ef-09dcb6a2c3fb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:50:06.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6120" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":277,"completed":104,"skipped":1651,"failed":0}
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:50:06.826: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4572
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 27 16:50:06.982: INFO: Waiting up to 5m0s for pod "pod-d4750338-b100-442d-8e6e-95d130a0d21d" in namespace "emptydir-4572" to be "Succeeded or Failed"
Apr 27 16:50:06.984: INFO: Pod "pod-d4750338-b100-442d-8e6e-95d130a0d21d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.911081ms
Apr 27 16:50:08.989: INFO: Pod "pod-d4750338-b100-442d-8e6e-95d130a0d21d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007848696s
Apr 27 16:50:10.995: INFO: Pod "pod-d4750338-b100-442d-8e6e-95d130a0d21d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013615553s
STEP: Saw pod success
Apr 27 16:50:10.995: INFO: Pod "pod-d4750338-b100-442d-8e6e-95d130a0d21d" satisfied condition "Succeeded or Failed"
Apr 27 16:50:10.998: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-d4750338-b100-442d-8e6e-95d130a0d21d container test-container: <nil>
STEP: delete the pod
Apr 27 16:50:11.018: INFO: Waiting for pod pod-d4750338-b100-442d-8e6e-95d130a0d21d to disappear
Apr 27 16:50:11.020: INFO: Pod pod-d4750338-b100-442d-8e6e-95d130a0d21d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:50:11.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4572" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":105,"skipped":1654,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:50:11.030: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7701
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Apr 27 16:50:11.203: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:50:14.844: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:50:30.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7701" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":277,"completed":106,"skipped":1655,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:50:30.436: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-14
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:50:30.595: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a0cb5120-ffda-446b-84b4-7bc07d88364b" in namespace "downward-api-14" to be "Succeeded or Failed"
Apr 27 16:50:30.598: INFO: Pod "downwardapi-volume-a0cb5120-ffda-446b-84b4-7bc07d88364b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.620732ms
Apr 27 16:50:32.601: INFO: Pod "downwardapi-volume-a0cb5120-ffda-446b-84b4-7bc07d88364b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006139734s
Apr 27 16:50:34.606: INFO: Pod "downwardapi-volume-a0cb5120-ffda-446b-84b4-7bc07d88364b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011093841s
STEP: Saw pod success
Apr 27 16:50:34.606: INFO: Pod "downwardapi-volume-a0cb5120-ffda-446b-84b4-7bc07d88364b" satisfied condition "Succeeded or Failed"
Apr 27 16:50:34.609: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downwardapi-volume-a0cb5120-ffda-446b-84b4-7bc07d88364b container client-container: <nil>
STEP: delete the pod
Apr 27 16:50:34.636: INFO: Waiting for pod downwardapi-volume-a0cb5120-ffda-446b-84b4-7bc07d88364b to disappear
Apr 27 16:50:34.639: INFO: Pod downwardapi-volume-a0cb5120-ffda-446b-84b4-7bc07d88364b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:50:34.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-14" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":277,"completed":107,"skipped":1662,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:50:34.649: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8783
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-0795d010-5470-434e-aef0-9f08546ebbf3
STEP: Creating a pod to test consume secrets
Apr 27 16:50:34.816: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fcabc665-afce-46b2-bcc8-4742b7e00f1f" in namespace "projected-8783" to be "Succeeded or Failed"
Apr 27 16:50:34.819: INFO: Pod "pod-projected-secrets-fcabc665-afce-46b2-bcc8-4742b7e00f1f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.451702ms
Apr 27 16:50:36.824: INFO: Pod "pod-projected-secrets-fcabc665-afce-46b2-bcc8-4742b7e00f1f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008570465s
STEP: Saw pod success
Apr 27 16:50:36.824: INFO: Pod "pod-projected-secrets-fcabc665-afce-46b2-bcc8-4742b7e00f1f" satisfied condition "Succeeded or Failed"
Apr 27 16:50:36.827: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-projected-secrets-fcabc665-afce-46b2-bcc8-4742b7e00f1f container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:50:36.846: INFO: Waiting for pod pod-projected-secrets-fcabc665-afce-46b2-bcc8-4742b7e00f1f to disappear
Apr 27 16:50:36.849: INFO: Pod pod-projected-secrets-fcabc665-afce-46b2-bcc8-4742b7e00f1f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:50:36.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8783" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":108,"skipped":1696,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:50:36.858: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6392
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 27 16:50:37.038: INFO: Number of nodes with available pods: 0
Apr 27 16:50:37.038: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:50:38.048: INFO: Number of nodes with available pods: 0
Apr 27 16:50:38.048: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 16:50:39.048: INFO: Number of nodes with available pods: 1
Apr 27 16:50:39.048: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 is running more than one daemon pod
Apr 27 16:50:40.049: INFO: Number of nodes with available pods: 2
Apr 27 16:50:40.049: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Apr 27 16:50:40.070: INFO: Number of nodes with available pods: 1
Apr 27 16:50:40.070: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 is running more than one daemon pod
Apr 27 16:50:41.081: INFO: Number of nodes with available pods: 1
Apr 27 16:50:41.081: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 is running more than one daemon pod
Apr 27 16:50:42.080: INFO: Number of nodes with available pods: 2
Apr 27 16:50:42.080: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6392, will wait for the garbage collector to delete the pods
Apr 27 16:50:42.145: INFO: Deleting DaemonSet.extensions daemon-set took: 6.702028ms
Apr 27 16:50:42.245: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.29015ms
Apr 27 16:50:45.250: INFO: Number of nodes with available pods: 0
Apr 27 16:50:45.250: INFO: Number of running nodes: 0, number of available pods: 0
Apr 27 16:50:45.253: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6392/daemonsets","resourceVersion":"22859"},"items":null}

Apr 27 16:50:45.257: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6392/pods","resourceVersion":"22859"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:50:45.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6392" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":277,"completed":109,"skipped":1719,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:50:45.283: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1138
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-1138/configmap-test-58b4c749-b9a4-4d7f-8ac6-09ad1e39fabb
STEP: Creating a pod to test consume configMaps
Apr 27 16:50:45.455: INFO: Waiting up to 5m0s for pod "pod-configmaps-d536826e-9a67-46fa-b57f-fd6f29443f67" in namespace "configmap-1138" to be "Succeeded or Failed"
Apr 27 16:50:45.458: INFO: Pod "pod-configmaps-d536826e-9a67-46fa-b57f-fd6f29443f67": Phase="Pending", Reason="", readiness=false. Elapsed: 3.121944ms
Apr 27 16:50:47.462: INFO: Pod "pod-configmaps-d536826e-9a67-46fa-b57f-fd6f29443f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007440935s
STEP: Saw pod success
Apr 27 16:50:47.462: INFO: Pod "pod-configmaps-d536826e-9a67-46fa-b57f-fd6f29443f67" satisfied condition "Succeeded or Failed"
Apr 27 16:50:47.465: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-configmaps-d536826e-9a67-46fa-b57f-fd6f29443f67 container env-test: <nil>
STEP: delete the pod
Apr 27 16:50:47.514: INFO: Waiting for pod pod-configmaps-d536826e-9a67-46fa-b57f-fd6f29443f67 to disappear
Apr 27 16:50:47.517: INFO: Pod pod-configmaps-d536826e-9a67-46fa-b57f-fd6f29443f67 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:50:47.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1138" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":277,"completed":110,"skipped":1732,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:50:47.527: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4162
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating replication controller my-hostname-basic-3fbf8c48-e176-4089-bd1a-c4bf586eefe1
Apr 27 16:50:47.680: INFO: Pod name my-hostname-basic-3fbf8c48-e176-4089-bd1a-c4bf586eefe1: Found 0 pods out of 1
Apr 27 16:50:52.683: INFO: Pod name my-hostname-basic-3fbf8c48-e176-4089-bd1a-c4bf586eefe1: Found 1 pods out of 1
Apr 27 16:50:52.684: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-3fbf8c48-e176-4089-bd1a-c4bf586eefe1" are running
Apr 27 16:50:52.686: INFO: Pod "my-hostname-basic-3fbf8c48-e176-4089-bd1a-c4bf586eefe1-9x9n5" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 16:50:47 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 16:50:49 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 16:50:49 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 16:50:47 +0000 UTC Reason: Message:}])
Apr 27 16:50:52.686: INFO: Trying to dial the pod
Apr 27 16:50:57.783: INFO: Controller my-hostname-basic-3fbf8c48-e176-4089-bd1a-c4bf586eefe1: Got expected result from replica 1 [my-hostname-basic-3fbf8c48-e176-4089-bd1a-c4bf586eefe1-9x9n5]: "my-hostname-basic-3fbf8c48-e176-4089-bd1a-c4bf586eefe1-9x9n5", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:50:57.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4162" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":277,"completed":111,"skipped":1777,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:50:57.794: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4040
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Apr 27 16:50:57.951: INFO: Waiting up to 5m0s for pod "downward-api-33609853-3f65-43bf-90b5-136e0dd5b708" in namespace "downward-api-4040" to be "Succeeded or Failed"
Apr 27 16:50:57.954: INFO: Pod "downward-api-33609853-3f65-43bf-90b5-136e0dd5b708": Phase="Pending", Reason="", readiness=false. Elapsed: 3.296125ms
Apr 27 16:50:59.959: INFO: Pod "downward-api-33609853-3f65-43bf-90b5-136e0dd5b708": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008631841s
STEP: Saw pod success
Apr 27 16:50:59.959: INFO: Pod "downward-api-33609853-3f65-43bf-90b5-136e0dd5b708" satisfied condition "Succeeded or Failed"
Apr 27 16:50:59.962: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downward-api-33609853-3f65-43bf-90b5-136e0dd5b708 container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:50:59.982: INFO: Waiting for pod downward-api-33609853-3f65-43bf-90b5-136e0dd5b708 to disappear
Apr 27 16:50:59.985: INFO: Pod downward-api-33609853-3f65-43bf-90b5-136e0dd5b708 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:50:59.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4040" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":277,"completed":112,"skipped":1786,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:50:59.995: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-7796
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:51:02.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7796" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":277,"completed":113,"skipped":1797,"failed":0}
S
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:51:02.226: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-7257
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
STEP: reading a file in the container
Apr 27 16:51:04.907: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-7257 pod-service-account-6bca4289-45b9-4c94-8bf6-5bd8023ca5a6 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Apr 27 16:51:05.369: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-7257 pod-service-account-6bca4289-45b9-4c94-8bf6-5bd8023ca5a6 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Apr 27 16:51:05.847: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-7257 pod-service-account-6bca4289-45b9-4c94-8bf6-5bd8023ca5a6 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:51:06.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7257" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":277,"completed":114,"skipped":1798,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:51:06.281: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4390
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:51:06.440: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8e7ee005-c7e7-4b30-9d75-75ac6993b196" in namespace "downward-api-4390" to be "Succeeded or Failed"
Apr 27 16:51:06.443: INFO: Pod "downwardapi-volume-8e7ee005-c7e7-4b30-9d75-75ac6993b196": Phase="Pending", Reason="", readiness=false. Elapsed: 2.850793ms
Apr 27 16:51:08.447: INFO: Pod "downwardapi-volume-8e7ee005-c7e7-4b30-9d75-75ac6993b196": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007421545s
STEP: Saw pod success
Apr 27 16:51:08.447: INFO: Pod "downwardapi-volume-8e7ee005-c7e7-4b30-9d75-75ac6993b196" satisfied condition "Succeeded or Failed"
Apr 27 16:51:08.451: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downwardapi-volume-8e7ee005-c7e7-4b30-9d75-75ac6993b196 container client-container: <nil>
STEP: delete the pod
Apr 27 16:51:08.470: INFO: Waiting for pod downwardapi-volume-8e7ee005-c7e7-4b30-9d75-75ac6993b196 to disappear
Apr 27 16:51:08.473: INFO: Pod downwardapi-volume-8e7ee005-c7e7-4b30-9d75-75ac6993b196 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:51:08.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4390" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":115,"skipped":1812,"failed":0}
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:51:08.484: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8890
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-1da05894-258c-4d3b-ba57-400a3dec18a9
STEP: Creating a pod to test consume configMaps
Apr 27 16:51:08.645: INFO: Waiting up to 5m0s for pod "pod-configmaps-a1c66ded-d4cf-4cd3-864d-ceecf90d0363" in namespace "configmap-8890" to be "Succeeded or Failed"
Apr 27 16:51:08.648: INFO: Pod "pod-configmaps-a1c66ded-d4cf-4cd3-864d-ceecf90d0363": Phase="Pending", Reason="", readiness=false. Elapsed: 2.859795ms
Apr 27 16:51:10.652: INFO: Pod "pod-configmaps-a1c66ded-d4cf-4cd3-864d-ceecf90d0363": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007335133s
STEP: Saw pod success
Apr 27 16:51:10.652: INFO: Pod "pod-configmaps-a1c66ded-d4cf-4cd3-864d-ceecf90d0363" satisfied condition "Succeeded or Failed"
Apr 27 16:51:10.655: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-configmaps-a1c66ded-d4cf-4cd3-864d-ceecf90d0363 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:51:10.680: INFO: Waiting for pod pod-configmaps-a1c66ded-d4cf-4cd3-864d-ceecf90d0363 to disappear
Apr 27 16:51:10.682: INFO: Pod pod-configmaps-a1c66ded-d4cf-4cd3-864d-ceecf90d0363 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:51:10.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8890" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":277,"completed":116,"skipped":1816,"failed":0}

------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:51:10.691: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8247
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-06b1bbd5-924d-42c9-a5cf-816765ad992c in namespace container-probe-8247
Apr 27 16:51:12.850: INFO: Started pod liveness-06b1bbd5-924d-42c9-a5cf-816765ad992c in namespace container-probe-8247
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 16:51:12.853: INFO: Initial restart count of pod liveness-06b1bbd5-924d-42c9-a5cf-816765ad992c is 0
Apr 27 16:51:26.888: INFO: Restart count of pod container-probe-8247/liveness-06b1bbd5-924d-42c9-a5cf-816765ad992c is now 1 (14.035227239s elapsed)
Apr 27 16:51:47.013: INFO: Restart count of pod container-probe-8247/liveness-06b1bbd5-924d-42c9-a5cf-816765ad992c is now 2 (34.160310528s elapsed)
Apr 27 16:52:07.057: INFO: Restart count of pod container-probe-8247/liveness-06b1bbd5-924d-42c9-a5cf-816765ad992c is now 3 (54.203873301s elapsed)
Apr 27 16:52:27.106: INFO: Restart count of pod container-probe-8247/liveness-06b1bbd5-924d-42c9-a5cf-816765ad992c is now 4 (1m14.25297713s elapsed)
Apr 27 16:53:37.261: INFO: Restart count of pod container-probe-8247/liveness-06b1bbd5-924d-42c9-a5cf-816765ad992c is now 5 (2m24.40756185s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:37.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8247" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":277,"completed":117,"skipped":1816,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:37.278: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-50
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:53:37.436: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1512843e-3f70-47d2-91fc-5076c1ece932" in namespace "downward-api-50" to be "Succeeded or Failed"
Apr 27 16:53:37.440: INFO: Pod "downwardapi-volume-1512843e-3f70-47d2-91fc-5076c1ece932": Phase="Pending", Reason="", readiness=false. Elapsed: 4.369922ms
Apr 27 16:53:39.445: INFO: Pod "downwardapi-volume-1512843e-3f70-47d2-91fc-5076c1ece932": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0088989s
STEP: Saw pod success
Apr 27 16:53:39.445: INFO: Pod "downwardapi-volume-1512843e-3f70-47d2-91fc-5076c1ece932" satisfied condition "Succeeded or Failed"
Apr 27 16:53:39.448: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downwardapi-volume-1512843e-3f70-47d2-91fc-5076c1ece932 container client-container: <nil>
STEP: delete the pod
Apr 27 16:53:39.558: INFO: Waiting for pod downwardapi-volume-1512843e-3f70-47d2-91fc-5076c1ece932 to disappear
Apr 27 16:53:39.561: INFO: Pod downwardapi-volume-1512843e-3f70-47d2-91fc-5076c1ece932 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:39.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-50" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":277,"completed":118,"skipped":1817,"failed":0}
SSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:39.571: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-8973
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:53:39.727: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-e525cbf0-e7e3-40a9-9c79-24cbba906e68" in namespace "security-context-test-8973" to be "Succeeded or Failed"
Apr 27 16:53:39.730: INFO: Pod "busybox-readonly-false-e525cbf0-e7e3-40a9-9c79-24cbba906e68": Phase="Pending", Reason="", readiness=false. Elapsed: 3.187251ms
Apr 27 16:53:41.734: INFO: Pod "busybox-readonly-false-e525cbf0-e7e3-40a9-9c79-24cbba906e68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007491266s
Apr 27 16:53:41.734: INFO: Pod "busybox-readonly-false-e525cbf0-e7e3-40a9-9c79-24cbba906e68" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:41.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8973" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":277,"completed":119,"skipped":1827,"failed":0}
SSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:41.745: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-9401
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:41.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-9401" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":277,"completed":120,"skipped":1831,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:41.907: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-11
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Apr 27 16:53:44.602: INFO: Successfully updated pod "annotationupdate49702744-64a0-421d-8dc5-051f0ffe3fd8"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:48.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-11" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":277,"completed":121,"skipped":1844,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:48.684: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4486
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name projected-secret-test-9e3ef89a-dbc3-4722-8a7d-f6d3d6eb09a0
STEP: Creating a pod to test consume secrets
Apr 27 16:53:48.843: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c37e7537-0608-411b-8804-f52a2700b739" in namespace "projected-4486" to be "Succeeded or Failed"
Apr 27 16:53:48.846: INFO: Pod "pod-projected-secrets-c37e7537-0608-411b-8804-f52a2700b739": Phase="Pending", Reason="", readiness=false. Elapsed: 3.593349ms
Apr 27 16:53:50.851: INFO: Pod "pod-projected-secrets-c37e7537-0608-411b-8804-f52a2700b739": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007874158s
STEP: Saw pod success
Apr 27 16:53:50.851: INFO: Pod "pod-projected-secrets-c37e7537-0608-411b-8804-f52a2700b739" satisfied condition "Succeeded or Failed"
Apr 27 16:53:50.854: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-projected-secrets-c37e7537-0608-411b-8804-f52a2700b739 container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:53:50.872: INFO: Waiting for pod pod-projected-secrets-c37e7537-0608-411b-8804-f52a2700b739 to disappear
Apr 27 16:53:50.875: INFO: Pod pod-projected-secrets-c37e7537-0608-411b-8804-f52a2700b739 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:50.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4486" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":277,"completed":122,"skipped":1861,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:50.884: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3633
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-5jjhj in namespace proxy-3633
I0427 16:53:51.043178    5439 runners.go:190] Created replication controller with name: proxy-service-5jjhj, namespace: proxy-3633, replica count: 1
I0427 16:53:52.093533    5439 runners.go:190] proxy-service-5jjhj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0427 16:53:53.093859    5439 runners.go:190] proxy-service-5jjhj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 16:53:54.094120    5439 runners.go:190] proxy-service-5jjhj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 16:53:55.094355    5439 runners.go:190] proxy-service-5jjhj Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 27 16:53:55.098: INFO: setup took 4.069876874s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Apr 27 16:53:55.109: INFO: (0) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 10.545884ms)
Apr 27 16:53:55.112: INFO: (0) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/rewriteme">test</a> (200; 13.293666ms)
Apr 27 16:53:55.112: INFO: (0) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname2/proxy/: bar (200; 13.489385ms)
Apr 27 16:53:55.112: INFO: (0) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 13.311415ms)
Apr 27 16:53:55.112: INFO: (0) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">... (200; 13.370852ms)
Apr 27 16:53:55.112: INFO: (0) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">test<... (200; 13.584058ms)
Apr 27 16:53:55.112: INFO: (0) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 13.914291ms)
Apr 27 16:53:55.112: INFO: (0) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname1/proxy/: foo (200; 14.005712ms)
Apr 27 16:53:55.112: INFO: (0) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname2/proxy/: bar (200; 13.940152ms)
Apr 27 16:53:55.115: INFO: (0) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 17.070132ms)
Apr 27 16:53:55.115: INFO: (0) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname1/proxy/: tls baz (200; 17.004919ms)
Apr 27 16:53:55.115: INFO: (0) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:460/proxy/: tls baz (200; 17.111674ms)
Apr 27 16:53:55.117: INFO: (0) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/tlsrewritem... (200; 18.579214ms)
Apr 27 16:53:55.117: INFO: (0) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname1/proxy/: foo (200; 18.983334ms)
Apr 27 16:53:55.119: INFO: (0) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname2/proxy/: tls qux (200; 20.524847ms)
Apr 27 16:53:55.119: INFO: (0) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:462/proxy/: tls qux (200; 20.505468ms)
Apr 27 16:53:55.127: INFO: (1) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/rewriteme">test</a> (200; 7.633693ms)
Apr 27 16:53:55.128: INFO: (1) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 8.563756ms)
Apr 27 16:53:55.128: INFO: (1) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:462/proxy/: tls qux (200; 8.039793ms)
Apr 27 16:53:55.128: INFO: (1) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">test<... (200; 7.936191ms)
Apr 27 16:53:55.128: INFO: (1) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">... (200; 7.894953ms)
Apr 27 16:53:55.128: INFO: (1) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:460/proxy/: tls baz (200; 8.990453ms)
Apr 27 16:53:55.128: INFO: (1) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname1/proxy/: tls baz (200; 8.888811ms)
Apr 27 16:53:55.128: INFO: (1) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 8.23381ms)
Apr 27 16:53:55.128: INFO: (1) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 9.307693ms)
Apr 27 16:53:55.129: INFO: (1) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 9.370219ms)
Apr 27 16:53:55.129: INFO: (1) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/tlsrewritem... (200; 9.056391ms)
Apr 27 16:53:55.130: INFO: (1) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname2/proxy/: tls qux (200; 10.158678ms)
Apr 27 16:53:55.130: INFO: (1) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname1/proxy/: foo (200; 11.066421ms)
Apr 27 16:53:55.130: INFO: (1) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname2/proxy/: bar (200; 10.708078ms)
Apr 27 16:53:55.131: INFO: (1) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname2/proxy/: bar (200; 11.872498ms)
Apr 27 16:53:55.131: INFO: (1) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname1/proxy/: foo (200; 12.213859ms)
Apr 27 16:53:55.138: INFO: (2) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 6.443913ms)
Apr 27 16:53:55.138: INFO: (2) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:462/proxy/: tls qux (200; 6.656062ms)
Apr 27 16:53:55.138: INFO: (2) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/rewriteme">test</a> (200; 6.709601ms)
Apr 27 16:53:55.138: INFO: (2) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:460/proxy/: tls baz (200; 6.664056ms)
Apr 27 16:53:55.138: INFO: (2) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">... (200; 6.638812ms)
Apr 27 16:53:55.139: INFO: (2) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 7.354865ms)
Apr 27 16:53:55.139: INFO: (2) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">test<... (200; 7.581206ms)
Apr 27 16:53:55.140: INFO: (2) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname1/proxy/: foo (200; 8.397743ms)
Apr 27 16:53:55.141: INFO: (2) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname1/proxy/: tls baz (200; 9.040549ms)
Apr 27 16:53:55.141: INFO: (2) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname2/proxy/: tls qux (200; 9.183015ms)
Apr 27 16:53:55.141: INFO: (2) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 9.033286ms)
Apr 27 16:53:55.141: INFO: (2) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/tlsrewritem... (200; 9.214053ms)
Apr 27 16:53:55.141: INFO: (2) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname2/proxy/: bar (200; 9.321489ms)
Apr 27 16:53:55.142: INFO: (2) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname2/proxy/: bar (200; 10.265714ms)
Apr 27 16:53:55.142: INFO: (2) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname1/proxy/: foo (200; 10.606981ms)
Apr 27 16:53:55.143: INFO: (2) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 11.225613ms)
Apr 27 16:53:55.151: INFO: (3) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname2/proxy/: bar (200; 7.568131ms)
Apr 27 16:53:55.152: INFO: (3) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/tlsrewritem... (200; 8.479303ms)
Apr 27 16:53:55.152: INFO: (3) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname1/proxy/: tls baz (200; 8.777026ms)
Apr 27 16:53:55.152: INFO: (3) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:462/proxy/: tls qux (200; 8.093503ms)
Apr 27 16:53:55.152: INFO: (3) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">... (200; 9.016364ms)
Apr 27 16:53:55.152: INFO: (3) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 8.917365ms)
Apr 27 16:53:55.152: INFO: (3) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:460/proxy/: tls baz (200; 8.171986ms)
Apr 27 16:53:55.152: INFO: (3) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 9.082107ms)
Apr 27 16:53:55.152: INFO: (3) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">test<... (200; 8.714316ms)
Apr 27 16:53:55.152: INFO: (3) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname2/proxy/: tls qux (200; 9.200912ms)
Apr 27 16:53:55.152: INFO: (3) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/rewriteme">test</a> (200; 9.359299ms)
Apr 27 16:53:55.153: INFO: (3) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 8.929484ms)
Apr 27 16:53:55.195: INFO: (3) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname1/proxy/: foo (200; 51.435987ms)
Apr 27 16:53:55.195: INFO: (3) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 51.956949ms)
Apr 27 16:53:55.195: INFO: (3) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname1/proxy/: foo (200; 51.54219ms)
Apr 27 16:53:55.195: INFO: (3) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname2/proxy/: bar (200; 51.458452ms)
Apr 27 16:53:55.202: INFO: (4) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 7.115369ms)
Apr 27 16:53:55.202: INFO: (4) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">... (200; 7.277784ms)
Apr 27 16:53:55.202: INFO: (4) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">test<... (200; 7.323001ms)
Apr 27 16:53:55.203: INFO: (4) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/tlsrewritem... (200; 7.806728ms)
Apr 27 16:53:55.203: INFO: (4) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:460/proxy/: tls baz (200; 8.002342ms)
Apr 27 16:53:55.203: INFO: (4) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname1/proxy/: foo (200; 7.843158ms)
Apr 27 16:53:55.203: INFO: (4) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/rewriteme">test</a> (200; 7.94287ms)
Apr 27 16:53:55.203: INFO: (4) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:462/proxy/: tls qux (200; 8.043009ms)
Apr 27 16:53:55.203: INFO: (4) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 7.965622ms)
Apr 27 16:53:55.203: INFO: (4) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname1/proxy/: tls baz (200; 8.133448ms)
Apr 27 16:53:55.203: INFO: (4) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname2/proxy/: tls qux (200; 7.98959ms)
Apr 27 16:53:55.203: INFO: (4) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname2/proxy/: bar (200; 8.075135ms)
Apr 27 16:53:55.205: INFO: (4) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname2/proxy/: bar (200; 10.177733ms)
Apr 27 16:53:55.205: INFO: (4) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 10.204234ms)
Apr 27 16:53:55.206: INFO: (4) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname1/proxy/: foo (200; 11.185575ms)
Apr 27 16:53:55.207: INFO: (4) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 11.642808ms)
Apr 27 16:53:55.215: INFO: (5) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">test<... (200; 8.177986ms)
Apr 27 16:53:55.215: INFO: (5) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 7.730936ms)
Apr 27 16:53:55.215: INFO: (5) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 8.331646ms)
Apr 27 16:53:55.215: INFO: (5) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">... (200; 8.190064ms)
Apr 27 16:53:55.215: INFO: (5) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/tlsrewritem... (200; 7.488635ms)
Apr 27 16:53:55.216: INFO: (5) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 8.481144ms)
Apr 27 16:53:55.216: INFO: (5) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:462/proxy/: tls qux (200; 7.950837ms)
Apr 27 16:53:55.216: INFO: (5) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname1/proxy/: tls baz (200; 8.305804ms)
Apr 27 16:53:55.216: INFO: (5) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 8.473459ms)
Apr 27 16:53:55.216: INFO: (5) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:460/proxy/: tls baz (200; 8.813844ms)
Apr 27 16:53:55.216: INFO: (5) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/rewriteme">test</a> (200; 8.705181ms)
Apr 27 16:53:55.217: INFO: (5) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname2/proxy/: tls qux (200; 8.978968ms)
Apr 27 16:53:55.217: INFO: (5) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname2/proxy/: bar (200; 10.484363ms)
Apr 27 16:53:55.218: INFO: (5) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname1/proxy/: foo (200; 10.306371ms)
Apr 27 16:53:55.218: INFO: (5) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname2/proxy/: bar (200; 10.270686ms)
Apr 27 16:53:55.218: INFO: (5) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname1/proxy/: foo (200; 10.767768ms)
Apr 27 16:53:55.227: INFO: (6) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 8.387982ms)
Apr 27 16:53:55.227: INFO: (6) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 8.142902ms)
Apr 27 16:53:55.227: INFO: (6) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">... (200; 8.558874ms)
Apr 27 16:53:55.227: INFO: (6) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 7.878652ms)
Apr 27 16:53:55.227: INFO: (6) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">test<... (200; 8.747739ms)
Apr 27 16:53:55.227: INFO: (6) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/tlsrewritem... (200; 8.230426ms)
Apr 27 16:53:55.228: INFO: (6) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:460/proxy/: tls baz (200; 8.989024ms)
Apr 27 16:53:55.228: INFO: (6) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:462/proxy/: tls qux (200; 9.334219ms)
Apr 27 16:53:55.228: INFO: (6) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 8.820276ms)
Apr 27 16:53:55.229: INFO: (6) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname2/proxy/: tls qux (200; 9.501678ms)
Apr 27 16:53:55.229: INFO: (6) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/rewriteme">test</a> (200; 10.033729ms)
Apr 27 16:53:55.229: INFO: (6) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname1/proxy/: tls baz (200; 10.109129ms)
Apr 27 16:53:55.230: INFO: (6) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname2/proxy/: bar (200; 11.581581ms)
Apr 27 16:53:55.230: INFO: (6) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname2/proxy/: bar (200; 10.771685ms)
Apr 27 16:53:55.230: INFO: (6) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname1/proxy/: foo (200; 10.930534ms)
Apr 27 16:53:55.233: INFO: (6) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname1/proxy/: foo (200; 13.304739ms)
Apr 27 16:53:55.239: INFO: (7) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">test<... (200; 6.628476ms)
Apr 27 16:53:55.240: INFO: (7) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 7.335988ms)
Apr 27 16:53:55.240: INFO: (7) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 7.257527ms)
Apr 27 16:53:55.240: INFO: (7) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:462/proxy/: tls qux (200; 7.385609ms)
Apr 27 16:53:55.240: INFO: (7) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/rewriteme">test</a> (200; 7.36761ms)
Apr 27 16:53:55.240: INFO: (7) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 7.267306ms)
Apr 27 16:53:55.240: INFO: (7) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">... (200; 7.371505ms)
Apr 27 16:53:55.241: INFO: (7) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/tlsrewritem... (200; 8.2224ms)
Apr 27 16:53:55.241: INFO: (7) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 8.299489ms)
Apr 27 16:53:55.241: INFO: (7) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:460/proxy/: tls baz (200; 8.280859ms)
Apr 27 16:53:55.242: INFO: (7) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname1/proxy/: tls baz (200; 9.380526ms)
Apr 27 16:53:55.242: INFO: (7) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname2/proxy/: tls qux (200; 9.263332ms)
Apr 27 16:53:55.242: INFO: (7) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname2/proxy/: bar (200; 9.363391ms)
Apr 27 16:53:55.242: INFO: (7) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname2/proxy/: bar (200; 9.257016ms)
Apr 27 16:53:55.243: INFO: (7) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname1/proxy/: foo (200; 10.383013ms)
Apr 27 16:53:55.244: INFO: (7) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname1/proxy/: foo (200; 11.600901ms)
Apr 27 16:53:55.252: INFO: (8) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 7.098136ms)
Apr 27 16:53:55.252: INFO: (8) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/tlsrewritem... (200; 7.254457ms)
Apr 27 16:53:55.252: INFO: (8) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:462/proxy/: tls qux (200; 7.189383ms)
Apr 27 16:53:55.252: INFO: (8) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 7.128321ms)
Apr 27 16:53:55.252: INFO: (8) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 7.249175ms)
Apr 27 16:53:55.252: INFO: (8) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:460/proxy/: tls baz (200; 7.238705ms)
Apr 27 16:53:55.252: INFO: (8) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">... (200; 7.27318ms)
Apr 27 16:53:55.253: INFO: (8) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/rewriteme">test</a> (200; 8.33027ms)
Apr 27 16:53:55.253: INFO: (8) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 8.445018ms)
Apr 27 16:53:55.253: INFO: (8) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">test<... (200; 8.473098ms)
Apr 27 16:53:55.254: INFO: (8) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname2/proxy/: tls qux (200; 9.089628ms)
Apr 27 16:53:55.254: INFO: (8) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname1/proxy/: foo (200; 9.217088ms)
Apr 27 16:53:55.254: INFO: (8) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname1/proxy/: tls baz (200; 9.357593ms)
Apr 27 16:53:55.254: INFO: (8) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname2/proxy/: bar (200; 9.346958ms)
Apr 27 16:53:55.255: INFO: (8) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname2/proxy/: bar (200; 10.195598ms)
Apr 27 16:53:55.256: INFO: (8) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname1/proxy/: foo (200; 11.154827ms)
Apr 27 16:53:55.263: INFO: (9) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/tlsrewritem... (200; 6.834762ms)
Apr 27 16:53:55.263: INFO: (9) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 6.786953ms)
Apr 27 16:53:55.263: INFO: (9) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">... (200; 6.747101ms)
Apr 27 16:53:55.263: INFO: (9) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 6.957427ms)
Apr 27 16:53:55.263: INFO: (9) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 6.885438ms)
Apr 27 16:53:55.263: INFO: (9) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname2/proxy/: tls qux (200; 7.467152ms)
Apr 27 16:53:55.263: INFO: (9) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 7.609589ms)
Apr 27 16:53:55.264: INFO: (9) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">test<... (200; 7.489765ms)
Apr 27 16:53:55.264: INFO: (9) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/rewriteme">test</a> (200; 8.572808ms)
Apr 27 16:53:55.265: INFO: (9) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname1/proxy/: tls baz (200; 8.707603ms)
Apr 27 16:53:55.265: INFO: (9) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:460/proxy/: tls baz (200; 8.772559ms)
Apr 27 16:53:55.265: INFO: (9) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:462/proxy/: tls qux (200; 8.574143ms)
Apr 27 16:53:55.265: INFO: (9) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname1/proxy/: foo (200; 9.45762ms)
Apr 27 16:53:55.265: INFO: (9) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname2/proxy/: bar (200; 9.467014ms)
Apr 27 16:53:55.266: INFO: (9) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname2/proxy/: bar (200; 9.50998ms)
Apr 27 16:53:55.266: INFO: (9) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname1/proxy/: foo (200; 10.508118ms)
Apr 27 16:53:55.286: INFO: (10) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/tlsrewritem... (200; 19.654297ms)
Apr 27 16:53:55.287: INFO: (10) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname1/proxy/: tls baz (200; 19.061213ms)
Apr 27 16:53:55.287: INFO: (10) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname2/proxy/: bar (200; 20.05277ms)
Apr 27 16:53:55.287: INFO: (10) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:460/proxy/: tls baz (200; 19.541158ms)
Apr 27 16:53:55.288: INFO: (10) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname1/proxy/: foo (200; 20.698091ms)
Apr 27 16:53:55.288: INFO: (10) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 20.111988ms)
Apr 27 16:53:55.288: INFO: (10) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname1/proxy/: foo (200; 20.810333ms)
Apr 27 16:53:55.288: INFO: (10) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">test<... (200; 20.350531ms)
Apr 27 16:53:55.288: INFO: (10) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname2/proxy/: tls qux (200; 21.043826ms)
Apr 27 16:53:55.288: INFO: (10) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">... (200; 20.668919ms)
Apr 27 16:53:55.288: INFO: (10) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/rewriteme">test</a> (200; 21.262526ms)
Apr 27 16:53:55.288: INFO: (10) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:462/proxy/: tls qux (200; 20.757608ms)
Apr 27 16:53:55.288: INFO: (10) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 20.998082ms)
Apr 27 16:53:55.289: INFO: (10) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname2/proxy/: bar (200; 22.183242ms)
Apr 27 16:53:55.289: INFO: (10) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 22.071039ms)
Apr 27 16:53:55.289: INFO: (10) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 22.529473ms)
Apr 27 16:53:55.298: INFO: (11) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname1/proxy/: foo (200; 7.860012ms)
Apr 27 16:53:55.298: INFO: (11) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname2/proxy/: bar (200; 8.079606ms)
Apr 27 16:53:55.298: INFO: (11) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname1/proxy/: foo (200; 8.401077ms)
Apr 27 16:53:55.298: INFO: (11) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname2/proxy/: tls qux (200; 8.579586ms)
Apr 27 16:53:55.298: INFO: (11) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">... (200; 8.258031ms)
Apr 27 16:53:55.298: INFO: (11) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname1/proxy/: tls baz (200; 7.837521ms)
Apr 27 16:53:55.299: INFO: (11) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname2/proxy/: bar (200; 9.545493ms)
Apr 27 16:53:55.299: INFO: (11) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">test<... (200; 9.098202ms)
Apr 27 16:53:55.299: INFO: (11) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/rewriteme">test</a> (200; 9.798417ms)
Apr 27 16:53:55.299: INFO: (11) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:462/proxy/: tls qux (200; 9.335659ms)
Apr 27 16:53:55.299: INFO: (11) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/tlsrewritem... (200; 9.784401ms)
Apr 27 16:53:55.299: INFO: (11) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:460/proxy/: tls baz (200; 9.453776ms)
Apr 27 16:53:55.300: INFO: (11) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 10.064241ms)
Apr 27 16:53:55.300: INFO: (11) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 10.009937ms)
Apr 27 16:53:55.301: INFO: (11) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 10.757699ms)
Apr 27 16:53:55.301: INFO: (11) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 11.378168ms)
Apr 27 16:53:55.310: INFO: (12) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname1/proxy/: tls baz (200; 8.103379ms)
Apr 27 16:53:55.310: INFO: (12) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">test<... (200; 8.071825ms)
Apr 27 16:53:55.310: INFO: (12) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 8.289097ms)
Apr 27 16:53:55.310: INFO: (12) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:460/proxy/: tls baz (200; 8.427904ms)
Apr 27 16:53:55.310: INFO: (12) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 8.222793ms)
Apr 27 16:53:55.310: INFO: (12) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 8.399434ms)
Apr 27 16:53:55.310: INFO: (12) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname2/proxy/: bar (200; 8.438089ms)
Apr 27 16:53:55.311: INFO: (12) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname2/proxy/: tls qux (200; 9.253983ms)
Apr 27 16:53:55.311: INFO: (12) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/rewriteme">test</a> (200; 9.582299ms)
Apr 27 16:53:55.311: INFO: (12) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">... (200; 9.499151ms)
Apr 27 16:53:55.311: INFO: (12) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:462/proxy/: tls qux (200; 9.73603ms)
Apr 27 16:53:55.311: INFO: (12) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/tlsrewritem... (200; 9.577174ms)
Apr 27 16:53:55.312: INFO: (12) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 10.223246ms)
Apr 27 16:53:55.312: INFO: (12) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname1/proxy/: foo (200; 10.32441ms)
Apr 27 16:53:55.313: INFO: (12) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname1/proxy/: foo (200; 11.346181ms)
Apr 27 16:53:55.313: INFO: (12) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname2/proxy/: bar (200; 11.324321ms)
Apr 27 16:53:55.321: INFO: (13) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 7.634139ms)
Apr 27 16:53:55.321: INFO: (13) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 8.166521ms)
Apr 27 16:53:55.321: INFO: (13) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 7.723024ms)
Apr 27 16:53:55.321: INFO: (13) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">... (200; 8.026423ms)
Apr 27 16:53:55.321: INFO: (13) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:460/proxy/: tls baz (200; 7.967435ms)
Apr 27 16:53:55.321: INFO: (13) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 7.629604ms)
Apr 27 16:53:55.322: INFO: (13) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/rewriteme">test</a> (200; 8.624356ms)
Apr 27 16:53:55.322: INFO: (13) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">test<... (200; 8.949356ms)
Apr 27 16:53:55.323: INFO: (13) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname1/proxy/: tls baz (200; 9.23077ms)
Apr 27 16:53:55.323: INFO: (13) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:462/proxy/: tls qux (200; 8.982485ms)
Apr 27 16:53:55.323: INFO: (13) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/tlsrewritem... (200; 9.19181ms)
Apr 27 16:53:55.324: INFO: (13) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname2/proxy/: bar (200; 10.292998ms)
Apr 27 16:53:55.324: INFO: (13) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname1/proxy/: foo (200; 10.144572ms)
Apr 27 16:53:55.324: INFO: (13) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname1/proxy/: foo (200; 10.393695ms)
Apr 27 16:53:55.324: INFO: (13) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname2/proxy/: bar (200; 10.816796ms)
Apr 27 16:53:55.324: INFO: (13) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname2/proxy/: tls qux (200; 10.390487ms)
Apr 27 16:53:55.332: INFO: (14) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/rewriteme">test</a> (200; 7.12609ms)
Apr 27 16:53:55.332: INFO: (14) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 7.168721ms)
Apr 27 16:53:55.332: INFO: (14) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 7.112606ms)
Apr 27 16:53:55.332: INFO: (14) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 7.170103ms)
Apr 27 16:53:55.332: INFO: (14) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 7.289278ms)
Apr 27 16:53:55.332: INFO: (14) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:460/proxy/: tls baz (200; 7.898442ms)
Apr 27 16:53:55.332: INFO: (14) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">test<... (200; 7.74228ms)
Apr 27 16:53:55.332: INFO: (14) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/tlsrewritem... (200; 7.821865ms)
Apr 27 16:53:55.333: INFO: (14) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname1/proxy/: foo (200; 8.839705ms)
Apr 27 16:53:55.333: INFO: (14) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname2/proxy/: bar (200; 8.938139ms)
Apr 27 16:53:55.333: INFO: (14) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:462/proxy/: tls qux (200; 8.856829ms)
Apr 27 16:53:55.333: INFO: (14) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname2/proxy/: tls qux (200; 9.012401ms)
Apr 27 16:53:55.333: INFO: (14) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">... (200; 9.122109ms)
Apr 27 16:53:55.333: INFO: (14) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname1/proxy/: tls baz (200; 8.996351ms)
Apr 27 16:53:55.334: INFO: (14) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname1/proxy/: foo (200; 9.941083ms)
Apr 27 16:53:55.334: INFO: (14) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname2/proxy/: bar (200; 9.997042ms)
Apr 27 16:53:55.386: INFO: (15) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname2/proxy/: bar (200; 51.288902ms)
Apr 27 16:53:55.386: INFO: (15) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 51.849854ms)
Apr 27 16:53:55.387: INFO: (15) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/rewriteme">test</a> (200; 52.226673ms)
Apr 27 16:53:55.387: INFO: (15) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 52.59917ms)
Apr 27 16:53:55.387: INFO: (15) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname2/proxy/: tls qux (200; 52.343404ms)
Apr 27 16:53:55.387: INFO: (15) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 52.383871ms)
Apr 27 16:53:55.387: INFO: (15) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:462/proxy/: tls qux (200; 52.563255ms)
Apr 27 16:53:55.388: INFO: (15) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">test<... (200; 53.284185ms)
Apr 27 16:53:55.388: INFO: (15) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">... (200; 53.643293ms)
Apr 27 16:53:55.388: INFO: (15) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/tlsrewritem... (200; 53.48551ms)
Apr 27 16:53:55.388: INFO: (15) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:460/proxy/: tls baz (200; 53.694841ms)
Apr 27 16:53:55.389: INFO: (15) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname2/proxy/: bar (200; 54.16746ms)
Apr 27 16:53:55.389: INFO: (15) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 54.394162ms)
Apr 27 16:53:55.390: INFO: (15) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname1/proxy/: foo (200; 55.068337ms)
Apr 27 16:53:55.390: INFO: (15) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname1/proxy/: foo (200; 55.625574ms)
Apr 27 16:53:55.391: INFO: (15) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname1/proxy/: tls baz (200; 56.002063ms)
Apr 27 16:53:55.401: INFO: (16) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:462/proxy/: tls qux (200; 10.03724ms)
Apr 27 16:53:55.405: INFO: (16) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/rewriteme">test</a> (200; 14.013046ms)
Apr 27 16:53:55.405: INFO: (16) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 13.8711ms)
Apr 27 16:53:55.405: INFO: (16) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/tlsrewritem... (200; 13.878339ms)
Apr 27 16:53:55.414: INFO: (16) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:460/proxy/: tls baz (200; 22.843123ms)
Apr 27 16:53:55.414: INFO: (16) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 23.037477ms)
Apr 27 16:53:55.414: INFO: (16) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname2/proxy/: bar (200; 23.068034ms)
Apr 27 16:53:55.414: INFO: (16) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">... (200; 23.121007ms)
Apr 27 16:53:55.414: INFO: (16) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 23.024955ms)
Apr 27 16:53:55.414: INFO: (16) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname2/proxy/: tls qux (200; 22.994163ms)
Apr 27 16:53:55.414: INFO: (16) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname1/proxy/: tls baz (200; 23.035378ms)
Apr 27 16:53:55.414: INFO: (16) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname1/proxy/: foo (200; 23.12782ms)
Apr 27 16:53:55.414: INFO: (16) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">test<... (200; 23.479389ms)
Apr 27 16:53:55.457: INFO: (16) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname2/proxy/: bar (200; 66.641225ms)
Apr 27 16:53:55.457: INFO: (16) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 66.704063ms)
Apr 27 16:53:55.458: INFO: (16) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname1/proxy/: foo (200; 67.036518ms)
Apr 27 16:53:55.467: INFO: (17) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 8.44771ms)
Apr 27 16:53:55.467: INFO: (17) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:460/proxy/: tls baz (200; 8.749207ms)
Apr 27 16:53:55.467: INFO: (17) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 9.422495ms)
Apr 27 16:53:55.467: INFO: (17) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/rewriteme">test</a> (200; 8.986984ms)
Apr 27 16:53:55.467: INFO: (17) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname1/proxy/: tls baz (200; 9.140282ms)
Apr 27 16:53:55.467: INFO: (17) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 8.875477ms)
Apr 27 16:53:55.468: INFO: (17) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 9.615972ms)
Apr 27 16:53:55.468: INFO: (17) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">... (200; 10.00297ms)
Apr 27 16:53:55.468: INFO: (17) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/tlsrewritem... (200; 10.464736ms)
Apr 27 16:53:55.468: INFO: (17) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:462/proxy/: tls qux (200; 10.270255ms)
Apr 27 16:53:55.468: INFO: (17) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname2/proxy/: tls qux (200; 9.400386ms)
Apr 27 16:53:55.468: INFO: (17) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">test<... (200; 10.155863ms)
Apr 27 16:53:55.469: INFO: (17) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname1/proxy/: foo (200; 10.386589ms)
Apr 27 16:53:55.471: INFO: (17) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname2/proxy/: bar (200; 11.914837ms)
Apr 27 16:53:55.471: INFO: (17) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname2/proxy/: bar (200; 12.683192ms)
Apr 27 16:53:55.471: INFO: (17) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname1/proxy/: foo (200; 12.070547ms)
Apr 27 16:53:55.481: INFO: (18) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/tlsrewritem... (200; 9.854841ms)
Apr 27 16:53:55.481: INFO: (18) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 9.838571ms)
Apr 27 16:53:55.481: INFO: (18) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:462/proxy/: tls qux (200; 9.790833ms)
Apr 27 16:53:55.481: INFO: (18) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 10.289557ms)
Apr 27 16:53:55.483: INFO: (18) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:460/proxy/: tls baz (200; 11.972176ms)
Apr 27 16:53:55.483: INFO: (18) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 11.704683ms)
Apr 27 16:53:55.483: INFO: (18) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">test<... (200; 12.116418ms)
Apr 27 16:53:55.484: INFO: (18) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/rewriteme">test</a> (200; 12.133036ms)
Apr 27 16:53:55.485: INFO: (18) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname2/proxy/: tls qux (200; 13.648129ms)
Apr 27 16:53:55.485: INFO: (18) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname2/proxy/: bar (200; 13.889493ms)
Apr 27 16:53:55.485: INFO: (18) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname2/proxy/: bar (200; 13.598713ms)
Apr 27 16:53:55.485: INFO: (18) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname1/proxy/: tls baz (200; 13.385798ms)
Apr 27 16:53:55.485: INFO: (18) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 13.278272ms)
Apr 27 16:53:55.485: INFO: (18) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">... (200; 13.545253ms)
Apr 27 16:53:55.486: INFO: (18) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname1/proxy/: foo (200; 15.055749ms)
Apr 27 16:53:55.487: INFO: (18) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname1/proxy/: foo (200; 16.516792ms)
Apr 27 16:53:55.500: INFO: (19) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 12.467018ms)
Apr 27 16:53:55.500: INFO: (19) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9/proxy/rewriteme">test</a> (200; 12.771373ms)
Apr 27 16:53:55.500: INFO: (19) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 12.648945ms)
Apr 27 16:53:55.500: INFO: (19) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:462/proxy/: tls qux (200; 12.028677ms)
Apr 27 16:53:55.500: INFO: (19) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:160/proxy/: foo (200; 12.774315ms)
Apr 27 16:53:55.500: INFO: (19) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">... (200; 11.821503ms)
Apr 27 16:53:55.501: INFO: (19) /api/v1/namespaces/proxy-3633/pods/http:proxy-service-5jjhj-wjdj9:162/proxy/: bar (200; 12.943255ms)
Apr 27 16:53:55.501: INFO: (19) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:460/proxy/: tls baz (200; 13.954537ms)
Apr 27 16:53:55.501: INFO: (19) /api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/https:proxy-service-5jjhj-wjdj9:443/proxy/tlsrewritem... (200; 13.117127ms)
Apr 27 16:53:55.501: INFO: (19) /api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/: <a href="/api/v1/namespaces/proxy-3633/pods/proxy-service-5jjhj-wjdj9:1080/proxy/rewriteme">test<... (200; 12.830525ms)
Apr 27 16:53:55.503: INFO: (19) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname2/proxy/: bar (200; 14.698037ms)
Apr 27 16:53:55.545: INFO: (19) /api/v1/namespaces/proxy-3633/services/proxy-service-5jjhj:portname1/proxy/: foo (200; 57.303674ms)
Apr 27 16:53:55.545: INFO: (19) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname1/proxy/: tls baz (200; 57.848171ms)
Apr 27 16:53:55.545: INFO: (19) /api/v1/namespaces/proxy-3633/services/https:proxy-service-5jjhj:tlsportname2/proxy/: tls qux (200; 57.232995ms)
Apr 27 16:53:55.545: INFO: (19) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname1/proxy/: foo (200; 57.417919ms)
Apr 27 16:53:55.545: INFO: (19) /api/v1/namespaces/proxy-3633/services/http:proxy-service-5jjhj:portname2/proxy/: bar (200; 56.961118ms)
STEP: deleting ReplicationController proxy-service-5jjhj in namespace proxy-3633, will wait for the garbage collector to delete the pods
Apr 27 16:53:55.606: INFO: Deleting ReplicationController proxy-service-5jjhj took: 6.085716ms
Apr 27 16:53:56.106: INFO: Terminating ReplicationController proxy-service-5jjhj pods took: 500.216154ms
[AfterEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:57.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3633" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":277,"completed":123,"skipped":1877,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:57.619: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-614
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:54:20.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-614" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":277,"completed":124,"skipped":1891,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:54:20.976: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8314
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Apr 27 16:54:22.169: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0427 16:54:22.169608    5439 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:54:22.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8314" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":277,"completed":125,"skipped":1906,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:54:22.179: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9117
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:54:22.342: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a14bb8b9-f7dc-4c32-bf95-8c7cd381bee1" in namespace "projected-9117" to be "Succeeded or Failed"
Apr 27 16:54:22.345: INFO: Pod "downwardapi-volume-a14bb8b9-f7dc-4c32-bf95-8c7cd381bee1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.012825ms
Apr 27 16:54:24.349: INFO: Pod "downwardapi-volume-a14bb8b9-f7dc-4c32-bf95-8c7cd381bee1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007460065s
STEP: Saw pod success
Apr 27 16:54:24.349: INFO: Pod "downwardapi-volume-a14bb8b9-f7dc-4c32-bf95-8c7cd381bee1" satisfied condition "Succeeded or Failed"
Apr 27 16:54:24.352: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downwardapi-volume-a14bb8b9-f7dc-4c32-bf95-8c7cd381bee1 container client-container: <nil>
STEP: delete the pod
Apr 27 16:54:24.372: INFO: Waiting for pod downwardapi-volume-a14bb8b9-f7dc-4c32-bf95-8c7cd381bee1 to disappear
Apr 27 16:54:24.375: INFO: Pod downwardapi-volume-a14bb8b9-f7dc-4c32-bf95-8c7cd381bee1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:54:24.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9117" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":277,"completed":126,"skipped":1935,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:54:24.385: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3849
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Apr 27 16:54:24.544: INFO: Waiting up to 5m0s for pod "downward-api-e279e885-22fc-430d-a78a-2c21077f6185" in namespace "downward-api-3849" to be "Succeeded or Failed"
Apr 27 16:54:24.547: INFO: Pod "downward-api-e279e885-22fc-430d-a78a-2c21077f6185": Phase="Pending", Reason="", readiness=false. Elapsed: 2.739366ms
Apr 27 16:54:26.551: INFO: Pod "downward-api-e279e885-22fc-430d-a78a-2c21077f6185": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006442654s
STEP: Saw pod success
Apr 27 16:54:26.551: INFO: Pod "downward-api-e279e885-22fc-430d-a78a-2c21077f6185" satisfied condition "Succeeded or Failed"
Apr 27 16:54:26.554: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downward-api-e279e885-22fc-430d-a78a-2c21077f6185 container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:54:26.571: INFO: Waiting for pod downward-api-e279e885-22fc-430d-a78a-2c21077f6185 to disappear
Apr 27 16:54:26.574: INFO: Pod downward-api-e279e885-22fc-430d-a78a-2c21077f6185 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:54:26.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3849" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":277,"completed":127,"skipped":1943,"failed":0}
SSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:54:26.583: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-2190
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Apr 27 16:54:26.938: INFO: Pod name wrapped-volume-race-093cf532-63ca-4d62-b298-68306eca072a: Found 1 pods out of 5
Apr 27 16:54:31.948: INFO: Pod name wrapped-volume-race-093cf532-63ca-4d62-b298-68306eca072a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-093cf532-63ca-4d62-b298-68306eca072a in namespace emptydir-wrapper-2190, will wait for the garbage collector to delete the pods
Apr 27 16:54:32.030: INFO: Deleting ReplicationController wrapped-volume-race-093cf532-63ca-4d62-b298-68306eca072a took: 10.028414ms
Apr 27 16:54:32.130: INFO: Terminating ReplicationController wrapped-volume-race-093cf532-63ca-4d62-b298-68306eca072a pods took: 100.174965ms
STEP: Creating RC which spawns configmap-volume pods
Apr 27 16:54:45.150: INFO: Pod name wrapped-volume-race-336e81ae-e770-4ddd-b7ef-187cd8a08997: Found 0 pods out of 5
Apr 27 16:54:50.161: INFO: Pod name wrapped-volume-race-336e81ae-e770-4ddd-b7ef-187cd8a08997: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-336e81ae-e770-4ddd-b7ef-187cd8a08997 in namespace emptydir-wrapper-2190, will wait for the garbage collector to delete the pods
Apr 27 16:54:50.246: INFO: Deleting ReplicationController wrapped-volume-race-336e81ae-e770-4ddd-b7ef-187cd8a08997 took: 8.640993ms
Apr 27 16:54:50.346: INFO: Terminating ReplicationController wrapped-volume-race-336e81ae-e770-4ddd-b7ef-187cd8a08997 pods took: 100.222024ms
STEP: Creating RC which spawns configmap-volume pods
Apr 27 16:54:55.162: INFO: Pod name wrapped-volume-race-86fb48e2-3947-4a07-a18a-8c45bfaf0c35: Found 0 pods out of 5
Apr 27 16:55:00.173: INFO: Pod name wrapped-volume-race-86fb48e2-3947-4a07-a18a-8c45bfaf0c35: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-86fb48e2-3947-4a07-a18a-8c45bfaf0c35 in namespace emptydir-wrapper-2190, will wait for the garbage collector to delete the pods
Apr 27 16:55:00.255: INFO: Deleting ReplicationController wrapped-volume-race-86fb48e2-3947-4a07-a18a-8c45bfaf0c35 took: 8.453563ms
Apr 27 16:55:00.355: INFO: Terminating ReplicationController wrapped-volume-race-86fb48e2-3947-4a07-a18a-8c45bfaf0c35 pods took: 100.262955ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:55:05.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2190" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":277,"completed":128,"skipped":1948,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:55:05.424: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4804
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Apr 27 16:55:05.571: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 27 16:55:05.586: INFO: Waiting for terminating namespaces to be deleted...
Apr 27 16:55:05.589: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp before test
Apr 27 16:55:05.667: INFO: node-exporter-9pkd5 from kube-system started at 2020-04-27 16:07:11 +0000 UTC (1 container statuses recorded)
Apr 27 16:55:05.667: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:55:05.667: INFO: metrics-server-5f76b49bb-ktlbv from kube-system started at 2020-04-27 16:07:31 +0000 UTC (1 container statuses recorded)
Apr 27 16:55:05.667: INFO: 	Container metrics-server ready: true, restart count 0
Apr 27 16:55:05.667: INFO: dashboard-metrics-scraper-76c7b697bc-l2z4c from kubernetes-dashboard started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:55:05.667: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 27 16:55:05.667: INFO: coredns-5cb857d789-s8ws2 from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:55:05.667: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:55:05.667: INFO: calico-typha-deploy-784665cc66-9ngtv from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:55:05.667: INFO: 	Container calico-typha ready: true, restart count 0
Apr 27 16:55:05.667: INFO: kubernetes-dashboard-6b586c4cb4-9c2rc from kubernetes-dashboard started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:55:05.667: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
Apr 27 16:55:05.667: INFO: blackbox-exporter-5dc75b79b7-7xcjk from kube-system started at 2020-04-27 16:07:11 +0000 UTC (1 container statuses recorded)
Apr 27 16:55:05.667: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 27 16:55:05.667: INFO: kube-proxy-h2cx7 from kube-system started at 2020-04-27 16:07:11 +0000 UTC (1 container statuses recorded)
Apr 27 16:55:05.667: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:55:05.667: INFO: node-problem-detector-tq7hl from kube-system started at 2020-04-27 16:07:11 +0000 UTC (1 container statuses recorded)
Apr 27 16:55:05.667: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 16:55:05.667: INFO: vpn-shoot-5b5f49b4bf-trqr9 from kube-system started at 2020-04-27 16:07:31 +0000 UTC (1 container statuses recorded)
Apr 27 16:55:05.667: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 27 16:55:05.667: INFO: calico-typha-vertical-autoscaler-5b477c88cf-k2f8l from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:55:05.667: INFO: 	Container autoscaler ready: true, restart count 6
Apr 27 16:55:05.667: INFO: calico-typha-horizontal-autoscaler-6fdd5d8746-hv92s from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:55:05.667: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 16:55:05.667: INFO: addons-nginx-ingress-controller-6cf77756b5-rw99m from kube-system started at 2020-04-27 16:07:33 +0000 UTC (1 container statuses recorded)
Apr 27 16:55:05.667: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 27 16:55:05.667: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-q52mz from kube-system started at 2020-04-27 16:07:41 +0000 UTC (1 container statuses recorded)
Apr 27 16:55:05.668: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr 27 16:55:05.668: INFO: calico-kube-controllers-77dcb8f688-7jxx4 from kube-system started at 2020-04-27 16:07:33 +0000 UTC (1 container statuses recorded)
Apr 27 16:55:05.668: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 27 16:55:05.668: INFO: calico-node-xphhz from kube-system started at 2020-04-27 16:15:29 +0000 UTC (1 container statuses recorded)
Apr 27 16:55:05.668: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:55:05.668: INFO: calico-node-vertical-autoscaler-74d4897db8-h9n8r from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:55:05.668: INFO: 	Container autoscaler ready: true, restart count 6
Apr 27 16:55:05.668: INFO: coredns-5cb857d789-lrv9m from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 16:55:05.668: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:55:05.668: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 before test
Apr 27 16:55:05.683: INFO: kube-proxy-jm5m6 from kube-system started at 2020-04-27 16:07:18 +0000 UTC (1 container statuses recorded)
Apr 27 16:55:05.683: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:55:05.683: INFO: calico-node-ld4x7 from kube-system started at 2020-04-27 16:15:20 +0000 UTC (1 container statuses recorded)
Apr 27 16:55:05.683: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:55:05.683: INFO: node-exporter-srfgn from kube-system started at 2020-04-27 16:07:18 +0000 UTC (1 container statuses recorded)
Apr 27 16:55:05.683: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:55:05.683: INFO: node-problem-detector-9thlx from kube-system started at 2020-04-27 16:07:18 +0000 UTC (1 container statuses recorded)
Apr 27 16:55:05.683: INFO: 	Container node-problem-detector ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1609bb80da1707d8], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1609bb80da7ba1d5], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:55:06.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4804" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":277,"completed":129,"skipped":1982,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:55:06.722: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5607
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:55:07.408: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:55:10.431: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:55:10.434: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3144-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:55:11.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5607" for this suite.
STEP: Destroying namespace "webhook-5607-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":277,"completed":130,"skipped":1990,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:55:11.707: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6825
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:55:12.417: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 27 16:55:14.428: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603312, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603312, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603312, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603312, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:55:17.443: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:55:17.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6825" for this suite.
STEP: Destroying namespace "webhook-6825-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":277,"completed":131,"skipped":2008,"failed":0}
SS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:55:17.699: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5407
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating pod
Apr 27 16:55:21.866: INFO: Pod pod-hostip-dc6af9c6-d455-4541-a387-e33ca517f249 has hostIP: 10.250.0.21
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:55:21.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5407" for this suite.
•{"msg":"PASSED [k8s.io] Pods should get a host IP [NodeConformance] [Conformance]","total":277,"completed":132,"skipped":2010,"failed":0}
S
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:55:21.881: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8988
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-32fbe9c5-01fa-40bc-9643-078870f85273
STEP: Creating configMap with name cm-test-opt-upd-3826a82b-db61-40c9-946f-3645cc726c10
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-32fbe9c5-01fa-40bc-9643-078870f85273
STEP: Updating configmap cm-test-opt-upd-3826a82b-db61-40c9-946f-3645cc726c10
STEP: Creating configMap with name cm-test-opt-create-65b4ef70-7451-4a66-a12a-ada3e5127db1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:56:44.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8988" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":133,"skipped":2011,"failed":0}
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:56:44.834: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2401
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:56:44.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2401" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":277,"completed":134,"skipped":2012,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:56:45.008: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename limitrange
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in limitrange-9745
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
Apr 27 16:56:45.164: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
Apr 27 16:56:45.170: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr 27 16:56:45.170: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
Apr 27 16:56:45.178: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr 27 16:56:45.178: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
Apr 27 16:56:45.187: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Apr 27 16:56:45.187: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
Apr 27 16:56:52.224: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:56:52.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-9745" for this suite.
•{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":277,"completed":135,"skipped":2026,"failed":0}
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:56:52.281: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3509
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Apr 27 16:56:54.453: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-3509 PodName:pod-sharedvolume-4c4de42f-4f04-4e36-a517-6212415257dc ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:56:54.453: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:56:54.853: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:56:54.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3509" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":277,"completed":136,"skipped":2029,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:56:54.864: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-429
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:56:55.540: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 27 16:56:57.550: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603415, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603415, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603415, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603415, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:57:00.566: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:57:01.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-429" for this suite.
STEP: Destroying namespace "webhook-429-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":277,"completed":137,"skipped":2052,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:57:01.191: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1576
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Apr 27 16:57:01.338: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:57:20.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1576" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":277,"completed":138,"skipped":2074,"failed":0}

------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:57:20.271: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-3526
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Apr 27 16:57:22.442: INFO: &Pod{ObjectMeta:{send-events-da96b4fc-c8aa-4c0d-a88d-e3628dd5265b  events-3526 /api/v1/namespaces/events-3526/pods/send-events-da96b4fc-c8aa-4c0d-a88d-e3628dd5265b 619a8eda-8d53-4774-9804-d742ccda962f 25524 0 2020-04-27 16:57:20 +0000 UTC <nil> <nil> map[name:foo time:420602722] map[cni.projectcalico.org/podIP:100.64.1.185/32 cni.projectcalico.org/podIPs:100.64.1.185/32 kubernetes.io/psp:e2e-test-privileged-psp] [] []  [{e2e.test Update v1 2020-04-27 16:57:20 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 116 105 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 112 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 114 116 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 99 111 110 116 97 105 110 101 114 80 111 114 116 92 34 58 56 48 44 92 34 112 114 111 116 111 99 111 108 92 34 58 92 34 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 99 111 110 116 97 105 110 101 114 80 111 114 116 34 58 123 125 44 34 102 58 112 114 111 116 111 99 111 108 34 58 123 125 125 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:57:21 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:57:22 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 49 56 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sww6t,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sww6t,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sww6t,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:57:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:57:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:57:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:57:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.21,PodIP:100.64.1.185,StartTime:2020-04-27 16:57:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:57:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://0597c8a1450db2aa5c9de2c5f476bc02b1f520d515201461672122ca2d3b3609,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.185,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Apr 27 16:57:24.446: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Apr 27 16:57:26.450: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:57:26.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-3526" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]","total":277,"completed":139,"skipped":2074,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:57:26.467: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-422
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating all guestbook components
Apr 27 16:57:26.611: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-slave
  labels:
    app: agnhost
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: slave
    tier: backend

Apr 27 16:57:26.611: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-422'
Apr 27 16:57:27.065: INFO: stderr: ""
Apr 27 16:57:27.065: INFO: stdout: "service/agnhost-slave created\n"
Apr 27 16:57:27.065: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-master
  labels:
    app: agnhost
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: master
    tier: backend

Apr 27 16:57:27.065: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-422'
Apr 27 16:57:27.432: INFO: stderr: ""
Apr 27 16:57:27.432: INFO: stdout: "service/agnhost-master created\n"
Apr 27 16:57:27.433: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr 27 16:57:27.433: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-422'
Apr 27 16:57:27.668: INFO: stderr: ""
Apr 27 16:57:27.668: INFO: stdout: "service/frontend created\n"
Apr 27 16:57:27.668: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Apr 27 16:57:27.669: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-422'
Apr 27 16:57:27.901: INFO: stderr: ""
Apr 27 16:57:27.901: INFO: stdout: "deployment.apps/frontend created\n"
Apr 27 16:57:27.902: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 27 16:57:27.902: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-422'
Apr 27 16:57:28.132: INFO: stderr: ""
Apr 27 16:57:28.132: INFO: stdout: "deployment.apps/agnhost-master created\n"
Apr 27 16:57:28.132: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--slaveof", "agnhost-master", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 27 16:57:28.132: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-422'
Apr 27 16:57:28.293: INFO: stderr: ""
Apr 27 16:57:28.293: INFO: stdout: "deployment.apps/agnhost-slave created\n"
STEP: validating guestbook app
Apr 27 16:57:28.293: INFO: Waiting for all frontend pods to be Running.
Apr 27 16:57:33.343: INFO: Waiting for frontend to serve content.
Apr 27 16:57:33.436: INFO: Trying to add a new entry to the guestbook.
Apr 27 16:57:33.563: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Apr 27 16:57:33.608: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-422'
Apr 27 16:57:33.696: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 16:57:33.696: INFO: stdout: "service \"agnhost-slave\" force deleted\n"
STEP: using delete to clean up resources
Apr 27 16:57:33.696: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-422'
Apr 27 16:57:33.782: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 16:57:33.782: INFO: stdout: "service \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 27 16:57:33.782: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-422'
Apr 27 16:57:33.862: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 16:57:33.862: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 27 16:57:33.862: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-422'
Apr 27 16:57:33.936: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 16:57:33.936: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 27 16:57:33.937: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-422'
Apr 27 16:57:34.008: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 16:57:34.008: INFO: stdout: "deployment.apps \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 27 16:57:34.008: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-422'
Apr 27 16:57:34.091: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 16:57:34.091: INFO: stdout: "deployment.apps \"agnhost-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:57:34.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-422" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":277,"completed":140,"skipped":2105,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:57:34.102: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8660
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:57:34.249: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr 27 16:57:37.900: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-8660 create -f -'
Apr 27 16:57:38.321: INFO: stderr: ""
Apr 27 16:57:38.321: INFO: stdout: "e2e-test-crd-publish-openapi-5420-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 27 16:57:38.322: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-8660 delete e2e-test-crd-publish-openapi-5420-crds test-cr'
Apr 27 16:57:38.435: INFO: stderr: ""
Apr 27 16:57:38.435: INFO: stdout: "e2e-test-crd-publish-openapi-5420-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Apr 27 16:57:38.435: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-8660 apply -f -'
Apr 27 16:57:38.609: INFO: stderr: ""
Apr 27 16:57:38.609: INFO: stdout: "e2e-test-crd-publish-openapi-5420-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 27 16:57:38.609: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-8660 delete e2e-test-crd-publish-openapi-5420-crds test-cr'
Apr 27 16:57:38.692: INFO: stderr: ""
Apr 27 16:57:38.692: INFO: stdout: "e2e-test-crd-publish-openapi-5420-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Apr 27 16:57:38.692: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-5420-crds'
Apr 27 16:57:38.909: INFO: stderr: ""
Apr 27 16:57:38.909: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5420-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:57:42.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8660" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":277,"completed":141,"skipped":2141,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:57:42.492: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5294
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-5294
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-5294
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5294
Apr 27 16:57:42.658: INFO: Found 0 stateful pods, waiting for 1
Apr 27 16:57:52.663: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Apr 27 16:57:52.667: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5294 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:57:58.196: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:57:58.196: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:57:58.196: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:57:58.213: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 27 16:58:08.218: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:58:08.218: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:58:08.234: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999738s
Apr 27 16:58:09.238: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996879769s
Apr 27 16:58:10.242: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.992943319s
Apr 27 16:58:11.246: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.988224114s
Apr 27 16:58:12.251: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.984103103s
Apr 27 16:58:13.256: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.9794273s
Apr 27 16:58:14.260: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.974778115s
Apr 27 16:58:15.266: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.97052924s
Apr 27 16:58:16.271: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.964728696s
Apr 27 16:58:17.276: INFO: Verifying statefulset ss doesn't scale past 1 for another 959.681177ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5294
Apr 27 16:58:18.281: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5294 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:58:18.707: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 16:58:18.707: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:58:18.707: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:58:18.711: INFO: Found 1 stateful pods, waiting for 3
Apr 27 16:58:28.716: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:58:28.716: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:58:28.716: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Apr 27 16:58:28.722: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5294 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:58:29.103: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:58:29.104: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:58:29.104: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:58:29.104: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5294 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:58:29.611: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:58:29.611: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:58:29.611: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:58:29.611: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5294 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:58:30.047: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:58:30.047: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:58:30.047: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:58:30.047: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:58:30.052: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr 27 16:58:40.061: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:58:40.061: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:58:40.061: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:58:40.074: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999722s
Apr 27 16:58:41.079: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995107392s
Apr 27 16:58:42.084: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990433257s
Apr 27 16:58:43.089: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985517925s
Apr 27 16:58:44.095: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.979842505s
Apr 27 16:58:45.100: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.974553416s
Apr 27 16:58:46.105: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.96909667s
Apr 27 16:58:47.112: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.963772557s
Apr 27 16:58:48.117: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.957068935s
Apr 27 16:58:49.122: INFO: Verifying statefulset ss doesn't scale past 3 for another 951.90569ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5294
Apr 27 16:58:50.127: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5294 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:58:50.638: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 16:58:50.638: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:58:50.638: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:58:50.638: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5294 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:58:51.071: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 16:58:51.071: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:58:51.071: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:58:51.071: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5294 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:58:51.542: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 16:58:51.542: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:58:51.542: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:58:51.542: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 16:59:11.566: INFO: Deleting all statefulset in ns statefulset-5294
Apr 27 16:59:11.569: INFO: Scaling statefulset ss to 0
Apr 27 16:59:11.580: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:59:11.582: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:59:11.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5294" for this suite.
•{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":277,"completed":142,"skipped":2205,"failed":0}

------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:59:11.604: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4896
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-404acb0f-7622-480c-a0c3-899cd28188ee
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:59:13.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4896" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":143,"skipped":2205,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:59:13.981: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7185
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 27 16:59:14.145: INFO: Waiting up to 5m0s for pod "pod-152dccc0-7f3c-4b6a-95f4-0da454ca9cff" in namespace "emptydir-7185" to be "Succeeded or Failed"
Apr 27 16:59:14.148: INFO: Pod "pod-152dccc0-7f3c-4b6a-95f4-0da454ca9cff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.972682ms
Apr 27 16:59:16.152: INFO: Pod "pod-152dccc0-7f3c-4b6a-95f4-0da454ca9cff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007003394s
STEP: Saw pod success
Apr 27 16:59:16.152: INFO: Pod "pod-152dccc0-7f3c-4b6a-95f4-0da454ca9cff" satisfied condition "Succeeded or Failed"
Apr 27 16:59:16.155: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-152dccc0-7f3c-4b6a-95f4-0da454ca9cff container test-container: <nil>
STEP: delete the pod
Apr 27 16:59:16.171: INFO: Waiting for pod pod-152dccc0-7f3c-4b6a-95f4-0da454ca9cff to disappear
Apr 27 16:59:16.175: INFO: Pod pod-152dccc0-7f3c-4b6a-95f4-0da454ca9cff no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:59:16.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7185" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":144,"skipped":2242,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:59:16.184: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1231
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's args
Apr 27 16:59:16.347: INFO: Waiting up to 5m0s for pod "var-expansion-ec6d934d-5e7c-4aba-ae3b-8571726b87c9" in namespace "var-expansion-1231" to be "Succeeded or Failed"
Apr 27 16:59:16.350: INFO: Pod "var-expansion-ec6d934d-5e7c-4aba-ae3b-8571726b87c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.769406ms
Apr 27 16:59:18.354: INFO: Pod "var-expansion-ec6d934d-5e7c-4aba-ae3b-8571726b87c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006749432s
STEP: Saw pod success
Apr 27 16:59:18.354: INFO: Pod "var-expansion-ec6d934d-5e7c-4aba-ae3b-8571726b87c9" satisfied condition "Succeeded or Failed"
Apr 27 16:59:18.357: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod var-expansion-ec6d934d-5e7c-4aba-ae3b-8571726b87c9 container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:59:18.376: INFO: Waiting for pod var-expansion-ec6d934d-5e7c-4aba-ae3b-8571726b87c9 to disappear
Apr 27 16:59:18.379: INFO: Pod var-expansion-ec6d934d-5e7c-4aba-ae3b-8571726b87c9 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:59:18.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1231" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":277,"completed":145,"skipped":2287,"failed":0}

------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:59:18.388: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6529
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-f7631358-6ccf-457b-98d2-885b4eeaf704
STEP: Creating configMap with name cm-test-opt-upd-954ca75c-7532-45f7-8a7e-26932a1524a4
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-f7631358-6ccf-457b-98d2-885b4eeaf704
STEP: Updating configmap cm-test-opt-upd-954ca75c-7532-45f7-8a7e-26932a1524a4
STEP: Creating configMap with name cm-test-opt-create-9ae436a5-da05-44ec-aa01-301d71292e43
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:00:49.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6529" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":146,"skipped":2287,"failed":0}
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:00:49.543: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3731
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-1a93f856-acab-4d49-bbaf-ed2bf47ffd6d
STEP: Creating a pod to test consume secrets
Apr 27 17:00:49.699: INFO: Waiting up to 5m0s for pod "pod-secrets-cb464877-7ba5-4e03-8c1b-5952d7cc05f3" in namespace "secrets-3731" to be "Succeeded or Failed"
Apr 27 17:00:49.702: INFO: Pod "pod-secrets-cb464877-7ba5-4e03-8c1b-5952d7cc05f3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.077594ms
Apr 27 17:00:51.706: INFO: Pod "pod-secrets-cb464877-7ba5-4e03-8c1b-5952d7cc05f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006702649s
STEP: Saw pod success
Apr 27 17:00:51.706: INFO: Pod "pod-secrets-cb464877-7ba5-4e03-8c1b-5952d7cc05f3" satisfied condition "Succeeded or Failed"
Apr 27 17:00:51.708: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-secrets-cb464877-7ba5-4e03-8c1b-5952d7cc05f3 container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:00:51.726: INFO: Waiting for pod pod-secrets-cb464877-7ba5-4e03-8c1b-5952d7cc05f3 to disappear
Apr 27 17:00:51.729: INFO: Pod pod-secrets-cb464877-7ba5-4e03-8c1b-5952d7cc05f3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:00:51.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3731" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":147,"skipped":2291,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:00:51.738: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7079
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:00:51.883: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config version'
Apr 27 17:00:56.969: INFO: stderr: ""
Apr 27 17:00:56.969: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.2\", GitCommit:\"52c56ce7a8272c798dbc29846288d7cd9fbae032\", GitTreeState:\"clean\", BuildDate:\"2020-04-16T11:56:40Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.2\", GitCommit:\"52c56ce7a8272c798dbc29846288d7cd9fbae032\", GitTreeState:\"clean\", BuildDate:\"2020-04-16T11:48:36Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:00:56.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7079" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":277,"completed":148,"skipped":2329,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:00:56.980: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5012
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:01:08.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5012" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":277,"completed":149,"skipped":2353,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:01:08.202: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-3105
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:01:08.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3105" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":277,"completed":150,"skipped":2365,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:01:08.363: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7230
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-7230/configmap-test-aab04741-35f2-4ff5-a754-870488c9605a
STEP: Creating a pod to test consume configMaps
Apr 27 17:01:08.523: INFO: Waiting up to 5m0s for pod "pod-configmaps-c7b15009-22bc-4450-bad7-6a2100396b17" in namespace "configmap-7230" to be "Succeeded or Failed"
Apr 27 17:01:08.527: INFO: Pod "pod-configmaps-c7b15009-22bc-4450-bad7-6a2100396b17": Phase="Pending", Reason="", readiness=false. Elapsed: 3.367522ms
Apr 27 17:01:10.531: INFO: Pod "pod-configmaps-c7b15009-22bc-4450-bad7-6a2100396b17": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007255919s
STEP: Saw pod success
Apr 27 17:01:10.531: INFO: Pod "pod-configmaps-c7b15009-22bc-4450-bad7-6a2100396b17" satisfied condition "Succeeded or Failed"
Apr 27 17:01:10.533: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-configmaps-c7b15009-22bc-4450-bad7-6a2100396b17 container env-test: <nil>
STEP: delete the pod
Apr 27 17:01:10.552: INFO: Waiting for pod pod-configmaps-c7b15009-22bc-4450-bad7-6a2100396b17 to disappear
Apr 27 17:01:10.555: INFO: Pod pod-configmaps-c7b15009-22bc-4450-bad7-6a2100396b17 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:01:10.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7230" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":277,"completed":151,"skipped":2379,"failed":0}
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:01:10.564: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8196
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-e0b1a894-f9d6-426e-9bcf-1fd92b0310b7
STEP: Creating a pod to test consume secrets
Apr 27 17:01:10.720: INFO: Waiting up to 5m0s for pod "pod-secrets-c1f7423a-c4af-4ff4-9dc4-dc3976b0eded" in namespace "secrets-8196" to be "Succeeded or Failed"
Apr 27 17:01:10.722: INFO: Pod "pod-secrets-c1f7423a-c4af-4ff4-9dc4-dc3976b0eded": Phase="Pending", Reason="", readiness=false. Elapsed: 2.595395ms
Apr 27 17:01:12.727: INFO: Pod "pod-secrets-c1f7423a-c4af-4ff4-9dc4-dc3976b0eded": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007565331s
STEP: Saw pod success
Apr 27 17:01:12.727: INFO: Pod "pod-secrets-c1f7423a-c4af-4ff4-9dc4-dc3976b0eded" satisfied condition "Succeeded or Failed"
Apr 27 17:01:12.731: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-secrets-c1f7423a-c4af-4ff4-9dc4-dc3976b0eded container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:01:12.748: INFO: Waiting for pod pod-secrets-c1f7423a-c4af-4ff4-9dc4-dc3976b0eded to disappear
Apr 27 17:01:12.752: INFO: Pod pod-secrets-c1f7423a-c4af-4ff4-9dc4-dc3976b0eded no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:01:12.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8196" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":152,"skipped":2380,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:01:12.762: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9116
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating api versions
Apr 27 17:01:12.916: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config api-versions'
Apr 27 17:01:12.992: INFO: stderr: ""
Apr 27 17:01:12.992: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncert.gardener.cloud/v1alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1beta1\ndns.gardener.cloud/v1alpha1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:01:12.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9116" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":277,"completed":153,"skipped":2393,"failed":0}
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:01:13.002: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1532
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod test-webserver-32253f80-1463-4eed-be9d-49eb2aa53e4a in namespace container-probe-1532
Apr 27 17:01:15.178: INFO: Started pod test-webserver-32253f80-1463-4eed-be9d-49eb2aa53e4a in namespace container-probe-1532
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 17:01:15.180: INFO: Initial restart count of pod test-webserver-32253f80-1463-4eed-be9d-49eb2aa53e4a is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:15.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1532" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":277,"completed":154,"skipped":2399,"failed":0}
SSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:15.762: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-9869
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:05:16.017: INFO: (0) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 100.06299ms)
Apr 27 17:05:16.024: INFO: (1) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.8501ms)
Apr 27 17:05:16.032: INFO: (2) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 7.450043ms)
Apr 27 17:05:16.038: INFO: (3) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.226562ms)
Apr 27 17:05:16.043: INFO: (4) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.234001ms)
Apr 27 17:05:16.050: INFO: (5) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.406008ms)
Apr 27 17:05:16.055: INFO: (6) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.171298ms)
Apr 27 17:05:16.060: INFO: (7) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.765528ms)
Apr 27 17:05:16.064: INFO: (8) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.674464ms)
Apr 27 17:05:16.069: INFO: (9) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.056841ms)
Apr 27 17:05:16.074: INFO: (10) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.902925ms)
Apr 27 17:05:16.079: INFO: (11) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.799579ms)
Apr 27 17:05:16.084: INFO: (12) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.922736ms)
Apr 27 17:05:16.089: INFO: (13) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.872589ms)
Apr 27 17:05:16.094: INFO: (14) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.820443ms)
Apr 27 17:05:16.099: INFO: (15) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.614303ms)
Apr 27 17:05:16.103: INFO: (16) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.856627ms)
Apr 27 17:05:16.108: INFO: (17) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.0035ms)
Apr 27 17:05:16.113: INFO: (18) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.629591ms)
Apr 27 17:05:16.118: INFO: (19) /api/v1/nodes/shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.525897ms)
[AfterEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:16.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9869" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node using proxy subresource  [Conformance]","total":277,"completed":155,"skipped":2409,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:16.126: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1488
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Apr 27 17:05:16.276: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 27 17:05:16.287: INFO: Waiting for terminating namespaces to be deleted...
Apr 27 17:05:16.290: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp before test
Apr 27 17:05:16.315: INFO: calico-node-vertical-autoscaler-74d4897db8-h9n8r from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 17:05:16.315: INFO: 	Container autoscaler ready: true, restart count 6
Apr 27 17:05:16.315: INFO: coredns-5cb857d789-lrv9m from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 17:05:16.315: INFO: 	Container coredns ready: true, restart count 0
Apr 27 17:05:16.315: INFO: node-exporter-9pkd5 from kube-system started at 2020-04-27 16:07:11 +0000 UTC (1 container statuses recorded)
Apr 27 17:05:16.315: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 17:05:16.315: INFO: metrics-server-5f76b49bb-ktlbv from kube-system started at 2020-04-27 16:07:31 +0000 UTC (1 container statuses recorded)
Apr 27 17:05:16.315: INFO: 	Container metrics-server ready: true, restart count 0
Apr 27 17:05:16.315: INFO: dashboard-metrics-scraper-76c7b697bc-l2z4c from kubernetes-dashboard started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 17:05:16.315: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 27 17:05:16.315: INFO: coredns-5cb857d789-s8ws2 from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 17:05:16.315: INFO: 	Container coredns ready: true, restart count 0
Apr 27 17:05:16.315: INFO: calico-typha-deploy-784665cc66-9ngtv from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 17:05:16.315: INFO: 	Container calico-typha ready: true, restart count 0
Apr 27 17:05:16.315: INFO: kubernetes-dashboard-6b586c4cb4-9c2rc from kubernetes-dashboard started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 17:05:16.315: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
Apr 27 17:05:16.315: INFO: blackbox-exporter-5dc75b79b7-7xcjk from kube-system started at 2020-04-27 16:07:11 +0000 UTC (1 container statuses recorded)
Apr 27 17:05:16.315: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 27 17:05:16.315: INFO: kube-proxy-h2cx7 from kube-system started at 2020-04-27 16:07:11 +0000 UTC (1 container statuses recorded)
Apr 27 17:05:16.315: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 17:05:16.315: INFO: node-problem-detector-tq7hl from kube-system started at 2020-04-27 16:07:11 +0000 UTC (1 container statuses recorded)
Apr 27 17:05:16.315: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 17:05:16.315: INFO: vpn-shoot-5b5f49b4bf-trqr9 from kube-system started at 2020-04-27 16:07:31 +0000 UTC (1 container statuses recorded)
Apr 27 17:05:16.315: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 27 17:05:16.315: INFO: calico-typha-vertical-autoscaler-5b477c88cf-k2f8l from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 17:05:16.315: INFO: 	Container autoscaler ready: true, restart count 6
Apr 27 17:05:16.315: INFO: calico-typha-horizontal-autoscaler-6fdd5d8746-hv92s from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 17:05:16.315: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 17:05:16.315: INFO: addons-nginx-ingress-controller-6cf77756b5-rw99m from kube-system started at 2020-04-27 16:07:33 +0000 UTC (1 container statuses recorded)
Apr 27 17:05:16.315: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 27 17:05:16.315: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-q52mz from kube-system started at 2020-04-27 16:07:41 +0000 UTC (1 container statuses recorded)
Apr 27 17:05:16.315: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr 27 17:05:16.315: INFO: calico-kube-controllers-77dcb8f688-7jxx4 from kube-system started at 2020-04-27 16:07:33 +0000 UTC (1 container statuses recorded)
Apr 27 17:05:16.315: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 27 17:05:16.315: INFO: calico-node-xphhz from kube-system started at 2020-04-27 16:15:29 +0000 UTC (1 container statuses recorded)
Apr 27 17:05:16.315: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 17:05:16.315: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 before test
Apr 27 17:05:16.387: INFO: calico-node-ld4x7 from kube-system started at 2020-04-27 16:15:20 +0000 UTC (1 container statuses recorded)
Apr 27 17:05:16.387: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 17:05:16.387: INFO: node-exporter-srfgn from kube-system started at 2020-04-27 16:07:18 +0000 UTC (1 container statuses recorded)
Apr 27 17:05:16.387: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 17:05:16.387: INFO: node-problem-detector-9thlx from kube-system started at 2020-04-27 16:07:18 +0000 UTC (1 container statuses recorded)
Apr 27 17:05:16.387: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 17:05:16.387: INFO: kube-proxy-jm5m6 from kube-system started at 2020-04-27 16:07:18 +0000 UTC (1 container statuses recorded)
Apr 27 17:05:16.387: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-1da030db-b3be-4d25-9bef-0f72a3593a9a 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-1da030db-b3be-4d25-9bef-0f72a3593a9a off the node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9
STEP: verifying the node doesn't have the label kubernetes.io/e2e-1da030db-b3be-4d25-9bef-0f72a3593a9a
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:24.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1488" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]","total":277,"completed":156,"skipped":2462,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:24.487: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4910
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 27 17:05:24.666: INFO: Number of nodes with available pods: 0
Apr 27 17:05:24.666: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 17:05:25.676: INFO: Number of nodes with available pods: 0
Apr 27 17:05:25.676: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 17:05:26.676: INFO: Number of nodes with available pods: 2
Apr 27 17:05:26.676: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Apr 27 17:05:26.695: INFO: Number of nodes with available pods: 1
Apr 27 17:05:26.695: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 17:05:27.705: INFO: Number of nodes with available pods: 1
Apr 27 17:05:27.705: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 17:05:28.705: INFO: Number of nodes with available pods: 1
Apr 27 17:05:28.705: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 17:05:29.703: INFO: Number of nodes with available pods: 1
Apr 27 17:05:29.703: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 17:05:30.704: INFO: Number of nodes with available pods: 1
Apr 27 17:05:30.704: INFO: Node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp is running more than one daemon pod
Apr 27 17:05:31.771: INFO: Number of nodes with available pods: 2
Apr 27 17:05:31.771: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4910, will wait for the garbage collector to delete the pods
Apr 27 17:05:31.836: INFO: Deleting DaemonSet.extensions daemon-set took: 5.181609ms
Apr 27 17:05:32.336: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.254216ms
Apr 27 17:05:45.039: INFO: Number of nodes with available pods: 0
Apr 27 17:05:45.039: INFO: Number of running nodes: 0, number of available pods: 0
Apr 27 17:05:45.042: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4910/daemonsets","resourceVersion":"28250"},"items":null}

Apr 27 17:05:45.045: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4910/pods","resourceVersion":"28250"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:45.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4910" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":277,"completed":157,"skipped":2477,"failed":0}
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:45.066: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8676
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Apr 27 17:06:25.254: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0427 17:06:25.254703    5439 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:06:25.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8676" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":277,"completed":158,"skipped":2481,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:06:25.264: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-8797
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:06:25.417: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating first CR 
Apr 27 17:06:25.987: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T17:06:25Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T17:06:25Z]] name:name1 resourceVersion:28507 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:7b82426a-3199-4716-b131-422fc7da4200] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Apr 27 17:06:35.994: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T17:06:35Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T17:06:35Z]] name:name2 resourceVersion:28592 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:3bf6a78b-abca-4709-84ab-1c487e1e0d40] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Apr 27 17:06:46.001: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T17:06:25Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T17:06:45Z]] name:name1 resourceVersion:28631 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:7b82426a-3199-4716-b131-422fc7da4200] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Apr 27 17:06:56.008: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T17:06:35Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T17:06:56Z]] name:name2 resourceVersion:28670 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:3bf6a78b-abca-4709-84ab-1c487e1e0d40] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Apr 27 17:07:06.017: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T17:06:25Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T17:06:45Z]] name:name1 resourceVersion:28708 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:7b82426a-3199-4716-b131-422fc7da4200] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Apr 27 17:07:16.025: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T17:06:35Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T17:06:56Z]] name:name2 resourceVersion:28747 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:3bf6a78b-abca-4709-84ab-1c487e1e0d40] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:07:26.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-8797" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":277,"completed":159,"skipped":2489,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:07:26.547: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-4335
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:07:26.790: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:07:33.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4335" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":277,"completed":160,"skipped":2518,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:07:33.286: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7812
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Apr 27 17:07:33.602: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Apr 27 17:07:50.865: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 17:07:54.461: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:08:08.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7812" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":277,"completed":161,"skipped":2525,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:08:08.511: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8064
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-2e72b6d8-ce37-4631-a5cf-1f783151fa80
STEP: Creating a pod to test consume secrets
Apr 27 17:08:08.676: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-846e0934-2dc6-400e-ae8d-9913f0cd4bb5" in namespace "projected-8064" to be "Succeeded or Failed"
Apr 27 17:08:08.680: INFO: Pod "pod-projected-secrets-846e0934-2dc6-400e-ae8d-9913f0cd4bb5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.202643ms
Apr 27 17:08:10.684: INFO: Pod "pod-projected-secrets-846e0934-2dc6-400e-ae8d-9913f0cd4bb5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007497999s
STEP: Saw pod success
Apr 27 17:08:10.684: INFO: Pod "pod-projected-secrets-846e0934-2dc6-400e-ae8d-9913f0cd4bb5" satisfied condition "Succeeded or Failed"
Apr 27 17:08:10.688: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-projected-secrets-846e0934-2dc6-400e-ae8d-9913f0cd4bb5 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:08:10.799: INFO: Waiting for pod pod-projected-secrets-846e0934-2dc6-400e-ae8d-9913f0cd4bb5 to disappear
Apr 27 17:08:10.802: INFO: Pod pod-projected-secrets-846e0934-2dc6-400e-ae8d-9913f0cd4bb5 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:08:10.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8064" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":162,"skipped":2579,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:08:10.812: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-5798
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Apr 27 17:08:10.956: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:08:14.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5798" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":277,"completed":163,"skipped":2620,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:08:14.760: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6462
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:08:14.924: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"2658a4cb-44da-4195-9ccb-6b601a0c2bc5", Controller:(*bool)(0xc004a05e4a), BlockOwnerDeletion:(*bool)(0xc004a05e4b)}}
Apr 27 17:08:14.928: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"833bf822-dc68-4dab-a892-e57dd4ba5846", Controller:(*bool)(0xc0049e0096), BlockOwnerDeletion:(*bool)(0xc0049e0097)}}
Apr 27 17:08:14.933: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"89f70f0b-8792-4958-ac7d-4ce4a76e7b81", Controller:(*bool)(0xc0049e02b6), BlockOwnerDeletion:(*bool)(0xc0049e02b7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:08:19.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6462" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":277,"completed":164,"skipped":2635,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:08:19.951: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7831
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Apr 27 17:08:22.637: INFO: Successfully updated pod "labelsupdate6778e542-a12d-486b-9776-149ed5d8d277"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:08:24.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7831" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":277,"completed":165,"skipped":2658,"failed":0}

------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:08:24.669: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3902
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating cluster-info
Apr 27 17:08:24.813: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config cluster-info'
Apr 27 17:08:25.117: INFO: stderr: ""
Apr 27 17:08:25.117: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:08:25.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3902" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]","total":277,"completed":166,"skipped":2658,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:08:25.127: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8855
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 27 17:08:27.480: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:08:27.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8855" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":277,"completed":167,"skipped":2715,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:08:27.502: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-4068
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:08:27.948: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:08:30.969: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:08:30.974: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:08:32.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-4068" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137
•{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":277,"completed":168,"skipped":2718,"failed":0}
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:08:32.415: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6212
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-6a1e1517-663e-4579-8208-2f505379282f in namespace container-probe-6212
Apr 27 17:08:34.686: INFO: Started pod busybox-6a1e1517-663e-4579-8208-2f505379282f in namespace container-probe-6212
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 17:08:34.690: INFO: Initial restart count of pod busybox-6a1e1517-663e-4579-8208-2f505379282f is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:12:35.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6212" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":277,"completed":169,"skipped":2719,"failed":0}
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:12:35.260: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3908
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-aeb7383e-aca9-4b62-84ee-36e88843251a
STEP: Creating a pod to test consume configMaps
Apr 27 17:12:35.416: INFO: Waiting up to 5m0s for pod "pod-configmaps-7d41c933-fd6f-4876-bd02-bad08ce30af8" in namespace "configmap-3908" to be "Succeeded or Failed"
Apr 27 17:12:35.419: INFO: Pod "pod-configmaps-7d41c933-fd6f-4876-bd02-bad08ce30af8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.759605ms
Apr 27 17:12:37.422: INFO: Pod "pod-configmaps-7d41c933-fd6f-4876-bd02-bad08ce30af8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006243881s
STEP: Saw pod success
Apr 27 17:12:37.422: INFO: Pod "pod-configmaps-7d41c933-fd6f-4876-bd02-bad08ce30af8" satisfied condition "Succeeded or Failed"
Apr 27 17:12:37.426: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-configmaps-7d41c933-fd6f-4876-bd02-bad08ce30af8 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 17:12:37.540: INFO: Waiting for pod pod-configmaps-7d41c933-fd6f-4876-bd02-bad08ce30af8 to disappear
Apr 27 17:12:37.543: INFO: Pod pod-configmaps-7d41c933-fd6f-4876-bd02-bad08ce30af8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:12:37.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3908" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":170,"skipped":2720,"failed":0}

------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:12:37.552: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5307
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-5982b488-3edb-4dec-9c68-a986eddee73e
STEP: Creating a pod to test consume secrets
Apr 27 17:12:37.711: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4e03bccb-f9ad-473a-9550-298e49c8e7ff" in namespace "projected-5307" to be "Succeeded or Failed"
Apr 27 17:12:37.714: INFO: Pod "pod-projected-secrets-4e03bccb-f9ad-473a-9550-298e49c8e7ff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.695735ms
Apr 27 17:12:39.718: INFO: Pod "pod-projected-secrets-4e03bccb-f9ad-473a-9550-298e49c8e7ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007243164s
STEP: Saw pod success
Apr 27 17:12:39.718: INFO: Pod "pod-projected-secrets-4e03bccb-f9ad-473a-9550-298e49c8e7ff" satisfied condition "Succeeded or Failed"
Apr 27 17:12:39.721: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-projected-secrets-4e03bccb-f9ad-473a-9550-298e49c8e7ff container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:12:39.738: INFO: Waiting for pod pod-projected-secrets-4e03bccb-f9ad-473a-9550-298e49c8e7ff to disappear
Apr 27 17:12:39.741: INFO: Pod pod-projected-secrets-4e03bccb-f9ad-473a-9550-298e49c8e7ff no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:12:39.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5307" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":171,"skipped":2720,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:12:39.750: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9698
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:12:40.483: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:12:43.504: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:12:43.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9698" for this suite.
STEP: Destroying namespace "webhook-9698-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":277,"completed":172,"skipped":2727,"failed":0}

------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:12:43.726: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8035
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-4ec6b99c-26cf-40c8-8234-303a1d7dc03c
STEP: Creating a pod to test consume secrets
Apr 27 17:12:43.882: INFO: Waiting up to 5m0s for pod "pod-secrets-5cd150b6-c49b-45b6-a332-a0f36c39a62a" in namespace "secrets-8035" to be "Succeeded or Failed"
Apr 27 17:12:43.885: INFO: Pod "pod-secrets-5cd150b6-c49b-45b6-a332-a0f36c39a62a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.684489ms
Apr 27 17:12:45.889: INFO: Pod "pod-secrets-5cd150b6-c49b-45b6-a332-a0f36c39a62a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006913925s
Apr 27 17:12:47.893: INFO: Pod "pod-secrets-5cd150b6-c49b-45b6-a332-a0f36c39a62a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011162035s
STEP: Saw pod success
Apr 27 17:12:47.893: INFO: Pod "pod-secrets-5cd150b6-c49b-45b6-a332-a0f36c39a62a" satisfied condition "Succeeded or Failed"
Apr 27 17:12:47.896: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-secrets-5cd150b6-c49b-45b6-a332-a0f36c39a62a container secret-env-test: <nil>
STEP: delete the pod
Apr 27 17:12:47.914: INFO: Waiting for pod pod-secrets-5cd150b6-c49b-45b6-a332-a0f36c39a62a to disappear
Apr 27 17:12:47.917: INFO: Pod pod-secrets-5cd150b6-c49b-45b6-a332-a0f36c39a62a no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:12:47.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8035" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":277,"completed":173,"skipped":2727,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:12:47.927: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4424
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:12:48.074: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Apr 27 17:12:51.716: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4424 create -f -'
Apr 27 17:12:52.041: INFO: stderr: ""
Apr 27 17:12:52.041: INFO: stdout: "e2e-test-crd-publish-openapi-7689-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 27 17:12:52.041: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4424 delete e2e-test-crd-publish-openapi-7689-crds test-foo'
Apr 27 17:12:52.117: INFO: stderr: ""
Apr 27 17:12:52.117: INFO: stdout: "e2e-test-crd-publish-openapi-7689-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Apr 27 17:12:52.117: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4424 apply -f -'
Apr 27 17:12:52.371: INFO: stderr: ""
Apr 27 17:12:52.371: INFO: stdout: "e2e-test-crd-publish-openapi-7689-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 27 17:12:52.371: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4424 delete e2e-test-crd-publish-openapi-7689-crds test-foo'
Apr 27 17:12:52.463: INFO: stderr: ""
Apr 27 17:12:52.463: INFO: stdout: "e2e-test-crd-publish-openapi-7689-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Apr 27 17:12:52.463: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4424 create -f -'
Apr 27 17:12:52.671: INFO: rc: 1
Apr 27 17:12:52.672: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4424 apply -f -'
Apr 27 17:12:52.811: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Apr 27 17:12:52.811: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4424 create -f -'
Apr 27 17:12:53.065: INFO: rc: 1
Apr 27 17:12:53.065: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4424 apply -f -'
Apr 27 17:12:53.280: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Apr 27 17:12:53.280: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-7689-crds'
Apr 27 17:12:53.555: INFO: stderr: ""
Apr 27 17:12:53.555: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7689-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Apr 27 17:12:53.555: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-7689-crds.metadata'
Apr 27 17:12:53.708: INFO: stderr: ""
Apr 27 17:12:53.708: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7689-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Apr 27 17:12:53.709: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-7689-crds.spec'
Apr 27 17:12:53.848: INFO: stderr: ""
Apr 27 17:12:53.848: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7689-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Apr 27 17:12:53.848: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-7689-crds.spec.bars'
Apr 27 17:12:53.998: INFO: stderr: ""
Apr 27 17:12:53.998: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7689-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Apr 27 17:12:53.999: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-7689-crds.spec.bars2'
Apr 27 17:12:54.221: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:12:57.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4424" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":277,"completed":174,"skipped":2736,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:12:57.845: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6348
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Apr 27 17:12:59.038: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0427 17:12:59.038506    5439 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:12:59.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6348" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":277,"completed":175,"skipped":2749,"failed":0}
SS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:12:59.047: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1448
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:12:59.193: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:13:03.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1448" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":277,"completed":176,"skipped":2751,"failed":0}
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:13:03.358: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6293
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:13:03.510: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr 27 17:13:08.520: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 27 17:13:08.520: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Apr 27 17:13:08.538: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-6293 /apis/apps/v1/namespaces/deployment-6293/deployments/test-cleanup-deployment ec56d50b-896c-4791-8afc-2494ef262c5e 30730 1 2020-04-27 17:13:08 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  [{e2e.test Update apps/v1 2020-04-27 17:13:08 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005e217f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Apr 27 17:13:08.542: INFO: New ReplicaSet "test-cleanup-deployment-b4867b47f" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-b4867b47f  deployment-6293 /apis/apps/v1/namespaces/deployment-6293/replicasets/test-cleanup-deployment-b4867b47f d3aeb51d-bf24-4486-9f00-d57014ec15a2 30732 1 2020-04-27 17:13:08 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment ec56d50b-896c-4791-8afc-2494ef262c5e 0xc000f021d0 0xc000f021d1}] []  [{kube-controller-manager Update apps/v1 2020-04-27 17:13:08 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 99 53 54 100 53 48 98 45 56 57 54 99 45 52 55 57 49 45 56 97 102 99 45 50 52 57 52 101 102 50 54 50 99 53 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: b4867b47f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000f022b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 17:13:08.542: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Apr 27 17:13:08.542: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-6293 /apis/apps/v1/namespaces/deployment-6293/replicasets/test-cleanup-controller b6f632a9-b178-43f3-a1c9-a5426b01c2de 30731 1 2020-04-27 17:13:03 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment ec56d50b-896c-4791-8afc-2494ef262c5e 0xc005e21f47 0xc005e21f48}] []  [{e2e.test Update apps/v1 2020-04-27 17:13:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 17:13:08 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 99 53 54 100 53 48 98 45 56 57 54 99 45 52 55 57 49 45 56 97 102 99 45 50 52 57 52 101 102 50 54 50 99 53 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc000f02138 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 27 17:13:08.546: INFO: Pod "test-cleanup-controller-nlkvb" is available:
&Pod{ObjectMeta:{test-cleanup-controller-nlkvb test-cleanup-controller- deployment-6293 /api/v1/namespaces/deployment-6293/pods/test-cleanup-controller-nlkvb d275828b-54f0-43be-855f-f59491426b62 30711 0 2020-04-27 17:13:03 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/podIP:100.64.1.228/32 cni.projectcalico.org/podIPs:100.64.1.228/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-cleanup-controller b6f632a9-b178-43f3-a1c9-a5426b01c2de 0xc003d000b7 0xc003d000b8}] []  [{kube-controller-manager Update v1 2020-04-27 17:13:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 98 54 102 54 51 50 97 57 45 98 49 55 56 45 52 51 102 51 45 97 49 99 57 45 97 53 52 50 54 98 48 49 99 50 100 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:13:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:13:05 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 50 50 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-p4d2z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-p4d2z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-p4d2z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:13:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:13:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:13:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:13:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.21,PodIP:100.64.1.228,StartTime:2020-04-27 17:13:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:13:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://5c9227bbf848693b84a05a8db2796f9489937e000ce51c253161cc88fa636ce3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.228,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:13:08.546: INFO: Pod "test-cleanup-deployment-b4867b47f-zzttx" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-b4867b47f-zzttx test-cleanup-deployment-b4867b47f- deployment-6293 /api/v1/namespaces/deployment-6293/pods/test-cleanup-deployment-b4867b47f-zzttx a40a54e3-1635-45cf-ac1a-5b8f34f74646 30733 0 2020-04-27 17:13:08 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-cleanup-deployment-b4867b47f d3aeb51d-bf24-4486-9f00-d57014ec15a2 0xc003d002f0 0xc003d002f1}] []  [{kube-controller-manager Update v1 2020-04-27 17:13:08 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 51 97 101 98 53 49 100 45 98 102 50 52 45 52 52 56 54 45 57 102 48 48 45 100 53 55 48 49 52 101 99 49 53 97 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-p4d2z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-p4d2z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-p4d2z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:13:08.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6293" for this suite.
•{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":277,"completed":177,"skipped":2758,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:13:08.556: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-3737
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:13:08.766: INFO: Waiting up to 5m0s for pod "busybox-user-65534-18fe299a-52bf-44cd-b58d-8c0d1fb1a3c9" in namespace "security-context-test-3737" to be "Succeeded or Failed"
Apr 27 17:13:08.769: INFO: Pod "busybox-user-65534-18fe299a-52bf-44cd-b58d-8c0d1fb1a3c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.820782ms
Apr 27 17:13:10.773: INFO: Pod "busybox-user-65534-18fe299a-52bf-44cd-b58d-8c0d1fb1a3c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00683912s
Apr 27 17:13:10.773: INFO: Pod "busybox-user-65534-18fe299a-52bf-44cd-b58d-8c0d1fb1a3c9" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:13:10.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3737" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":178,"skipped":2790,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:13:10.782: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1282
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Apr 27 17:13:10.926: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 17:13:14.538: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:13:28.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1282" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":277,"completed":179,"skipped":2852,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:13:28.693: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5513
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Apr 27 17:13:31.379: INFO: Successfully updated pod "labelsupdate383f9a97-1c1a-4369-a28d-a8ada0a2ef67"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:13:35.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5513" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":277,"completed":180,"skipped":2865,"failed":0}
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:13:35.422: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1522
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 27 17:13:37.588: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:13:37.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1522" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":181,"skipped":2878,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:13:37.610: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7102
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-3bff38c7-1077-44f7-85e2-8619509eff36
STEP: Creating a pod to test consume configMaps
Apr 27 17:13:37.768: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ee93db69-c6bf-40db-98e1-705fb1a58c78" in namespace "projected-7102" to be "Succeeded or Failed"
Apr 27 17:13:37.771: INFO: Pod "pod-projected-configmaps-ee93db69-c6bf-40db-98e1-705fb1a58c78": Phase="Pending", Reason="", readiness=false. Elapsed: 2.627264ms
Apr 27 17:13:39.775: INFO: Pod "pod-projected-configmaps-ee93db69-c6bf-40db-98e1-705fb1a58c78": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00677067s
STEP: Saw pod success
Apr 27 17:13:39.775: INFO: Pod "pod-projected-configmaps-ee93db69-c6bf-40db-98e1-705fb1a58c78" satisfied condition "Succeeded or Failed"
Apr 27 17:13:39.778: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-projected-configmaps-ee93db69-c6bf-40db-98e1-705fb1a58c78 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 17:13:39.795: INFO: Waiting for pod pod-projected-configmaps-ee93db69-c6bf-40db-98e1-705fb1a58c78 to disappear
Apr 27 17:13:39.797: INFO: Pod pod-projected-configmaps-ee93db69-c6bf-40db-98e1-705fb1a58c78 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:13:39.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7102" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":182,"skipped":2907,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:13:39.807: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8189
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:13:50.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8189" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":277,"completed":183,"skipped":2917,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:13:51.003: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7807
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 27 17:13:53.684: INFO: Successfully updated pod "pod-update-50ec48a3-331c-4aa8-8369-599deb800e12"
STEP: verifying the updated pod is in kubernetes
Apr 27 17:13:53.690: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:13:53.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7807" for this suite.
•{"msg":"PASSED [k8s.io] Pods should be updated [NodeConformance] [Conformance]","total":277,"completed":184,"skipped":2935,"failed":0}
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:13:53.699: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5890
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-c68b96f0-a312-40aa-b496-b2acd1b12ccc
STEP: Creating a pod to test consume secrets
Apr 27 17:13:53.853: INFO: Waiting up to 5m0s for pod "pod-secrets-122c76ee-5533-42c5-8695-be52253f55c3" in namespace "secrets-5890" to be "Succeeded or Failed"
Apr 27 17:13:53.856: INFO: Pod "pod-secrets-122c76ee-5533-42c5-8695-be52253f55c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.658377ms
Apr 27 17:13:55.860: INFO: Pod "pod-secrets-122c76ee-5533-42c5-8695-be52253f55c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007181758s
STEP: Saw pod success
Apr 27 17:13:55.860: INFO: Pod "pod-secrets-122c76ee-5533-42c5-8695-be52253f55c3" satisfied condition "Succeeded or Failed"
Apr 27 17:13:55.863: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-secrets-122c76ee-5533-42c5-8695-be52253f55c3 container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:13:55.882: INFO: Waiting for pod pod-secrets-122c76ee-5533-42c5-8695-be52253f55c3 to disappear
Apr 27 17:13:55.885: INFO: Pod pod-secrets-122c76ee-5533-42c5-8695-be52253f55c3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:13:55.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5890" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":277,"completed":185,"skipped":2938,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:13:55.894: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-3115
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:13:56.046: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-f2d93b93-4f4e-4c26-b37d-6c23fa9426fc" in namespace "security-context-test-3115" to be "Succeeded or Failed"
Apr 27 17:13:56.049: INFO: Pod "alpine-nnp-false-f2d93b93-4f4e-4c26-b37d-6c23fa9426fc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.0661ms
Apr 27 17:13:58.053: INFO: Pod "alpine-nnp-false-f2d93b93-4f4e-4c26-b37d-6c23fa9426fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007282375s
Apr 27 17:14:00.057: INFO: Pod "alpine-nnp-false-f2d93b93-4f4e-4c26-b37d-6c23fa9426fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0114138s
Apr 27 17:14:00.057: INFO: Pod "alpine-nnp-false-f2d93b93-4f4e-4c26-b37d-6c23fa9426fc" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:00.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3115" for this suite.
•{"msg":"PASSED [k8s.io] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":186,"skipped":2946,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:00.076: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5796
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Starting the proxy
Apr 27 17:14:00.221: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy --unix-socket=/tmp/kubectl-proxy-unix478760226/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:00.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5796" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":277,"completed":187,"skipped":2972,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:00.282: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3099
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:02.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3099" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":188,"skipped":2993,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:02.469: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9300
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:14:03.082: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 27 17:14:05.093: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604443, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604443, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604443, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604443, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:14:08.109: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:08.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9300" for this suite.
STEP: Destroying namespace "webhook-9300-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":277,"completed":189,"skipped":3032,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:08.307: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8276
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:14:12.488: INFO: Waiting up to 5m0s for pod "client-envvars-1b45cf7a-8d7e-4f66-b7d2-6e7c3678f874" in namespace "pods-8276" to be "Succeeded or Failed"
Apr 27 17:14:12.491: INFO: Pod "client-envvars-1b45cf7a-8d7e-4f66-b7d2-6e7c3678f874": Phase="Pending", Reason="", readiness=false. Elapsed: 2.788536ms
Apr 27 17:14:14.499: INFO: Pod "client-envvars-1b45cf7a-8d7e-4f66-b7d2-6e7c3678f874": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010175716s
STEP: Saw pod success
Apr 27 17:14:14.499: INFO: Pod "client-envvars-1b45cf7a-8d7e-4f66-b7d2-6e7c3678f874" satisfied condition "Succeeded or Failed"
Apr 27 17:14:14.502: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod client-envvars-1b45cf7a-8d7e-4f66-b7d2-6e7c3678f874 container env3cont: <nil>
STEP: delete the pod
Apr 27 17:14:14.520: INFO: Waiting for pod client-envvars-1b45cf7a-8d7e-4f66-b7d2-6e7c3678f874 to disappear
Apr 27 17:14:14.524: INFO: Pod client-envvars-1b45cf7a-8d7e-4f66-b7d2-6e7c3678f874 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:14.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8276" for this suite.
•{"msg":"PASSED [k8s.io] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":277,"completed":190,"skipped":3058,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:14.534: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-1407
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test hostPath mode
Apr 27 17:14:14.687: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-1407" to be "Succeeded or Failed"
Apr 27 17:14:14.689: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.780178ms
Apr 27 17:14:16.693: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006351408s
Apr 27 17:14:18.698: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011090342s
STEP: Saw pod success
Apr 27 17:14:18.698: INFO: Pod "pod-host-path-test" satisfied condition "Succeeded or Failed"
Apr 27 17:14:18.701: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Apr 27 17:14:18.719: INFO: Waiting for pod pod-host-path-test to disappear
Apr 27 17:14:18.722: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:18.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-1407" for this suite.
•{"msg":"PASSED [sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":191,"skipped":3112,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should patch a secret [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:18.732: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7369
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a secret [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:18.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7369" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should patch a secret [Conformance]","total":277,"completed":192,"skipped":3175,"failed":0}
SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:18.917: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5222
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service multi-endpoint-test in namespace services-5222
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5222 to expose endpoints map[]
Apr 27 17:14:19.087: INFO: successfully validated that service multi-endpoint-test in namespace services-5222 exposes endpoints map[] (8.217364ms elapsed)
STEP: Creating pod pod1 in namespace services-5222
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5222 to expose endpoints map[pod1:[100]]
Apr 27 17:14:21.119: INFO: successfully validated that service multi-endpoint-test in namespace services-5222 exposes endpoints map[pod1:[100]] (2.023075377s elapsed)
STEP: Creating pod pod2 in namespace services-5222
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5222 to expose endpoints map[pod1:[100] pod2:[101]]
Apr 27 17:14:23.153: INFO: successfully validated that service multi-endpoint-test in namespace services-5222 exposes endpoints map[pod1:[100] pod2:[101]] (2.029023859s elapsed)
STEP: Deleting pod pod1 in namespace services-5222
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5222 to expose endpoints map[pod2:[101]]
Apr 27 17:14:24.172: INFO: successfully validated that service multi-endpoint-test in namespace services-5222 exposes endpoints map[pod2:[101]] (1.013262895s elapsed)
STEP: Deleting pod pod2 in namespace services-5222
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5222 to expose endpoints map[]
Apr 27 17:14:25.185: INFO: successfully validated that service multi-endpoint-test in namespace services-5222 exposes endpoints map[] (1.007443553s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:25.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5222" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":277,"completed":193,"skipped":3177,"failed":0}
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:25.211: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7203
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-546e66c6-4d44-4582-9697-c8dab3e99eb0
STEP: Creating a pod to test consume configMaps
Apr 27 17:14:25.368: INFO: Waiting up to 5m0s for pod "pod-configmaps-974f47bd-fa85-489a-87a8-b0994cb0b6ed" in namespace "configmap-7203" to be "Succeeded or Failed"
Apr 27 17:14:25.370: INFO: Pod "pod-configmaps-974f47bd-fa85-489a-87a8-b0994cb0b6ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.564175ms
Apr 27 17:14:27.375: INFO: Pod "pod-configmaps-974f47bd-fa85-489a-87a8-b0994cb0b6ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006820832s
STEP: Saw pod success
Apr 27 17:14:27.375: INFO: Pod "pod-configmaps-974f47bd-fa85-489a-87a8-b0994cb0b6ed" satisfied condition "Succeeded or Failed"
Apr 27 17:14:27.377: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-configmaps-974f47bd-fa85-489a-87a8-b0994cb0b6ed container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 17:14:27.394: INFO: Waiting for pod pod-configmaps-974f47bd-fa85-489a-87a8-b0994cb0b6ed to disappear
Apr 27 17:14:27.397: INFO: Pod pod-configmaps-974f47bd-fa85-489a-87a8-b0994cb0b6ed no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:27.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7203" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":194,"skipped":3182,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:27.407: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7094
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-e8f88fcf-6478-4bf8-ab56-d250abb39d57
STEP: Creating a pod to test consume configMaps
Apr 27 17:14:27.562: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6340163b-0ded-4e1d-83cf-2b992eee23e6" in namespace "projected-7094" to be "Succeeded or Failed"
Apr 27 17:14:27.564: INFO: Pod "pod-projected-configmaps-6340163b-0ded-4e1d-83cf-2b992eee23e6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.695179ms
Apr 27 17:14:29.569: INFO: Pod "pod-projected-configmaps-6340163b-0ded-4e1d-83cf-2b992eee23e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006831466s
STEP: Saw pod success
Apr 27 17:14:29.569: INFO: Pod "pod-projected-configmaps-6340163b-0ded-4e1d-83cf-2b992eee23e6" satisfied condition "Succeeded or Failed"
Apr 27 17:14:29.572: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-projected-configmaps-6340163b-0ded-4e1d-83cf-2b992eee23e6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 17:14:29.589: INFO: Waiting for pod pod-projected-configmaps-6340163b-0ded-4e1d-83cf-2b992eee23e6 to disappear
Apr 27 17:14:29.591: INFO: Pod pod-projected-configmaps-6340163b-0ded-4e1d-83cf-2b992eee23e6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:29.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7094" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":277,"completed":195,"skipped":3203,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:29.601: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9129
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting the proxy server
Apr 27 17:14:29.745: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:29.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9129" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":277,"completed":196,"skipped":3206,"failed":0}
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:29.843: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9573
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl label
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1206
STEP: creating the pod
Apr 27 17:14:29.989: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-9573'
Apr 27 17:14:30.223: INFO: stderr: ""
Apr 27 17:14:30.223: INFO: stdout: "pod/pause created\n"
Apr 27 17:14:30.223: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr 27 17:14:30.223: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9573" to be "running and ready"
Apr 27 17:14:30.227: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.837372ms
Apr 27 17:14:32.231: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.007977652s
Apr 27 17:14:32.231: INFO: Pod "pause" satisfied condition "running and ready"
Apr 27 17:14:32.231: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: adding the label testing-label with value testing-label-value to a pod
Apr 27 17:14:32.231: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config label pods pause testing-label=testing-label-value --namespace=kubectl-9573'
Apr 27 17:14:32.311: INFO: stderr: ""
Apr 27 17:14:32.311: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Apr 27 17:14:32.311: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod pause -L testing-label --namespace=kubectl-9573'
Apr 27 17:14:32.389: INFO: stderr: ""
Apr 27 17:14:32.389: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Apr 27 17:14:32.389: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config label pods pause testing-label- --namespace=kubectl-9573'
Apr 27 17:14:32.473: INFO: stderr: ""
Apr 27 17:14:32.474: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Apr 27 17:14:32.474: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod pause -L testing-label --namespace=kubectl-9573'
Apr 27 17:14:32.540: INFO: stderr: ""
Apr 27 17:14:32.540: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1213
STEP: using delete to clean up resources
Apr 27 17:14:32.540: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-9573'
Apr 27 17:14:32.618: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 17:14:32.618: INFO: stdout: "pod \"pause\" force deleted\n"
Apr 27 17:14:32.618: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=pause --no-headers --namespace=kubectl-9573'
Apr 27 17:14:32.710: INFO: stderr: "No resources found in kubectl-9573 namespace.\n"
Apr 27 17:14:32.710: INFO: stdout: ""
Apr 27 17:14:32.710: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=pause --namespace=kubectl-9573 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 27 17:14:32.793: INFO: stderr: ""
Apr 27 17:14:32.793: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:32.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9573" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":277,"completed":197,"skipped":3211,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:32.803: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1903
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 27 17:14:32.954: INFO: Waiting up to 5m0s for pod "pod-82df1dc2-57f1-42b6-a301-64fabed2d90e" in namespace "emptydir-1903" to be "Succeeded or Failed"
Apr 27 17:14:32.957: INFO: Pod "pod-82df1dc2-57f1-42b6-a301-64fabed2d90e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.737164ms
Apr 27 17:14:34.965: INFO: Pod "pod-82df1dc2-57f1-42b6-a301-64fabed2d90e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010590899s
STEP: Saw pod success
Apr 27 17:14:34.965: INFO: Pod "pod-82df1dc2-57f1-42b6-a301-64fabed2d90e" satisfied condition "Succeeded or Failed"
Apr 27 17:14:34.968: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-82df1dc2-57f1-42b6-a301-64fabed2d90e container test-container: <nil>
STEP: delete the pod
Apr 27 17:14:34.985: INFO: Waiting for pod pod-82df1dc2-57f1-42b6-a301-64fabed2d90e to disappear
Apr 27 17:14:34.988: INFO: Pod pod-82df1dc2-57f1-42b6-a301-64fabed2d90e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:34.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1903" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":198,"skipped":3237,"failed":0}
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:34.997: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2453
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-1a1a763a-fa40-468c-8bfa-0a1053f7b084
STEP: Creating a pod to test consume secrets
Apr 27 17:14:35.204: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-04f44701-e5e1-4b1a-a650-ac87cfa014c9" in namespace "projected-2453" to be "Succeeded or Failed"
Apr 27 17:14:35.206: INFO: Pod "pod-projected-secrets-04f44701-e5e1-4b1a-a650-ac87cfa014c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.903426ms
Apr 27 17:14:37.211: INFO: Pod "pod-projected-secrets-04f44701-e5e1-4b1a-a650-ac87cfa014c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007008357s
Apr 27 17:14:39.215: INFO: Pod "pod-projected-secrets-04f44701-e5e1-4b1a-a650-ac87cfa014c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011689008s
STEP: Saw pod success
Apr 27 17:14:39.215: INFO: Pod "pod-projected-secrets-04f44701-e5e1-4b1a-a650-ac87cfa014c9" satisfied condition "Succeeded or Failed"
Apr 27 17:14:39.219: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-projected-secrets-04f44701-e5e1-4b1a-a650-ac87cfa014c9 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:14:39.236: INFO: Waiting for pod pod-projected-secrets-04f44701-e5e1-4b1a-a650-ac87cfa014c9 to disappear
Apr 27 17:14:39.239: INFO: Pod pod-projected-secrets-04f44701-e5e1-4b1a-a650-ac87cfa014c9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:39.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2453" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":199,"skipped":3238,"failed":0}
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:39.249: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9820
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-9b1bda62-51da-45c7-a2b7-d1714496e470
STEP: Creating a pod to test consume configMaps
Apr 27 17:14:39.407: INFO: Waiting up to 5m0s for pod "pod-configmaps-02c36dbe-6754-420b-bb67-fbcc17eddf00" in namespace "configmap-9820" to be "Succeeded or Failed"
Apr 27 17:14:39.410: INFO: Pod "pod-configmaps-02c36dbe-6754-420b-bb67-fbcc17eddf00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.520203ms
Apr 27 17:14:41.414: INFO: Pod "pod-configmaps-02c36dbe-6754-420b-bb67-fbcc17eddf00": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006634132s
STEP: Saw pod success
Apr 27 17:14:41.414: INFO: Pod "pod-configmaps-02c36dbe-6754-420b-bb67-fbcc17eddf00" satisfied condition "Succeeded or Failed"
Apr 27 17:14:41.417: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-configmaps-02c36dbe-6754-420b-bb67-fbcc17eddf00 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 17:14:41.434: INFO: Waiting for pod pod-configmaps-02c36dbe-6754-420b-bb67-fbcc17eddf00 to disappear
Apr 27 17:14:41.437: INFO: Pod pod-configmaps-02c36dbe-6754-420b-bb67-fbcc17eddf00 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:41.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9820" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":200,"skipped":3239,"failed":0}
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:41.446: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6668
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:14:41.966: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 27 17:14:43.978: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604481, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604481, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604481, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604481, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:14:46.994: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:47.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6668" for this suite.
STEP: Destroying namespace "webhook-6668-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":277,"completed":201,"skipped":3240,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:47.053: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2760
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:14:47.200: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:54.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2760" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":277,"completed":202,"skipped":3248,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:54.343: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8659
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-8659
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 27 17:14:54.488: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 27 17:14:54.514: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 17:14:56.518: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:14:58.518: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:15:00.519: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:15:02.518: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:15:04.518: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:15:06.518: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:15:08.519: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr 27 17:15:08.525: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Apr 27 17:15:10.547: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.252:8080/dial?request=hostname&protocol=udp&host=100.64.0.38&port=8081&tries=1'] Namespace:pod-network-test-8659 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 17:15:10.547: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 17:15:10.946: INFO: Waiting for responses: map[]
Apr 27 17:15:10.950: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.252:8080/dial?request=hostname&protocol=udp&host=100.64.1.251&port=8081&tries=1'] Namespace:pod-network-test-8659 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 17:15:10.950: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 17:15:11.300: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:15:11.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8659" for this suite.
•{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":277,"completed":203,"skipped":3267,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:15:11.312: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-307
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:157
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:15:11.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-307" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":277,"completed":204,"skipped":3292,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:15:11.487: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8157
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:15:27.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8157" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":277,"completed":205,"skipped":3325,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:15:27.717: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1221
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:15:28.288: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:15:31.309: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:15:31.314: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2286-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:15:32.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1221" for this suite.
STEP: Destroying namespace "webhook-1221-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":277,"completed":206,"skipped":3379,"failed":0}
SS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:15:32.796: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6250
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Apr 27 17:15:33.008: INFO: Waiting up to 5m0s for pod "downward-api-329fcf82-753c-4cd0-bd60-85ebd6e21f49" in namespace "downward-api-6250" to be "Succeeded or Failed"
Apr 27 17:15:33.011: INFO: Pod "downward-api-329fcf82-753c-4cd0-bd60-85ebd6e21f49": Phase="Pending", Reason="", readiness=false. Elapsed: 2.55768ms
Apr 27 17:15:35.064: INFO: Pod "downward-api-329fcf82-753c-4cd0-bd60-85ebd6e21f49": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.055795616s
STEP: Saw pod success
Apr 27 17:15:35.064: INFO: Pod "downward-api-329fcf82-753c-4cd0-bd60-85ebd6e21f49" satisfied condition "Succeeded or Failed"
Apr 27 17:15:35.069: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downward-api-329fcf82-753c-4cd0-bd60-85ebd6e21f49 container dapi-container: <nil>
STEP: delete the pod
Apr 27 17:15:35.101: INFO: Waiting for pod downward-api-329fcf82-753c-4cd0-bd60-85ebd6e21f49 to disappear
Apr 27 17:15:35.104: INFO: Pod downward-api-329fcf82-753c-4cd0-bd60-85ebd6e21f49 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:15:35.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6250" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":277,"completed":207,"skipped":3381,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:15:35.115: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4764
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:15:51.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4764" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":277,"completed":208,"skipped":3396,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:15:51.320: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7581
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 27 17:15:51.473: INFO: Waiting up to 5m0s for pod "pod-157118e6-09d1-484c-865e-70a6b962e966" in namespace "emptydir-7581" to be "Succeeded or Failed"
Apr 27 17:15:51.476: INFO: Pod "pod-157118e6-09d1-484c-865e-70a6b962e966": Phase="Pending", Reason="", readiness=false. Elapsed: 2.692096ms
Apr 27 17:15:53.480: INFO: Pod "pod-157118e6-09d1-484c-865e-70a6b962e966": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006727675s
STEP: Saw pod success
Apr 27 17:15:53.480: INFO: Pod "pod-157118e6-09d1-484c-865e-70a6b962e966" satisfied condition "Succeeded or Failed"
Apr 27 17:15:53.483: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-157118e6-09d1-484c-865e-70a6b962e966 container test-container: <nil>
STEP: delete the pod
Apr 27 17:15:53.520: INFO: Waiting for pod pod-157118e6-09d1-484c-865e-70a6b962e966 to disappear
Apr 27 17:15:53.523: INFO: Pod pod-157118e6-09d1-484c-865e-70a6b962e966 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:15:53.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7581" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":209,"skipped":3456,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:15:53.535: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8104
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:15:54.191: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 27 17:15:56.201: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604554, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604554, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604554, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604554, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:15:59.215: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:15:59.221: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2341-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:16:00.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8104" for this suite.
STEP: Destroying namespace "webhook-8104-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":277,"completed":210,"skipped":3463,"failed":0}
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:16:00.539: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5615
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-d08328b0-19bf-4b55-b277-f2b82987abc6
STEP: Creating a pod to test consume secrets
Apr 27 17:16:00.717: INFO: Waiting up to 5m0s for pod "pod-secrets-dbcfb8a1-4394-4f4b-bdcb-a15f8f5093ed" in namespace "secrets-5615" to be "Succeeded or Failed"
Apr 27 17:16:00.720: INFO: Pod "pod-secrets-dbcfb8a1-4394-4f4b-bdcb-a15f8f5093ed": Phase="Pending", Reason="", readiness=false. Elapsed: 3.165259ms
Apr 27 17:16:02.724: INFO: Pod "pod-secrets-dbcfb8a1-4394-4f4b-bdcb-a15f8f5093ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007040191s
STEP: Saw pod success
Apr 27 17:16:02.724: INFO: Pod "pod-secrets-dbcfb8a1-4394-4f4b-bdcb-a15f8f5093ed" satisfied condition "Succeeded or Failed"
Apr 27 17:16:02.727: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-secrets-dbcfb8a1-4394-4f4b-bdcb-a15f8f5093ed container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:16:02.743: INFO: Waiting for pod pod-secrets-dbcfb8a1-4394-4f4b-bdcb-a15f8f5093ed to disappear
Apr 27 17:16:02.747: INFO: Pod pod-secrets-dbcfb8a1-4394-4f4b-bdcb-a15f8f5093ed no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:16:02.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5615" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":211,"skipped":3464,"failed":0}
SS
------------------------------
[k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:16:02.756: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-3129
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:164
Apr 27 17:16:02.902: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 27 17:17:02.926: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:17:02.929: INFO: Starting informer...
STEP: Starting pod...
Apr 27 17:17:03.146: INFO: Pod is running on shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Apr 27 17:17:03.161: INFO: Pod wasn't evicted. Proceeding
Apr 27 17:17:03.161: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Apr 27 17:18:18.174: INFO: Pod wasn't evicted. Test successful
[AfterEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:18:18.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-3129" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":277,"completed":212,"skipped":3466,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:18:18.185: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8380
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 27 17:18:22.391: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 17:18:22.395: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 27 17:18:24.395: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 17:18:24.400: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 27 17:18:26.395: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 17:18:26.400: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 27 17:18:28.395: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 17:18:28.400: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 27 17:18:30.395: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 17:18:30.400: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 27 17:18:32.395: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 17:18:32.400: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 27 17:18:34.395: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 17:18:34.400: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 27 17:18:36.395: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 17:18:36.400: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:18:36.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8380" for this suite.
•{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":277,"completed":213,"skipped":3495,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:18:36.513: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4814
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name secret-emptykey-test-f9e8c666-baaf-4583-8732-c443511d698d
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:18:36.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4814" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should fail to create secret due to empty secret key [Conformance]","total":277,"completed":214,"skipped":3543,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:18:36.673: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1107
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 27 17:18:36.825: INFO: Waiting up to 5m0s for pod "pod-6826542f-b94c-4336-9059-78f240751df9" in namespace "emptydir-1107" to be "Succeeded or Failed"
Apr 27 17:18:36.828: INFO: Pod "pod-6826542f-b94c-4336-9059-78f240751df9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.045627ms
Apr 27 17:18:38.833: INFO: Pod "pod-6826542f-b94c-4336-9059-78f240751df9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007621249s
STEP: Saw pod success
Apr 27 17:18:38.833: INFO: Pod "pod-6826542f-b94c-4336-9059-78f240751df9" satisfied condition "Succeeded or Failed"
Apr 27 17:18:38.836: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-6826542f-b94c-4336-9059-78f240751df9 container test-container: <nil>
STEP: delete the pod
Apr 27 17:18:38.853: INFO: Waiting for pod pod-6826542f-b94c-4336-9059-78f240751df9 to disappear
Apr 27 17:18:38.856: INFO: Pod pod-6826542f-b94c-4336-9059-78f240751df9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:18:38.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1107" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":215,"skipped":3544,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:18:38.865: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7845
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:18:42.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7845" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":277,"completed":216,"skipped":3554,"failed":0}
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:18:42.050: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1923
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:18:42.590: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:18:45.614: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:18:45.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1923" for this suite.
STEP: Destroying namespace "webhook-1923-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":277,"completed":217,"skipped":3555,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:18:45.890: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6492
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:18:46.041: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1ae93bc3-d4c2-4840-9304-ff77ce584b00" in namespace "projected-6492" to be "Succeeded or Failed"
Apr 27 17:18:46.044: INFO: Pod "downwardapi-volume-1ae93bc3-d4c2-4840-9304-ff77ce584b00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.93998ms
Apr 27 17:18:48.048: INFO: Pod "downwardapi-volume-1ae93bc3-d4c2-4840-9304-ff77ce584b00": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006864963s
STEP: Saw pod success
Apr 27 17:18:48.048: INFO: Pod "downwardapi-volume-1ae93bc3-d4c2-4840-9304-ff77ce584b00" satisfied condition "Succeeded or Failed"
Apr 27 17:18:48.051: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downwardapi-volume-1ae93bc3-d4c2-4840-9304-ff77ce584b00 container client-container: <nil>
STEP: delete the pod
Apr 27 17:18:48.099: INFO: Waiting for pod downwardapi-volume-1ae93bc3-d4c2-4840-9304-ff77ce584b00 to disappear
Apr 27 17:18:48.104: INFO: Pod downwardapi-volume-1ae93bc3-d4c2-4840-9304-ff77ce584b00 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:18:48.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6492" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":218,"skipped":3580,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:18:48.114: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4738
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:18:48.382: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr 27 17:18:53.386: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 27 17:18:53.386: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr 27 17:18:55.391: INFO: Creating deployment "test-rollover-deployment"
Apr 27 17:18:55.398: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr 27 17:18:57.405: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr 27 17:18:57.411: INFO: Ensure that both replica sets have 1 created replica
Apr 27 17:18:57.418: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr 27 17:18:57.426: INFO: Updating deployment test-rollover-deployment
Apr 27 17:18:57.426: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr 27 17:18:59.433: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr 27 17:18:59.439: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr 27 17:18:59.445: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 17:18:59.445: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604735, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604735, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604737, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604735, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:19:01.454: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 17:19:01.454: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604735, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604735, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604740, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604735, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:19:03.453: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 17:19:03.453: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604735, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604735, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604740, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604735, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:19:05.453: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 17:19:05.454: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604735, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604735, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604740, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604735, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:19:07.453: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 17:19:07.454: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604735, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604735, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604740, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604735, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:19:09.453: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 17:19:09.454: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604735, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604735, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604740, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604735, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:19:11.454: INFO: 
Apr 27 17:19:11.454: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Apr 27 17:19:11.466: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-4738 /apis/apps/v1/namespaces/deployment-4738/deployments/test-rollover-deployment 27ca13ea-66c3-433c-b715-e07a5ef07cbe 33441 2 2020-04-27 17:18:55 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-04-27 17:18:57 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 17:19:10 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003bba828 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-04-27 17:18:55 +0000 UTC,LastTransitionTime:2020-04-27 17:18:55 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-84f7f6f64b" has successfully progressed.,LastUpdateTime:2020-04-27 17:19:10 +0000 UTC,LastTransitionTime:2020-04-27 17:18:55 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 27 17:19:11.470: INFO: New ReplicaSet "test-rollover-deployment-84f7f6f64b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-84f7f6f64b  deployment-4738 /apis/apps/v1/namespaces/deployment-4738/replicasets/test-rollover-deployment-84f7f6f64b fed8861b-05dc-4169-8f2a-20ad9fe4a813 33434 2 2020-04-27 17:18:57 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 27ca13ea-66c3-433c-b715-e07a5ef07cbe 0xc003be2217 0xc003be2218}] []  [{kube-controller-manager Update apps/v1 2020-04-27 17:19:10 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 55 99 97 49 51 101 97 45 54 54 99 51 45 52 51 51 99 45 98 55 49 53 45 101 48 55 97 53 101 102 48 55 99 98 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 84f7f6f64b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003be22a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 27 17:19:11.470: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr 27 17:19:11.470: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-4738 /apis/apps/v1/namespaces/deployment-4738/replicasets/test-rollover-controller 46c9748f-b124-428b-85b4-b526192f0886 33440 2 2020-04-27 17:18:48 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 27ca13ea-66c3-433c-b715-e07a5ef07cbe 0xc003be2007 0xc003be2008}] []  [{e2e.test Update apps/v1 2020-04-27 17:18:48 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 17:19:10 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 55 99 97 49 51 101 97 45 54 54 99 51 45 52 51 51 99 45 98 55 49 53 45 101 48 55 97 53 101 102 48 55 99 98 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003be20a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 17:19:11.470: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-5686c4cfd5  deployment-4738 /apis/apps/v1/namespaces/deployment-4738/replicasets/test-rollover-deployment-5686c4cfd5 ca0528b6-6934-42d4-992d-14fc1bbef7c2 33374 2 2020-04-27 17:18:55 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 27ca13ea-66c3-433c-b715-e07a5ef07cbe 0xc003be2117 0xc003be2118}] []  [{kube-controller-manager Update apps/v1 2020-04-27 17:18:57 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 55 99 97 49 51 101 97 45 54 54 99 51 45 52 51 51 99 45 98 55 49 53 45 101 48 55 97 53 101 102 48 55 99 98 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 114 101 100 105 115 45 115 108 97 118 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5686c4cfd5,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003be21a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 17:19:11.474: INFO: Pod "test-rollover-deployment-84f7f6f64b-6nrqv" is available:
&Pod{ObjectMeta:{test-rollover-deployment-84f7f6f64b-6nrqv test-rollover-deployment-84f7f6f64b- deployment-4738 /api/v1/namespaces/deployment-4738/pods/test-rollover-deployment-84f7f6f64b-6nrqv 87441307-bc52-4a77-a50f-54e8024053e9 33391 0 2020-04-27 17:18:57 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[cni.projectcalico.org/podIP:100.64.1.18/32 cni.projectcalico.org/podIPs:100.64.1.18/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rollover-deployment-84f7f6f64b fed8861b-05dc-4169-8f2a-20ad9fe4a813 0xc003b6cfd7 0xc003b6cfd8}] []  [{kube-controller-manager Update v1 2020-04-27 17:18:57 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 101 100 56 56 54 49 98 45 48 53 100 99 45 52 49 54 57 45 56 102 50 97 45 50 48 97 100 57 102 101 52 97 56 49 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:18:58 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:19:00 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 49 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-g945g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-g945g,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-g945g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:18:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:18:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.21,PodIP:100.64.1.18,StartTime:2020-04-27 17:18:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:18:59 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://c5e602a3e69f888824df371954f1613655350ebf5f5a8c30069891449342145a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.18,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:19:11.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4738" for this suite.
•{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":277,"completed":219,"skipped":3593,"failed":0}

------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:19:11.483: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7683
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:19:11.629: INFO: Creating deployment "webserver-deployment"
Apr 27 17:19:11.634: INFO: Waiting for observed generation 1
Apr 27 17:19:13.641: INFO: Waiting for all required pods to come up
Apr 27 17:19:13.647: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Apr 27 17:19:15.663: INFO: Waiting for deployment "webserver-deployment" to complete
Apr 27 17:19:15.669: INFO: Updating deployment "webserver-deployment" with a non-existent image
Apr 27 17:19:15.676: INFO: Updating deployment webserver-deployment
Apr 27 17:19:15.676: INFO: Waiting for observed generation 2
Apr 27 17:19:17.683: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr 27 17:19:17.685: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr 27 17:19:17.688: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 27 17:19:17.696: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr 27 17:19:17.696: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr 27 17:19:17.699: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 27 17:19:17.705: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Apr 27 17:19:17.705: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Apr 27 17:19:17.712: INFO: Updating deployment webserver-deployment
Apr 27 17:19:17.712: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Apr 27 17:19:17.717: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr 27 17:19:17.720: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Apr 27 17:19:17.730: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-7683 /apis/apps/v1/namespaces/deployment-7683/deployments/webserver-deployment d61de817-d0b3-4b6b-a772-56b44ca79d1d 33612 3 2020-04-27 17:19:11 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-04-27 17:19:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 17:19:17 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003cea398 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-6676bcd6d4" is progressing.,LastUpdateTime:2020-04-27 17:19:15 +0000 UTC,LastTransitionTime:2020-04-27 17:19:11 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-04-27 17:19:17 +0000 UTC,LastTransitionTime:2020-04-27 17:19:17 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Apr 27 17:19:17.736: INFO: New ReplicaSet "webserver-deployment-6676bcd6d4" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-6676bcd6d4  deployment-7683 /apis/apps/v1/namespaces/deployment-7683/replicasets/webserver-deployment-6676bcd6d4 92ef64bc-4dd5-4673-893d-fd88633030c5 33609 3 2020-04-27 17:19:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment d61de817-d0b3-4b6b-a772-56b44ca79d1d 0xc003cea7e7 0xc003cea7e8}] []  [{kube-controller-manager Update apps/v1 2020-04-27 17:19:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 54 49 100 101 56 49 55 45 100 48 98 51 45 52 98 54 98 45 97 55 55 50 45 53 54 98 52 52 99 97 55 57 100 49 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 6676bcd6d4,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003cea868 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 17:19:17.736: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Apr 27 17:19:17.736: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-84855cf797  deployment-7683 /apis/apps/v1/namespaces/deployment-7683/replicasets/webserver-deployment-84855cf797 abf9b75a-82ad-47d0-bd2a-d97559a45f9c 33608 3 2020-04-27 17:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment d61de817-d0b3-4b6b-a772-56b44ca79d1d 0xc003cea8c7 0xc003cea8c8}] []  [{kube-controller-manager Update apps/v1 2020-04-27 17:19:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 54 49 100 101 56 49 55 45 100 48 98 51 45 52 98 54 98 45 97 55 55 50 45 53 54 98 52 52 99 97 55 57 100 49 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 84855cf797,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003cea938 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Apr 27 17:19:17.744: INFO: Pod "webserver-deployment-6676bcd6d4-7hgzx" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-7hgzx webserver-deployment-6676bcd6d4- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-6676bcd6d4-7hgzx 1ee4996b-27a0-4f98-9691-e9b437b9430e 33593 0 2020-04-27 17:19:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:100.64.0.43/32 cni.projectcalico.org/podIPs:100.64.0.43/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 92ef64bc-4dd5-4673-893d-fd88633030c5 0xc003c84927 0xc003c84928}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:15 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 50 101 102 54 52 98 99 45 52 100 100 53 45 52 54 55 51 45 56 57 51 100 45 102 100 56 56 54 51 51 48 51 48 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:19:15 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:19:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2020-04-27 17:19:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.744: INFO: Pod "webserver-deployment-6676bcd6d4-b6588" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-b6588 webserver-deployment-6676bcd6d4- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-6676bcd6d4-b6588 da64594c-9fc5-496b-9823-90ec431f632f 33592 0 2020-04-27 17:19:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:100.64.0.42/32 cni.projectcalico.org/podIPs:100.64.0.42/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 92ef64bc-4dd5-4673-893d-fd88633030c5 0xc003c84af0 0xc003c84af1}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:15 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 50 101 102 54 52 98 99 45 52 100 100 53 45 52 54 55 51 45 56 57 51 100 45 102 100 56 56 54 51 51 48 51 48 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:19:15 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:19:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2020-04-27 17:19:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.745: INFO: Pod "webserver-deployment-6676bcd6d4-fbdtb" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-fbdtb webserver-deployment-6676bcd6d4- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-6676bcd6d4-fbdtb 6f5bc4c1-f3fd-45fb-a12f-c187555f861e 33625 0 2020-04-27 17:19:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 92ef64bc-4dd5-4673-893d-fd88633030c5 0xc003c84ca0 0xc003c84ca1}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 50 101 102 54 52 98 99 45 52 100 100 53 45 52 54 55 51 45 56 57 51 100 45 102 100 56 56 54 51 51 48 51 48 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.745: INFO: Pod "webserver-deployment-6676bcd6d4-gwvx2" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-gwvx2 webserver-deployment-6676bcd6d4- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-6676bcd6d4-gwvx2 128652d7-c3ea-4a91-9e40-c756f6a2a706 33628 0 2020-04-27 17:19:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 92ef64bc-4dd5-4673-893d-fd88633030c5 0xc003c84dd0 0xc003c84dd1}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 50 101 102 54 52 98 99 45 52 100 100 53 45 52 54 55 51 45 56 57 51 100 45 102 100 56 56 54 51 51 48 51 48 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.745: INFO: Pod "webserver-deployment-6676bcd6d4-m5pfd" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-m5pfd webserver-deployment-6676bcd6d4- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-6676bcd6d4-m5pfd b896466d-266b-44b4-9d50-a4b6066bcc39 33603 0 2020-04-27 17:19:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:100.64.1.27/32 cni.projectcalico.org/podIPs:100.64.1.27/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 92ef64bc-4dd5-4673-893d-fd88633030c5 0xc003c84f07 0xc003c84f08}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:15 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 50 101 102 54 52 98 99 45 52 100 100 53 45 52 54 55 51 45 56 57 51 100 45 102 100 56 56 54 51 51 48 51 48 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:19:15 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:19:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.21,PodIP:,StartTime:2020-04-27 17:19:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.745: INFO: Pod "webserver-deployment-6676bcd6d4-mcd7q" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-mcd7q webserver-deployment-6676bcd6d4- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-6676bcd6d4-mcd7q 423d20a5-4647-4e3d-b58e-8342f5ecc7c2 33604 0 2020-04-27 17:19:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:100.64.1.28/32 cni.projectcalico.org/podIPs:100.64.1.28/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 92ef64bc-4dd5-4673-893d-fd88633030c5 0xc003c850d0 0xc003c850d1}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:15 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 50 101 102 54 52 98 99 45 52 100 100 53 45 52 54 55 51 45 56 57 51 100 45 102 100 56 56 54 51 51 48 51 48 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:19:15 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:19:17 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.21,PodIP:,StartTime:2020-04-27 17:19:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.745: INFO: Pod "webserver-deployment-6676bcd6d4-p8qtn" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-p8qtn webserver-deployment-6676bcd6d4- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-6676bcd6d4-p8qtn 92a34a16-cbc7-494c-97bc-6d9087c55d74 33629 0 2020-04-27 17:19:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 92ef64bc-4dd5-4673-893d-fd88633030c5 0xc003c85280 0xc003c85281}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 50 101 102 54 52 98 99 45 52 100 100 53 45 52 54 55 51 45 56 57 51 100 45 102 100 56 56 54 51 51 48 51 48 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.746: INFO: Pod "webserver-deployment-6676bcd6d4-s22zq" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-s22zq webserver-deployment-6676bcd6d4- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-6676bcd6d4-s22zq e392d720-7a1c-4797-a053-2658c98fe387 33634 0 2020-04-27 17:19:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 92ef64bc-4dd5-4673-893d-fd88633030c5 0xc003c85397 0xc003c85398}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 50 101 102 54 52 98 99 45 52 100 100 53 45 52 54 55 51 45 56 57 51 100 45 102 100 56 56 54 51 51 48 51 48 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.746: INFO: Pod "webserver-deployment-6676bcd6d4-sl2n2" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-sl2n2 webserver-deployment-6676bcd6d4- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-6676bcd6d4-sl2n2 743c8128-5804-471b-b3bd-8407dabb4c54 33627 0 2020-04-27 17:19:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 92ef64bc-4dd5-4673-893d-fd88633030c5 0xc003c854c0 0xc003c854c1}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 50 101 102 54 52 98 99 45 52 100 100 53 45 52 54 55 51 45 56 57 51 100 45 102 100 56 56 54 51 51 48 51 48 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.746: INFO: Pod "webserver-deployment-6676bcd6d4-vs6kx" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-vs6kx webserver-deployment-6676bcd6d4- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-6676bcd6d4-vs6kx 4f18fdc1-0fd8-4f6d-9df7-439478213fe9 33602 0 2020-04-27 17:19:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:100.64.1.26/32 cni.projectcalico.org/podIPs:100.64.1.26/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 92ef64bc-4dd5-4673-893d-fd88633030c5 0xc003c855f7 0xc003c855f8}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:15 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 50 101 102 54 52 98 99 45 52 100 100 53 45 52 54 55 51 45 56 57 51 100 45 102 100 56 56 54 51 51 48 51 48 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:19:15 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:19:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.21,PodIP:,StartTime:2020-04-27 17:19:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.746: INFO: Pod "webserver-deployment-6676bcd6d4-x5mz5" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-x5mz5 webserver-deployment-6676bcd6d4- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-6676bcd6d4-x5mz5 e1399930-cff8-4ff6-875c-79820903db11 33616 0 2020-04-27 17:19:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 92ef64bc-4dd5-4673-893d-fd88633030c5 0xc003c857a0 0xc003c857a1}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 50 101 102 54 52 98 99 45 52 100 100 53 45 52 54 55 51 45 56 57 51 100 45 102 100 56 56 54 51 51 48 51 48 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.746: INFO: Pod "webserver-deployment-6676bcd6d4-zq7bf" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-zq7bf webserver-deployment-6676bcd6d4- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-6676bcd6d4-zq7bf 19922af2-43dc-4111-a3b7-367f537abec0 33623 0 2020-04-27 17:19:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 92ef64bc-4dd5-4673-893d-fd88633030c5 0xc003c858d0 0xc003c858d1}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 50 101 102 54 52 98 99 45 52 100 100 53 45 52 54 55 51 45 56 57 51 100 45 102 100 56 56 54 51 51 48 51 48 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.746: INFO: Pod "webserver-deployment-84855cf797-28cps" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-28cps webserver-deployment-84855cf797- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-84855cf797-28cps 700a887a-ec50-4805-a379-1a731cc350e0 33519 0 2020-04-27 17:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.0.39/32 cni.projectcalico.org/podIPs:100.64.0.39/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 abf9b75a-82ad-47d0-bd2a-d97559a45f9c 0xc003c85a20 0xc003c85a21}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:11 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 98 102 57 98 55 53 97 45 56 50 97 100 45 52 55 100 48 45 98 100 50 97 45 100 57 55 53 53 57 97 52 53 102 57 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:19:12 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:19:13 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 48 46 51 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.0.39,StartTime:2020-04-27 17:19:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:19:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://a730a40bd79b4f5a447c244c4b4fa7a4aa326878a1bfac45014f2164bbaef1b1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.39,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.747: INFO: Pod "webserver-deployment-84855cf797-4gtnb" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-4gtnb webserver-deployment-84855cf797- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-84855cf797-4gtnb 1073e981-173b-43ae-81a3-c7e3efbac96c 33632 0 2020-04-27 17:19:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 abf9b75a-82ad-47d0-bd2a-d97559a45f9c 0xc003c85bd0 0xc003c85bd1}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 98 102 57 98 55 53 97 45 56 50 97 100 45 52 55 100 48 45 98 100 50 97 45 100 57 55 53 53 57 97 52 53 102 57 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.747: INFO: Pod "webserver-deployment-84855cf797-9b2v5" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-9b2v5 webserver-deployment-84855cf797- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-84855cf797-9b2v5 172798bf-80dd-4606-89e3-6345d7b92f3a 33631 0 2020-04-27 17:19:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 abf9b75a-82ad-47d0-bd2a-d97559a45f9c 0xc003c85cd7 0xc003c85cd8}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 98 102 57 98 55 53 97 45 56 50 97 100 45 52 55 100 48 45 98 100 50 97 45 100 57 55 53 53 57 97 52 53 102 57 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.747: INFO: Pod "webserver-deployment-84855cf797-b7tdj" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-b7tdj webserver-deployment-84855cf797- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-84855cf797-b7tdj f68bcefe-92be-439b-855f-b9da75a75a85 33527 0 2020-04-27 17:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.22/32 cni.projectcalico.org/podIPs:100.64.1.22/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 abf9b75a-82ad-47d0-bd2a-d97559a45f9c 0xc003c85df7 0xc003c85df8}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:11 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 98 102 57 98 55 53 97 45 56 50 97 100 45 52 55 100 48 45 98 100 50 97 45 100 57 55 53 53 57 97 52 53 102 57 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:19:13 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:19:15 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 50 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.21,PodIP:100.64.1.22,StartTime:2020-04-27 17:19:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:19:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://985cb3fb3fd9120f0bb9a6c0fb823ed2c4aea66a8b084f0c221826c44b3aa179,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.22,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.747: INFO: Pod "webserver-deployment-84855cf797-d6qss" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-d6qss webserver-deployment-84855cf797- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-84855cf797-d6qss 13a2cd8b-3281-4e90-907c-c3ebeccaa406 33630 0 2020-04-27 17:19:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 abf9b75a-82ad-47d0-bd2a-d97559a45f9c 0xc003c85fa0 0xc003c85fa1}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 98 102 57 98 55 53 97 45 56 50 97 100 45 52 55 100 48 45 98 100 50 97 45 100 57 55 53 53 57 97 52 53 102 57 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.747: INFO: Pod "webserver-deployment-84855cf797-d952n" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-d952n webserver-deployment-84855cf797- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-84855cf797-d952n b6bba94e-2e37-40a0-a0ce-dafeb97ae0f0 33516 0 2020-04-27 17:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.0.40/32 cni.projectcalico.org/podIPs:100.64.0.40/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 abf9b75a-82ad-47d0-bd2a-d97559a45f9c 0xc003d260e0 0xc003d260e1}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:11 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 98 102 57 98 55 53 97 45 56 50 97 100 45 52 55 100 48 45 98 100 50 97 45 100 57 55 53 53 57 97 52 53 102 57 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:19:13 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:19:13 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 48 46 52 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.0.40,StartTime:2020-04-27 17:19:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:19:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://1cb4abb7411ae466f5d8dbfb083e5aeaf0b053271162d4d88d11cee17d3bc5fc,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.40,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.748: INFO: Pod "webserver-deployment-84855cf797-ffnx4" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-ffnx4 webserver-deployment-84855cf797- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-84855cf797-ffnx4 fb3bda06-f1e7-45cc-9655-dea57b826b86 33621 0 2020-04-27 17:19:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 abf9b75a-82ad-47d0-bd2a-d97559a45f9c 0xc003d26290 0xc003d26291}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 98 102 57 98 55 53 97 45 56 50 97 100 45 52 55 100 48 45 98 100 50 97 45 100 57 55 53 53 57 97 52 53 102 57 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.748: INFO: Pod "webserver-deployment-84855cf797-g7q69" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-g7q69 webserver-deployment-84855cf797- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-84855cf797-g7q69 6fa19a6f-c413-45ff-bdc6-1a49c06c90bc 33530 0 2020-04-27 17:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.23/32 cni.projectcalico.org/podIPs:100.64.1.23/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 abf9b75a-82ad-47d0-bd2a-d97559a45f9c 0xc003d263e0 0xc003d263e1}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:11 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 98 102 57 98 55 53 97 45 56 50 97 100 45 52 55 100 48 45 98 100 50 97 45 100 57 55 53 53 57 97 52 53 102 57 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:19:13 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:19:15 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 50 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.21,PodIP:100.64.1.23,StartTime:2020-04-27 17:19:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:19:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://eeadb4aabf27c8445af36dc216a077377e95e67da13f5abafcba6e0548393d6d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.23,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.748: INFO: Pod "webserver-deployment-84855cf797-hdd7w" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-hdd7w webserver-deployment-84855cf797- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-84855cf797-hdd7w b275b322-1421-41a5-b401-519a5f2b2b50 33522 0 2020-04-27 17:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.24/32 cni.projectcalico.org/podIPs:100.64.1.24/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 abf9b75a-82ad-47d0-bd2a-d97559a45f9c 0xc003d265b0 0xc003d265b1}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:11 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 98 102 57 98 55 53 97 45 56 50 97 100 45 52 55 100 48 45 98 100 50 97 45 100 57 55 53 53 57 97 52 53 102 57 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:19:13 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:19:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 50 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.21,PodIP:100.64.1.24,StartTime:2020-04-27 17:19:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:19:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://e9609db8ab48369b67b82eb3778d4e69f8705284da37dafe6e5570d0d31d624d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.24,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.748: INFO: Pod "webserver-deployment-84855cf797-jp82n" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-jp82n webserver-deployment-84855cf797- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-84855cf797-jp82n 8046b60a-caa3-4498-a79d-763d232cde85 33633 0 2020-04-27 17:19:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 abf9b75a-82ad-47d0-bd2a-d97559a45f9c 0xc003d26760 0xc003d26761}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 98 102 57 98 55 53 97 45 56 50 97 100 45 52 55 100 48 45 98 100 50 97 45 100 57 55 53 53 57 97 52 53 102 57 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.748: INFO: Pod "webserver-deployment-84855cf797-khrfp" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-khrfp webserver-deployment-84855cf797- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-84855cf797-khrfp 68f17e5a-58b0-4aee-826b-759a8cd76e78 33620 0 2020-04-27 17:19:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 abf9b75a-82ad-47d0-bd2a-d97559a45f9c 0xc003d26880 0xc003d26881}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 98 102 57 98 55 53 97 45 56 50 97 100 45 52 55 100 48 45 98 100 50 97 45 100 57 55 53 53 57 97 52 53 102 57 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.748: INFO: Pod "webserver-deployment-84855cf797-rx6l4" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-rx6l4 webserver-deployment-84855cf797- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-84855cf797-rx6l4 a1f5defb-2477-4f08-a03f-5de4a806c6cf 33533 0 2020-04-27 17:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.25/32 cni.projectcalico.org/podIPs:100.64.1.25/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 abf9b75a-82ad-47d0-bd2a-d97559a45f9c 0xc003d269c0 0xc003d269c1}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:11 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 98 102 57 98 55 53 97 45 56 50 97 100 45 52 55 100 48 45 98 100 50 97 45 100 57 55 53 53 57 97 52 53 102 57 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:19:13 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:19:15 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 50 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.21,PodIP:100.64.1.25,StartTime:2020-04-27 17:19:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:19:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://2965e2e82949884a99b091df71e01d4563270778cb56abc1d2ba559f1ffa03ca,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.25,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.749: INFO: Pod "webserver-deployment-84855cf797-vbfxw" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-vbfxw webserver-deployment-84855cf797- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-84855cf797-vbfxw e603f3f5-a075-4444-a0c4-b0743ce6daf8 33536 0 2020-04-27 17:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.21/32 cni.projectcalico.org/podIPs:100.64.1.21/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 abf9b75a-82ad-47d0-bd2a-d97559a45f9c 0xc003d26b90 0xc003d26b91}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:11 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 98 102 57 98 55 53 97 45 56 50 97 100 45 52 55 100 48 45 98 100 50 97 45 100 57 55 53 53 57 97 52 53 102 57 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:19:13 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:19:15 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 50 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.21,PodIP:100.64.1.21,StartTime:2020-04-27 17:19:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:19:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://1375d2f56ca2e09d1896d12a2c409b66dbc0756b8d155e3a18e73db4c718c175,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.21,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.749: INFO: Pod "webserver-deployment-84855cf797-zjkj9" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-zjkj9 webserver-deployment-84855cf797- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-84855cf797-zjkj9 de2579a2-580e-4f8c-864f-852cf7fd8b56 33613 0 2020-04-27 17:19:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 abf9b75a-82ad-47d0-bd2a-d97559a45f9c 0xc003d26d40 0xc003d26d41}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 98 102 57 98 55 53 97 45 56 50 97 100 45 52 55 100 48 45 98 100 50 97 45 100 57 55 53 53 57 97 52 53 102 57 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 17:19:17.749: INFO: Pod "webserver-deployment-84855cf797-zptls" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-zptls webserver-deployment-84855cf797- deployment-7683 /api/v1/namespaces/deployment-7683/pods/webserver-deployment-84855cf797-zptls fd06cb1a-7404-471a-bb96-0ea8cfd42fd7 33513 0 2020-04-27 17:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.0.41/32 cni.projectcalico.org/podIPs:100.64.0.41/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 abf9b75a-82ad-47d0-bd2a-d97559a45f9c 0xc003d26e80 0xc003d26e81}] []  [{kube-controller-manager Update v1 2020-04-27 17:19:11 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 98 102 57 98 55 53 97 45 56 50 97 100 45 52 55 100 48 45 98 100 50 97 45 100 57 55 53 53 57 97 52 53 102 57 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:19:13 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:19:13 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 48 46 52 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hqkrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hqkrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hqkrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:19:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.0.41,StartTime:2020-04-27 17:19:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:19:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://43c9cde0d32756c204dd5e182f45027b35881200201d9992bf5fa969c52cbccc,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:19:17.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7683" for this suite.
•{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":277,"completed":220,"skipped":3593,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:19:17.775: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5281
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-5a09e2a9-c7dd-49d4-a86b-f8586fdd08fd
STEP: Creating secret with name s-test-opt-upd-c798b50f-2abb-448e-9396-a9f493840d76
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-5a09e2a9-c7dd-49d4-a86b-f8586fdd08fd
STEP: Updating secret s-test-opt-upd-c798b50f-2abb-448e-9396-a9f493840d76
STEP: Creating secret with name s-test-opt-create-bcc674f4-9c0f-431b-a86f-0eeaae14de58
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:19:28.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5281" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":221,"skipped":3608,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:19:28.415: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9953
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:19:28.570: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c0f4f262-11f2-4373-9d23-8518cebb509f" in namespace "projected-9953" to be "Succeeded or Failed"
Apr 27 17:19:28.573: INFO: Pod "downwardapi-volume-c0f4f262-11f2-4373-9d23-8518cebb509f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.772411ms
Apr 27 17:19:30.577: INFO: Pod "downwardapi-volume-c0f4f262-11f2-4373-9d23-8518cebb509f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007333799s
STEP: Saw pod success
Apr 27 17:19:30.577: INFO: Pod "downwardapi-volume-c0f4f262-11f2-4373-9d23-8518cebb509f" satisfied condition "Succeeded or Failed"
Apr 27 17:19:30.582: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downwardapi-volume-c0f4f262-11f2-4373-9d23-8518cebb509f container client-container: <nil>
STEP: delete the pod
Apr 27 17:19:30.639: INFO: Waiting for pod downwardapi-volume-c0f4f262-11f2-4373-9d23-8518cebb509f to disappear
Apr 27 17:19:30.703: INFO: Pod downwardapi-volume-c0f4f262-11f2-4373-9d23-8518cebb509f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:19:30.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9953" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":222,"skipped":3650,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:19:30.713: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3957
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:19:31.529: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:19:34.550: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:19:45.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3957" for this suite.
STEP: Destroying namespace "webhook-3957-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":277,"completed":223,"skipped":3660,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:19:45.171: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6374
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 27 17:19:49.363: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 17:19:49.366: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 17:19:51.367: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 17:19:51.372: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 17:19:53.367: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 17:19:53.371: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 17:19:55.367: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 17:19:55.371: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:19:55.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6374" for this suite.
•{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":277,"completed":224,"skipped":3759,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:19:55.391: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1156
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Apr 27 17:19:58.085: INFO: Successfully updated pod "annotationupdate428357a7-7844-4366-8fab-468648527470"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:20:02.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1156" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":277,"completed":225,"skipped":3809,"failed":0}
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:20:02.144: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6166
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-5b267717-bdab-4675-b157-c0ea1397491f
STEP: Creating a pod to test consume configMaps
Apr 27 17:20:02.302: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-226f11c1-bead-41d5-9fc4-11224e9fe13e" in namespace "projected-6166" to be "Succeeded or Failed"
Apr 27 17:20:02.305: INFO: Pod "pod-projected-configmaps-226f11c1-bead-41d5-9fc4-11224e9fe13e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.786632ms
Apr 27 17:20:04.309: INFO: Pod "pod-projected-configmaps-226f11c1-bead-41d5-9fc4-11224e9fe13e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007508232s
STEP: Saw pod success
Apr 27 17:20:04.310: INFO: Pod "pod-projected-configmaps-226f11c1-bead-41d5-9fc4-11224e9fe13e" satisfied condition "Succeeded or Failed"
Apr 27 17:20:04.313: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-projected-configmaps-226f11c1-bead-41d5-9fc4-11224e9fe13e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 17:20:04.330: INFO: Waiting for pod pod-projected-configmaps-226f11c1-bead-41d5-9fc4-11224e9fe13e to disappear
Apr 27 17:20:04.333: INFO: Pod pod-projected-configmaps-226f11c1-bead-41d5-9fc4-11224e9fe13e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:20:04.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6166" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":277,"completed":226,"skipped":3810,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:20:04.343: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6525
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Apr 27 17:20:04.562: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 27 17:20:04.574: INFO: Waiting for terminating namespaces to be deleted...
Apr 27 17:20:04.578: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-rc9dp before test
Apr 27 17:20:04.604: INFO: vpn-shoot-5b5f49b4bf-trqr9 from kube-system started at 2020-04-27 16:07:31 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.604: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 27 17:20:04.604: INFO: calico-typha-vertical-autoscaler-5b477c88cf-k2f8l from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.604: INFO: 	Container autoscaler ready: true, restart count 6
Apr 27 17:20:04.604: INFO: calico-kube-controllers-77dcb8f688-7jxx4 from kube-system started at 2020-04-27 16:07:33 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.604: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 27 17:20:04.604: INFO: calico-node-vertical-autoscaler-74d4897db8-h9n8r from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.604: INFO: 	Container autoscaler ready: true, restart count 6
Apr 27 17:20:04.604: INFO: node-exporter-9pkd5 from kube-system started at 2020-04-27 16:07:11 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.604: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 17:20:04.604: INFO: calico-typha-horizontal-autoscaler-6fdd5d8746-hv92s from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.604: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 17:20:04.604: INFO: calico-typha-deploy-784665cc66-9ngtv from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.604: INFO: 	Container calico-typha ready: true, restart count 0
Apr 27 17:20:04.604: INFO: kubernetes-dashboard-6b586c4cb4-9c2rc from kubernetes-dashboard started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.604: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
Apr 27 17:20:04.604: INFO: addons-nginx-ingress-controller-6cf77756b5-rw99m from kube-system started at 2020-04-27 16:07:33 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.604: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 27 17:20:04.604: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-q52mz from kube-system started at 2020-04-27 16:07:41 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.604: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr 27 17:20:04.604: INFO: blackbox-exporter-5dc75b79b7-7xcjk from kube-system started at 2020-04-27 16:07:11 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.604: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 27 17:20:04.604: INFO: kube-proxy-h2cx7 from kube-system started at 2020-04-27 16:07:11 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.604: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 17:20:04.604: INFO: node-problem-detector-tq7hl from kube-system started at 2020-04-27 16:07:11 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.604: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 17:20:04.604: INFO: calico-node-xphhz from kube-system started at 2020-04-27 16:15:29 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.604: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 17:20:04.604: INFO: coredns-5cb857d789-lrv9m from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.604: INFO: 	Container coredns ready: true, restart count 0
Apr 27 17:20:04.604: INFO: metrics-server-5f76b49bb-ktlbv from kube-system started at 2020-04-27 16:07:31 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.604: INFO: 	Container metrics-server ready: true, restart count 0
Apr 27 17:20:04.604: INFO: dashboard-metrics-scraper-76c7b697bc-l2z4c from kubernetes-dashboard started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.604: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 27 17:20:04.604: INFO: coredns-5cb857d789-s8ws2 from kube-system started at 2020-04-27 16:07:32 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.604: INFO: 	Container coredns ready: true, restart count 0
Apr 27 17:20:04.604: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 before test
Apr 27 17:20:04.616: INFO: calico-node-ld4x7 from kube-system started at 2020-04-27 16:15:20 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.616: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 17:20:04.616: INFO: node-problem-detector-9thlx from kube-system started at 2020-04-27 16:07:18 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.616: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 17:20:04.616: INFO: kube-proxy-jm5m6 from kube-system started at 2020-04-27 16:07:18 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.616: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 17:20:04.616: INFO: node-exporter-srfgn from kube-system started at 2020-04-27 16:07:18 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.616: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 17:20:04.616: INFO: annotationupdate428357a7-7844-4366-8fab-468648527470 from projected-1156 started at 2020-04-27 17:19:55 +0000 UTC (1 container statuses recorded)
Apr 27 17:20:04.616: INFO: 	Container client-container ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-bbbcc126-a930-49c1-8b7b-aea07134c9c4 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-bbbcc126-a930-49c1-8b7b-aea07134c9c4 off the node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9
STEP: verifying the node doesn't have the label kubernetes.io/e2e-bbbcc126-a930-49c1-8b7b-aea07134c9c4
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:20:08.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6525" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":277,"completed":227,"skipped":3831,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:20:08.698: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9680
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 27 17:20:08.852: INFO: Waiting up to 5m0s for pod "pod-a85c932e-b96d-46fc-b221-d6e2bb97a464" in namespace "emptydir-9680" to be "Succeeded or Failed"
Apr 27 17:20:08.855: INFO: Pod "pod-a85c932e-b96d-46fc-b221-d6e2bb97a464": Phase="Pending", Reason="", readiness=false. Elapsed: 2.88101ms
Apr 27 17:20:10.860: INFO: Pod "pod-a85c932e-b96d-46fc-b221-d6e2bb97a464": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007270988s
STEP: Saw pod success
Apr 27 17:20:10.860: INFO: Pod "pod-a85c932e-b96d-46fc-b221-d6e2bb97a464" satisfied condition "Succeeded or Failed"
Apr 27 17:20:10.863: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-a85c932e-b96d-46fc-b221-d6e2bb97a464 container test-container: <nil>
STEP: delete the pod
Apr 27 17:20:10.889: INFO: Waiting for pod pod-a85c932e-b96d-46fc-b221-d6e2bb97a464 to disappear
Apr 27 17:20:10.892: INFO: Pod pod-a85c932e-b96d-46fc-b221-d6e2bb97a464 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:20:10.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9680" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":228,"skipped":3840,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:20:10.901: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5474
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-8a5efa68-d123-4321-8470-f0c5295aafbd
STEP: Creating a pod to test consume configMaps
Apr 27 17:20:11.058: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b674c4b0-e4c9-4239-8932-944514bc1be5" in namespace "projected-5474" to be "Succeeded or Failed"
Apr 27 17:20:11.062: INFO: Pod "pod-projected-configmaps-b674c4b0-e4c9-4239-8932-944514bc1be5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.504588ms
Apr 27 17:20:13.066: INFO: Pod "pod-projected-configmaps-b674c4b0-e4c9-4239-8932-944514bc1be5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007993911s
STEP: Saw pod success
Apr 27 17:20:13.066: INFO: Pod "pod-projected-configmaps-b674c4b0-e4c9-4239-8932-944514bc1be5" satisfied condition "Succeeded or Failed"
Apr 27 17:20:13.069: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-projected-configmaps-b674c4b0-e4c9-4239-8932-944514bc1be5 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 17:20:13.085: INFO: Waiting for pod pod-projected-configmaps-b674c4b0-e4c9-4239-8932-944514bc1be5 to disappear
Apr 27 17:20:13.088: INFO: Pod pod-projected-configmaps-b674c4b0-e4c9-4239-8932-944514bc1be5 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:20:13.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5474" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":277,"completed":229,"skipped":3859,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:20:13.097: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5222
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:20:13.252: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4e47e928-d501-4426-9ecd-437f078b53db" in namespace "downward-api-5222" to be "Succeeded or Failed"
Apr 27 17:20:13.255: INFO: Pod "downwardapi-volume-4e47e928-d501-4426-9ecd-437f078b53db": Phase="Pending", Reason="", readiness=false. Elapsed: 3.110295ms
Apr 27 17:20:15.258: INFO: Pod "downwardapi-volume-4e47e928-d501-4426-9ecd-437f078b53db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006703361s
STEP: Saw pod success
Apr 27 17:20:15.259: INFO: Pod "downwardapi-volume-4e47e928-d501-4426-9ecd-437f078b53db" satisfied condition "Succeeded or Failed"
Apr 27 17:20:15.262: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downwardapi-volume-4e47e928-d501-4426-9ecd-437f078b53db container client-container: <nil>
STEP: delete the pod
Apr 27 17:20:15.280: INFO: Waiting for pod downwardapi-volume-4e47e928-d501-4426-9ecd-437f078b53db to disappear
Apr 27 17:20:15.283: INFO: Pod downwardapi-volume-4e47e928-d501-4426-9ecd-437f078b53db no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:20:15.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5222" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":277,"completed":230,"skipped":3860,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:20:15.293: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4483
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-4483
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating stateful set ss in namespace statefulset-4483
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4483
Apr 27 17:20:15.454: INFO: Found 0 stateful pods, waiting for 1
Apr 27 17:20:25.458: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Apr 27 17:20:25.461: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 17:20:31.206: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 17:20:31.206: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 17:20:31.206: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 17:20:31.210: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 17:20:31.210: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 17:20:31.223: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Apr 27 17:20:31.223: INFO: ss-0  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:15 +0000 UTC  }]
Apr 27 17:20:31.223: INFO: 
Apr 27 17:20:31.223: INFO: StatefulSet ss has not reached scale 3, at 1
Apr 27 17:20:32.227: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996809364s
Apr 27 17:20:33.232: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992234933s
Apr 27 17:20:34.268: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987239748s
Apr 27 17:20:35.273: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.95170809s
Apr 27 17:20:36.278: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.946755269s
Apr 27 17:20:37.282: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.941747763s
Apr 27 17:20:38.287: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.937051117s
Apr 27 17:20:39.291: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.932451942s
Apr 27 17:20:40.296: INFO: Verifying statefulset ss doesn't scale past 3 for another 927.791681ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4483
Apr 27 17:20:41.304: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:20:41.766: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 17:20:41.766: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 17:20:41.766: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 17:20:41.766: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:20:42.274: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 27 17:20:42.275: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 17:20:42.275: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 17:20:42.275: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:20:42.700: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 27 17:20:42.700: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 17:20:42.700: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 17:20:42.705: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 17:20:42.705: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 17:20:42.705: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Apr 27 17:20:42.710: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 17:20:43.175: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 17:20:43.175: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 17:20:43.175: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 17:20:43.175: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 17:20:43.640: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 17:20:43.640: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 17:20:43.640: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 17:20:43.640: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 17:20:44.127: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 17:20:44.127: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 17:20:44.127: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 17:20:44.127: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 17:20:44.131: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Apr 27 17:20:54.140: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 17:20:54.140: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 17:20:54.141: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 17:20:54.152: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Apr 27 17:20:54.152: INFO: ss-0  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:15 +0000 UTC  }]
Apr 27 17:20:54.153: INFO: ss-1  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  }]
Apr 27 17:20:54.153: INFO: ss-2  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  }]
Apr 27 17:20:54.153: INFO: 
Apr 27 17:20:54.153: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 27 17:20:55.157: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Apr 27 17:20:55.157: INFO: ss-0  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:15 +0000 UTC  }]
Apr 27 17:20:55.157: INFO: ss-1  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  }]
Apr 27 17:20:55.157: INFO: ss-2  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  }]
Apr 27 17:20:55.157: INFO: 
Apr 27 17:20:55.157: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 27 17:20:56.162: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Apr 27 17:20:56.162: INFO: ss-0  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:15 +0000 UTC  }]
Apr 27 17:20:56.162: INFO: ss-1  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  }]
Apr 27 17:20:56.162: INFO: ss-2  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  }]
Apr 27 17:20:56.162: INFO: 
Apr 27 17:20:56.162: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 27 17:20:57.167: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Apr 27 17:20:57.167: INFO: ss-0  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:15 +0000 UTC  }]
Apr 27 17:20:57.167: INFO: ss-1  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  }]
Apr 27 17:20:57.167: INFO: ss-2  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  }]
Apr 27 17:20:57.167: INFO: 
Apr 27 17:20:57.167: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 27 17:20:58.172: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Apr 27 17:20:58.173: INFO: ss-0  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:15 +0000 UTC  }]
Apr 27 17:20:58.173: INFO: ss-1  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  }]
Apr 27 17:20:58.173: INFO: ss-2  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  }]
Apr 27 17:20:58.173: INFO: 
Apr 27 17:20:58.173: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 27 17:20:59.179: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Apr 27 17:20:59.180: INFO: ss-0  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:15 +0000 UTC  }]
Apr 27 17:20:59.180: INFO: ss-1  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  }]
Apr 27 17:20:59.180: INFO: ss-2  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  }]
Apr 27 17:20:59.180: INFO: 
Apr 27 17:20:59.180: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 27 17:21:00.185: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Apr 27 17:21:00.186: INFO: ss-0  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:15 +0000 UTC  }]
Apr 27 17:21:00.186: INFO: ss-1  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  }]
Apr 27 17:21:00.186: INFO: ss-2  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  }]
Apr 27 17:21:00.186: INFO: 
Apr 27 17:21:00.186: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 27 17:21:01.191: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Apr 27 17:21:01.191: INFO: ss-0  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:15 +0000 UTC  }]
Apr 27 17:21:01.191: INFO: ss-1  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  }]
Apr 27 17:21:01.191: INFO: ss-2  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  }]
Apr 27 17:21:01.191: INFO: 
Apr 27 17:21:01.191: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 27 17:21:02.196: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Apr 27 17:21:02.196: INFO: ss-0  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:15 +0000 UTC  }]
Apr 27 17:21:02.196: INFO: ss-1  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  }]
Apr 27 17:21:02.196: INFO: ss-2  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  }]
Apr 27 17:21:02.196: INFO: 
Apr 27 17:21:02.196: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 27 17:21:03.202: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Apr 27 17:21:03.202: INFO: ss-0  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:15 +0000 UTC  }]
Apr 27 17:21:03.202: INFO: ss-1  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  }]
Apr 27 17:21:03.202: INFO: ss-2  shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:44 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 17:20:31 +0000 UTC  }]
Apr 27 17:21:03.202: INFO: 
Apr 27 17:21:03.202: INFO: StatefulSet ss has not reached scale 0, at 3
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4483
Apr 27 17:21:04.208: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:21:04.443: INFO: rc: 1
Apr 27 17:21:04.443: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Apr 27 17:21:14.443: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:21:19.518: INFO: rc: 1
Apr 27 17:21:19.518: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:21:29.519: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:21:29.595: INFO: rc: 1
Apr 27 17:21:29.595: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:21:39.596: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:21:39.710: INFO: rc: 1
Apr 27 17:21:39.710: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:21:49.710: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:21:49.784: INFO: rc: 1
Apr 27 17:21:49.784: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:21:59.784: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:21:59.859: INFO: rc: 1
Apr 27 17:21:59.859: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:22:09.859: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:22:09.952: INFO: rc: 1
Apr 27 17:22:09.952: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:22:19.952: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:22:25.027: INFO: rc: 1
Apr 27 17:22:25.027: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:22:35.028: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:22:35.125: INFO: rc: 1
Apr 27 17:22:35.125: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:22:45.125: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:22:45.198: INFO: rc: 1
Apr 27 17:22:45.198: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:22:55.198: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:22:55.326: INFO: rc: 1
Apr 27 17:22:55.326: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:23:05.326: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:23:05.403: INFO: rc: 1
Apr 27 17:23:05.403: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:23:15.403: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:23:20.479: INFO: rc: 1
Apr 27 17:23:20.479: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:23:30.479: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:23:30.593: INFO: rc: 1
Apr 27 17:23:30.593: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:23:40.593: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:23:40.664: INFO: rc: 1
Apr 27 17:23:40.664: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:23:50.664: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:23:50.737: INFO: rc: 1
Apr 27 17:23:50.737: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:24:00.738: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:24:00.815: INFO: rc: 1
Apr 27 17:24:00.815: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:24:10.815: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:24:10.934: INFO: rc: 1
Apr 27 17:24:10.934: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:24:20.934: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:24:21.032: INFO: rc: 1
Apr 27 17:24:21.032: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:24:31.032: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:24:31.104: INFO: rc: 1
Apr 27 17:24:31.105: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:24:41.105: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:24:41.198: INFO: rc: 1
Apr 27 17:24:41.199: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:24:51.199: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:24:56.277: INFO: rc: 1
Apr 27 17:24:56.277: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:25:06.277: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:25:06.349: INFO: rc: 1
Apr 27 17:25:06.349: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:25:16.349: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:25:16.462: INFO: rc: 1
Apr 27 17:25:16.462: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:25:26.463: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:25:26.533: INFO: rc: 1
Apr 27 17:25:26.533: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:25:36.533: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:25:36.601: INFO: rc: 1
Apr 27 17:25:36.601: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:25:46.602: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:25:46.680: INFO: rc: 1
Apr 27 17:25:46.680: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:25:56.680: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:25:56.775: INFO: rc: 1
Apr 27 17:25:56.775: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Apr 27 17:26:06.775: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4483 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:26:06.846: INFO: rc: 1
Apr 27 17:26:06.846: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: 
Apr 27 17:26:06.846: INFO: Scaling statefulset ss to 0
Apr 27 17:26:06.857: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 17:26:06.860: INFO: Deleting all statefulset in ns statefulset-4483
Apr 27 17:26:06.863: INFO: Scaling statefulset ss to 0
Apr 27 17:26:06.873: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 17:26:06.875: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:26:06.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4483" for this suite.

• [SLOW TEST:351.601 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":277,"completed":231,"skipped":3868,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:26:06.895: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-1356
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-1356, will wait for the garbage collector to delete the pods
Apr 27 17:26:09.109: INFO: Deleting Job.batch foo took: 6.120888ms
Apr 27 17:26:09.209: INFO: Terminating Job.batch foo pods took: 100.295408ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:26:55.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1356" for this suite.
•{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":277,"completed":232,"skipped":3881,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:26:55.123: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7303
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service nodeport-service with the type=NodePort in namespace services-7303
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-7303
STEP: creating replication controller externalsvc in namespace services-7303
I0427 17:26:55.294827    5439 runners.go:190] Created replication controller with name: externalsvc, namespace: services-7303, replica count: 2
I0427 17:26:58.346929    5439 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Apr 27 17:26:58.365: INFO: Creating new exec pod
Apr 27 17:27:00.377: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-7303 execpodf9628 -- /bin/sh -x -c nslookup nodeport-service'
Apr 27 17:27:00.843: INFO: stderr: "+ nslookup nodeport-service\n"
Apr 27 17:27:00.843: INFO: stdout: "Server:\t\t100.104.0.10\nAddress:\t100.104.0.10#53\n\nnodeport-service.services-7303.svc.cluster.local\tcanonical name = externalsvc.services-7303.svc.cluster.local.\nName:\texternalsvc.services-7303.svc.cluster.local\nAddress: 100.108.85.82\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-7303, will wait for the garbage collector to delete the pods
Apr 27 17:27:00.903: INFO: Deleting ReplicationController externalsvc took: 6.170294ms
Apr 27 17:27:01.403: INFO: Terminating ReplicationController externalsvc pods took: 500.313664ms
Apr 27 17:27:05.218: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:27:05.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7303" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":277,"completed":233,"skipped":3892,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:27:05.237: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6795
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:27:09.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6795" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":277,"completed":234,"skipped":3900,"failed":0}
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:27:09.432: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5342
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:27:09.598: INFO: The status of Pod test-webserver-32d18369-e09a-4bf4-a9f8-bfed6fa86504 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 17:27:11.603: INFO: The status of Pod test-webserver-32d18369-e09a-4bf4-a9f8-bfed6fa86504 is Running (Ready = false)
Apr 27 17:27:13.604: INFO: The status of Pod test-webserver-32d18369-e09a-4bf4-a9f8-bfed6fa86504 is Running (Ready = false)
Apr 27 17:27:15.603: INFO: The status of Pod test-webserver-32d18369-e09a-4bf4-a9f8-bfed6fa86504 is Running (Ready = false)
Apr 27 17:27:17.603: INFO: The status of Pod test-webserver-32d18369-e09a-4bf4-a9f8-bfed6fa86504 is Running (Ready = false)
Apr 27 17:27:19.604: INFO: The status of Pod test-webserver-32d18369-e09a-4bf4-a9f8-bfed6fa86504 is Running (Ready = false)
Apr 27 17:27:21.603: INFO: The status of Pod test-webserver-32d18369-e09a-4bf4-a9f8-bfed6fa86504 is Running (Ready = false)
Apr 27 17:27:23.604: INFO: The status of Pod test-webserver-32d18369-e09a-4bf4-a9f8-bfed6fa86504 is Running (Ready = false)
Apr 27 17:27:25.603: INFO: The status of Pod test-webserver-32d18369-e09a-4bf4-a9f8-bfed6fa86504 is Running (Ready = true)
Apr 27 17:27:25.608: INFO: Container started at 2020-04-27 17:27:10 +0000 UTC, pod became ready at 2020-04-27 17:27:25 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:27:25.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5342" for this suite.
•{"msg":"PASSED [k8s.io] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":277,"completed":235,"skipped":3903,"failed":0}
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:27:25.618: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-1005
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
Apr 27 17:27:26.302: INFO: created pod pod-service-account-defaultsa
Apr 27 17:27:26.302: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr 27 17:27:26.308: INFO: created pod pod-service-account-mountsa
Apr 27 17:27:26.308: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr 27 17:27:26.314: INFO: created pod pod-service-account-nomountsa
Apr 27 17:27:26.314: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr 27 17:27:26.320: INFO: created pod pod-service-account-defaultsa-mountspec
Apr 27 17:27:26.320: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr 27 17:27:26.325: INFO: created pod pod-service-account-mountsa-mountspec
Apr 27 17:27:26.325: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr 27 17:27:26.330: INFO: created pod pod-service-account-nomountsa-mountspec
Apr 27 17:27:26.330: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr 27 17:27:26.335: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr 27 17:27:26.335: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr 27 17:27:26.340: INFO: created pod pod-service-account-mountsa-nomountspec
Apr 27 17:27:26.340: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr 27 17:27:26.345: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr 27 17:27:26.345: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:27:26.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1005" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":277,"completed":236,"skipped":3913,"failed":0}
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:27:26.356: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1223
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:27:32.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1223" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":277,"completed":237,"skipped":3916,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:27:32.631: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9371
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 27 17:27:32.783: INFO: Waiting up to 5m0s for pod "pod-816ef89e-2683-41d5-832f-4656ae580dc1" in namespace "emptydir-9371" to be "Succeeded or Failed"
Apr 27 17:27:32.786: INFO: Pod "pod-816ef89e-2683-41d5-832f-4656ae580dc1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.780078ms
Apr 27 17:27:34.791: INFO: Pod "pod-816ef89e-2683-41d5-832f-4656ae580dc1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007633927s
STEP: Saw pod success
Apr 27 17:27:34.791: INFO: Pod "pod-816ef89e-2683-41d5-832f-4656ae580dc1" satisfied condition "Succeeded or Failed"
Apr 27 17:27:34.794: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-816ef89e-2683-41d5-832f-4656ae580dc1 container test-container: <nil>
STEP: delete the pod
Apr 27 17:27:34.904: INFO: Waiting for pod pod-816ef89e-2683-41d5-832f-4656ae580dc1 to disappear
Apr 27 17:27:34.907: INFO: Pod pod-816ef89e-2683-41d5-832f-4656ae580dc1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:27:34.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9371" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":238,"skipped":3946,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:27:34.917: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2130
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Apr 27 17:27:35.075: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2130 /api/v1/namespaces/watch-2130/configmaps/e2e-watch-test-watch-closed d3848e70-f46e-4c4f-a40c-32157835d6a7 36495 0 2020-04-27 17:27:35 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-04-27 17:27:35 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 17:27:35.075: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2130 /api/v1/namespaces/watch-2130/configmaps/e2e-watch-test-watch-closed d3848e70-f46e-4c4f-a40c-32157835d6a7 36496 0 2020-04-27 17:27:35 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-04-27 17:27:35 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Apr 27 17:27:35.089: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2130 /api/v1/namespaces/watch-2130/configmaps/e2e-watch-test-watch-closed d3848e70-f46e-4c4f-a40c-32157835d6a7 36497 0 2020-04-27 17:27:35 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-04-27 17:27:35 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 17:27:35.089: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2130 /api/v1/namespaces/watch-2130/configmaps/e2e-watch-test-watch-closed d3848e70-f46e-4c4f-a40c-32157835d6a7 36498 0 2020-04-27 17:27:35 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-04-27 17:27:35 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:27:35.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2130" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":277,"completed":239,"skipped":4000,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:27:35.099: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-415
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-86fdf160-60d2-4256-a2f9-5c5e98fab29b
STEP: Creating a pod to test consume configMaps
Apr 27 17:27:35.258: INFO: Waiting up to 5m0s for pod "pod-configmaps-479f53eb-668d-439e-b8bc-a6079a3d664b" in namespace "configmap-415" to be "Succeeded or Failed"
Apr 27 17:27:35.261: INFO: Pod "pod-configmaps-479f53eb-668d-439e-b8bc-a6079a3d664b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.974233ms
Apr 27 17:27:37.265: INFO: Pod "pod-configmaps-479f53eb-668d-439e-b8bc-a6079a3d664b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007534878s
STEP: Saw pod success
Apr 27 17:27:37.265: INFO: Pod "pod-configmaps-479f53eb-668d-439e-b8bc-a6079a3d664b" satisfied condition "Succeeded or Failed"
Apr 27 17:27:37.268: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-configmaps-479f53eb-668d-439e-b8bc-a6079a3d664b container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 17:27:37.287: INFO: Waiting for pod pod-configmaps-479f53eb-668d-439e-b8bc-a6079a3d664b to disappear
Apr 27 17:27:37.290: INFO: Pod pod-configmaps-479f53eb-668d-439e-b8bc-a6079a3d664b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:27:37.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-415" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":277,"completed":240,"skipped":4047,"failed":0}
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:27:37.300: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3417
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3417.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3417.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3417.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3417.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 17:27:41.648: INFO: DNS probes using dns-test-20876deb-3206-442f-92d3-04669dc74d54 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3417.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3417.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3417.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3417.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 17:27:45.770: INFO: File wheezy_udp@dns-test-service-3.dns-3417.svc.cluster.local from pod  dns-3417/dns-test-ed77bb3b-d3d4-4a95-a44a-9f09b94005f8 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 17:27:45.855: INFO: File jessie_udp@dns-test-service-3.dns-3417.svc.cluster.local from pod  dns-3417/dns-test-ed77bb3b-d3d4-4a95-a44a-9f09b94005f8 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 17:27:45.855: INFO: Lookups using dns-3417/dns-test-ed77bb3b-d3d4-4a95-a44a-9f09b94005f8 failed for: [wheezy_udp@dns-test-service-3.dns-3417.svc.cluster.local jessie_udp@dns-test-service-3.dns-3417.svc.cluster.local]

Apr 27 17:27:50.862: INFO: File wheezy_udp@dns-test-service-3.dns-3417.svc.cluster.local from pod  dns-3417/dns-test-ed77bb3b-d3d4-4a95-a44a-9f09b94005f8 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 17:27:50.905: INFO: File jessie_udp@dns-test-service-3.dns-3417.svc.cluster.local from pod  dns-3417/dns-test-ed77bb3b-d3d4-4a95-a44a-9f09b94005f8 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 17:27:50.905: INFO: Lookups using dns-3417/dns-test-ed77bb3b-d3d4-4a95-a44a-9f09b94005f8 failed for: [wheezy_udp@dns-test-service-3.dns-3417.svc.cluster.local jessie_udp@dns-test-service-3.dns-3417.svc.cluster.local]

Apr 27 17:27:55.863: INFO: File wheezy_udp@dns-test-service-3.dns-3417.svc.cluster.local from pod  dns-3417/dns-test-ed77bb3b-d3d4-4a95-a44a-9f09b94005f8 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 17:27:55.949: INFO: File jessie_udp@dns-test-service-3.dns-3417.svc.cluster.local from pod  dns-3417/dns-test-ed77bb3b-d3d4-4a95-a44a-9f09b94005f8 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 17:27:55.949: INFO: Lookups using dns-3417/dns-test-ed77bb3b-d3d4-4a95-a44a-9f09b94005f8 failed for: [wheezy_udp@dns-test-service-3.dns-3417.svc.cluster.local jessie_udp@dns-test-service-3.dns-3417.svc.cluster.local]

Apr 27 17:28:00.865: INFO: File wheezy_udp@dns-test-service-3.dns-3417.svc.cluster.local from pod  dns-3417/dns-test-ed77bb3b-d3d4-4a95-a44a-9f09b94005f8 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 17:28:00.947: INFO: File jessie_udp@dns-test-service-3.dns-3417.svc.cluster.local from pod  dns-3417/dns-test-ed77bb3b-d3d4-4a95-a44a-9f09b94005f8 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 17:28:00.947: INFO: Lookups using dns-3417/dns-test-ed77bb3b-d3d4-4a95-a44a-9f09b94005f8 failed for: [wheezy_udp@dns-test-service-3.dns-3417.svc.cluster.local jessie_udp@dns-test-service-3.dns-3417.svc.cluster.local]

Apr 27 17:28:05.863: INFO: File wheezy_udp@dns-test-service-3.dns-3417.svc.cluster.local from pod  dns-3417/dns-test-ed77bb3b-d3d4-4a95-a44a-9f09b94005f8 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 17:28:05.948: INFO: File jessie_udp@dns-test-service-3.dns-3417.svc.cluster.local from pod  dns-3417/dns-test-ed77bb3b-d3d4-4a95-a44a-9f09b94005f8 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 27 17:28:05.948: INFO: Lookups using dns-3417/dns-test-ed77bb3b-d3d4-4a95-a44a-9f09b94005f8 failed for: [wheezy_udp@dns-test-service-3.dns-3417.svc.cluster.local jessie_udp@dns-test-service-3.dns-3417.svc.cluster.local]

Apr 27 17:28:10.905: INFO: DNS probes using dns-test-ed77bb3b-d3d4-4a95-a44a-9f09b94005f8 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3417.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3417.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3417.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3417.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 17:28:15.125: INFO: DNS probes using dns-test-b32fc0cf-6c9f-45ea-811e-f89cdc1eb39d succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:28:15.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3417" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":277,"completed":241,"skipped":4050,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:28:15.163: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7615
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:28:15.308: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr 27 17:28:18.920: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7615 create -f -'
Apr 27 17:28:24.513: INFO: stderr: ""
Apr 27 17:28:24.513: INFO: stdout: "e2e-test-crd-publish-openapi-1713-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 27 17:28:24.513: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7615 delete e2e-test-crd-publish-openapi-1713-crds test-cr'
Apr 27 17:28:24.593: INFO: stderr: ""
Apr 27 17:28:24.593: INFO: stdout: "e2e-test-crd-publish-openapi-1713-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Apr 27 17:28:24.593: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7615 apply -f -'
Apr 27 17:28:24.838: INFO: stderr: ""
Apr 27 17:28:24.838: INFO: stdout: "e2e-test-crd-publish-openapi-1713-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 27 17:28:24.838: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7615 delete e2e-test-crd-publish-openapi-1713-crds test-cr'
Apr 27 17:28:24.937: INFO: stderr: ""
Apr 27 17:28:24.937: INFO: stdout: "e2e-test-crd-publish-openapi-1713-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Apr 27 17:28:24.937: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-1713-crds'
Apr 27 17:28:25.084: INFO: stderr: ""
Apr 27 17:28:25.084: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1713-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:28:28.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7615" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":277,"completed":242,"skipped":4056,"failed":0}
SSSSSSSSSSSSS
------------------------------
[k8s.io] Lease 
  lease API should be available [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Lease
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:28:28.678: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename lease-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in lease-test-3648
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Lease
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:28:28.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-3648" for this suite.
•{"msg":"PASSED [k8s.io] Lease lease API should be available [Conformance]","total":277,"completed":243,"skipped":4069,"failed":0}
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:28:28.874: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3048
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override command
Apr 27 17:28:29.027: INFO: Waiting up to 5m0s for pod "client-containers-36339bbe-2a04-4220-8f84-c61824a0901d" in namespace "containers-3048" to be "Succeeded or Failed"
Apr 27 17:28:29.030: INFO: Pod "client-containers-36339bbe-2a04-4220-8f84-c61824a0901d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.027637ms
Apr 27 17:28:31.035: INFO: Pod "client-containers-36339bbe-2a04-4220-8f84-c61824a0901d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00836755s
STEP: Saw pod success
Apr 27 17:28:31.035: INFO: Pod "client-containers-36339bbe-2a04-4220-8f84-c61824a0901d" satisfied condition "Succeeded or Failed"
Apr 27 17:28:31.038: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod client-containers-36339bbe-2a04-4220-8f84-c61824a0901d container test-container: <nil>
STEP: delete the pod
Apr 27 17:28:31.056: INFO: Waiting for pod client-containers-36339bbe-2a04-4220-8f84-c61824a0901d to disappear
Apr 27 17:28:31.059: INFO: Pod client-containers-36339bbe-2a04-4220-8f84-c61824a0901d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:28:31.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3048" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":277,"completed":244,"skipped":4070,"failed":0}
SSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:28:31.068: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6267
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6267 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6267;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6267 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6267;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6267.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6267.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6267.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6267.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6267.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6267.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6267.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6267.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6267.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6267.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6267.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6267.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6267.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 3.201.109.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.109.201.3_udp@PTR;check="$$(dig +tcp +noall +answer +search 3.201.109.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.109.201.3_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6267 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6267;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6267 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6267;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6267.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6267.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6267.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6267.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6267.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6267.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6267.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6267.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6267.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6267.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6267.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6267.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6267.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 3.201.109.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.109.201.3_udp@PTR;check="$$(dig +tcp +noall +answer +search 3.201.109.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.109.201.3_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 17:28:35.341: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:35.385: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:35.391: INFO: Unable to read wheezy_udp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:35.396: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:35.401: INFO: Unable to read wheezy_udp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:35.405: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:35.410: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:35.414: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:35.842: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:35.848: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:35.852: INFO: Unable to read jessie_udp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:35.857: INFO: Unable to read jessie_tcp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:35.861: INFO: Unable to read jessie_udp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:35.866: INFO: Unable to read jessie_tcp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:35.870: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:35.875: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:36.210: INFO: Lookups using dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6267 wheezy_tcp@dns-test-service.dns-6267 wheezy_udp@dns-test-service.dns-6267.svc wheezy_tcp@dns-test-service.dns-6267.svc wheezy_udp@_http._tcp.dns-test-service.dns-6267.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6267.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6267 jessie_tcp@dns-test-service.dns-6267 jessie_udp@dns-test-service.dns-6267.svc jessie_tcp@dns-test-service.dns-6267.svc jessie_udp@_http._tcp.dns-test-service.dns-6267.svc jessie_tcp@_http._tcp.dns-test-service.dns-6267.svc]

Apr 27 17:28:41.216: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:41.259: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:41.264: INFO: Unable to read wheezy_udp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:41.269: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:41.273: INFO: Unable to read wheezy_udp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:41.278: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:41.282: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:41.286: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:41.674: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:41.683: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:41.688: INFO: Unable to read jessie_udp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:41.695: INFO: Unable to read jessie_tcp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:41.702: INFO: Unable to read jessie_udp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:41.746: INFO: Unable to read jessie_tcp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:41.752: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:41.757: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:42.103: INFO: Lookups using dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6267 wheezy_tcp@dns-test-service.dns-6267 wheezy_udp@dns-test-service.dns-6267.svc wheezy_tcp@dns-test-service.dns-6267.svc wheezy_udp@_http._tcp.dns-test-service.dns-6267.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6267.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6267 jessie_tcp@dns-test-service.dns-6267 jessie_udp@dns-test-service.dns-6267.svc jessie_tcp@dns-test-service.dns-6267.svc jessie_udp@_http._tcp.dns-test-service.dns-6267.svc jessie_tcp@_http._tcp.dns-test-service.dns-6267.svc]

Apr 27 17:28:46.217: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:46.222: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:46.227: INFO: Unable to read wheezy_udp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:46.232: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:46.237: INFO: Unable to read wheezy_udp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:46.243: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:46.248: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:46.252: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:46.640: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:46.645: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:46.650: INFO: Unable to read jessie_udp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:46.655: INFO: Unable to read jessie_tcp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:46.660: INFO: Unable to read jessie_udp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:46.664: INFO: Unable to read jessie_tcp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:46.668: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:46.673: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:47.058: INFO: Lookups using dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6267 wheezy_tcp@dns-test-service.dns-6267 wheezy_udp@dns-test-service.dns-6267.svc wheezy_tcp@dns-test-service.dns-6267.svc wheezy_udp@_http._tcp.dns-test-service.dns-6267.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6267.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6267 jessie_tcp@dns-test-service.dns-6267 jessie_udp@dns-test-service.dns-6267.svc jessie_tcp@dns-test-service.dns-6267.svc jessie_udp@_http._tcp.dns-test-service.dns-6267.svc jessie_tcp@_http._tcp.dns-test-service.dns-6267.svc]

Apr 27 17:28:51.217: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:51.260: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:51.265: INFO: Unable to read wheezy_udp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:51.270: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:51.274: INFO: Unable to read wheezy_udp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:51.279: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:51.284: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:51.289: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:51.683: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:51.689: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:51.694: INFO: Unable to read jessie_udp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:51.702: INFO: Unable to read jessie_tcp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:51.706: INFO: Unable to read jessie_udp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:51.711: INFO: Unable to read jessie_tcp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:51.716: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:51.721: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:52.110: INFO: Lookups using dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6267 wheezy_tcp@dns-test-service.dns-6267 wheezy_udp@dns-test-service.dns-6267.svc wheezy_tcp@dns-test-service.dns-6267.svc wheezy_udp@_http._tcp.dns-test-service.dns-6267.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6267.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6267 jessie_tcp@dns-test-service.dns-6267 jessie_udp@dns-test-service.dns-6267.svc jessie_tcp@dns-test-service.dns-6267.svc jessie_udp@_http._tcp.dns-test-service.dns-6267.svc jessie_tcp@_http._tcp.dns-test-service.dns-6267.svc]

Apr 27 17:28:56.217: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:56.261: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:56.267: INFO: Unable to read wheezy_udp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:56.271: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:56.276: INFO: Unable to read wheezy_udp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:56.281: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:56.285: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:56.289: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:56.678: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:56.684: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:56.689: INFO: Unable to read jessie_udp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:56.693: INFO: Unable to read jessie_tcp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:56.698: INFO: Unable to read jessie_udp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:56.703: INFO: Unable to read jessie_tcp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:56.708: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:56.712: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:28:57.059: INFO: Lookups using dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6267 wheezy_tcp@dns-test-service.dns-6267 wheezy_udp@dns-test-service.dns-6267.svc wheezy_tcp@dns-test-service.dns-6267.svc wheezy_udp@_http._tcp.dns-test-service.dns-6267.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6267.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6267 jessie_tcp@dns-test-service.dns-6267 jessie_udp@dns-test-service.dns-6267.svc jessie_tcp@dns-test-service.dns-6267.svc jessie_udp@_http._tcp.dns-test-service.dns-6267.svc jessie_tcp@_http._tcp.dns-test-service.dns-6267.svc]

Apr 27 17:29:01.216: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:29:01.221: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:29:01.226: INFO: Unable to read wheezy_udp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:29:01.230: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:29:01.235: INFO: Unable to read wheezy_udp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:29:01.240: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:29:01.245: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:29:01.253: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:29:01.683: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:29:01.691: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:29:01.699: INFO: Unable to read jessie_udp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:29:01.704: INFO: Unable to read jessie_tcp@dns-test-service.dns-6267 from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:29:01.710: INFO: Unable to read jessie_udp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:29:01.715: INFO: Unable to read jessie_tcp@dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:29:01.720: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:29:01.724: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6267.svc from pod dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4: the server could not find the requested resource (get pods dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4)
Apr 27 17:29:02.113: INFO: Lookups using dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6267 wheezy_tcp@dns-test-service.dns-6267 wheezy_udp@dns-test-service.dns-6267.svc wheezy_tcp@dns-test-service.dns-6267.svc wheezy_udp@_http._tcp.dns-test-service.dns-6267.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6267.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6267 jessie_tcp@dns-test-service.dns-6267 jessie_udp@dns-test-service.dns-6267.svc jessie_tcp@dns-test-service.dns-6267.svc jessie_udp@_http._tcp.dns-test-service.dns-6267.svc jessie_tcp@_http._tcp.dns-test-service.dns-6267.svc]

Apr 27 17:29:08.001: INFO: DNS probes using dns-6267/dns-test-f41b9bc5-1d83-4f25-a34e-1f216b1adbf4 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:29:08.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6267" for this suite.
•{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":277,"completed":245,"skipped":4073,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:29:08.052: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1094
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching services
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:29:08.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1094" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":277,"completed":246,"skipped":4114,"failed":0}
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:29:08.211: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1273
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1273.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1273.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 17:29:10.931: INFO: DNS probes using dns-1273/dns-test-ee04477e-21c1-47bb-a55a-ff6221df3860 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:29:10.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1273" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":277,"completed":247,"skipped":4120,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:29:10.952: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5996
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5996.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-5996.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5996.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-5996.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5996.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5996.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-5996.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5996.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-5996.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5996.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 17:29:13.214: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:13.256: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:13.262: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:13.267: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:13.400: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:13.405: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:13.413: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:13.418: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:13.507: INFO: Lookups using dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5996.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5996.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local jessie_udp@dns-test-service-2.dns-5996.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5996.svc.cluster.local]

Apr 27 17:29:18.514: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:18.519: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:18.523: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:18.528: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:18.659: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:18.666: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:18.672: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:18.676: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:18.807: INFO: Lookups using dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5996.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5996.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local jessie_udp@dns-test-service-2.dns-5996.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5996.svc.cluster.local]

Apr 27 17:29:23.514: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:23.558: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:23.564: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:23.568: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:23.701: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:23.706: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:23.711: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:23.716: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:23.804: INFO: Lookups using dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5996.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5996.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local jessie_udp@dns-test-service-2.dns-5996.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5996.svc.cluster.local]

Apr 27 17:29:28.514: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:28.519: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:28.523: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:28.527: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:28.659: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:28.665: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:28.670: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:28.675: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:28.763: INFO: Lookups using dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5996.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5996.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local jessie_udp@dns-test-service-2.dns-5996.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5996.svc.cluster.local]

Apr 27 17:29:33.514: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:33.519: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:33.524: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:33.528: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:33.660: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:33.666: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:33.671: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:33.675: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:33.805: INFO: Lookups using dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5996.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5996.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local jessie_udp@dns-test-service-2.dns-5996.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5996.svc.cluster.local]

Apr 27 17:29:38.513: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:38.558: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:38.564: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:38.569: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:38.701: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:38.706: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:38.710: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:38.716: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5996.svc.cluster.local from pod dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3: the server could not find the requested resource (get pods dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3)
Apr 27 17:29:38.804: INFO: Lookups using dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5996.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5996.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5996.svc.cluster.local jessie_udp@dns-test-service-2.dns-5996.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5996.svc.cluster.local]

Apr 27 17:29:44.240: INFO: DNS probes using dns-5996/dns-test-4249cd3a-ddcb-4a10-8fa3-72b94b3146a3 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:29:44.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5996" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":277,"completed":248,"skipped":4172,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:29:44.273: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-4660
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:29:44.416: INFO: Creating ReplicaSet my-hostname-basic-413530b2-48af-47ba-881b-765f253915b9
Apr 27 17:29:44.423: INFO: Pod name my-hostname-basic-413530b2-48af-47ba-881b-765f253915b9: Found 0 pods out of 1
Apr 27 17:29:49.427: INFO: Pod name my-hostname-basic-413530b2-48af-47ba-881b-765f253915b9: Found 1 pods out of 1
Apr 27 17:29:49.427: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-413530b2-48af-47ba-881b-765f253915b9" is running
Apr 27 17:29:49.430: INFO: Pod "my-hostname-basic-413530b2-48af-47ba-881b-765f253915b9-ll4xr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 17:29:44 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 17:29:46 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 17:29:46 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 17:29:44 +0000 UTC Reason: Message:}])
Apr 27 17:29:49.430: INFO: Trying to dial the pod
Apr 27 17:29:54.527: INFO: Controller my-hostname-basic-413530b2-48af-47ba-881b-765f253915b9: Got expected result from replica 1 [my-hostname-basic-413530b2-48af-47ba-881b-765f253915b9-ll4xr]: "my-hostname-basic-413530b2-48af-47ba-881b-765f253915b9-ll4xr", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:29:54.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4660" for this suite.
•{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":277,"completed":249,"skipped":4201,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:29:54.538: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1619
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with configMap that has name projected-configmap-test-upd-34e044a9-0a03-4e1a-8562-26f2be9bc007
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-34e044a9-0a03-4e1a-8562-26f2be9bc007
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:29:58.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1619" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":250,"skipped":4206,"failed":0}

------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:29:58.828: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8974
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Apr 27 17:29:58.973: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-8974'
Apr 27 17:30:04.227: INFO: stderr: ""
Apr 27 17:30:04.227: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Apr 27 17:30:05.231: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:30:05.231: INFO: Found 1 / 1
Apr 27 17:30:05.231: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Apr 27 17:30:05.234: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:30:05.234: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 27 17:30:05.234: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config patch pod agnhost-master-tpnnm --namespace=kubectl-8974 -p {"metadata":{"annotations":{"x":"y"}}}'
Apr 27 17:30:05.311: INFO: stderr: ""
Apr 27 17:30:05.311: INFO: stdout: "pod/agnhost-master-tpnnm patched\n"
STEP: checking annotations
Apr 27 17:30:05.314: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:30:05.314: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:30:05.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8974" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":277,"completed":251,"skipped":4206,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:30:05.324: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-2950
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Apr 27 17:30:05.470: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the sample API server.
Apr 27 17:30:06.205: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
Apr 27 17:30:08.251: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:30:10.256: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:30:12.272: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:30:14.271: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:30:16.273: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:30:18.273: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 17:30:21.672: INFO: Waited 1.408887492s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:30:22.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-2950" for this suite.
•{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":277,"completed":252,"skipped":4241,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:30:22.416: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-9555
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:30:22.599: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:30:24.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9555" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":277,"completed":253,"skipped":4248,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:30:24.198: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8027
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-f5wt
STEP: Creating a pod to test atomic-volume-subpath
Apr 27 17:30:24.383: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-f5wt" in namespace "subpath-8027" to be "Succeeded or Failed"
Apr 27 17:30:24.386: INFO: Pod "pod-subpath-test-configmap-f5wt": Phase="Pending", Reason="", readiness=false. Elapsed: 3.191011ms
Apr 27 17:30:26.390: INFO: Pod "pod-subpath-test-configmap-f5wt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00753237s
Apr 27 17:30:28.396: INFO: Pod "pod-subpath-test-configmap-f5wt": Phase="Running", Reason="", readiness=true. Elapsed: 4.012776201s
Apr 27 17:30:30.400: INFO: Pod "pod-subpath-test-configmap-f5wt": Phase="Running", Reason="", readiness=true. Elapsed: 6.01764899s
Apr 27 17:30:32.405: INFO: Pod "pod-subpath-test-configmap-f5wt": Phase="Running", Reason="", readiness=true. Elapsed: 8.022227245s
Apr 27 17:30:34.410: INFO: Pod "pod-subpath-test-configmap-f5wt": Phase="Running", Reason="", readiness=true. Elapsed: 10.027350296s
Apr 27 17:30:36.415: INFO: Pod "pod-subpath-test-configmap-f5wt": Phase="Running", Reason="", readiness=true. Elapsed: 12.032050505s
Apr 27 17:30:38.419: INFO: Pod "pod-subpath-test-configmap-f5wt": Phase="Running", Reason="", readiness=true. Elapsed: 14.036545193s
Apr 27 17:30:40.424: INFO: Pod "pod-subpath-test-configmap-f5wt": Phase="Running", Reason="", readiness=true. Elapsed: 16.040701426s
Apr 27 17:30:42.428: INFO: Pod "pod-subpath-test-configmap-f5wt": Phase="Running", Reason="", readiness=true. Elapsed: 18.045031049s
Apr 27 17:30:44.432: INFO: Pod "pod-subpath-test-configmap-f5wt": Phase="Running", Reason="", readiness=true. Elapsed: 20.049249241s
Apr 27 17:30:46.436: INFO: Pod "pod-subpath-test-configmap-f5wt": Phase="Running", Reason="", readiness=true. Elapsed: 22.053273521s
Apr 27 17:30:48.441: INFO: Pod "pod-subpath-test-configmap-f5wt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.058174101s
STEP: Saw pod success
Apr 27 17:30:48.441: INFO: Pod "pod-subpath-test-configmap-f5wt" satisfied condition "Succeeded or Failed"
Apr 27 17:30:48.444: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-subpath-test-configmap-f5wt container test-container-subpath-configmap-f5wt: <nil>
STEP: delete the pod
Apr 27 17:30:48.506: INFO: Waiting for pod pod-subpath-test-configmap-f5wt to disappear
Apr 27 17:30:48.509: INFO: Pod pod-subpath-test-configmap-f5wt no longer exists
STEP: Deleting pod pod-subpath-test-configmap-f5wt
Apr 27 17:30:48.509: INFO: Deleting pod "pod-subpath-test-configmap-f5wt" in namespace "subpath-8027"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:30:48.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8027" for this suite.
•{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]","total":277,"completed":254,"skipped":4261,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:30:48.521: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-547
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl replace
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Apr 27 17:30:48.665: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-pod --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-547'
Apr 27 17:30:48.777: INFO: stderr: ""
Apr 27 17:30:48.777: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Apr 27 17:30:53.830: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod e2e-test-httpd-pod --namespace=kubectl-547 -o json'
Apr 27 17:30:53.903: INFO: stderr: ""
Apr 27 17:30:53.903: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"100.64.1.85/32\",\n            \"cni.projectcalico.org/podIPs\": \"100.64.1.85/32\",\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2020-04-27T17:30:48Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"managedFields\": [\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:labels\": {\n                            \".\": {},\n                            \"f:run\": {}\n                        }\n                    },\n                    \"f:spec\": {\n                        \"f:containers\": {\n                            \"k:{\\\"name\\\":\\\"e2e-test-httpd-pod\\\"}\": {\n                                \".\": {},\n                                \"f:image\": {},\n                                \"f:imagePullPolicy\": {},\n                                \"f:name\": {},\n                                \"f:resources\": {},\n                                \"f:terminationMessagePath\": {},\n                                \"f:terminationMessagePolicy\": {}\n                            }\n                        },\n                        \"f:dnsPolicy\": {},\n                        \"f:enableServiceLinks\": {},\n                        \"f:restartPolicy\": {},\n                        \"f:schedulerName\": {},\n                        \"f:securityContext\": {},\n                        \"f:terminationGracePeriodSeconds\": {}\n                    }\n                },\n                \"manager\": \"kubectl\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-04-27T17:30:48Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:annotations\": {\n                            \"f:cni.projectcalico.org/podIP\": {},\n                            \"f:cni.projectcalico.org/podIPs\": {}\n                        }\n                    }\n                },\n                \"manager\": \"calico\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-04-27T17:30:49Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:status\": {\n                        \"f:conditions\": {\n                            \"k:{\\\"type\\\":\\\"ContainersReady\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Initialized\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Ready\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            }\n                        },\n                        \"f:containerStatuses\": {},\n                        \"f:hostIP\": {},\n                        \"f:phase\": {},\n                        \"f:podIP\": {},\n                        \"f:podIPs\": {\n                            \".\": {},\n                            \"k:{\\\"ip\\\":\\\"100.64.1.85\\\"}\": {\n                                \".\": {},\n                                \"f:ip\": {}\n                            }\n                        },\n                        \"f:startTime\": {}\n                    }\n                },\n                \"manager\": \"kubelet\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-04-27T17:30:50Z\"\n            }\n        ],\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-547\",\n        \"resourceVersion\": \"37760\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-547/pods/e2e-test-httpd-pod\",\n        \"uid\": \"18de503c-7b4f-4edd-8197-dfb379529519\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-v6zgc\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-v6zgc\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-v6zgc\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-27T17:30:48Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-27T17:30:50Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-27T17:30:50Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-27T17:30:48Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://c89c3459ac42c7f873f754043c3739020112fc0bad60acc9cccbdf27d10e159b\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-04-27T17:30:49Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.0.21\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.64.1.85\",\n        \"podIPs\": [\n            {\n                \"ip\": \"100.64.1.85\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-04-27T17:30:48Z\"\n    }\n}\n"
STEP: replace the image in the pod
Apr 27 17:30:53.903: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config replace -f - --namespace=kubectl-547'
Apr 27 17:30:54.142: INFO: stderr: ""
Apr 27 17:30:54.142: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Apr 27 17:30:54.146: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pods e2e-test-httpd-pod --namespace=kubectl-547'
Apr 27 17:31:05.026: INFO: stderr: ""
Apr 27 17:31:05.026: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:31:05.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-547" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":277,"completed":255,"skipped":4262,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:31:05.037: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1131
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-1131
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Apr 27 17:31:05.193: INFO: Found 0 stateful pods, waiting for 3
Apr 27 17:31:15.198: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 17:31:15.198: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 17:31:15.198: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Apr 27 17:31:15.226: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Apr 27 17:31:25.261: INFO: Updating stateful set ss2
Apr 27 17:31:25.268: INFO: Waiting for Pod statefulset-1131/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Apr 27 17:31:35.306: INFO: Found 2 stateful pods, waiting for 3
Apr 27 17:31:45.312: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 17:31:45.312: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 17:31:45.312: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Apr 27 17:31:45.340: INFO: Updating stateful set ss2
Apr 27 17:31:45.351: INFO: Waiting for Pod statefulset-1131/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 27 17:31:55.376: INFO: Updating stateful set ss2
Apr 27 17:31:55.383: INFO: Waiting for StatefulSet statefulset-1131/ss2 to complete update
Apr 27 17:31:55.383: INFO: Waiting for Pod statefulset-1131/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 17:32:12.265: INFO: Deleting all statefulset in ns statefulset-1131
Apr 27 17:32:12.268: INFO: Scaling statefulset ss2 to 0
Apr 27 17:32:42.290: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 17:32:42.294: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:32:42.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1131" for this suite.
•{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":277,"completed":256,"skipped":4297,"failed":0}

------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:32:42.315: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3964
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 27 17:32:42.467: INFO: Waiting up to 5m0s for pod "pod-4a775560-cc86-411e-a824-27491f465261" in namespace "emptydir-3964" to be "Succeeded or Failed"
Apr 27 17:32:42.470: INFO: Pod "pod-4a775560-cc86-411e-a824-27491f465261": Phase="Pending", Reason="", readiness=false. Elapsed: 2.738824ms
Apr 27 17:32:44.474: INFO: Pod "pod-4a775560-cc86-411e-a824-27491f465261": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006973395s
STEP: Saw pod success
Apr 27 17:32:44.475: INFO: Pod "pod-4a775560-cc86-411e-a824-27491f465261" satisfied condition "Succeeded or Failed"
Apr 27 17:32:44.478: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-4a775560-cc86-411e-a824-27491f465261 container test-container: <nil>
STEP: delete the pod
Apr 27 17:32:44.589: INFO: Waiting for pod pod-4a775560-cc86-411e-a824-27491f465261 to disappear
Apr 27 17:32:44.592: INFO: Pod pod-4a775560-cc86-411e-a824-27491f465261 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:32:44.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3964" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":257,"skipped":4297,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:32:44.602: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4015
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-4015
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-4015
I0427 17:32:44.769460    5439 runners.go:190] Created replication controller with name: externalname-service, namespace: services-4015, replica count: 2
I0427 17:32:47.819995    5439 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 27 17:32:47.820: INFO: Creating new exec pod
Apr 27 17:32:50.832: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-4015 execpodh9qpr -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Apr 27 17:32:56.339: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 27 17:32:56.339: INFO: stdout: ""
Apr 27 17:32:56.340: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-4015 execpodh9qpr -- /bin/sh -x -c nc -zv -t -w 2 100.105.2.198 80'
Apr 27 17:32:56.842: INFO: stderr: "+ nc -zv -t -w 2 100.105.2.198 80\nConnection to 100.105.2.198 80 port [tcp/http] succeeded!\n"
Apr 27 17:32:56.842: INFO: stdout: ""
Apr 27 17:32:56.842: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:32:56.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4015" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":277,"completed":258,"skipped":4310,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:32:56.867: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5819
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-5819
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 27 17:32:57.014: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 27 17:32:57.040: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 17:32:59.044: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:33:01.043: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:33:03.044: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:33:05.044: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:33:07.044: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:33:09.044: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:33:11.044: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:33:13.043: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:33:15.043: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr 27 17:33:15.049: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Apr 27 17:33:17.079: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.0.54 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5819 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 17:33:17.080: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 17:33:18.425: INFO: Found all expected endpoints: [netserver-0]
Apr 27 17:33:18.429: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.1.98 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5819 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 17:33:18.429: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 17:33:19.770: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:33:19.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5819" for this suite.
•{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":259,"skipped":4329,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:33:19.788: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7207
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:33:19.951: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ef9f11b6-e759-4571-9799-bb56e12561a0" in namespace "downward-api-7207" to be "Succeeded or Failed"
Apr 27 17:33:19.954: INFO: Pod "downwardapi-volume-ef9f11b6-e759-4571-9799-bb56e12561a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.80049ms
Apr 27 17:33:21.958: INFO: Pod "downwardapi-volume-ef9f11b6-e759-4571-9799-bb56e12561a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006691129s
STEP: Saw pod success
Apr 27 17:33:21.958: INFO: Pod "downwardapi-volume-ef9f11b6-e759-4571-9799-bb56e12561a0" satisfied condition "Succeeded or Failed"
Apr 27 17:33:21.961: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downwardapi-volume-ef9f11b6-e759-4571-9799-bb56e12561a0 container client-container: <nil>
STEP: delete the pod
Apr 27 17:33:21.980: INFO: Waiting for pod downwardapi-volume-ef9f11b6-e759-4571-9799-bb56e12561a0 to disappear
Apr 27 17:33:21.982: INFO: Pod downwardapi-volume-ef9f11b6-e759-4571-9799-bb56e12561a0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:33:21.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7207" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":260,"skipped":4362,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:33:21.992: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2839
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Apr 27 17:33:22.137: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:33:25.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2839" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":277,"completed":261,"skipped":4394,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:33:25.993: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9391
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Apr 27 17:33:26.138: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-9391'
Apr 27 17:33:26.326: INFO: stderr: ""
Apr 27 17:33:26.326: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 27 17:33:26.326: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9391'
Apr 27 17:33:26.402: INFO: stderr: ""
Apr 27 17:33:26.402: INFO: stdout: "update-demo-nautilus-2gj7p update-demo-nautilus-h8g4g "
Apr 27 17:33:26.403: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-2gj7p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9391'
Apr 27 17:33:26.472: INFO: stderr: ""
Apr 27 17:33:26.472: INFO: stdout: ""
Apr 27 17:33:26.472: INFO: update-demo-nautilus-2gj7p is created but not running
Apr 27 17:33:31.472: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9391'
Apr 27 17:33:31.563: INFO: stderr: ""
Apr 27 17:33:31.563: INFO: stdout: "update-demo-nautilus-2gj7p update-demo-nautilus-h8g4g "
Apr 27 17:33:31.563: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-2gj7p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9391'
Apr 27 17:33:31.644: INFO: stderr: ""
Apr 27 17:33:31.644: INFO: stdout: "true"
Apr 27 17:33:31.644: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-2gj7p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9391'
Apr 27 17:33:31.711: INFO: stderr: ""
Apr 27 17:33:31.711: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 17:33:31.711: INFO: validating pod update-demo-nautilus-2gj7p
Apr 27 17:33:31.801: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 17:33:31.801: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 17:33:31.801: INFO: update-demo-nautilus-2gj7p is verified up and running
Apr 27 17:33:31.801: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-h8g4g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9391'
Apr 27 17:33:31.873: INFO: stderr: ""
Apr 27 17:33:31.873: INFO: stdout: "true"
Apr 27 17:33:31.873: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-h8g4g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9391'
Apr 27 17:33:31.943: INFO: stderr: ""
Apr 27 17:33:31.943: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 17:33:31.943: INFO: validating pod update-demo-nautilus-h8g4g
Apr 27 17:33:32.035: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 17:33:32.035: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 17:33:32.035: INFO: update-demo-nautilus-h8g4g is verified up and running
STEP: scaling down the replication controller
Apr 27 17:33:32.037: INFO: scanned /root for discovery docs: <nil>
Apr 27 17:33:32.038: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-9391'
Apr 27 17:33:33.140: INFO: stderr: ""
Apr 27 17:33:33.140: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 27 17:33:33.140: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9391'
Apr 27 17:33:33.216: INFO: stderr: ""
Apr 27 17:33:33.216: INFO: stdout: "update-demo-nautilus-2gj7p update-demo-nautilus-h8g4g "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr 27 17:33:38.216: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9391'
Apr 27 17:33:38.296: INFO: stderr: ""
Apr 27 17:33:38.296: INFO: stdout: "update-demo-nautilus-2gj7p update-demo-nautilus-h8g4g "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr 27 17:33:43.297: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9391'
Apr 27 17:33:43.374: INFO: stderr: ""
Apr 27 17:33:43.374: INFO: stdout: "update-demo-nautilus-2gj7p update-demo-nautilus-h8g4g "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr 27 17:33:48.374: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9391'
Apr 27 17:33:48.452: INFO: stderr: ""
Apr 27 17:33:48.452: INFO: stdout: "update-demo-nautilus-2gj7p "
Apr 27 17:33:48.452: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-2gj7p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9391'
Apr 27 17:33:48.527: INFO: stderr: ""
Apr 27 17:33:48.527: INFO: stdout: "true"
Apr 27 17:33:48.527: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-2gj7p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9391'
Apr 27 17:33:48.596: INFO: stderr: ""
Apr 27 17:33:48.596: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 17:33:48.596: INFO: validating pod update-demo-nautilus-2gj7p
Apr 27 17:33:48.604: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 17:33:48.604: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 17:33:48.604: INFO: update-demo-nautilus-2gj7p is verified up and running
STEP: scaling up the replication controller
Apr 27 17:33:48.606: INFO: scanned /root for discovery docs: <nil>
Apr 27 17:33:48.606: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-9391'
Apr 27 17:33:49.702: INFO: stderr: ""
Apr 27 17:33:49.702: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 27 17:33:49.702: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9391'
Apr 27 17:33:49.785: INFO: stderr: ""
Apr 27 17:33:49.785: INFO: stdout: "update-demo-nautilus-2gj7p update-demo-nautilus-7zzc5 "
Apr 27 17:33:49.785: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-2gj7p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9391'
Apr 27 17:33:49.878: INFO: stderr: ""
Apr 27 17:33:49.878: INFO: stdout: "true"
Apr 27 17:33:49.878: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-2gj7p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9391'
Apr 27 17:33:49.955: INFO: stderr: ""
Apr 27 17:33:49.955: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 17:33:49.955: INFO: validating pod update-demo-nautilus-2gj7p
Apr 27 17:33:49.962: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 17:33:49.962: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 17:33:49.962: INFO: update-demo-nautilus-2gj7p is verified up and running
Apr 27 17:33:49.962: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-7zzc5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9391'
Apr 27 17:33:50.038: INFO: stderr: ""
Apr 27 17:33:50.038: INFO: stdout: ""
Apr 27 17:33:50.038: INFO: update-demo-nautilus-7zzc5 is created but not running
Apr 27 17:33:55.039: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9391'
Apr 27 17:33:55.129: INFO: stderr: ""
Apr 27 17:33:55.129: INFO: stdout: "update-demo-nautilus-2gj7p update-demo-nautilus-7zzc5 "
Apr 27 17:33:55.129: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-2gj7p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9391'
Apr 27 17:33:55.208: INFO: stderr: ""
Apr 27 17:33:55.208: INFO: stdout: "true"
Apr 27 17:33:55.208: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-2gj7p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9391'
Apr 27 17:33:55.285: INFO: stderr: ""
Apr 27 17:33:55.285: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 17:33:55.285: INFO: validating pod update-demo-nautilus-2gj7p
Apr 27 17:33:55.292: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 17:33:55.292: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 17:33:55.292: INFO: update-demo-nautilus-2gj7p is verified up and running
Apr 27 17:33:55.292: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-7zzc5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9391'
Apr 27 17:33:55.358: INFO: stderr: ""
Apr 27 17:33:55.358: INFO: stdout: "true"
Apr 27 17:33:55.358: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-7zzc5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9391'
Apr 27 17:33:55.432: INFO: stderr: ""
Apr 27 17:33:55.432: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 17:33:55.432: INFO: validating pod update-demo-nautilus-7zzc5
Apr 27 17:33:55.522: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 17:33:55.522: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 17:33:55.522: INFO: update-demo-nautilus-7zzc5 is verified up and running
STEP: using delete to clean up resources
Apr 27 17:33:55.522: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-9391'
Apr 27 17:33:55.598: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 17:33:55.598: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 27 17:33:55.598: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9391'
Apr 27 17:33:55.679: INFO: stderr: "No resources found in kubectl-9391 namespace.\n"
Apr 27 17:33:55.679: INFO: stdout: ""
Apr 27 17:33:55.679: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-9391 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 27 17:33:55.755: INFO: stderr: ""
Apr 27 17:33:55.755: INFO: stdout: "update-demo-nautilus-2gj7p\nupdate-demo-nautilus-7zzc5\n"
Apr 27 17:33:56.255: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9391'
Apr 27 17:33:56.337: INFO: stderr: "No resources found in kubectl-9391 namespace.\n"
Apr 27 17:33:56.337: INFO: stdout: ""
Apr 27 17:33:56.337: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-9391 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 27 17:33:56.415: INFO: stderr: ""
Apr 27 17:33:56.415: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:33:56.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9391" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":277,"completed":262,"skipped":4397,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:33:56.426: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8337
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on node default medium
Apr 27 17:33:56.584: INFO: Waiting up to 5m0s for pod "pod-dd161c3a-cfa5-4606-9edc-e0a8c29e4cf6" in namespace "emptydir-8337" to be "Succeeded or Failed"
Apr 27 17:33:56.587: INFO: Pod "pod-dd161c3a-cfa5-4606-9edc-e0a8c29e4cf6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.247829ms
Apr 27 17:33:58.592: INFO: Pod "pod-dd161c3a-cfa5-4606-9edc-e0a8c29e4cf6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007673594s
STEP: Saw pod success
Apr 27 17:33:58.592: INFO: Pod "pod-dd161c3a-cfa5-4606-9edc-e0a8c29e4cf6" satisfied condition "Succeeded or Failed"
Apr 27 17:33:58.595: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-dd161c3a-cfa5-4606-9edc-e0a8c29e4cf6 container test-container: <nil>
STEP: delete the pod
Apr 27 17:33:58.613: INFO: Waiting for pod pod-dd161c3a-cfa5-4606-9edc-e0a8c29e4cf6 to disappear
Apr 27 17:33:58.616: INFO: Pod pod-dd161c3a-cfa5-4606-9edc-e0a8c29e4cf6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:33:58.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8337" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":263,"skipped":4416,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:33:58.625: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1566
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:33:58.789: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c6c1fbb2-99a0-4478-9445-e6df283bd6a5" in namespace "projected-1566" to be "Succeeded or Failed"
Apr 27 17:33:58.792: INFO: Pod "downwardapi-volume-c6c1fbb2-99a0-4478-9445-e6df283bd6a5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.716625ms
Apr 27 17:34:00.797: INFO: Pod "downwardapi-volume-c6c1fbb2-99a0-4478-9445-e6df283bd6a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007046829s
STEP: Saw pod success
Apr 27 17:34:00.797: INFO: Pod "downwardapi-volume-c6c1fbb2-99a0-4478-9445-e6df283bd6a5" satisfied condition "Succeeded or Failed"
Apr 27 17:34:00.799: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downwardapi-volume-c6c1fbb2-99a0-4478-9445-e6df283bd6a5 container client-container: <nil>
STEP: delete the pod
Apr 27 17:34:00.817: INFO: Waiting for pod downwardapi-volume-c6c1fbb2-99a0-4478-9445-e6df283bd6a5 to disappear
Apr 27 17:34:00.820: INFO: Pod downwardapi-volume-c6c1fbb2-99a0-4478-9445-e6df283bd6a5 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:34:00.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1566" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":277,"completed":264,"skipped":4431,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:34:00.830: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-767
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:34:01.898: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 27 17:34:03.909: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605641, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605641, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605641, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605641, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:34:06.923: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Apr 27 17:34:07.030: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:34:07.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-767" for this suite.
STEP: Destroying namespace "webhook-767-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":277,"completed":265,"skipped":4445,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:34:07.131: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4601
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating secret secrets-4601/secret-test-9977ad5c-c3c7-4ec4-ad40-6196bdba0d4e
STEP: Creating a pod to test consume secrets
Apr 27 17:34:07.290: INFO: Waiting up to 5m0s for pod "pod-configmaps-f6fbf299-8cac-4c49-af2b-701138d488dc" in namespace "secrets-4601" to be "Succeeded or Failed"
Apr 27 17:34:07.292: INFO: Pod "pod-configmaps-f6fbf299-8cac-4c49-af2b-701138d488dc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.569324ms
Apr 27 17:34:09.297: INFO: Pod "pod-configmaps-f6fbf299-8cac-4c49-af2b-701138d488dc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007206377s
STEP: Saw pod success
Apr 27 17:34:09.297: INFO: Pod "pod-configmaps-f6fbf299-8cac-4c49-af2b-701138d488dc" satisfied condition "Succeeded or Failed"
Apr 27 17:34:09.300: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-configmaps-f6fbf299-8cac-4c49-af2b-701138d488dc container env-test: <nil>
STEP: delete the pod
Apr 27 17:34:09.318: INFO: Waiting for pod pod-configmaps-f6fbf299-8cac-4c49-af2b-701138d488dc to disappear
Apr 27 17:34:09.321: INFO: Pod pod-configmaps-f6fbf299-8cac-4c49-af2b-701138d488dc no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:34:09.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4601" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":277,"completed":266,"skipped":4450,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:34:09.330: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1950
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-8d3e11b2-d83c-4df6-b0cf-db2e95ff4498
STEP: Creating a pod to test consume configMaps
Apr 27 17:34:09.492: INFO: Waiting up to 5m0s for pod "pod-configmaps-5e20ca54-30e0-49c8-9e62-d1dcb6a9be64" in namespace "configmap-1950" to be "Succeeded or Failed"
Apr 27 17:34:09.495: INFO: Pod "pod-configmaps-5e20ca54-30e0-49c8-9e62-d1dcb6a9be64": Phase="Pending", Reason="", readiness=false. Elapsed: 2.729713ms
Apr 27 17:34:11.499: INFO: Pod "pod-configmaps-5e20ca54-30e0-49c8-9e62-d1dcb6a9be64": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007238135s
STEP: Saw pod success
Apr 27 17:34:11.499: INFO: Pod "pod-configmaps-5e20ca54-30e0-49c8-9e62-d1dcb6a9be64" satisfied condition "Succeeded or Failed"
Apr 27 17:34:11.503: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod pod-configmaps-5e20ca54-30e0-49c8-9e62-d1dcb6a9be64 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 17:34:11.522: INFO: Waiting for pod pod-configmaps-5e20ca54-30e0-49c8-9e62-d1dcb6a9be64 to disappear
Apr 27 17:34:11.525: INFO: Pod pod-configmaps-5e20ca54-30e0-49c8-9e62-d1dcb6a9be64 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:34:11.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1950" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":267,"skipped":4479,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:34:11.534: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-8995
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Apr 27 17:34:14.712: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:34:15.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8995" for this suite.
•{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":277,"completed":268,"skipped":4490,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:34:15.739: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-848
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0427 17:34:25.911174    5439 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 27 17:34:25.911: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:34:25.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-848" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":277,"completed":269,"skipped":4501,"failed":0}
S
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:34:25.919: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4732
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4732.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-4732.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4732.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4732.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-4732.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4732.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 17:34:30.689: INFO: DNS probes using dns-4732/dns-test-0facdeb4-2eb4-460c-813b-29d6ac5eae4b succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:34:30.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4732" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":277,"completed":270,"skipped":4502,"failed":0}
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:34:30.718: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5607
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Apr 27 17:34:30.862: INFO: namespace kubectl-5607
Apr 27 17:34:30.862: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-5607'
Apr 27 17:34:31.072: INFO: stderr: ""
Apr 27 17:34:31.072: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Apr 27 17:34:32.077: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:34:32.077: INFO: Found 0 / 1
Apr 27 17:34:33.075: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:34:33.075: INFO: Found 1 / 1
Apr 27 17:34:33.075: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 27 17:34:33.079: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 17:34:33.079: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 27 17:34:33.079: INFO: wait on agnhost-master startup in kubectl-5607 
Apr 27 17:34:33.079: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs agnhost-master-ldvwg agnhost-master --namespace=kubectl-5607'
Apr 27 17:34:33.169: INFO: stderr: ""
Apr 27 17:34:33.169: INFO: stdout: "Paused\n"
STEP: exposing RC
Apr 27 17:34:33.169: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config expose rc agnhost-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-5607'
Apr 27 17:34:33.262: INFO: stderr: ""
Apr 27 17:34:33.262: INFO: stdout: "service/rm2 exposed\n"
Apr 27 17:34:33.265: INFO: Service rm2 in namespace kubectl-5607 found.
STEP: exposing service
Apr 27 17:34:35.273: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1j2-hub.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-5607'
Apr 27 17:34:35.358: INFO: stderr: ""
Apr 27 17:34:35.358: INFO: stdout: "service/rm3 exposed\n"
Apr 27 17:34:35.361: INFO: Service rm3 in namespace kubectl-5607 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:34:37.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5607" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":277,"completed":271,"skipped":4508,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:34:37.379: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7400
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Apr 27 17:34:37.555: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7400 /api/v1/namespaces/watch-7400/configmaps/e2e-watch-test-resource-version d115e5f6-8abe-41f4-9a98-5c2b31eddef9 39373 0 2020-04-27 17:34:37 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-04-27 17:34:37 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 17:34:37.555: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7400 /api/v1/namespaces/watch-7400/configmaps/e2e-watch-test-resource-version d115e5f6-8abe-41f4-9a98-5c2b31eddef9 39374 0 2020-04-27 17:34:37 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-04-27 17:34:37 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:34:37.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7400" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":277,"completed":272,"skipped":4562,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:34:37.563: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9579
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:34:37.722: INFO: Waiting up to 5m0s for pod "downwardapi-volume-10d4fc52-5779-47ec-a937-5e0d21636f5f" in namespace "downward-api-9579" to be "Succeeded or Failed"
Apr 27 17:34:37.725: INFO: Pod "downwardapi-volume-10d4fc52-5779-47ec-a937-5e0d21636f5f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.766988ms
Apr 27 17:34:39.729: INFO: Pod "downwardapi-volume-10d4fc52-5779-47ec-a937-5e0d21636f5f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006961639s
STEP: Saw pod success
Apr 27 17:34:39.729: INFO: Pod "downwardapi-volume-10d4fc52-5779-47ec-a937-5e0d21636f5f" satisfied condition "Succeeded or Failed"
Apr 27 17:34:39.732: INFO: Trying to get logs from node shoot--it--tm1j2-hub-worker-1-z1-5f8b79c777-wxbr9 pod downwardapi-volume-10d4fc52-5779-47ec-a937-5e0d21636f5f container client-container: <nil>
STEP: delete the pod
Apr 27 17:34:39.751: INFO: Waiting for pod downwardapi-volume-10d4fc52-5779-47ec-a937-5e0d21636f5f to disappear
Apr 27 17:34:39.753: INFO: Pod downwardapi-volume-10d4fc52-5779-47ec-a937-5e0d21636f5f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:34:39.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9579" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":277,"completed":273,"skipped":4629,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:34:39.762: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-311
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:34:40.579: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 27 17:34:42.673: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605680, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605680, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605680, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723605680, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:34:45.688: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:34:45.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-311" for this suite.
STEP: Destroying namespace "webhook-311-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":277,"completed":274,"skipped":4637,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:34:45.853: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8234
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 27 17:34:50.120: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 27 17:34:50.124: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 27 17:34:52.124: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 27 17:34:52.128: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 27 17:34:54.124: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 27 17:34:54.128: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:34:54.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8234" for this suite.
•{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":277,"completed":275,"skipped":4651,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:34:54.139: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-9329
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:34:54.313: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-56d0b1b7-9901-42f0-b6d2-6e310aca04e4" in namespace "security-context-test-9329" to be "Succeeded or Failed"
Apr 27 17:34:54.316: INFO: Pod "busybox-privileged-false-56d0b1b7-9901-42f0-b6d2-6e310aca04e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.868783ms
Apr 27 17:34:56.320: INFO: Pod "busybox-privileged-false-56d0b1b7-9901-42f0-b6d2-6e310aca04e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0068092s
Apr 27 17:34:56.320: INFO: Pod "busybox-privileged-false-56d0b1b7-9901-42f0-b6d2-6e310aca04e4" satisfied condition "Succeeded or Failed"
Apr 27 17:34:56.329: INFO: Got logs for pod "busybox-privileged-false-56d0b1b7-9901-42f0-b6d2-6e310aca04e4": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:34:56.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9329" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":276,"skipped":4669,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:34:56.341: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8957
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 27 17:34:59.016: INFO: Successfully updated pod "pod-update-activedeadlineseconds-6c560959-efbf-4cc6-8905-fe4f06bf5acd"
Apr 27 17:34:59.016: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-6c560959-efbf-4cc6-8905-fe4f06bf5acd" in namespace "pods-8957" to be "terminated due to deadline exceeded"
Apr 27 17:34:59.019: INFO: Pod "pod-update-activedeadlineseconds-6c560959-efbf-4cc6-8905-fe4f06bf5acd": Phase="Running", Reason="", readiness=true. Elapsed: 3.090583ms
Apr 27 17:35:01.022: INFO: Pod "pod-update-activedeadlineseconds-6c560959-efbf-4cc6-8905-fe4f06bf5acd": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.006358058s
Apr 27 17:35:01.023: INFO: Pod "pod-update-activedeadlineseconds-6c560959-efbf-4cc6-8905-fe4f06bf5acd" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:35:01.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8957" for this suite.
•{"msg":"PASSED [k8s.io] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":277,"completed":277,"skipped":4688,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSApr 27 17:35:01.032: INFO: Running AfterSuite actions on all nodes
Apr 27 17:35:01.032: INFO: Running AfterSuite actions on node 1
Apr 27 17:35:01.032: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/e2e/artifacts/1588004362/junit_01.xml
{"msg":"Test Suite completed","total":277,"completed":277,"skipped":4715,"failed":0}

Ran 277 of 4992 Specs in 4536.826 seconds
SUCCESS! -- 277 Passed | 0 Failed | 0 Flaked | 0 Pending | 4715 Skipped
PASS

Ginkgo ran 1 suite in 1h15m38.504839899s
Test Suite Passed
