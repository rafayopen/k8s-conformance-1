I0529 16:59:30.961057      20 test_context.go:410] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-852825370
I0529 16:59:30.961216      20 test_context.go:423] Tolerating taints "node-role.kubernetes.io/master" when considering if nodes are ready
I0529 16:59:30.961398      20 e2e.go:124] Starting e2e run "c8b815dd-bd9a-442e-b20a-5c4565bd2910" on Ginkgo node 1
{"msg":"Test Suite starting","total":277,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1590771569 - Will randomize all specs
Will run 277 of 4992 specs

May 29 16:59:31.000: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
E0529 16:59:31.003632      20 progress.go:119] Failed to post progress update to http://localhost:8099/progress: Post http://localhost:8099/progress: dial tcp 127.0.0.1:8099: connect: connection refused
May 29 16:59:31.003: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
May 29 16:59:31.061: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 29 16:59:31.162: INFO: 16 / 16 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 29 16:59:31.162: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
May 29 16:59:31.162: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
May 29 16:59:31.476: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
May 29 16:59:31.476: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
May 29 16:59:31.476: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'wormhole' (0 seconds elapsed)
May 29 16:59:31.476: INFO: e2e test version: v1.18.1
May 29 16:59:31.480: INFO: kube-apiserver version: v1.18.1
May 29 16:59:31.480: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 16:59:31.509: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 16:59:31.512: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename pods
May 29 16:59:31.929: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 29 16:59:36.569: INFO: Successfully updated pod "pod-update-da92b8b6-d7c2-4371-8ace-a4d66b4c6387"
STEP: verifying the updated pod is in kubernetes
May 29 16:59:36.595: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 16:59:36.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1578" for this suite.

• [SLOW TEST:5.126 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should be updated [NodeConformance] [Conformance]","total":277,"completed":1,"skipped":14,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 16:59:36.642: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 29 16:59:37.580: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 29 16:59:39.615: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726368377, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726368377, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726368377, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726368377, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 29 16:59:42.650: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
May 29 16:59:42.712: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 16:59:42.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9692" for this suite.
STEP: Destroying namespace "webhook-9692-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.410 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":277,"completed":2,"skipped":26,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 16:59:43.053: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-b361a503-2992-4cf2-acc7-e5e5d1f72c02
STEP: Creating a pod to test consume configMaps
May 29 16:59:43.207: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9068d6b8-749a-41bc-8486-09520e2f827e" in namespace "projected-6553" to be "Succeeded or Failed"
May 29 16:59:43.216: INFO: Pod "pod-projected-configmaps-9068d6b8-749a-41bc-8486-09520e2f827e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.140279ms
May 29 16:59:45.228: INFO: Pod "pod-projected-configmaps-9068d6b8-749a-41bc-8486-09520e2f827e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020738s
May 29 16:59:47.239: INFO: Pod "pod-projected-configmaps-9068d6b8-749a-41bc-8486-09520e2f827e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03190332s
May 29 16:59:49.253: INFO: Pod "pod-projected-configmaps-9068d6b8-749a-41bc-8486-09520e2f827e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.045426586s
STEP: Saw pod success
May 29 16:59:49.253: INFO: Pod "pod-projected-configmaps-9068d6b8-749a-41bc-8486-09520e2f827e" satisfied condition "Succeeded or Failed"
May 29 16:59:49.262: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-projected-configmaps-9068d6b8-749a-41bc-8486-09520e2f827e container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 29 16:59:49.388: INFO: Waiting for pod pod-projected-configmaps-9068d6b8-749a-41bc-8486-09520e2f827e to disappear
May 29 16:59:49.398: INFO: Pod pod-projected-configmaps-9068d6b8-749a-41bc-8486-09520e2f827e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 16:59:49.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6553" for this suite.

• [SLOW TEST:6.379 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":277,"completed":3,"skipped":39,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 16:59:49.436: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl label
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1206
STEP: creating the pod
May 29 16:59:49.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 create -f - --namespace=kubectl-206'
May 29 16:59:50.535: INFO: stderr: ""
May 29 16:59:50.535: INFO: stdout: "pod/pause created\n"
May 29 16:59:50.535: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May 29 16:59:50.535: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-206" to be "running and ready"
May 29 16:59:50.549: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 14.641013ms
May 29 16:59:52.562: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027230821s
May 29 16:59:54.578: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.043477284s
May 29 16:59:54.578: INFO: Pod "pause" satisfied condition "running and ready"
May 29 16:59:54.578: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: adding the label testing-label with value testing-label-value to a pod
May 29 16:59:54.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 label pods pause testing-label=testing-label-value --namespace=kubectl-206'
May 29 16:59:54.731: INFO: stderr: ""
May 29 16:59:54.731: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
May 29 16:59:54.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pod pause -L testing-label --namespace=kubectl-206'
May 29 16:59:54.883: INFO: stderr: ""
May 29 16:59:54.883: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
May 29 16:59:54.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 label pods pause testing-label- --namespace=kubectl-206'
May 29 16:59:55.061: INFO: stderr: ""
May 29 16:59:55.061: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
May 29 16:59:55.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pod pause -L testing-label --namespace=kubectl-206'
May 29 16:59:55.210: INFO: stderr: ""
May 29 16:59:55.210: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1213
STEP: using delete to clean up resources
May 29 16:59:55.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 delete --grace-period=0 --force -f - --namespace=kubectl-206'
May 29 16:59:55.408: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 16:59:55.408: INFO: stdout: "pod \"pause\" force deleted\n"
May 29 16:59:55.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get rc,svc -l name=pause --no-headers --namespace=kubectl-206'
May 29 16:59:55.636: INFO: stderr: "No resources found in kubectl-206 namespace.\n"
May 29 16:59:55.636: INFO: stdout: ""
May 29 16:59:55.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods -l name=pause --namespace=kubectl-206 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 29 16:59:55.776: INFO: stderr: ""
May 29 16:59:55.776: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 16:59:55.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-206" for this suite.

• [SLOW TEST:6.400 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1203
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":277,"completed":4,"skipped":57,"failed":0}
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 16:59:55.836: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
May 29 16:59:55.989: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:00:17.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9859" for this suite.

• [SLOW TEST:21.447 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":277,"completed":5,"skipped":57,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:00:17.291: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-6d827dfc-2192-4c3f-80b9-b0ba7f10c294
STEP: Creating a pod to test consume configMaps
May 29 17:00:17.573: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a88cf1d1-6fb0-43da-8f5e-1d746b73b031" in namespace "projected-730" to be "Succeeded or Failed"
May 29 17:00:17.589: INFO: Pod "pod-projected-configmaps-a88cf1d1-6fb0-43da-8f5e-1d746b73b031": Phase="Pending", Reason="", readiness=false. Elapsed: 15.611785ms
May 29 17:00:19.603: INFO: Pod "pod-projected-configmaps-a88cf1d1-6fb0-43da-8f5e-1d746b73b031": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029581939s
May 29 17:00:21.618: INFO: Pod "pod-projected-configmaps-a88cf1d1-6fb0-43da-8f5e-1d746b73b031": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044886164s
STEP: Saw pod success
May 29 17:00:21.619: INFO: Pod "pod-projected-configmaps-a88cf1d1-6fb0-43da-8f5e-1d746b73b031" satisfied condition "Succeeded or Failed"
May 29 17:00:21.629: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-projected-configmaps-a88cf1d1-6fb0-43da-8f5e-1d746b73b031 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 29 17:00:21.850: INFO: Waiting for pod pod-projected-configmaps-a88cf1d1-6fb0-43da-8f5e-1d746b73b031 to disappear
May 29 17:00:21.903: INFO: Pod pod-projected-configmaps-a88cf1d1-6fb0-43da-8f5e-1d746b73b031 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:00:21.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-730" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":277,"completed":6,"skipped":113,"failed":0}
SS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:00:21.999: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8572 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8572;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8572 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8572;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8572.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8572.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8572.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8572.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8572.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8572.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8572.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8572.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8572.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8572.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8572.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8572.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8572.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 246.119.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.119.246_udp@PTR;check="$$(dig +tcp +noall +answer +search 246.119.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.119.246_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8572 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8572;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8572 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8572;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8572.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8572.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8572.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8572.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8572.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8572.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8572.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8572.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8572.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8572.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8572.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8572.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8572.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 246.119.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.119.246_udp@PTR;check="$$(dig +tcp +noall +answer +search 246.119.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.119.246_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 29 17:00:28.456: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:28.470: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:28.498: INFO: Unable to read wheezy_udp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:28.514: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:28.529: INFO: Unable to read wheezy_udp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:28.543: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:28.559: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:28.570: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:28.659: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:28.683: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:28.697: INFO: Unable to read jessie_udp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:28.712: INFO: Unable to read jessie_tcp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:28.727: INFO: Unable to read jessie_udp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:28.739: INFO: Unable to read jessie_tcp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:28.754: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:28.766: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:28.856: INFO: Lookups using dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8572 wheezy_tcp@dns-test-service.dns-8572 wheezy_udp@dns-test-service.dns-8572.svc wheezy_tcp@dns-test-service.dns-8572.svc wheezy_udp@_http._tcp.dns-test-service.dns-8572.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8572.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8572 jessie_tcp@dns-test-service.dns-8572 jessie_udp@dns-test-service.dns-8572.svc jessie_tcp@dns-test-service.dns-8572.svc jessie_udp@_http._tcp.dns-test-service.dns-8572.svc jessie_tcp@_http._tcp.dns-test-service.dns-8572.svc]

May 29 17:00:34.016: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:34.050: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:34.104: INFO: Unable to read wheezy_udp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:34.129: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:34.152: INFO: Unable to read wheezy_udp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:34.168: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:34.190: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:34.212: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:34.309: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:34.322: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:34.332: INFO: Unable to read jessie_udp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:34.348: INFO: Unable to read jessie_tcp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:34.362: INFO: Unable to read jessie_udp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:34.384: INFO: Unable to read jessie_tcp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:34.452: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:34.464: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:34.603: INFO: Lookups using dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8572 wheezy_tcp@dns-test-service.dns-8572 wheezy_udp@dns-test-service.dns-8572.svc wheezy_tcp@dns-test-service.dns-8572.svc wheezy_udp@_http._tcp.dns-test-service.dns-8572.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8572.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8572 jessie_tcp@dns-test-service.dns-8572 jessie_udp@dns-test-service.dns-8572.svc jessie_tcp@dns-test-service.dns-8572.svc jessie_udp@_http._tcp.dns-test-service.dns-8572.svc jessie_tcp@_http._tcp.dns-test-service.dns-8572.svc]

May 29 17:00:38.872: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:38.886: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:38.900: INFO: Unable to read wheezy_udp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:38.913: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:38.927: INFO: Unable to read wheezy_udp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:38.940: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:38.962: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:38.981: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:39.117: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:39.127: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:39.137: INFO: Unable to read jessie_udp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:39.151: INFO: Unable to read jessie_tcp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:39.165: INFO: Unable to read jessie_udp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:39.178: INFO: Unable to read jessie_tcp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:39.192: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:39.209: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:39.306: INFO: Lookups using dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8572 wheezy_tcp@dns-test-service.dns-8572 wheezy_udp@dns-test-service.dns-8572.svc wheezy_tcp@dns-test-service.dns-8572.svc wheezy_udp@_http._tcp.dns-test-service.dns-8572.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8572.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8572 jessie_tcp@dns-test-service.dns-8572 jessie_udp@dns-test-service.dns-8572.svc jessie_tcp@dns-test-service.dns-8572.svc jessie_udp@_http._tcp.dns-test-service.dns-8572.svc jessie_tcp@_http._tcp.dns-test-service.dns-8572.svc]

May 29 17:00:43.871: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:43.882: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:43.894: INFO: Unable to read wheezy_udp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:43.909: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:43.921: INFO: Unable to read wheezy_udp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:43.932: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:43.943: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:43.958: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:44.064: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:44.081: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:44.096: INFO: Unable to read jessie_udp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:44.107: INFO: Unable to read jessie_tcp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:44.118: INFO: Unable to read jessie_udp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:44.133: INFO: Unable to read jessie_tcp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:44.144: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:44.168: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:44.260: INFO: Lookups using dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8572 wheezy_tcp@dns-test-service.dns-8572 wheezy_udp@dns-test-service.dns-8572.svc wheezy_tcp@dns-test-service.dns-8572.svc wheezy_udp@_http._tcp.dns-test-service.dns-8572.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8572.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8572 jessie_tcp@dns-test-service.dns-8572 jessie_udp@dns-test-service.dns-8572.svc jessie_tcp@dns-test-service.dns-8572.svc jessie_udp@_http._tcp.dns-test-service.dns-8572.svc jessie_tcp@_http._tcp.dns-test-service.dns-8572.svc]

May 29 17:00:48.873: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:48.891: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:49.054: INFO: Unable to read wheezy_udp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:49.066: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:49.141: INFO: Unable to read wheezy_udp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:49.159: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:49.174: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:49.196: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:49.309: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:49.322: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:49.337: INFO: Unable to read jessie_udp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:49.353: INFO: Unable to read jessie_tcp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:49.391: INFO: Unable to read jessie_udp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:49.404: INFO: Unable to read jessie_tcp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:49.420: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:49.431: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:49.525: INFO: Lookups using dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8572 wheezy_tcp@dns-test-service.dns-8572 wheezy_udp@dns-test-service.dns-8572.svc wheezy_tcp@dns-test-service.dns-8572.svc wheezy_udp@_http._tcp.dns-test-service.dns-8572.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8572.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8572 jessie_tcp@dns-test-service.dns-8572 jessie_udp@dns-test-service.dns-8572.svc jessie_tcp@dns-test-service.dns-8572.svc jessie_udp@_http._tcp.dns-test-service.dns-8572.svc jessie_tcp@_http._tcp.dns-test-service.dns-8572.svc]

May 29 17:00:53.874: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:53.888: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:54.139: INFO: Unable to read wheezy_udp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:54.155: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:54.172: INFO: Unable to read wheezy_udp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:54.187: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:54.205: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:54.219: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:54.318: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:54.335: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:54.392: INFO: Unable to read jessie_udp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:54.427: INFO: Unable to read jessie_tcp@dns-test-service.dns-8572 from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:54.442: INFO: Unable to read jessie_udp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:54.458: INFO: Unable to read jessie_tcp@dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:54.474: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:54.490: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8572.svc from pod dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f: the server could not find the requested resource (get pods dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f)
May 29 17:00:54.628: INFO: Lookups using dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8572 wheezy_tcp@dns-test-service.dns-8572 wheezy_udp@dns-test-service.dns-8572.svc wheezy_tcp@dns-test-service.dns-8572.svc wheezy_udp@_http._tcp.dns-test-service.dns-8572.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8572.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8572 jessie_tcp@dns-test-service.dns-8572 jessie_udp@dns-test-service.dns-8572.svc jessie_tcp@dns-test-service.dns-8572.svc jessie_udp@_http._tcp.dns-test-service.dns-8572.svc jessie_tcp@_http._tcp.dns-test-service.dns-8572.svc]

May 29 17:00:59.326: INFO: DNS probes using dns-8572/dns-test-a7ac7577-5858-48e9-a9b0-e293526bbe2f succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:00:59.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8572" for this suite.

• [SLOW TEST:37.535 seconds]
[sig-network] DNS
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":277,"completed":7,"skipped":115,"failed":0}
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:00:59.534: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating secret secrets-1571/secret-test-c097a79a-034f-4c48-9116-d4f121a21f44
STEP: Creating a pod to test consume secrets
May 29 17:00:59.686: INFO: Waiting up to 5m0s for pod "pod-configmaps-bed9f2c3-f6ad-4179-a99c-96522eaf3867" in namespace "secrets-1571" to be "Succeeded or Failed"
May 29 17:00:59.696: INFO: Pod "pod-configmaps-bed9f2c3-f6ad-4179-a99c-96522eaf3867": Phase="Pending", Reason="", readiness=false. Elapsed: 9.719963ms
May 29 17:01:01.706: INFO: Pod "pod-configmaps-bed9f2c3-f6ad-4179-a99c-96522eaf3867": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019258824s
May 29 17:01:03.720: INFO: Pod "pod-configmaps-bed9f2c3-f6ad-4179-a99c-96522eaf3867": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03350589s
May 29 17:01:05.730: INFO: Pod "pod-configmaps-bed9f2c3-f6ad-4179-a99c-96522eaf3867": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.043233427s
STEP: Saw pod success
May 29 17:01:05.730: INFO: Pod "pod-configmaps-bed9f2c3-f6ad-4179-a99c-96522eaf3867" satisfied condition "Succeeded or Failed"
May 29 17:01:05.742: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-configmaps-bed9f2c3-f6ad-4179-a99c-96522eaf3867 container env-test: <nil>
STEP: delete the pod
May 29 17:01:05.798: INFO: Waiting for pod pod-configmaps-bed9f2c3-f6ad-4179-a99c-96522eaf3867 to disappear
May 29 17:01:05.808: INFO: Pod pod-configmaps-bed9f2c3-f6ad-4179-a99c-96522eaf3867 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:01:05.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1571" for this suite.

• [SLOW TEST:6.310 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:35
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":277,"completed":8,"skipped":116,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:01:05.855: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-9e86aeac-d20f-4661-84fd-e2929565fee5
STEP: Creating a pod to test consume configMaps
May 29 17:01:06.077: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1ac18421-c70a-4bd0-8703-abfa70e4f9f0" in namespace "projected-2009" to be "Succeeded or Failed"
May 29 17:01:06.094: INFO: Pod "pod-projected-configmaps-1ac18421-c70a-4bd0-8703-abfa70e4f9f0": Phase="Pending", Reason="", readiness=false. Elapsed: 16.264248ms
May 29 17:01:08.108: INFO: Pod "pod-projected-configmaps-1ac18421-c70a-4bd0-8703-abfa70e4f9f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030721539s
May 29 17:01:10.120: INFO: Pod "pod-projected-configmaps-1ac18421-c70a-4bd0-8703-abfa70e4f9f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042179144s
STEP: Saw pod success
May 29 17:01:10.120: INFO: Pod "pod-projected-configmaps-1ac18421-c70a-4bd0-8703-abfa70e4f9f0" satisfied condition "Succeeded or Failed"
May 29 17:01:10.326: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-projected-configmaps-1ac18421-c70a-4bd0-8703-abfa70e4f9f0 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 29 17:01:10.582: INFO: Waiting for pod pod-projected-configmaps-1ac18421-c70a-4bd0-8703-abfa70e4f9f0 to disappear
May 29 17:01:10.616: INFO: Pod pod-projected-configmaps-1ac18421-c70a-4bd0-8703-abfa70e4f9f0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:01:10.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2009" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":9,"skipped":126,"failed":0}
SSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:01:10.701: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:171
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating server pod server in namespace prestop-5964
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-5964
STEP: Deleting pre-stop pod
May 29 17:01:24.071: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:01:24.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-5964" for this suite.

• [SLOW TEST:13.458 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":277,"completed":10,"skipped":133,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:01:24.161: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-0b1d76b1-2a2f-4d4f-a4bb-7d608810a046
STEP: Creating a pod to test consume secrets
May 29 17:01:24.353: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-af0bf263-fbc6-4710-893c-dc87c9a435d2" in namespace "projected-4766" to be "Succeeded or Failed"
May 29 17:01:24.361: INFO: Pod "pod-projected-secrets-af0bf263-fbc6-4710-893c-dc87c9a435d2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.675188ms
May 29 17:01:26.374: INFO: Pod "pod-projected-secrets-af0bf263-fbc6-4710-893c-dc87c9a435d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021525986s
May 29 17:01:28.385: INFO: Pod "pod-projected-secrets-af0bf263-fbc6-4710-893c-dc87c9a435d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032510314s
STEP: Saw pod success
May 29 17:01:28.385: INFO: Pod "pod-projected-secrets-af0bf263-fbc6-4710-893c-dc87c9a435d2" satisfied condition "Succeeded or Failed"
May 29 17:01:28.395: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-projected-secrets-af0bf263-fbc6-4710-893c-dc87c9a435d2 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 29 17:01:28.456: INFO: Waiting for pod pod-projected-secrets-af0bf263-fbc6-4710-893c-dc87c9a435d2 to disappear
May 29 17:01:28.464: INFO: Pod pod-projected-secrets-af0bf263-fbc6-4710-893c-dc87c9a435d2 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:01:28.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4766" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":11,"skipped":152,"failed":0}

------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:01:28.503: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-b3958d7c-293d-40d4-95a5-4a728bf08d53
STEP: Creating a pod to test consume configMaps
May 29 17:01:28.653: INFO: Waiting up to 5m0s for pod "pod-configmaps-df9d95e6-a9c7-4352-a156-fc82056729da" in namespace "configmap-9091" to be "Succeeded or Failed"
May 29 17:01:28.662: INFO: Pod "pod-configmaps-df9d95e6-a9c7-4352-a156-fc82056729da": Phase="Pending", Reason="", readiness=false. Elapsed: 9.024537ms
May 29 17:01:30.677: INFO: Pod "pod-configmaps-df9d95e6-a9c7-4352-a156-fc82056729da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023340126s
May 29 17:01:32.693: INFO: Pod "pod-configmaps-df9d95e6-a9c7-4352-a156-fc82056729da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039725262s
STEP: Saw pod success
May 29 17:01:32.693: INFO: Pod "pod-configmaps-df9d95e6-a9c7-4352-a156-fc82056729da" satisfied condition "Succeeded or Failed"
May 29 17:01:32.704: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-configmaps-df9d95e6-a9c7-4352-a156-fc82056729da container configmap-volume-test: <nil>
STEP: delete the pod
May 29 17:01:32.768: INFO: Waiting for pod pod-configmaps-df9d95e6-a9c7-4352-a156-fc82056729da to disappear
May 29 17:01:32.777: INFO: Pod pod-configmaps-df9d95e6-a9c7-4352-a156-fc82056729da no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:01:32.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9091" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":277,"completed":12,"skipped":152,"failed":0}
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:01:32.821: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 29 17:01:41.863: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 29 17:01:41.882: INFO: Pod pod-with-poststart-http-hook still exists
May 29 17:01:43.883: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 29 17:01:43.896: INFO: Pod pod-with-poststart-http-hook still exists
May 29 17:01:45.883: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 29 17:01:45.895: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:01:45.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9086" for this suite.

• [SLOW TEST:13.119 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":277,"completed":13,"skipped":154,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:01:45.948: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:01:46.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4673" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":277,"completed":14,"skipped":160,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:01:46.213: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:01:46.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 version'
May 29 17:01:46.559: INFO: stderr: ""
May 29 17:01:46.559: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.1\", GitCommit:\"7879fc12a63337efff607952a323df90cdc7a335\", GitTreeState:\"clean\", BuildDate:\"2020-04-08T17:38:50Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.1\", GitCommit:\"7879fc12a63337efff607952a323df90cdc7a335\", GitTreeState:\"clean\", BuildDate:\"2020-04-08T17:30:47Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:01:46.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2362" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":277,"completed":15,"skipped":194,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:01:46.622: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-7722
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
May 29 17:01:46.851: INFO: Found 0 stateful pods, waiting for 3
May 29 17:01:56.865: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 29 17:01:56.865: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 29 17:01:56.865: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
May 29 17:02:06.872: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 29 17:02:06.872: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 29 17:02:06.872: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
May 29 17:02:06.945: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
May 29 17:02:17.351: INFO: Updating stateful set ss2
May 29 17:02:17.420: INFO: Waiting for Pod statefulset-7722/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
May 29 17:02:27.643: INFO: Found 2 stateful pods, waiting for 3
May 29 17:02:37.661: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 29 17:02:37.661: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 29 17:02:37.661: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
May 29 17:02:37.774: INFO: Updating stateful set ss2
May 29 17:02:37.811: INFO: Waiting for Pod statefulset-7722/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
May 29 17:02:47.880: INFO: Updating stateful set ss2
May 29 17:02:47.931: INFO: Waiting for StatefulSet statefulset-7722/ss2 to complete update
May 29 17:02:47.931: INFO: Waiting for Pod statefulset-7722/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
May 29 17:02:57.959: INFO: Waiting for StatefulSet statefulset-7722/ss2 to complete update
May 29 17:02:57.959: INFO: Waiting for Pod statefulset-7722/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
May 29 17:03:07.987: INFO: Deleting all statefulset in ns statefulset-7722
May 29 17:03:07.998: INFO: Scaling statefulset ss2 to 0
May 29 17:03:28.065: INFO: Waiting for statefulset status.replicas updated to 0
May 29 17:03:28.077: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:03:28.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7722" for this suite.

• [SLOW TEST:101.551 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":277,"completed":16,"skipped":205,"failed":0}
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:03:28.181: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-fbf4620a-3691-4dc1-8a12-c0562ecbe622
STEP: Creating a pod to test consume secrets
May 29 17:03:28.640: INFO: Waiting up to 5m0s for pod "pod-secrets-1c534f03-9903-4060-b377-d20e28a63373" in namespace "secrets-2220" to be "Succeeded or Failed"
May 29 17:03:28.652: INFO: Pod "pod-secrets-1c534f03-9903-4060-b377-d20e28a63373": Phase="Pending", Reason="", readiness=false. Elapsed: 12.167633ms
May 29 17:03:30.666: INFO: Pod "pod-secrets-1c534f03-9903-4060-b377-d20e28a63373": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025832756s
May 29 17:03:32.699: INFO: Pod "pod-secrets-1c534f03-9903-4060-b377-d20e28a63373": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058898483s
STEP: Saw pod success
May 29 17:03:32.700: INFO: Pod "pod-secrets-1c534f03-9903-4060-b377-d20e28a63373" satisfied condition "Succeeded or Failed"
May 29 17:03:32.718: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-secrets-1c534f03-9903-4060-b377-d20e28a63373 container secret-volume-test: <nil>
STEP: delete the pod
May 29 17:03:32.891: INFO: Waiting for pod pod-secrets-1c534f03-9903-4060-b377-d20e28a63373 to disappear
May 29 17:03:32.912: INFO: Pod pod-secrets-1c534f03-9903-4060-b377-d20e28a63373 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:03:32.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2220" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":17,"skipped":210,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:03:32.951: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
May 29 17:03:33.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 create -f - --namespace=kubectl-2553'
May 29 17:03:33.470: INFO: stderr: ""
May 29 17:03:33.470: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 29 17:03:33.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2553'
May 29 17:03:33.652: INFO: stderr: ""
May 29 17:03:33.652: INFO: stdout: "update-demo-nautilus-8h9k7 update-demo-nautilus-8hcxg "
May 29 17:03:33.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods update-demo-nautilus-8h9k7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2553'
May 29 17:03:33.798: INFO: stderr: ""
May 29 17:03:33.798: INFO: stdout: ""
May 29 17:03:33.798: INFO: update-demo-nautilus-8h9k7 is created but not running
May 29 17:03:38.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2553'
May 29 17:03:38.941: INFO: stderr: ""
May 29 17:03:38.941: INFO: stdout: "update-demo-nautilus-8h9k7 update-demo-nautilus-8hcxg "
May 29 17:03:38.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods update-demo-nautilus-8h9k7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2553'
May 29 17:03:39.086: INFO: stderr: ""
May 29 17:03:39.086: INFO: stdout: "true"
May 29 17:03:39.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods update-demo-nautilus-8h9k7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2553'
May 29 17:03:39.196: INFO: stderr: ""
May 29 17:03:39.196: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 29 17:03:39.196: INFO: validating pod update-demo-nautilus-8h9k7
May 29 17:03:39.218: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 17:03:39.218: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 17:03:39.218: INFO: update-demo-nautilus-8h9k7 is verified up and running
May 29 17:03:39.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods update-demo-nautilus-8hcxg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2553'
May 29 17:03:39.341: INFO: stderr: ""
May 29 17:03:39.341: INFO: stdout: "true"
May 29 17:03:39.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods update-demo-nautilus-8hcxg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2553'
May 29 17:03:39.592: INFO: stderr: ""
May 29 17:03:39.592: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 29 17:03:39.592: INFO: validating pod update-demo-nautilus-8hcxg
May 29 17:03:39.607: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 17:03:39.607: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 17:03:39.607: INFO: update-demo-nautilus-8hcxg is verified up and running
STEP: scaling down the replication controller
May 29 17:03:39.612: INFO: scanned /root for discovery docs: <nil>
May 29 17:03:39.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-2553'
May 29 17:03:40.832: INFO: stderr: ""
May 29 17:03:40.833: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 29 17:03:40.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2553'
May 29 17:03:40.992: INFO: stderr: ""
May 29 17:03:40.992: INFO: stdout: "update-demo-nautilus-8h9k7 update-demo-nautilus-8hcxg "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 29 17:03:45.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2553'
May 29 17:03:46.148: INFO: stderr: ""
May 29 17:03:46.148: INFO: stdout: "update-demo-nautilus-8h9k7 update-demo-nautilus-8hcxg "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 29 17:03:51.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2553'
May 29 17:03:51.587: INFO: stderr: ""
May 29 17:03:51.587: INFO: stdout: "update-demo-nautilus-8h9k7 "
May 29 17:03:51.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods update-demo-nautilus-8h9k7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2553'
May 29 17:03:51.732: INFO: stderr: ""
May 29 17:03:51.732: INFO: stdout: "true"
May 29 17:03:51.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods update-demo-nautilus-8h9k7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2553'
May 29 17:03:51.909: INFO: stderr: ""
May 29 17:03:51.909: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 29 17:03:51.909: INFO: validating pod update-demo-nautilus-8h9k7
May 29 17:03:51.923: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 17:03:51.923: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 17:03:51.923: INFO: update-demo-nautilus-8h9k7 is verified up and running
STEP: scaling up the replication controller
May 29 17:03:51.925: INFO: scanned /root for discovery docs: <nil>
May 29 17:03:51.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-2553'
May 29 17:03:53.144: INFO: stderr: ""
May 29 17:03:53.144: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 29 17:03:53.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2553'
May 29 17:03:53.307: INFO: stderr: ""
May 29 17:03:53.307: INFO: stdout: "update-demo-nautilus-8h9k7 update-demo-nautilus-ml8th "
May 29 17:03:53.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods update-demo-nautilus-8h9k7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2553'
May 29 17:03:53.453: INFO: stderr: ""
May 29 17:03:53.453: INFO: stdout: "true"
May 29 17:03:53.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods update-demo-nautilus-8h9k7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2553'
May 29 17:03:53.643: INFO: stderr: ""
May 29 17:03:53.643: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 29 17:03:53.643: INFO: validating pod update-demo-nautilus-8h9k7
May 29 17:03:53.676: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 17:03:53.676: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 17:03:53.676: INFO: update-demo-nautilus-8h9k7 is verified up and running
May 29 17:03:53.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods update-demo-nautilus-ml8th -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2553'
May 29 17:03:53.834: INFO: stderr: ""
May 29 17:03:53.834: INFO: stdout: ""
May 29 17:03:53.834: INFO: update-demo-nautilus-ml8th is created but not running
May 29 17:03:58.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2553'
May 29 17:03:58.986: INFO: stderr: ""
May 29 17:03:58.986: INFO: stdout: "update-demo-nautilus-8h9k7 update-demo-nautilus-ml8th "
May 29 17:03:58.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods update-demo-nautilus-8h9k7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2553'
May 29 17:03:59.167: INFO: stderr: ""
May 29 17:03:59.167: INFO: stdout: "true"
May 29 17:03:59.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods update-demo-nautilus-8h9k7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2553'
May 29 17:03:59.318: INFO: stderr: ""
May 29 17:03:59.318: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 29 17:03:59.318: INFO: validating pod update-demo-nautilus-8h9k7
May 29 17:03:59.333: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 17:03:59.333: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 17:03:59.333: INFO: update-demo-nautilus-8h9k7 is verified up and running
May 29 17:03:59.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods update-demo-nautilus-ml8th -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2553'
May 29 17:03:59.510: INFO: stderr: ""
May 29 17:03:59.510: INFO: stdout: "true"
May 29 17:03:59.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods update-demo-nautilus-ml8th -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2553'
May 29 17:03:59.662: INFO: stderr: ""
May 29 17:03:59.662: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 29 17:03:59.662: INFO: validating pod update-demo-nautilus-ml8th
May 29 17:03:59.685: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 17:03:59.685: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 17:03:59.685: INFO: update-demo-nautilus-ml8th is verified up and running
STEP: using delete to clean up resources
May 29 17:03:59.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 delete --grace-period=0 --force -f - --namespace=kubectl-2553'
May 29 17:03:59.873: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 17:03:59.873: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 29 17:03:59.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2553'
May 29 17:04:00.047: INFO: stderr: "No resources found in kubectl-2553 namespace.\n"
May 29 17:04:00.047: INFO: stdout: ""
May 29 17:04:00.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods -l name=update-demo --namespace=kubectl-2553 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 29 17:04:00.214: INFO: stderr: ""
May 29 17:04:00.214: INFO: stdout: "update-demo-nautilus-8h9k7\nupdate-demo-nautilus-ml8th\n"
May 29 17:04:00.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2553'
May 29 17:04:00.867: INFO: stderr: "No resources found in kubectl-2553 namespace.\n"
May 29 17:04:00.867: INFO: stdout: ""
May 29 17:04:00.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods -l name=update-demo --namespace=kubectl-2553 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 29 17:04:01.033: INFO: stderr: ""
May 29 17:04:01.033: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:04:01.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2553" for this suite.

• [SLOW TEST:28.350 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:269
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":277,"completed":18,"skipped":212,"failed":0}
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:04:01.301: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
May 29 17:04:06.652: INFO: Successfully updated pod "labelsupdate1036e386-9d57-4fa8-a6bd-f3fcbed6053b"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:04:08.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-751" for this suite.

• [SLOW TEST:7.442 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":277,"completed":19,"skipped":216,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:04:08.747: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating cluster-info
May 29 17:04:08.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 cluster-info'
May 29 17:04:09.039: INFO: stderr: ""
May 29 17:04:09.039: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.3.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.3.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://10.3.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:04:09.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1093" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]","total":277,"completed":20,"skipped":258,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:04:09.080: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:04:09.213: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
May 29 17:04:09.242: INFO: Pod name sample-pod: Found 0 pods out of 1
May 29 17:04:14.251: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 29 17:04:14.251: INFO: Creating deployment "test-rolling-update-deployment"
May 29 17:04:14.265: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
May 29 17:04:14.282: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
May 29 17:04:16.313: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
May 29 17:04:16.326: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726368654, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726368654, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726368654, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726368654, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-59d5cb45c7\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:04:18.342: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
May 29 17:04:18.386: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-2292 /apis/apps/v1/namespaces/deployment-2292/deployments/test-rolling-update-deployment dde679ff-7716-4b3c-b343-cd796c15d444 12709453500 1 2020-05-29 17:04:14 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2020-05-29 17:04:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-05-29 17:04:17 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005a37bf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-05-29 17:04:14 +0000 UTC,LastTransitionTime:2020-05-29 17:04:14 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-59d5cb45c7" has successfully progressed.,LastUpdateTime:2020-05-29 17:04:17 +0000 UTC,LastTransitionTime:2020-05-29 17:04:14 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

May 29 17:04:18.397: INFO: New ReplicaSet "test-rolling-update-deployment-59d5cb45c7" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7  deployment-2292 /apis/apps/v1/namespaces/deployment-2292/replicasets/test-rolling-update-deployment-59d5cb45c7 42e875f3-bd17-4af5-9988-f5e2ff3e498a 12709453467 1 2020-05-29 17:04:14 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment dde679ff-7716-4b3c-b343-cd796c15d444 0xc0059d81b7 0xc0059d81b8}] []  [{kube-controller-manager Update apps/v1 2020-05-29 17:04:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 100 101 54 55 57 102 102 45 55 55 49 54 45 52 98 51 99 45 98 51 52 51 45 99 100 55 57 54 99 49 53 100 52 52 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 59d5cb45c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0059d8258 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May 29 17:04:18.397: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
May 29 17:04:18.398: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-2292 /apis/apps/v1/namespaces/deployment-2292/replicasets/test-rolling-update-controller ddd19469-9e7d-4f42-8c5b-702924f9c50e 12709453492 2 2020-05-29 17:04:09 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment dde679ff-7716-4b3c-b343-cd796c15d444 0xc0059d8087 0xc0059d8088}] []  [{e2e.test Update apps/v1 2020-05-29 17:04:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-05-29 17:04:17 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 100 101 54 55 57 102 102 45 55 55 49 54 45 52 98 51 99 45 98 51 52 51 45 99 100 55 57 54 99 49 53 100 52 52 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0059d8148 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May 29 17:04:18.413: INFO: Pod "test-rolling-update-deployment-59d5cb45c7-j6q8d" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7-j6q8d test-rolling-update-deployment-59d5cb45c7- deployment-2292 /api/v1/namespaces/deployment-2292/pods/test-rolling-update-deployment-59d5cb45c7-j6q8d 7f5c2f65-3db7-488a-94eb-4439c05cf243 12709453466 0 2020-05-29 17:04:14 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[cni.projectcalico.org/podIP:10.2.2.129/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-59d5cb45c7 42e875f3-bd17-4af5-9988-f5e2ff3e498a 0xc0059f6857 0xc0059f6858}] []  [{kube-controller-manager Update v1 2020-05-29 17:04:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 50 101 56 55 53 102 51 45 98 100 49 55 45 52 97 102 53 45 57 57 56 56 45 102 53 101 50 102 102 51 101 52 57 56 97 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:04:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-05-29 17:04:17 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 46 50 46 49 50 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-vbpzg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-vbpzg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-vbpzg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:04:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:04:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:04:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:04:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.83.108.252,PodIP:10.2.2.129,StartTime:2020-05-29 17:04:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-29 17:04:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://dcb4aaaec5e4af9ebb14adc29b0a97019ce5836bd46ed6ebf67e1e95760380c7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.2.129,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:04:18.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2292" for this suite.

• [SLOW TEST:9.367 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":277,"completed":21,"skipped":287,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:04:18.452: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on node default medium
May 29 17:04:18.579: INFO: Waiting up to 5m0s for pod "pod-4d79949b-eab6-4acc-9a72-2ad009676e15" in namespace "emptydir-6036" to be "Succeeded or Failed"
May 29 17:04:18.592: INFO: Pod "pod-4d79949b-eab6-4acc-9a72-2ad009676e15": Phase="Pending", Reason="", readiness=false. Elapsed: 12.09062ms
May 29 17:04:20.603: INFO: Pod "pod-4d79949b-eab6-4acc-9a72-2ad009676e15": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023139265s
May 29 17:04:22.614: INFO: Pod "pod-4d79949b-eab6-4acc-9a72-2ad009676e15": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035005142s
STEP: Saw pod success
May 29 17:04:22.615: INFO: Pod "pod-4d79949b-eab6-4acc-9a72-2ad009676e15" satisfied condition "Succeeded or Failed"
May 29 17:04:22.626: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-4d79949b-eab6-4acc-9a72-2ad009676e15 container test-container: <nil>
STEP: delete the pod
May 29 17:04:22.679: INFO: Waiting for pod pod-4d79949b-eab6-4acc-9a72-2ad009676e15 to disappear
May 29 17:04:22.688: INFO: Pod pod-4d79949b-eab6-4acc-9a72-2ad009676e15 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:04:22.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6036" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":22,"skipped":307,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:04:22.728: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-mk6f
STEP: Creating a pod to test atomic-volume-subpath
May 29 17:04:22.965: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-mk6f" in namespace "subpath-4204" to be "Succeeded or Failed"
May 29 17:04:22.994: INFO: Pod "pod-subpath-test-configmap-mk6f": Phase="Pending", Reason="", readiness=false. Elapsed: 29.039977ms
May 29 17:04:25.005: INFO: Pod "pod-subpath-test-configmap-mk6f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039587897s
May 29 17:04:27.018: INFO: Pod "pod-subpath-test-configmap-mk6f": Phase="Running", Reason="", readiness=true. Elapsed: 4.052414102s
May 29 17:04:29.030: INFO: Pod "pod-subpath-test-configmap-mk6f": Phase="Running", Reason="", readiness=true. Elapsed: 6.064947176s
May 29 17:04:31.048: INFO: Pod "pod-subpath-test-configmap-mk6f": Phase="Running", Reason="", readiness=true. Elapsed: 8.082458535s
May 29 17:04:33.070: INFO: Pod "pod-subpath-test-configmap-mk6f": Phase="Running", Reason="", readiness=true. Elapsed: 10.10457566s
May 29 17:04:35.082: INFO: Pod "pod-subpath-test-configmap-mk6f": Phase="Running", Reason="", readiness=true. Elapsed: 12.117298382s
May 29 17:04:37.095: INFO: Pod "pod-subpath-test-configmap-mk6f": Phase="Running", Reason="", readiness=true. Elapsed: 14.130165709s
May 29 17:04:39.107: INFO: Pod "pod-subpath-test-configmap-mk6f": Phase="Running", Reason="", readiness=true. Elapsed: 16.141797706s
May 29 17:04:41.120: INFO: Pod "pod-subpath-test-configmap-mk6f": Phase="Running", Reason="", readiness=true. Elapsed: 18.155242479s
May 29 17:04:43.131: INFO: Pod "pod-subpath-test-configmap-mk6f": Phase="Running", Reason="", readiness=true. Elapsed: 20.166330943s
May 29 17:04:45.142: INFO: Pod "pod-subpath-test-configmap-mk6f": Phase="Running", Reason="", readiness=true. Elapsed: 22.177213169s
May 29 17:04:47.156: INFO: Pod "pod-subpath-test-configmap-mk6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.190709582s
STEP: Saw pod success
May 29 17:04:47.156: INFO: Pod "pod-subpath-test-configmap-mk6f" satisfied condition "Succeeded or Failed"
May 29 17:04:47.166: INFO: Trying to get logs from node node-cncf-lab-3 pod pod-subpath-test-configmap-mk6f container test-container-subpath-configmap-mk6f: <nil>
STEP: delete the pod
May 29 17:04:47.332: INFO: Waiting for pod pod-subpath-test-configmap-mk6f to disappear
May 29 17:04:47.343: INFO: Pod pod-subpath-test-configmap-mk6f no longer exists
STEP: Deleting pod pod-subpath-test-configmap-mk6f
May 29 17:04:47.344: INFO: Deleting pod "pod-subpath-test-configmap-mk6f" in namespace "subpath-4204"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:04:47.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4204" for this suite.

• [SLOW TEST:24.660 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]","total":277,"completed":23,"skipped":340,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:04:47.399: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-77eed75a-390b-4ec9-b36c-a159befbe81d
STEP: Creating a pod to test consume configMaps
May 29 17:04:48.502: INFO: Waiting up to 5m0s for pod "pod-configmaps-dbacf4a9-fdc0-4fee-93d2-1c0d028d10fb" in namespace "configmap-524" to be "Succeeded or Failed"
May 29 17:04:48.707: INFO: Pod "pod-configmaps-dbacf4a9-fdc0-4fee-93d2-1c0d028d10fb": Phase="Pending", Reason="", readiness=false. Elapsed: 204.34697ms
May 29 17:04:50.721: INFO: Pod "pod-configmaps-dbacf4a9-fdc0-4fee-93d2-1c0d028d10fb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.218182854s
May 29 17:04:53.016: INFO: Pod "pod-configmaps-dbacf4a9-fdc0-4fee-93d2-1c0d028d10fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.513860969s
STEP: Saw pod success
May 29 17:04:53.017: INFO: Pod "pod-configmaps-dbacf4a9-fdc0-4fee-93d2-1c0d028d10fb" satisfied condition "Succeeded or Failed"
May 29 17:04:53.048: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-configmaps-dbacf4a9-fdc0-4fee-93d2-1c0d028d10fb container configmap-volume-test: <nil>
STEP: delete the pod
May 29 17:04:53.140: INFO: Waiting for pod pod-configmaps-dbacf4a9-fdc0-4fee-93d2-1c0d028d10fb to disappear
May 29 17:04:53.156: INFO: Pod pod-configmaps-dbacf4a9-fdc0-4fee-93d2-1c0d028d10fb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:04:53.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-524" for this suite.

• [SLOW TEST:5.813 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":24,"skipped":351,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:04:53.213: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
May 29 17:04:53.430: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4f87fc35-82dc-435e-9719-a83dadacd8c0" in namespace "projected-2160" to be "Succeeded or Failed"
May 29 17:04:53.452: INFO: Pod "downwardapi-volume-4f87fc35-82dc-435e-9719-a83dadacd8c0": Phase="Pending", Reason="", readiness=false. Elapsed: 22.123398ms
May 29 17:04:55.465: INFO: Pod "downwardapi-volume-4f87fc35-82dc-435e-9719-a83dadacd8c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034514803s
May 29 17:04:57.478: INFO: Pod "downwardapi-volume-4f87fc35-82dc-435e-9719-a83dadacd8c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047669886s
STEP: Saw pod success
May 29 17:04:57.478: INFO: Pod "downwardapi-volume-4f87fc35-82dc-435e-9719-a83dadacd8c0" satisfied condition "Succeeded or Failed"
May 29 17:04:57.488: INFO: Trying to get logs from node node-cncf-lab-1 pod downwardapi-volume-4f87fc35-82dc-435e-9719-a83dadacd8c0 container client-container: <nil>
STEP: delete the pod
May 29 17:04:57.877: INFO: Waiting for pod downwardapi-volume-4f87fc35-82dc-435e-9719-a83dadacd8c0 to disappear
May 29 17:04:57.885: INFO: Pod downwardapi-volume-4f87fc35-82dc-435e-9719-a83dadacd8c0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:04:57.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2160" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":277,"completed":25,"skipped":356,"failed":0}
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:04:57.924: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5726.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5726.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5726.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5726.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5726.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5726.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5726.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5726.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5726.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5726.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5726.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 179.30.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.30.179_udp@PTR;check="$$(dig +tcp +noall +answer +search 179.30.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.30.179_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5726.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5726.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5726.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5726.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5726.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5726.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5726.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5726.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5726.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5726.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5726.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 179.30.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.30.179_udp@PTR;check="$$(dig +tcp +noall +answer +search 179.30.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.30.179_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 29 17:05:04.178: INFO: Unable to read wheezy_udp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:04.201: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:04.215: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:04.236: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:04.393: INFO: Unable to read jessie_udp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:04.408: INFO: Unable to read jessie_tcp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:04.425: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:04.439: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:04.530: INFO: Lookups using dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe failed for: [wheezy_udp@dns-test-service.dns-5726.svc.cluster.local wheezy_tcp@dns-test-service.dns-5726.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local jessie_udp@dns-test-service.dns-5726.svc.cluster.local jessie_tcp@dns-test-service.dns-5726.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local]

May 29 17:05:09.544: INFO: Unable to read wheezy_udp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:09.561: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:09.576: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:09.593: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:09.689: INFO: Unable to read jessie_udp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:09.704: INFO: Unable to read jessie_tcp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:09.720: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:09.738: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:09.839: INFO: Lookups using dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe failed for: [wheezy_udp@dns-test-service.dns-5726.svc.cluster.local wheezy_tcp@dns-test-service.dns-5726.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local jessie_udp@dns-test-service.dns-5726.svc.cluster.local jessie_tcp@dns-test-service.dns-5726.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local]

May 29 17:05:14.546: INFO: Unable to read wheezy_udp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:14.563: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:14.576: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:14.589: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:14.684: INFO: Unable to read jessie_udp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:14.698: INFO: Unable to read jessie_tcp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:14.710: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:14.725: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:14.833: INFO: Lookups using dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe failed for: [wheezy_udp@dns-test-service.dns-5726.svc.cluster.local wheezy_tcp@dns-test-service.dns-5726.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local jessie_udp@dns-test-service.dns-5726.svc.cluster.local jessie_tcp@dns-test-service.dns-5726.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local]

May 29 17:05:19.546: INFO: Unable to read wheezy_udp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:19.557: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:19.573: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:19.588: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:19.789: INFO: Unable to read jessie_udp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:19.801: INFO: Unable to read jessie_tcp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:19.817: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:19.829: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:19.921: INFO: Lookups using dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe failed for: [wheezy_udp@dns-test-service.dns-5726.svc.cluster.local wheezy_tcp@dns-test-service.dns-5726.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local jessie_udp@dns-test-service.dns-5726.svc.cluster.local jessie_tcp@dns-test-service.dns-5726.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local]

May 29 17:05:24.545: INFO: Unable to read wheezy_udp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:24.561: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:24.575: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:24.633: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:25.025: INFO: Unable to read jessie_udp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:25.038: INFO: Unable to read jessie_tcp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:25.052: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:25.067: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:25.172: INFO: Lookups using dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe failed for: [wheezy_udp@dns-test-service.dns-5726.svc.cluster.local wheezy_tcp@dns-test-service.dns-5726.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local jessie_udp@dns-test-service.dns-5726.svc.cluster.local jessie_tcp@dns-test-service.dns-5726.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local]

May 29 17:05:29.544: INFO: Unable to read wheezy_udp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:29.559: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:29.572: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:29.587: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:29.693: INFO: Unable to read jessie_udp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:29.709: INFO: Unable to read jessie_tcp@dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:29.722: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:29.736: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local from pod dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe: the server could not find the requested resource (get pods dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe)
May 29 17:05:29.821: INFO: Lookups using dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe failed for: [wheezy_udp@dns-test-service.dns-5726.svc.cluster.local wheezy_tcp@dns-test-service.dns-5726.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local jessie_udp@dns-test-service.dns-5726.svc.cluster.local jessie_tcp@dns-test-service.dns-5726.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5726.svc.cluster.local]

May 29 17:05:34.848: INFO: DNS probes using dns-5726/dns-test-6d8bde5d-786f-4b15-bcb3-dd801815b2fe succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:05:34.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5726" for this suite.

• [SLOW TEST:37.104 seconds]
[sig-network] DNS
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":277,"completed":26,"skipped":361,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:05:35.036: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
May 29 17:05:42.377: INFO: Successfully updated pod "annotationupdate2a94135b-ecdb-4f56-ac03-72a587b25794"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:05:46.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5394" for this suite.

• [SLOW TEST:12.341 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":277,"completed":27,"skipped":377,"failed":0}
S
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:05:47.377: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:06:47.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2037" for this suite.

• [SLOW TEST:60.267 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":277,"completed":28,"skipped":378,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:06:47.645: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 29 17:06:49.471: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
May 29 17:06:51.511: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726368809, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726368809, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726368809, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726368809, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 29 17:06:54.582: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
May 29 17:06:58.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 attach --namespace=webhook-8993 to-be-attached-pod -i -c=container1'
May 29 17:06:58.948: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:06:58.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8993" for this suite.
STEP: Destroying namespace "webhook-8993-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:11.543 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":277,"completed":29,"skipped":409,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:06:59.191: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching services
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:06:59.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1360" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":277,"completed":30,"skipped":432,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:06:59.369: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl replace
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
May 29 17:06:59.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 run e2e-test-httpd-pod --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-6525'
May 29 17:06:59.662: INFO: stderr: ""
May 29 17:06:59.662: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
May 29 17:07:04.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pod e2e-test-httpd-pod --namespace=kubectl-6525 -o json'
May 29 17:07:04.881: INFO: stderr: ""
May 29 17:07:04.881: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.2.3.11/32\"\n        },\n        \"creationTimestamp\": \"2020-05-29T17:06:59Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"managedFields\": [\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:labels\": {\n                            \".\": {},\n                            \"f:run\": {}\n                        }\n                    },\n                    \"f:spec\": {\n                        \"f:containers\": {\n                            \"k:{\\\"name\\\":\\\"e2e-test-httpd-pod\\\"}\": {\n                                \".\": {},\n                                \"f:image\": {},\n                                \"f:imagePullPolicy\": {},\n                                \"f:name\": {},\n                                \"f:resources\": {},\n                                \"f:terminationMessagePath\": {},\n                                \"f:terminationMessagePolicy\": {}\n                            }\n                        },\n                        \"f:dnsPolicy\": {},\n                        \"f:enableServiceLinks\": {},\n                        \"f:restartPolicy\": {},\n                        \"f:schedulerName\": {},\n                        \"f:securityContext\": {},\n                        \"f:terminationGracePeriodSeconds\": {}\n                    }\n                },\n                \"manager\": \"kubectl\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-05-29T17:06:59Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:annotations\": {\n                            \".\": {},\n                            \"f:cni.projectcalico.org/podIP\": {}\n                        }\n                    }\n                },\n                \"manager\": \"calico\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-05-29T17:07:00Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:status\": {\n                        \"f:conditions\": {\n                            \"k:{\\\"type\\\":\\\"ContainersReady\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Initialized\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Ready\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            }\n                        },\n                        \"f:containerStatuses\": {},\n                        \"f:hostIP\": {},\n                        \"f:phase\": {},\n                        \"f:podIP\": {},\n                        \"f:podIPs\": {\n                            \".\": {},\n                            \"k:{\\\"ip\\\":\\\"10.2.3.11\\\"}\": {\n                                \".\": {},\n                                \"f:ip\": {}\n                            }\n                        },\n                        \"f:startTime\": {}\n                    }\n                },\n                \"manager\": \"kubelet\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-05-29T17:07:03Z\"\n            }\n        ],\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-6525\",\n        \"resourceVersion\": \"12709516569\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-6525/pods/e2e-test-httpd-pod\",\n        \"uid\": \"70207205-0312-4834-a2b2-b4ca5177c9c1\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"Always\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-zzkk8\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"node-cncf-lab-3\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-zzkk8\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-zzkk8\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-05-29T17:06:59Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-05-29T17:07:03Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-05-29T17:07:03Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-05-29T17:06:59Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://7837afafcab9b1497de52a43971a1ccf006176cd4d3e83600745c39e8f785fb3\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-05-29T17:07:02Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"51.178.95.196\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.2.3.11\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.2.3.11\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-05-29T17:06:59Z\"\n    }\n}\n"
STEP: replace the image in the pod
May 29 17:07:04.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 replace -f - --namespace=kubectl-6525'
May 29 17:07:05.189: INFO: stderr: ""
May 29 17:07:05.189: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
May 29 17:07:05.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 delete pods e2e-test-httpd-pod --namespace=kubectl-6525'
May 29 17:07:16.226: INFO: stderr: ""
May 29 17:07:16.226: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:07:16.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6525" for this suite.

• [SLOW TEST:16.889 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1450
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":277,"completed":31,"skipped":445,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:07:16.257: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
May 29 17:07:16.455: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2602 /api/v1/namespaces/watch-2602/configmaps/e2e-watch-test-label-changed 8ef6718d-3137-4013-8bea-0a4903deb04f 12709521865 0 2020-05-29 17:07:16 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-05-29 17:07:16 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
May 29 17:07:16.457: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2602 /api/v1/namespaces/watch-2602/configmaps/e2e-watch-test-label-changed 8ef6718d-3137-4013-8bea-0a4903deb04f 12709521925 0 2020-05-29 17:07:16 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-05-29 17:07:16 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
May 29 17:07:16.457: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2602 /api/v1/namespaces/watch-2602/configmaps/e2e-watch-test-label-changed 8ef6718d-3137-4013-8bea-0a4903deb04f 12709521936 0 2020-05-29 17:07:16 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-05-29 17:07:16 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
May 29 17:07:26.566: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2602 /api/v1/namespaces/watch-2602/configmaps/e2e-watch-test-label-changed 8ef6718d-3137-4013-8bea-0a4903deb04f 12709525637 0 2020-05-29 17:07:16 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-05-29 17:07:26 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
May 29 17:07:26.567: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2602 /api/v1/namespaces/watch-2602/configmaps/e2e-watch-test-label-changed 8ef6718d-3137-4013-8bea-0a4903deb04f 12709525645 0 2020-05-29 17:07:16 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-05-29 17:07:26 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
May 29 17:07:26.568: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2602 /api/v1/namespaces/watch-2602/configmaps/e2e-watch-test-label-changed 8ef6718d-3137-4013-8bea-0a4903deb04f 12709525648 0 2020-05-29 17:07:16 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-05-29 17:07:26 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:07:26.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2602" for this suite.

• [SLOW TEST:10.357 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":277,"completed":32,"skipped":452,"failed":0}
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:07:26.616: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-41f1b490-ff9b-4ee5-a3c0-2f9a4e48fe8d
STEP: Creating configMap with name cm-test-opt-upd-be50e484-26bf-48ae-aa02-a8974133b87f
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-41f1b490-ff9b-4ee5-a3c0-2f9a4e48fe8d
STEP: Updating configmap cm-test-opt-upd-be50e484-26bf-48ae-aa02-a8974133b87f
STEP: Creating configMap with name cm-test-opt-create-04bbc5d3-7f62-466b-baf5-d57895fc0fb6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:08:41.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7119" for this suite.

• [SLOW TEST:74.751 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":33,"skipped":452,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:08:41.369: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-9f471c05-c533-409a-af4c-164d07aff277
STEP: Creating a pod to test consume configMaps
May 29 17:08:41.523: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-765eb69a-07a0-4f66-9c12-dcf9e75c6c99" in namespace "projected-7066" to be "Succeeded or Failed"
May 29 17:08:41.532: INFO: Pod "pod-projected-configmaps-765eb69a-07a0-4f66-9c12-dcf9e75c6c99": Phase="Pending", Reason="", readiness=false. Elapsed: 9.808032ms
May 29 17:08:43.543: INFO: Pod "pod-projected-configmaps-765eb69a-07a0-4f66-9c12-dcf9e75c6c99": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02005383s
May 29 17:08:45.556: INFO: Pod "pod-projected-configmaps-765eb69a-07a0-4f66-9c12-dcf9e75c6c99": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033929001s
STEP: Saw pod success
May 29 17:08:45.557: INFO: Pod "pod-projected-configmaps-765eb69a-07a0-4f66-9c12-dcf9e75c6c99" satisfied condition "Succeeded or Failed"
May 29 17:08:45.570: INFO: Trying to get logs from node node-cncf-lab-3 pod pod-projected-configmaps-765eb69a-07a0-4f66-9c12-dcf9e75c6c99 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 29 17:08:45.689: INFO: Waiting for pod pod-projected-configmaps-765eb69a-07a0-4f66-9c12-dcf9e75c6c99 to disappear
May 29 17:08:45.699: INFO: Pod pod-projected-configmaps-765eb69a-07a0-4f66-9c12-dcf9e75c6c99 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:08:45.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7066" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":34,"skipped":486,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:08:45.734: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:09:21.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9530" for this suite.
STEP: Destroying namespace "nsdeletetest-7994" for this suite.
May 29 17:09:21.500: INFO: Namespace nsdeletetest-7994 was already deleted
STEP: Destroying namespace "nsdeletetest-2240" for this suite.

• [SLOW TEST:35.786 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":277,"completed":35,"skipped":494,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:09:21.525: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
May 29 17:09:21.659: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
May 29 17:09:31.237: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:09:31.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3463" for this suite.

• [SLOW TEST:9.764 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should be submitted and removed [NodeConformance] [Conformance]","total":277,"completed":36,"skipped":509,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:09:31.290: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-82445fe4-50f8-442f-b97e-a08b0847ce99
STEP: Creating a pod to test consume secrets
May 29 17:09:31.424: INFO: Waiting up to 5m0s for pod "pod-secrets-a0e4b0c0-533e-4cc2-91e4-a0e2aaed0d43" in namespace "secrets-6611" to be "Succeeded or Failed"
May 29 17:09:31.436: INFO: Pod "pod-secrets-a0e4b0c0-533e-4cc2-91e4-a0e2aaed0d43": Phase="Pending", Reason="", readiness=false. Elapsed: 10.880308ms
May 29 17:09:33.449: INFO: Pod "pod-secrets-a0e4b0c0-533e-4cc2-91e4-a0e2aaed0d43": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023774829s
May 29 17:09:35.460: INFO: Pod "pod-secrets-a0e4b0c0-533e-4cc2-91e4-a0e2aaed0d43": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034760135s
May 29 17:09:37.471: INFO: Pod "pod-secrets-a0e4b0c0-533e-4cc2-91e4-a0e2aaed0d43": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.045770724s
STEP: Saw pod success
May 29 17:09:37.471: INFO: Pod "pod-secrets-a0e4b0c0-533e-4cc2-91e4-a0e2aaed0d43" satisfied condition "Succeeded or Failed"
May 29 17:09:37.480: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-secrets-a0e4b0c0-533e-4cc2-91e4-a0e2aaed0d43 container secret-env-test: <nil>
STEP: delete the pod
May 29 17:09:37.540: INFO: Waiting for pod pod-secrets-a0e4b0c0-533e-4cc2-91e4-a0e2aaed0d43 to disappear
May 29 17:09:37.547: INFO: Pod pod-secrets-a0e4b0c0-533e-4cc2-91e4-a0e2aaed0d43 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:09:37.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6611" for this suite.

• [SLOW TEST:6.291 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:35
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":277,"completed":37,"skipped":518,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:09:37.581: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
May 29 17:09:37.715: INFO: Waiting up to 5m0s for pod "pod-01c247e6-a3fb-47f1-ac9e-cab7b6dddf21" in namespace "emptydir-9256" to be "Succeeded or Failed"
May 29 17:09:37.728: INFO: Pod "pod-01c247e6-a3fb-47f1-ac9e-cab7b6dddf21": Phase="Pending", Reason="", readiness=false. Elapsed: 12.313058ms
May 29 17:09:39.748: INFO: Pod "pod-01c247e6-a3fb-47f1-ac9e-cab7b6dddf21": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032461611s
May 29 17:09:41.758: INFO: Pod "pod-01c247e6-a3fb-47f1-ac9e-cab7b6dddf21": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042353495s
May 29 17:09:43.778: INFO: Pod "pod-01c247e6-a3fb-47f1-ac9e-cab7b6dddf21": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.062124035s
STEP: Saw pod success
May 29 17:09:43.778: INFO: Pod "pod-01c247e6-a3fb-47f1-ac9e-cab7b6dddf21" satisfied condition "Succeeded or Failed"
May 29 17:09:43.808: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-01c247e6-a3fb-47f1-ac9e-cab7b6dddf21 container test-container: <nil>
STEP: delete the pod
May 29 17:09:44.132: INFO: Waiting for pod pod-01c247e6-a3fb-47f1-ac9e-cab7b6dddf21 to disappear
May 29 17:09:44.153: INFO: Pod pod-01c247e6-a3fb-47f1-ac9e-cab7b6dddf21 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:09:44.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9256" for this suite.

• [SLOW TEST:6.811 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":38,"skipped":528,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:09:44.393: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-bcfb6494-9d19-4a62-af9b-220bc56bdba8
STEP: Creating a pod to test consume configMaps
May 29 17:09:44.585: INFO: Waiting up to 5m0s for pod "pod-configmaps-55a1885c-300f-4a8b-9214-9891fec74320" in namespace "configmap-6952" to be "Succeeded or Failed"
May 29 17:09:44.624: INFO: Pod "pod-configmaps-55a1885c-300f-4a8b-9214-9891fec74320": Phase="Pending", Reason="", readiness=false. Elapsed: 38.618426ms
May 29 17:09:46.637: INFO: Pod "pod-configmaps-55a1885c-300f-4a8b-9214-9891fec74320": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051986477s
May 29 17:09:48.647: INFO: Pod "pod-configmaps-55a1885c-300f-4a8b-9214-9891fec74320": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062063765s
STEP: Saw pod success
May 29 17:09:48.648: INFO: Pod "pod-configmaps-55a1885c-300f-4a8b-9214-9891fec74320" satisfied condition "Succeeded or Failed"
May 29 17:09:48.660: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-configmaps-55a1885c-300f-4a8b-9214-9891fec74320 container configmap-volume-test: <nil>
STEP: delete the pod
May 29 17:09:48.733: INFO: Waiting for pod pod-configmaps-55a1885c-300f-4a8b-9214-9891fec74320 to disappear
May 29 17:09:48.748: INFO: Pod pod-configmaps-55a1885c-300f-4a8b-9214-9891fec74320 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:09:48.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6952" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":39,"skipped":554,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:09:48.792: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
May 29 17:09:48.943: INFO: Waiting up to 5m0s for pod "downward-api-3dbd023c-11f5-42e2-b0d0-cd80a626261b" in namespace "downward-api-8696" to be "Succeeded or Failed"
May 29 17:09:48.954: INFO: Pod "downward-api-3dbd023c-11f5-42e2-b0d0-cd80a626261b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.986045ms
May 29 17:09:50.966: INFO: Pod "downward-api-3dbd023c-11f5-42e2-b0d0-cd80a626261b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023106439s
May 29 17:09:52.980: INFO: Pod "downward-api-3dbd023c-11f5-42e2-b0d0-cd80a626261b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037106758s
STEP: Saw pod success
May 29 17:09:52.980: INFO: Pod "downward-api-3dbd023c-11f5-42e2-b0d0-cd80a626261b" satisfied condition "Succeeded or Failed"
May 29 17:09:52.991: INFO: Trying to get logs from node node-cncf-lab-1 pod downward-api-3dbd023c-11f5-42e2-b0d0-cd80a626261b container dapi-container: <nil>
STEP: delete the pod
May 29 17:09:53.062: INFO: Waiting for pod downward-api-3dbd023c-11f5-42e2-b0d0-cd80a626261b to disappear
May 29 17:09:53.073: INFO: Pod downward-api-3dbd023c-11f5-42e2-b0d0-cd80a626261b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:09:53.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8696" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":277,"completed":40,"skipped":563,"failed":0}
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:09:53.112: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-404
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 29 17:09:53.249: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
May 29 17:09:53.595: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May 29 17:09:55.601: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May 29 17:09:57.618: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 17:09:59.604: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 17:10:01.606: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 17:10:03.604: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 17:10:05.609: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 17:10:07.607: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 17:10:09.608: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 17:10:11.605: INFO: The status of Pod netserver-0 is Running (Ready = true)
May 29 17:10:11.625: INFO: The status of Pod netserver-1 is Running (Ready = false)
May 29 17:10:13.638: INFO: The status of Pod netserver-1 is Running (Ready = true)
May 29 17:10:13.658: INFO: The status of Pod netserver-2 is Running (Ready = true)
May 29 17:10:13.682: INFO: The status of Pod netserver-3 is Running (Ready = true)
STEP: Creating test pods
May 29 17:10:17.797: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.2.142 8081 | grep -v '^\s*$'] Namespace:pod-network-test-404 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:10:17.797: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 17:10:19.083: INFO: Found all expected endpoints: [netserver-0]
May 29 17:10:19.096: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.0.28 8081 | grep -v '^\s*$'] Namespace:pod-network-test-404 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:10:19.096: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 17:10:20.374: INFO: Found all expected endpoints: [netserver-1]
May 29 17:10:20.387: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.3.14 8081 | grep -v '^\s*$'] Namespace:pod-network-test-404 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:10:20.387: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 17:10:21.661: INFO: Found all expected endpoints: [netserver-2]
May 29 17:10:22.305: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.1.59 8081 | grep -v '^\s*$'] Namespace:pod-network-test-404 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:10:22.306: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 17:10:23.709: INFO: Found all expected endpoints: [netserver-3]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:10:23.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-404" for this suite.

• [SLOW TEST:30.630 seconds]
[sig-network] Networking
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":41,"skipped":566,"failed":0}
SSSSSSSS
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:10:23.746: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename limitrange
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
May 29 17:10:23.890: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
May 29 17:10:23.908: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
May 29 17:10:23.908: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
May 29 17:10:23.932: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
May 29 17:10:23.933: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
May 29 17:10:23.958: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
May 29 17:10:23.958: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
May 29 17:10:31.176: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:10:31.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-3513" for this suite.

• [SLOW TEST:7.508 seconds]
[sig-scheduling] LimitRange
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":277,"completed":42,"skipped":574,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:10:31.254: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-5e89afbd-718c-4d53-9f75-ed42c346a78b
STEP: Creating a pod to test consume secrets
May 29 17:10:31.450: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d8617cdf-29d1-4999-99c9-5c2070cd3f77" in namespace "projected-4133" to be "Succeeded or Failed"
May 29 17:10:31.462: INFO: Pod "pod-projected-secrets-d8617cdf-29d1-4999-99c9-5c2070cd3f77": Phase="Pending", Reason="", readiness=false. Elapsed: 12.104816ms
May 29 17:10:33.477: INFO: Pod "pod-projected-secrets-d8617cdf-29d1-4999-99c9-5c2070cd3f77": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026573246s
May 29 17:10:35.497: INFO: Pod "pod-projected-secrets-d8617cdf-29d1-4999-99c9-5c2070cd3f77": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047298633s
STEP: Saw pod success
May 29 17:10:35.498: INFO: Pod "pod-projected-secrets-d8617cdf-29d1-4999-99c9-5c2070cd3f77" satisfied condition "Succeeded or Failed"
May 29 17:10:35.508: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-projected-secrets-d8617cdf-29d1-4999-99c9-5c2070cd3f77 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 29 17:10:36.421: INFO: Waiting for pod pod-projected-secrets-d8617cdf-29d1-4999-99c9-5c2070cd3f77 to disappear
May 29 17:10:36.435: INFO: Pod pod-projected-secrets-d8617cdf-29d1-4999-99c9-5c2070cd3f77 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:10:36.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4133" for this suite.

• [SLOW TEST:5.216 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":43,"skipped":582,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:10:36.471: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:10:36.618: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-0f518277-98e0-44fa-85a2-3ad83d736692" in namespace "security-context-test-6457" to be "Succeeded or Failed"
May 29 17:10:36.648: INFO: Pod "alpine-nnp-false-0f518277-98e0-44fa-85a2-3ad83d736692": Phase="Pending", Reason="", readiness=false. Elapsed: 29.48547ms
May 29 17:10:38.661: INFO: Pod "alpine-nnp-false-0f518277-98e0-44fa-85a2-3ad83d736692": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043113457s
May 29 17:10:40.715: INFO: Pod "alpine-nnp-false-0f518277-98e0-44fa-85a2-3ad83d736692": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.096775831s
May 29 17:10:40.715: INFO: Pod "alpine-nnp-false-0f518277-98e0-44fa-85a2-3ad83d736692" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:10:40.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6457" for this suite.
•{"msg":"PASSED [k8s.io] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":44,"skipped":590,"failed":0}
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:10:40.979: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
May 29 17:10:41.092: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 29 17:10:41.133: INFO: Waiting for terminating namespaces to be deleted...
May 29 17:10:41.145: INFO: 
Logging pods the kubelet thinks is on node node-cncf-lab-1 before test
May 29 17:10:41.165: INFO: alpine-nnp-false-0f518277-98e0-44fa-85a2-3ad83d736692 from security-context-test-6457 started at 2020-05-29 17:10:36 +0000 UTC (1 container statuses recorded)
May 29 17:10:41.166: INFO: 	Container alpine-nnp-false-0f518277-98e0-44fa-85a2-3ad83d736692 ready: false, restart count 0
May 29 17:10:41.166: INFO: canal-6vpdg from kube-system started at 2020-05-29 12:57:00 +0000 UTC (2 container statuses recorded)
May 29 17:10:41.166: INFO: 	Container calico-node ready: true, restart count 0
May 29 17:10:41.166: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:10:41.166: INFO: sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-dngk9 from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:10:41.166: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:10:41.166: INFO: 	Container systemd-logs ready: true, restart count 0
May 29 17:10:41.166: INFO: kube-proxy-24chw from kube-system started at 2020-05-29 12:57:00 +0000 UTC (1 container statuses recorded)
May 29 17:10:41.167: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:10:41.167: INFO: wormhole-b4h5r from kube-system started at 2020-05-29 12:57:00 +0000 UTC (1 container statuses recorded)
May 29 17:10:41.167: INFO: 	Container wormhole ready: true, restart count 0
May 29 17:10:41.167: INFO: 
Logging pods the kubelet thinks is on node node-cncf-lab-2 before test
May 29 17:10:41.283: INFO: coredns-78ff568f7c-8tdx9 from kube-system started at 2020-05-29 12:54:56 +0000 UTC (1 container statuses recorded)
May 29 17:10:41.284: INFO: 	Container coredns ready: true, restart count 0
May 29 17:10:41.284: INFO: canal-xdv24 from kube-system started at 2020-05-29 12:52:43 +0000 UTC (2 container statuses recorded)
May 29 17:10:41.284: INFO: 	Container calico-node ready: true, restart count 0
May 29 17:10:41.284: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:10:41.284: INFO: kube-dns-autoscaler-579dbcdc47-vzwfl from kube-system started at 2020-05-29 12:53:14 +0000 UTC (1 container statuses recorded)
May 29 17:10:41.284: INFO: 	Container autoscaler ready: true, restart count 0
May 29 17:10:41.284: INFO: wormhole-rbswg from kube-system started at 2020-05-29 12:52:43 +0000 UTC (1 container statuses recorded)
May 29 17:10:41.284: INFO: 	Container wormhole ready: true, restart count 0
May 29 17:10:41.285: INFO: coredns-78ff568f7c-d8dj2 from kube-system started at 2020-05-29 12:53:14 +0000 UTC (1 container statuses recorded)
May 29 17:10:41.285: INFO: 	Container coredns ready: true, restart count 0
May 29 17:10:41.285: INFO: sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-pvwlk from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:10:41.285: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:10:41.285: INFO: 	Container systemd-logs ready: true, restart count 0
May 29 17:10:41.286: INFO: kube-proxy-88gmf from kube-system started at 2020-05-29 12:52:43 +0000 UTC (1 container statuses recorded)
May 29 17:10:41.286: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:10:41.286: INFO: metrics-server-79cfd68c87-l6wn9 from kube-system started at 2020-05-29 12:53:03 +0000 UTC (1 container statuses recorded)
May 29 17:10:41.286: INFO: 	Container metrics-server ready: true, restart count 0
May 29 17:10:41.286: INFO: 
Logging pods the kubelet thinks is on node node-cncf-lab-3 before test
May 29 17:10:41.392: INFO: canal-lh9kw from kube-system started at 2020-05-29 12:59:04 +0000 UTC (2 container statuses recorded)
May 29 17:10:41.393: INFO: 	Container calico-node ready: true, restart count 0
May 29 17:10:41.393: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:10:41.394: INFO: kube-proxy-7bqtd from kube-system started at 2020-05-29 12:59:04 +0000 UTC (1 container statuses recorded)
May 29 17:10:41.394: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:10:41.394: INFO: wormhole-8llxp from kube-system started at 2020-05-29 12:59:04 +0000 UTC (1 container statuses recorded)
May 29 17:10:41.394: INFO: 	Container wormhole ready: true, restart count 0
May 29 17:10:41.394: INFO: sonobuoy from sonobuoy started at 2020-05-29 16:59:22 +0000 UTC (1 container statuses recorded)
May 29 17:10:41.394: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 29 17:10:41.394: INFO: sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-kp7d8 from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:10:41.394: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:10:41.394: INFO: 	Container systemd-logs ready: true, restart count 0
May 29 17:10:41.394: INFO: 
Logging pods the kubelet thinks is on node node-cncf-lab-4 before test
May 29 17:10:41.484: INFO: kube-proxy-rkjk6 from kube-system started at 2020-05-29 12:54:56 +0000 UTC (1 container statuses recorded)
May 29 17:10:41.484: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:10:41.484: INFO: sonobuoy-e2e-job-1012d486abe04715 from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:10:41.484: INFO: 	Container e2e ready: true, restart count 0
May 29 17:10:41.484: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:10:41.484: INFO: wormhole-n2mpq from kube-system started at 2020-05-29 12:54:56 +0000 UTC (1 container statuses recorded)
May 29 17:10:41.484: INFO: 	Container wormhole ready: true, restart count 0
May 29 17:10:41.484: INFO: sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-7449p from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:10:41.484: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:10:41.484: INFO: 	Container systemd-logs ready: true, restart count 0
May 29 17:10:41.485: INFO: canal-7v9cn from kube-system started at 2020-05-29 12:54:56 +0000 UTC (2 container statuses recorded)
May 29 17:10:41.485: INFO: 	Container calico-node ready: true, restart count 0
May 29 17:10:41.485: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-23088861-9794-4804-a26f-d8df399724d8 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-23088861-9794-4804-a26f-d8df399724d8 off the node node-cncf-lab-1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-23088861-9794-4804-a26f-d8df399724d8
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:10:48.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3980" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:7.116 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":277,"completed":45,"skipped":599,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:10:48.106: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-ecaa13bf-6dfb-4a06-92d3-ed8c9b20f4e5
STEP: Creating a pod to test consume secrets
May 29 17:10:48.265: INFO: Waiting up to 5m0s for pod "pod-secrets-b5b4990e-018a-45da-a8ef-a94e6d0df410" in namespace "secrets-9136" to be "Succeeded or Failed"
May 29 17:10:48.284: INFO: Pod "pod-secrets-b5b4990e-018a-45da-a8ef-a94e6d0df410": Phase="Pending", Reason="", readiness=false. Elapsed: 19.01831ms
May 29 17:10:50.300: INFO: Pod "pod-secrets-b5b4990e-018a-45da-a8ef-a94e6d0df410": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034387949s
May 29 17:10:52.314: INFO: Pod "pod-secrets-b5b4990e-018a-45da-a8ef-a94e6d0df410": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049284439s
STEP: Saw pod success
May 29 17:10:52.315: INFO: Pod "pod-secrets-b5b4990e-018a-45da-a8ef-a94e6d0df410" satisfied condition "Succeeded or Failed"
May 29 17:10:52.327: INFO: Trying to get logs from node node-cncf-lab-3 pod pod-secrets-b5b4990e-018a-45da-a8ef-a94e6d0df410 container secret-volume-test: <nil>
STEP: delete the pod
May 29 17:10:52.401: INFO: Waiting for pod pod-secrets-b5b4990e-018a-45da-a8ef-a94e6d0df410 to disappear
May 29 17:10:52.415: INFO: Pod pod-secrets-b5b4990e-018a-45da-a8ef-a94e6d0df410 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:10:52.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9136" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":46,"skipped":627,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:10:52.461: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-712d7351-ff20-43bd-b074-28a518b646d7
STEP: Creating a pod to test consume configMaps
May 29 17:10:52.610: INFO: Waiting up to 5m0s for pod "pod-configmaps-7da792c7-5a34-4bf7-bc50-8e690b1777ea" in namespace "configmap-2589" to be "Succeeded or Failed"
May 29 17:10:52.648: INFO: Pod "pod-configmaps-7da792c7-5a34-4bf7-bc50-8e690b1777ea": Phase="Pending", Reason="", readiness=false. Elapsed: 37.838617ms
May 29 17:10:54.922: INFO: Pod "pod-configmaps-7da792c7-5a34-4bf7-bc50-8e690b1777ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.311105787s
May 29 17:10:56.932: INFO: Pod "pod-configmaps-7da792c7-5a34-4bf7-bc50-8e690b1777ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.321912369s
STEP: Saw pod success
May 29 17:10:56.933: INFO: Pod "pod-configmaps-7da792c7-5a34-4bf7-bc50-8e690b1777ea" satisfied condition "Succeeded or Failed"
May 29 17:10:56.950: INFO: Trying to get logs from node node-cncf-lab-3 pod pod-configmaps-7da792c7-5a34-4bf7-bc50-8e690b1777ea container configmap-volume-test: <nil>
STEP: delete the pod
May 29 17:10:57.028: INFO: Waiting for pod pod-configmaps-7da792c7-5a34-4bf7-bc50-8e690b1777ea to disappear
May 29 17:10:57.047: INFO: Pod pod-configmaps-7da792c7-5a34-4bf7-bc50-8e690b1777ea no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:10:57.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2589" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":47,"skipped":676,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:10:57.095: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:10:57.302: INFO: Create a RollingUpdate DaemonSet
May 29 17:10:57.321: INFO: Check that daemon pods launch on every node of the cluster
May 29 17:10:57.339: INFO: Number of nodes with available pods: 0
May 29 17:10:57.340: INFO: Node node-cncf-lab-1 is running more than one daemon pod
May 29 17:10:58.446: INFO: Number of nodes with available pods: 0
May 29 17:10:58.447: INFO: Node node-cncf-lab-1 is running more than one daemon pod
May 29 17:10:59.372: INFO: Number of nodes with available pods: 0
May 29 17:10:59.372: INFO: Node node-cncf-lab-1 is running more than one daemon pod
May 29 17:11:00.399: INFO: Number of nodes with available pods: 0
May 29 17:11:00.399: INFO: Node node-cncf-lab-1 is running more than one daemon pod
May 29 17:11:01.371: INFO: Number of nodes with available pods: 4
May 29 17:11:01.371: INFO: Number of running nodes: 4, number of available pods: 4
May 29 17:11:01.371: INFO: Update the DaemonSet to trigger a rollout
May 29 17:11:01.961: INFO: Updating DaemonSet daemon-set
May 29 17:11:14.014: INFO: Roll back the DaemonSet before rollout is complete
May 29 17:11:14.033: INFO: Updating DaemonSet daemon-set
May 29 17:11:14.033: INFO: Make sure DaemonSet rollback is complete
May 29 17:11:14.041: INFO: Wrong image for pod: daemon-set-zr6bx. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
May 29 17:11:14.041: INFO: Pod daemon-set-zr6bx is not available
May 29 17:11:15.075: INFO: Wrong image for pod: daemon-set-zr6bx. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
May 29 17:11:15.075: INFO: Pod daemon-set-zr6bx is not available
May 29 17:11:16.077: INFO: Pod daemon-set-48n98 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-382, will wait for the garbage collector to delete the pods
May 29 17:11:16.254: INFO: Deleting DaemonSet.extensions daemon-set took: 56.277747ms
May 29 17:11:16.764: INFO: Terminating DaemonSet.extensions daemon-set pods took: 509.958026ms
May 29 17:11:26.575: INFO: Number of nodes with available pods: 0
May 29 17:11:26.575: INFO: Number of running nodes: 0, number of available pods: 0
May 29 17:11:26.593: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-382/daemonsets","resourceVersion":"12709615308"},"items":null}

May 29 17:11:26.604: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-382/pods","resourceVersion":"12709615312"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:11:26.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-382" for this suite.

• [SLOW TEST:29.600 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":277,"completed":48,"skipped":754,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:11:26.700: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
May 29 17:11:31.446: INFO: &Pod{ObjectMeta:{send-events-314bbc47-99c9-4068-b1e5-20e7ec2301ce  events-7880 /api/v1/namespaces/events-7880/pods/send-events-314bbc47-99c9-4068-b1e5-20e7ec2301ce a4517e5f-948f-4f96-a5a5-1a479fbee678 12709616784 0 2020-05-29 17:11:26 +0000 UTC <nil> <nil> map[name:foo time:828959046] map[cni.projectcalico.org/podIP:10.2.2.149/32] [] []  [{e2e.test Update v1 2020-05-29 17:11:26 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 116 105 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 112 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 114 116 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 99 111 110 116 97 105 110 101 114 80 111 114 116 92 34 58 56 48 44 92 34 112 114 111 116 111 99 111 108 92 34 58 92 34 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 99 111 110 116 97 105 110 101 114 80 111 114 116 34 58 123 125 44 34 102 58 112 114 111 116 111 99 111 108 34 58 123 125 125 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:11:28 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-05-29 17:11:29 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 46 50 46 49 52 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9fnfm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9fnfm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9fnfm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:11:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:11:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:11:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:11:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.83.108.252,PodIP:10.2.2.149,StartTime:2020-05-29 17:11:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-29 17:11:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://4c17c1a51da0d2cd17df5c65e4a9d942300d1ce865b7c5bcdbf103dea0ea9071,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.2.149,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
May 29 17:11:34.282: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
May 29 17:11:36.295: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:11:37.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7880" for this suite.

• [SLOW TEST:10.529 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]","total":277,"completed":49,"skipped":783,"failed":0}
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:11:37.234: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 29 17:11:38.276: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 29 17:11:41.699: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369098, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369098, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369098, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369098, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 29 17:11:45.116: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:11:45.128: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:11:48.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1194" for this suite.
STEP: Destroying namespace "webhook-1194-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:12.033 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":277,"completed":50,"skipped":783,"failed":0}
SSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:11:49.269: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:11:49.475: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-2b1ca9eb-b7e6-4fc6-9b77-b40d475ca75b" in namespace "security-context-test-8170" to be "Succeeded or Failed"
May 29 17:11:49.486: INFO: Pod "busybox-readonly-false-2b1ca9eb-b7e6-4fc6-9b77-b40d475ca75b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.136406ms
May 29 17:11:51.496: INFO: Pod "busybox-readonly-false-2b1ca9eb-b7e6-4fc6-9b77-b40d475ca75b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021658315s
May 29 17:11:53.509: INFO: Pod "busybox-readonly-false-2b1ca9eb-b7e6-4fc6-9b77-b40d475ca75b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034544165s
May 29 17:11:53.509: INFO: Pod "busybox-readonly-false-2b1ca9eb-b7e6-4fc6-9b77-b40d475ca75b" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:11:53.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8170" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":277,"completed":51,"skipped":788,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:11:53.552: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:11:53.720: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:11:55.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5458" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":277,"completed":52,"skipped":810,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:11:55.612: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:11:55.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9659" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":277,"completed":53,"skipped":827,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:11:55.857: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:12:07.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2429" for this suite.

• [SLOW TEST:11.554 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":277,"completed":54,"skipped":834,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:12:07.413: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 29 17:12:16.008: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 29 17:12:16.037: INFO: Pod pod-with-prestop-exec-hook still exists
May 29 17:12:18.037: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 29 17:12:18.049: INFO: Pod pod-with-prestop-exec-hook still exists
May 29 17:12:20.037: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 29 17:12:20.048: INFO: Pod pod-with-prestop-exec-hook still exists
May 29 17:12:22.037: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 29 17:12:22.916: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:12:23.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-477" for this suite.

• [SLOW TEST:16.501 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":277,"completed":55,"skipped":877,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:12:23.916: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
May 29 17:12:24.643: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the sample API server.
May 29 17:12:25.215: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
May 29 17:12:27.370: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369145, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369145, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369145, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369145, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:12:29.386: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369145, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369145, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369145, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369145, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:12:33.038: INFO: Waited 1.613810909s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:12:34.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-5951" for this suite.

• [SLOW TEST:10.175 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":277,"completed":56,"skipped":908,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:12:34.100: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-2d74044e-c72c-4b27-aa55-7108abc55ba2
STEP: Creating a pod to test consume secrets
May 29 17:12:35.215: INFO: Waiting up to 5m0s for pod "pod-secrets-f5028eac-a155-444c-8e5b-aea1b0eea5a6" in namespace "secrets-8163" to be "Succeeded or Failed"
May 29 17:12:35.393: INFO: Pod "pod-secrets-f5028eac-a155-444c-8e5b-aea1b0eea5a6": Phase="Pending", Reason="", readiness=false. Elapsed: 177.733766ms
May 29 17:12:37.405: INFO: Pod "pod-secrets-f5028eac-a155-444c-8e5b-aea1b0eea5a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.189730828s
May 29 17:12:39.420: INFO: Pod "pod-secrets-f5028eac-a155-444c-8e5b-aea1b0eea5a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.205019006s
STEP: Saw pod success
May 29 17:12:39.420: INFO: Pod "pod-secrets-f5028eac-a155-444c-8e5b-aea1b0eea5a6" satisfied condition "Succeeded or Failed"
May 29 17:12:39.432: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-secrets-f5028eac-a155-444c-8e5b-aea1b0eea5a6 container secret-volume-test: <nil>
STEP: delete the pod
May 29 17:12:39.521: INFO: Waiting for pod pod-secrets-f5028eac-a155-444c-8e5b-aea1b0eea5a6 to disappear
May 29 17:12:39.533: INFO: Pod pod-secrets-f5028eac-a155-444c-8e5b-aea1b0eea5a6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:12:39.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8163" for this suite.

• [SLOW TEST:5.469 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":57,"skipped":940,"failed":0}
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:12:39.569: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
May 29 17:12:39.674: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
May 29 17:12:53.978: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 17:13:00.669: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:13:15.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5690" for this suite.

• [SLOW TEST:35.727 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":277,"completed":58,"skipped":940,"failed":0}
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:13:15.297: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-downwardapi-vrcj
STEP: Creating a pod to test atomic-volume-subpath
May 29 17:13:15.492: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-vrcj" in namespace "subpath-9030" to be "Succeeded or Failed"
May 29 17:13:15.501: INFO: Pod "pod-subpath-test-downwardapi-vrcj": Phase="Pending", Reason="", readiness=false. Elapsed: 8.705133ms
May 29 17:13:17.515: INFO: Pod "pod-subpath-test-downwardapi-vrcj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022690811s
May 29 17:13:19.528: INFO: Pod "pod-subpath-test-downwardapi-vrcj": Phase="Running", Reason="", readiness=true. Elapsed: 4.035994872s
May 29 17:13:21.542: INFO: Pod "pod-subpath-test-downwardapi-vrcj": Phase="Running", Reason="", readiness=true. Elapsed: 6.049335496s
May 29 17:13:23.560: INFO: Pod "pod-subpath-test-downwardapi-vrcj": Phase="Running", Reason="", readiness=true. Elapsed: 8.067262571s
May 29 17:13:25.573: INFO: Pod "pod-subpath-test-downwardapi-vrcj": Phase="Running", Reason="", readiness=true. Elapsed: 10.080645761s
May 29 17:13:27.586: INFO: Pod "pod-subpath-test-downwardapi-vrcj": Phase="Running", Reason="", readiness=true. Elapsed: 12.093249751s
May 29 17:13:29.596: INFO: Pod "pod-subpath-test-downwardapi-vrcj": Phase="Running", Reason="", readiness=true. Elapsed: 14.103129995s
May 29 17:13:31.626: INFO: Pod "pod-subpath-test-downwardapi-vrcj": Phase="Running", Reason="", readiness=true. Elapsed: 16.13361636s
May 29 17:13:33.641: INFO: Pod "pod-subpath-test-downwardapi-vrcj": Phase="Running", Reason="", readiness=true. Elapsed: 18.148265715s
May 29 17:13:35.652: INFO: Pod "pod-subpath-test-downwardapi-vrcj": Phase="Running", Reason="", readiness=true. Elapsed: 20.159783254s
May 29 17:13:37.664: INFO: Pod "pod-subpath-test-downwardapi-vrcj": Phase="Running", Reason="", readiness=true. Elapsed: 22.171507847s
May 29 17:13:39.674: INFO: Pod "pod-subpath-test-downwardapi-vrcj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.18159507s
STEP: Saw pod success
May 29 17:13:39.674: INFO: Pod "pod-subpath-test-downwardapi-vrcj" satisfied condition "Succeeded or Failed"
May 29 17:13:39.684: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-subpath-test-downwardapi-vrcj container test-container-subpath-downwardapi-vrcj: <nil>
STEP: delete the pod
May 29 17:13:39.753: INFO: Waiting for pod pod-subpath-test-downwardapi-vrcj to disappear
May 29 17:13:39.763: INFO: Pod pod-subpath-test-downwardapi-vrcj no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-vrcj
May 29 17:13:39.763: INFO: Deleting pod "pod-subpath-test-downwardapi-vrcj" in namespace "subpath-9030"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:13:39.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9030" for this suite.

• [SLOW TEST:24.519 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [LinuxOnly] [Conformance]","total":277,"completed":59,"skipped":941,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:13:39.817: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-35b2006d-b438-4d16-879d-a259a22501a1
STEP: Creating secret with name s-test-opt-upd-b8de36e4-db60-4808-ac2c-0ea28232473d
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-35b2006d-b438-4d16-879d-a259a22501a1
STEP: Updating secret s-test-opt-upd-b8de36e4-db60-4808-ac2c-0ea28232473d
STEP: Creating secret with name s-test-opt-create-cd6e7604-a3df-42a8-9373-c689f807d573
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:15:04.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5375" for this suite.

• [SLOW TEST:84.772 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":60,"skipped":954,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:15:04.591: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
May 29 17:15:04.786: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2903c07d-005f-4e7c-a371-60b7bc3d7f54" in namespace "downward-api-9001" to be "Succeeded or Failed"
May 29 17:15:04.803: INFO: Pod "downwardapi-volume-2903c07d-005f-4e7c-a371-60b7bc3d7f54": Phase="Pending", Reason="", readiness=false. Elapsed: 17.000687ms
May 29 17:15:06.819: INFO: Pod "downwardapi-volume-2903c07d-005f-4e7c-a371-60b7bc3d7f54": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032353657s
May 29 17:15:08.838: INFO: Pod "downwardapi-volume-2903c07d-005f-4e7c-a371-60b7bc3d7f54": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052215739s
STEP: Saw pod success
May 29 17:15:08.839: INFO: Pod "downwardapi-volume-2903c07d-005f-4e7c-a371-60b7bc3d7f54" satisfied condition "Succeeded or Failed"
May 29 17:15:08.854: INFO: Trying to get logs from node node-cncf-lab-3 pod downwardapi-volume-2903c07d-005f-4e7c-a371-60b7bc3d7f54 container client-container: <nil>
STEP: delete the pod
May 29 17:15:08.971: INFO: Waiting for pod downwardapi-volume-2903c07d-005f-4e7c-a371-60b7bc3d7f54 to disappear
May 29 17:15:08.982: INFO: Pod downwardapi-volume-2903c07d-005f-4e7c-a371-60b7bc3d7f54 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:15:08.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9001" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":61,"skipped":966,"failed":0}
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:15:09.025: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-38ab0c28-b5a9-4dd2-8c44-72a6ffbfb402
STEP: Creating a pod to test consume secrets
May 29 17:15:10.137: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e40530b4-1be1-48e3-af25-66342ddfb5f8" in namespace "projected-5657" to be "Succeeded or Failed"
May 29 17:15:10.156: INFO: Pod "pod-projected-secrets-e40530b4-1be1-48e3-af25-66342ddfb5f8": Phase="Pending", Reason="", readiness=false. Elapsed: 18.610318ms
May 29 17:15:12.170: INFO: Pod "pod-projected-secrets-e40530b4-1be1-48e3-af25-66342ddfb5f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032581976s
May 29 17:15:14.182: INFO: Pod "pod-projected-secrets-e40530b4-1be1-48e3-af25-66342ddfb5f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044319067s
May 29 17:15:16.194: INFO: Pod "pod-projected-secrets-e40530b4-1be1-48e3-af25-66342ddfb5f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.056268034s
STEP: Saw pod success
May 29 17:15:16.194: INFO: Pod "pod-projected-secrets-e40530b4-1be1-48e3-af25-66342ddfb5f8" satisfied condition "Succeeded or Failed"
May 29 17:15:18.321: INFO: Trying to get logs from node node-cncf-lab-3 pod pod-projected-secrets-e40530b4-1be1-48e3-af25-66342ddfb5f8 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 29 17:15:18.459: INFO: Waiting for pod pod-projected-secrets-e40530b4-1be1-48e3-af25-66342ddfb5f8 to disappear
May 29 17:15:18.471: INFO: Pod pod-projected-secrets-e40530b4-1be1-48e3-af25-66342ddfb5f8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:15:18.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5657" for this suite.

• [SLOW TEST:9.479 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":62,"skipped":969,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:15:18.515: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
May 29 17:15:28.766: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
W0529 17:15:28.766838      20 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 29 17:15:28.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9998" for this suite.

• [SLOW TEST:10.282 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":277,"completed":63,"skipped":979,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:15:28.802: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:15:28.954: INFO: Pod name rollover-pod: Found 0 pods out of 1
May 29 17:15:33.968: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 29 17:15:33.969: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
May 29 17:15:35.979: INFO: Creating deployment "test-rollover-deployment"
May 29 17:15:36.009: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
May 29 17:15:38.050: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
May 29 17:15:38.412: INFO: Ensure that both replica sets have 1 created replica
May 29 17:15:38.436: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
May 29 17:15:38.457: INFO: Updating deployment test-rollover-deployment
May 29 17:15:38.457: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
May 29 17:15:40.508: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
May 29 17:15:40.564: INFO: Make sure deployment "test-rollover-deployment" is complete
May 29 17:15:40.606: INFO: all replica sets need to contain the pod-template-hash label
May 29 17:15:40.606: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369336, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369336, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369338, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369336, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:15:42.629: INFO: all replica sets need to contain the pod-template-hash label
May 29 17:15:42.629: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369336, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369336, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369341, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369336, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:15:44.629: INFO: all replica sets need to contain the pod-template-hash label
May 29 17:15:44.630: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369336, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369336, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369341, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369336, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:15:46.640: INFO: all replica sets need to contain the pod-template-hash label
May 29 17:15:46.640: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369336, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369336, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369341, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369336, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:15:48.642: INFO: all replica sets need to contain the pod-template-hash label
May 29 17:15:48.642: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369336, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369336, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369341, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369336, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:15:50.634: INFO: all replica sets need to contain the pod-template-hash label
May 29 17:15:50.634: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369336, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369336, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369341, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369336, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:15:52.631: INFO: 
May 29 17:15:52.631: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
May 29 17:15:52.667: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-9149 /apis/apps/v1/namespaces/deployment-9149/deployments/test-rollover-deployment 7ed1a528-3072-420d-b4e6-cdbaddcee638 12709710184 2 2020-05-29 17:15:35 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-05-29 17:15:38 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-05-29 17:15:51 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005bac368 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-05-29 17:15:36 +0000 UTC,LastTransitionTime:2020-05-29 17:15:36 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-84f7f6f64b" has successfully progressed.,LastUpdateTime:2020-05-29 17:15:51 +0000 UTC,LastTransitionTime:2020-05-29 17:15:36 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

May 29 17:15:52.683: INFO: New ReplicaSet "test-rollover-deployment-84f7f6f64b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-84f7f6f64b  deployment-9149 /apis/apps/v1/namespaces/deployment-9149/replicasets/test-rollover-deployment-84f7f6f64b 1924856f-fab6-47bd-bca9-7b5d23a6bdf5 12709710156 2 2020-05-29 17:15:38 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 7ed1a528-3072-420d-b4e6-cdbaddcee638 0xc005bac9f7 0xc005bac9f8}] []  [{kube-controller-manager Update apps/v1 2020-05-29 17:15:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 55 101 100 49 97 53 50 56 45 51 48 55 50 45 52 50 48 100 45 98 52 101 54 45 99 100 98 97 100 100 99 101 101 54 51 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 84f7f6f64b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005baca88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May 29 17:15:52.683: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
May 29 17:15:52.684: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-9149 /apis/apps/v1/namespaces/deployment-9149/replicasets/test-rollover-controller 2eda2989-f9d3-4089-a462-a57ee42248cc 12709710180 2 2020-05-29 17:15:28 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 7ed1a528-3072-420d-b4e6-cdbaddcee638 0xc005bac7e7 0xc005bac7e8}] []  [{e2e.test Update apps/v1 2020-05-29 17:15:28 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-05-29 17:15:51 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 55 101 100 49 97 53 50 56 45 51 48 55 50 45 52 50 48 100 45 98 52 101 54 45 99 100 98 97 100 100 99 101 101 54 51 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005bac888 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May 29 17:15:52.684: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-5686c4cfd5  deployment-9149 /apis/apps/v1/namespaces/deployment-9149/replicasets/test-rollover-deployment-5686c4cfd5 a6d21c5c-fca9-4aa3-939a-67691cf1f65c 12709704789 2 2020-05-29 17:15:36 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 7ed1a528-3072-420d-b4e6-cdbaddcee638 0xc005bac8f7 0xc005bac8f8}] []  [{kube-controller-manager Update apps/v1 2020-05-29 17:15:38 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 55 101 100 49 97 53 50 56 45 51 48 55 50 45 52 50 48 100 45 98 52 101 54 45 99 100 98 97 100 100 99 101 101 54 51 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 114 101 100 105 115 45 115 108 97 118 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5686c4cfd5,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005bac988 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May 29 17:15:52.702: INFO: Pod "test-rollover-deployment-84f7f6f64b-dpgbf" is available:
&Pod{ObjectMeta:{test-rollover-deployment-84f7f6f64b-dpgbf test-rollover-deployment-84f7f6f64b- deployment-9149 /api/v1/namespaces/deployment-9149/pods/test-rollover-deployment-84f7f6f64b-dpgbf cf6bec6c-163d-4ef7-a656-615c7045953e 12709705935 0 2020-05-29 17:15:38 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[cni.projectcalico.org/podIP:10.2.2.158/32] [{apps/v1 ReplicaSet test-rollover-deployment-84f7f6f64b 1924856f-fab6-47bd-bca9-7b5d23a6bdf5 0xc005bad087 0xc005bad088}] []  [{kube-controller-manager Update v1 2020-05-29 17:15:38 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 57 50 52 56 53 54 102 45 102 97 98 54 45 52 55 98 100 45 98 99 97 57 45 55 98 53 100 50 51 97 54 98 100 102 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:15:39 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-05-29 17:15:41 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 46 50 46 49 53 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rmjth,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rmjth,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rmjth,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:15:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:15:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:15:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:15:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.83.108.252,PodIP:10.2.2.158,StartTime:2020-05-29 17:15:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-29 17:15:40 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://dae1ec80fe4a0923f1ffabd6b54f6ac96a0a7fa1e14790e8e1138ed84a124534,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.2.158,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:15:52.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9149" for this suite.

• [SLOW TEST:23.984 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":277,"completed":64,"skipped":1016,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:15:52.789: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl logs
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1288
STEP: creating an pod
May 29 17:15:52.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 run logs-generator --image=us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 --namespace=kubectl-1240 -- logs-generator --log-lines-total 100 --run-duration 20s'
May 29 17:15:53.299: INFO: stderr: ""
May 29 17:15:53.299: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Waiting for log generator to start.
May 29 17:15:53.300: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
May 29 17:15:53.300: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-1240" to be "running and ready, or succeeded"
May 29 17:15:53.311: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 11.114869ms
May 29 17:15:55.319: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019906653s
May 29 17:15:57.372: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.072701753s
May 29 17:15:57.372: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
May 29 17:15:57.372: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
May 29 17:15:57.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 logs logs-generator logs-generator --namespace=kubectl-1240'
May 29 17:15:57.579: INFO: stderr: ""
May 29 17:15:57.579: INFO: stdout: "I0529 17:15:55.606875       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/fcw 335\nI0529 17:15:55.807200       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/kfz 508\nI0529 17:15:56.007279       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/sljz 264\nI0529 17:15:56.207094       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/lrgx 482\nI0529 17:15:56.407123       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/jqt 275\nI0529 17:15:56.608187       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/5kgw 444\nI0529 17:15:56.807268       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/v6z 266\nI0529 17:15:57.007240       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/wkh 449\nI0529 17:15:57.207279       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/mw5 209\nI0529 17:15:57.407269       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/6p98 306\n"
STEP: limiting log lines
May 29 17:15:57.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 logs logs-generator logs-generator --namespace=kubectl-1240 --tail=1'
May 29 17:15:57.780: INFO: stderr: ""
May 29 17:15:57.780: INFO: stdout: "I0529 17:15:57.607172       1 logs_generator.go:76] 10 POST /api/v1/namespaces/default/pods/sgvg 332\n"
May 29 17:15:57.781: INFO: got output "I0529 17:15:57.607172       1 logs_generator.go:76] 10 POST /api/v1/namespaces/default/pods/sgvg 332\n"
STEP: limiting log bytes
May 29 17:15:57.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 logs logs-generator logs-generator --namespace=kubectl-1240 --limit-bytes=1'
May 29 17:15:57.998: INFO: stderr: ""
May 29 17:15:57.998: INFO: stdout: "I"
May 29 17:15:57.998: INFO: got output "I"
STEP: exposing timestamps
May 29 17:15:57.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 logs logs-generator logs-generator --namespace=kubectl-1240 --tail=1 --timestamps'
May 29 17:15:58.199: INFO: stderr: ""
May 29 17:15:58.199: INFO: stdout: "2020-05-29T17:15:58.007855888Z I0529 17:15:58.007160       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/67kr 535\n"
May 29 17:15:58.199: INFO: got output "2020-05-29T17:15:58.007855888Z I0529 17:15:58.007160       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/67kr 535\n"
STEP: restricting to a time range
May 29 17:16:00.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 logs logs-generator logs-generator --namespace=kubectl-1240 --since=1s'
May 29 17:16:00.881: INFO: stderr: ""
May 29 17:16:00.881: INFO: stdout: "I0529 17:16:00.007322       1 logs_generator.go:76] 22 POST /api/v1/namespaces/default/pods/svq 342\nI0529 17:16:00.207234       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/default/pods/9f6 525\nI0529 17:16:00.407220       1 logs_generator.go:76] 24 PUT /api/v1/namespaces/kube-system/pods/9l6n 237\nI0529 17:16:00.607134       1 logs_generator.go:76] 25 GET /api/v1/namespaces/ns/pods/r9c7 451\nI0529 17:16:00.807052       1 logs_generator.go:76] 26 GET /api/v1/namespaces/default/pods/m6j 353\n"
May 29 17:16:00.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 logs logs-generator logs-generator --namespace=kubectl-1240 --since=24h'
May 29 17:16:01.082: INFO: stderr: ""
May 29 17:16:01.082: INFO: stdout: "I0529 17:15:55.606875       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/fcw 335\nI0529 17:15:55.807200       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/kfz 508\nI0529 17:15:56.007279       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/sljz 264\nI0529 17:15:56.207094       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/lrgx 482\nI0529 17:15:56.407123       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/jqt 275\nI0529 17:15:56.608187       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/5kgw 444\nI0529 17:15:56.807268       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/v6z 266\nI0529 17:15:57.007240       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/wkh 449\nI0529 17:15:57.207279       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/mw5 209\nI0529 17:15:57.407269       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/6p98 306\nI0529 17:15:57.607172       1 logs_generator.go:76] 10 POST /api/v1/namespaces/default/pods/sgvg 332\nI0529 17:15:57.807077       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/dzrm 323\nI0529 17:15:58.007160       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/67kr 535\nI0529 17:15:58.207154       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/2r7r 200\nI0529 17:15:58.407179       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/ns/pods/lz9 379\nI0529 17:15:58.607044       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/5rz 365\nI0529 17:15:58.808698       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/qgdr 502\nI0529 17:15:59.007160       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/qj6s 285\nI0529 17:15:59.207142       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/65v 489\nI0529 17:15:59.407209       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/27rn 302\nI0529 17:15:59.607279       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/tv2 557\nI0529 17:15:59.807309       1 logs_generator.go:76] 21 GET /api/v1/namespaces/ns/pods/b7ks 468\nI0529 17:16:00.007322       1 logs_generator.go:76] 22 POST /api/v1/namespaces/default/pods/svq 342\nI0529 17:16:00.207234       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/default/pods/9f6 525\nI0529 17:16:00.407220       1 logs_generator.go:76] 24 PUT /api/v1/namespaces/kube-system/pods/9l6n 237\nI0529 17:16:00.607134       1 logs_generator.go:76] 25 GET /api/v1/namespaces/ns/pods/r9c7 451\nI0529 17:16:00.807052       1 logs_generator.go:76] 26 GET /api/v1/namespaces/default/pods/m6j 353\nI0529 17:16:01.007117       1 logs_generator.go:76] 27 GET /api/v1/namespaces/default/pods/9jrw 411\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1294
May 29 17:16:01.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 delete pod logs-generator --namespace=kubectl-1240'
May 29 17:16:10.652: INFO: stderr: ""
May 29 17:16:10.652: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:16:10.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1240" for this suite.

• [SLOW TEST:17.927 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1284
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":277,"completed":65,"skipped":1018,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:16:10.717: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override all
May 29 17:16:10.941: INFO: Waiting up to 5m0s for pod "client-containers-8b7e4026-c17c-4c68-8ed7-ae6924cf0184" in namespace "containers-2780" to be "Succeeded or Failed"
May 29 17:16:10.953: INFO: Pod "client-containers-8b7e4026-c17c-4c68-8ed7-ae6924cf0184": Phase="Pending", Reason="", readiness=false. Elapsed: 11.825594ms
May 29 17:16:12.970: INFO: Pod "client-containers-8b7e4026-c17c-4c68-8ed7-ae6924cf0184": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028500741s
May 29 17:16:14.986: INFO: Pod "client-containers-8b7e4026-c17c-4c68-8ed7-ae6924cf0184": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044641073s
STEP: Saw pod success
May 29 17:16:14.986: INFO: Pod "client-containers-8b7e4026-c17c-4c68-8ed7-ae6924cf0184" satisfied condition "Succeeded or Failed"
May 29 17:16:14.996: INFO: Trying to get logs from node node-cncf-lab-1 pod client-containers-8b7e4026-c17c-4c68-8ed7-ae6924cf0184 container test-container: <nil>
STEP: delete the pod
May 29 17:16:15.068: INFO: Waiting for pod client-containers-8b7e4026-c17c-4c68-8ed7-ae6924cf0184 to disappear
May 29 17:16:15.078: INFO: Pod client-containers-8b7e4026-c17c-4c68-8ed7-ae6924cf0184 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:16:15.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2780" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":277,"completed":66,"skipped":1044,"failed":0}
SSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:16:15.112: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test hostPath mode
May 29 17:16:15.259: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-1206" to be "Succeeded or Failed"
May 29 17:16:15.274: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 14.785515ms
May 29 17:16:17.286: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026950736s
May 29 17:16:19.297: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038099834s
May 29 17:16:21.344: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.08452521s
STEP: Saw pod success
May 29 17:16:21.344: INFO: Pod "pod-host-path-test" satisfied condition "Succeeded or Failed"
May 29 17:16:21.360: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
May 29 17:16:21.412: INFO: Waiting for pod pod-host-path-test to disappear
May 29 17:16:21.423: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:16:21.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-1206" for this suite.

• [SLOW TEST:6.340 seconds]
[sig-storage] HostPath
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":67,"skipped":1047,"failed":0}
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:16:21.454: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:16:38.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8207" for this suite.

• [SLOW TEST:17.113 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":277,"completed":68,"skipped":1048,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:16:38.574: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-projected-j5kk
STEP: Creating a pod to test atomic-volume-subpath
May 29 17:16:38.846: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-j5kk" in namespace "subpath-9426" to be "Succeeded or Failed"
May 29 17:16:38.855: INFO: Pod "pod-subpath-test-projected-j5kk": Phase="Pending", Reason="", readiness=false. Elapsed: 8.50938ms
May 29 17:16:40.870: INFO: Pod "pod-subpath-test-projected-j5kk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02350541s
May 29 17:16:42.896: INFO: Pod "pod-subpath-test-projected-j5kk": Phase="Running", Reason="", readiness=true. Elapsed: 4.049689071s
May 29 17:16:44.927: INFO: Pod "pod-subpath-test-projected-j5kk": Phase="Running", Reason="", readiness=true. Elapsed: 6.080185575s
May 29 17:16:46.939: INFO: Pod "pod-subpath-test-projected-j5kk": Phase="Running", Reason="", readiness=true. Elapsed: 8.092976659s
May 29 17:16:48.951: INFO: Pod "pod-subpath-test-projected-j5kk": Phase="Running", Reason="", readiness=true. Elapsed: 10.104237083s
May 29 17:16:50.963: INFO: Pod "pod-subpath-test-projected-j5kk": Phase="Running", Reason="", readiness=true. Elapsed: 12.11672122s
May 29 17:16:52.976: INFO: Pod "pod-subpath-test-projected-j5kk": Phase="Running", Reason="", readiness=true. Elapsed: 14.129256774s
May 29 17:16:54.991: INFO: Pod "pod-subpath-test-projected-j5kk": Phase="Running", Reason="", readiness=true. Elapsed: 16.144540562s
May 29 17:16:57.006: INFO: Pod "pod-subpath-test-projected-j5kk": Phase="Running", Reason="", readiness=true. Elapsed: 18.159819054s
May 29 17:16:59.019: INFO: Pod "pod-subpath-test-projected-j5kk": Phase="Running", Reason="", readiness=true. Elapsed: 20.172524054s
May 29 17:17:01.051: INFO: Pod "pod-subpath-test-projected-j5kk": Phase="Running", Reason="", readiness=true. Elapsed: 22.204741433s
May 29 17:17:03.203: INFO: Pod "pod-subpath-test-projected-j5kk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.356344856s
STEP: Saw pod success
May 29 17:17:03.203: INFO: Pod "pod-subpath-test-projected-j5kk" satisfied condition "Succeeded or Failed"
May 29 17:17:03.218: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-subpath-test-projected-j5kk container test-container-subpath-projected-j5kk: <nil>
STEP: delete the pod
May 29 17:17:03.289: INFO: Waiting for pod pod-subpath-test-projected-j5kk to disappear
May 29 17:17:03.305: INFO: Pod pod-subpath-test-projected-j5kk no longer exists
STEP: Deleting pod pod-subpath-test-projected-j5kk
May 29 17:17:03.305: INFO: Deleting pod "pod-subpath-test-projected-j5kk" in namespace "subpath-9426"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:17:03.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9426" for this suite.

• [SLOW TEST:24.790 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [LinuxOnly] [Conformance]","total":277,"completed":69,"skipped":1076,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:17:03.371: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:17:03.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 create -f - --namespace=kubectl-6399'
May 29 17:17:03.857: INFO: stderr: ""
May 29 17:17:03.857: INFO: stdout: "replicationcontroller/agnhost-master created\n"
May 29 17:17:03.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 create -f - --namespace=kubectl-6399'
May 29 17:17:04.134: INFO: stderr: ""
May 29 17:17:04.134: INFO: stdout: "service/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
May 29 17:17:05.228: INFO: Selector matched 1 pods for map[app:agnhost]
May 29 17:17:05.228: INFO: Found 0 / 1
May 29 17:17:06.145: INFO: Selector matched 1 pods for map[app:agnhost]
May 29 17:17:06.146: INFO: Found 0 / 1
May 29 17:17:07.144: INFO: Selector matched 1 pods for map[app:agnhost]
May 29 17:17:07.144: INFO: Found 1 / 1
May 29 17:17:07.144: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 29 17:17:07.157: INFO: Selector matched 1 pods for map[app:agnhost]
May 29 17:17:07.157: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 29 17:17:07.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 describe pod agnhost-master-g4gmm --namespace=kubectl-6399'
May 29 17:17:07.350: INFO: stderr: ""
May 29 17:17:07.350: INFO: stdout: "Name:         agnhost-master-g4gmm\nNamespace:    kubectl-6399\nPriority:     0\nNode:         node-cncf-lab-1/51.83.108.252\nStart Time:   Fri, 29 May 2020 17:17:03 +0000\nLabels:       app=agnhost\n              role=master\nAnnotations:  cni.projectcalico.org/podIP: 10.2.2.165/32\nStatus:       Running\nIP:           10.2.2.165\nIPs:\n  IP:           10.2.2.165\nControlled By:  ReplicationController/agnhost-master\nContainers:\n  agnhost-master:\n    Container ID:   docker://2597a210023c9aa700e9473bb5c6ee8b64392749182ec5371847d5743321cc49\n    Image:          us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Image ID:       docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 29 May 2020 17:17:06 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-gnsdr (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-gnsdr:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-gnsdr\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                      Message\n  ----    ------     ----  ----                      -------\n  Normal  Scheduled  4s    default-scheduler         Successfully assigned kubectl-6399/agnhost-master-g4gmm to node-cncf-lab-1\n  Normal  Pulling    2s    kubelet, node-cncf-lab-1  Pulling image \"us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\"\n  Normal  Pulled     2s    kubelet, node-cncf-lab-1  Successfully pulled image \"us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\"\n  Normal  Created    1s    kubelet, node-cncf-lab-1  Created container agnhost-master\n  Normal  Started    1s    kubelet, node-cncf-lab-1  Started container agnhost-master\n"
May 29 17:17:07.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 describe rc agnhost-master --namespace=kubectl-6399'
May 29 17:17:07.866: INFO: stderr: ""
May 29 17:17:07.867: INFO: stdout: "Name:         agnhost-master\nNamespace:    kubectl-6399\nSelector:     app=agnhost,role=master\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=master\n  Containers:\n   agnhost-master:\n    Image:        us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: agnhost-master-g4gmm\n"
May 29 17:17:07.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 describe service agnhost-master --namespace=kubectl-6399'
May 29 17:17:08.085: INFO: stderr: ""
May 29 17:17:08.085: INFO: stdout: "Name:              agnhost-master\nNamespace:         kubectl-6399\nLabels:            app=agnhost\n                   role=master\nAnnotations:       <none>\nSelector:          app=agnhost,role=master\nType:              ClusterIP\nIP:                10.3.142.149\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.2.2.165:6379\nSession Affinity:  None\nEvents:            <none>\n"
May 29 17:17:08.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 describe node node-cncf-lab-1'
May 29 17:17:08.328: INFO: stderr: ""
May 29 17:17:08.328: INFO: stdout: "Name:               node-cncf-lab-1\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=0ff9e048-50af-4b2e-bc61-72611d23fca7\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=GRA5\n                    failure-domain.beta.kubernetes.io/zone=nova\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=node-cncf-lab-1\n                    kubernetes.io/os=linux\n                    node.k8s.ovh/type=standard\n                    node.kubernetes.io/instance-type=0ff9e048-50af-4b2e-bc61-72611d23fca7\n                    topology.cinder.csi.openstack.org/zone=nova\n                    topology.kubernetes.io/region=GRA5\n                    topology.kubernetes.io/zone=nova\nAnnotations:        alpha.kubernetes.io/provided-node-ip: 51.83.108.252\n                    csi.volume.kubernetes.io/nodeid: {\"cinder.csi.openstack.org\":\"7210c830-6ff3-41fc-b113-2cee1269e943\"}\n                    flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"1a:db:f2:bd:88:49\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 51.83.108.252\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.2.2.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 29 May 2020 12:57:00 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  node-cncf-lab-1\n  AcquireTime:     <unset>\n  RenewTime:       Fri, 29 May 2020 17:17:01 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Fri, 29 May 2020 17:16:13 +0000   Fri, 29 May 2020 12:57:00 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Fri, 29 May 2020 17:16:13 +0000   Fri, 29 May 2020 12:57:00 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Fri, 29 May 2020 17:16:13 +0000   Fri, 29 May 2020 12:57:00 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Fri, 29 May 2020 17:16:13 +0000   Fri, 29 May 2020 12:57:20 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  51.83.108.252\n  Hostname:    node-cncf-lab-1\nCapacity:\n  cpu:                2\n  ephemeral-storage:  50633164Ki\n  hugepages-2Mi:      0\n  memory:             6965752Ki\n  pods:               110\nAllocatable:\n  cpu:                1900m\n  ephemeral-storage:  50633164Ki\n  hugepages-2Mi:      0\n  memory:             5405176Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 7210c8306ff341fcb1132cee1269e943\n  System UUID:                7210C830-6FF3-41FC-B113-2CEE1269E943\n  Boot ID:                    c477a172-80b7-408f-b6ea-5ee1a0647e3b\n  Kernel Version:             4.15.0-96-generic\n  OS Image:                   Ubuntu 18.04.4 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://18.6.3\n  Kubelet Version:            v1.18.1\n  Kube-Proxy Version:         v1.18.1\nPodCIDR:                      10.2.2.0/24\nPodCIDRs:                     10.2.2.0/24\nProviderID:                   openstack:///7210c830-6ff3-41fc-b113-2cee1269e943\nNon-terminated Pods:          (5 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 canal-6vpdg                                                250m (13%)    0 (0%)      0 (0%)           0 (0%)         4h20m\n  kube-system                 kube-proxy-24chw                                           100m (5%)     0 (0%)      200Mi (3%)       200Mi (3%)     4h20m\n  kube-system                 wormhole-b4h5r                                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         4h20m\n  kubectl-6399                agnhost-master-g4gmm                                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         5s\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-dngk9    0 (0%)        0 (0%)      0 (0%)           0 (0%)         17m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                350m (18%)  0 (0%)\n  memory             200Mi (3%)  200Mi (3%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
May 29 17:17:08.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 describe namespace kubectl-6399'
May 29 17:17:08.506: INFO: stderr: ""
May 29 17:17:08.506: INFO: stdout: "Name:         kubectl-6399\nLabels:       e2e-framework=kubectl\n              e2e-run=c8b815dd-bd9a-442e-b20a-5c4565bd2910\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:17:08.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6399" for this suite.

• [SLOW TEST:5.173 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:978
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":277,"completed":70,"skipped":1095,"failed":0}
S
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:17:08.545: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:17:40.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8801" for this suite.

• [SLOW TEST:32.241 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  blackbox test
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
    when starting a container that exits
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:41
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":277,"completed":71,"skipped":1096,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:17:40.789: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
May 29 17:17:41.577: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0529 17:17:41.577412      20 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:17:41.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1626" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":277,"completed":72,"skipped":1126,"failed":0}

------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:17:42.352: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1418
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
May 29 17:17:42.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 run e2e-test-httpd-pod --restart=Never --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-4669'
May 29 17:17:42.810: INFO: stderr: ""
May 29 17:17:42.810: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1423
May 29 17:17:42.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 delete pods e2e-test-httpd-pod --namespace=kubectl-4669'
May 29 17:17:50.698: INFO: stderr: ""
May 29 17:17:50.698: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:17:50.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4669" for this suite.

• [SLOW TEST:8.422 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":277,"completed":73,"skipped":1126,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:17:50.774: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-80995a22-bcee-4d83-afcb-517ea61d2111
STEP: Creating a pod to test consume configMaps
May 29 17:17:51.071: INFO: Waiting up to 5m0s for pod "pod-configmaps-25c0f98e-39f3-4d95-bd26-dcbcc5d0c18f" in namespace "configmap-2143" to be "Succeeded or Failed"
May 29 17:17:51.085: INFO: Pod "pod-configmaps-25c0f98e-39f3-4d95-bd26-dcbcc5d0c18f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.584117ms
May 29 17:17:53.096: INFO: Pod "pod-configmaps-25c0f98e-39f3-4d95-bd26-dcbcc5d0c18f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02490602s
May 29 17:17:55.108: INFO: Pod "pod-configmaps-25c0f98e-39f3-4d95-bd26-dcbcc5d0c18f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037296901s
STEP: Saw pod success
May 29 17:17:55.108: INFO: Pod "pod-configmaps-25c0f98e-39f3-4d95-bd26-dcbcc5d0c18f" satisfied condition "Succeeded or Failed"
May 29 17:17:55.122: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-configmaps-25c0f98e-39f3-4d95-bd26-dcbcc5d0c18f container configmap-volume-test: <nil>
STEP: delete the pod
May 29 17:17:55.205: INFO: Waiting for pod pod-configmaps-25c0f98e-39f3-4d95-bd26-dcbcc5d0c18f to disappear
May 29 17:17:55.216: INFO: Pod pod-configmaps-25c0f98e-39f3-4d95-bd26-dcbcc5d0c18f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:17:55.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2143" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":277,"completed":74,"skipped":1139,"failed":0}
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:17:55.255: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 29 17:18:04.339: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 29 17:18:04.353: INFO: Pod pod-with-prestop-http-hook still exists
May 29 17:18:06.353: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 29 17:18:06.372: INFO: Pod pod-with-prestop-http-hook still exists
May 29 17:18:08.353: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 29 17:18:08.364: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:18:08.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3983" for this suite.

• [SLOW TEST:13.434 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":277,"completed":75,"skipped":1145,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:18:08.689: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service multi-endpoint-test in namespace services-7484
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7484 to expose endpoints map[]
May 29 17:18:09.126: INFO: successfully validated that service multi-endpoint-test in namespace services-7484 exposes endpoints map[] (41.294018ms elapsed)
STEP: Creating pod pod1 in namespace services-7484
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7484 to expose endpoints map[pod1:[100]]
May 29 17:18:13.002: INFO: successfully validated that service multi-endpoint-test in namespace services-7484 exposes endpoints map[pod1:[100]] (3.842958676s elapsed)
STEP: Creating pod pod2 in namespace services-7484
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7484 to expose endpoints map[pod1:[100] pod2:[101]]
May 29 17:18:16.199: INFO: successfully validated that service multi-endpoint-test in namespace services-7484 exposes endpoints map[pod1:[100] pod2:[101]] (3.181025323s elapsed)
STEP: Deleting pod pod1 in namespace services-7484
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7484 to expose endpoints map[pod2:[101]]
May 29 17:18:16.248: INFO: successfully validated that service multi-endpoint-test in namespace services-7484 exposes endpoints map[pod2:[101]] (23.824383ms elapsed)
STEP: Deleting pod pod2 in namespace services-7484
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7484 to expose endpoints map[]
May 29 17:18:16.286: INFO: successfully validated that service multi-endpoint-test in namespace services-7484 exposes endpoints map[] (21.982245ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:18:16.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7484" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:7.687 seconds]
[sig-network] Services
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":277,"completed":76,"skipped":1196,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:18:16.377: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-93769316-e95a-439d-8f76-df5e40d12873 in namespace container-probe-2482
May 29 17:18:20.541: INFO: Started pod busybox-93769316-e95a-439d-8f76-df5e40d12873 in namespace container-probe-2482
STEP: checking the pod's current state and verifying that restartCount is present
May 29 17:18:20.551: INFO: Initial restart count of pod busybox-93769316-e95a-439d-8f76-df5e40d12873 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:22:21.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2482" for this suite.

• [SLOW TEST:244.881 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":277,"completed":77,"skipped":1215,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:22:21.278: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 29 17:22:22.043: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 29 17:22:24.080: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369742, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369742, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369742, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369742, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 29 17:22:27.119: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:22:27.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8713" for this suite.
STEP: Destroying namespace "webhook-8713-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.308 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":277,"completed":78,"skipped":1249,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:22:27.596: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-4186, will wait for the garbage collector to delete the pods
May 29 17:22:32.021: INFO: Deleting Job.batch foo took: 20.358691ms
May 29 17:22:32.121: INFO: Terminating Job.batch foo pods took: 100.402876ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:23:10.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4186" for this suite.

• [SLOW TEST:43.500 seconds]
[sig-apps] Job
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":277,"completed":79,"skipped":1264,"failed":0}
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:23:11.097: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 29 17:23:11.919: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 29 17:23:13.956: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369791, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369791, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369791, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369791, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 29 17:23:17.014: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:23:17.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2593" for this suite.
STEP: Destroying namespace "webhook-2593-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.244 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":277,"completed":80,"skipped":1264,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:23:17.341: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating api versions
May 29 17:23:17.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 api-versions'
May 29 17:23:17.782: INFO: stderr: ""
May 29 17:23:17.782: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nkube.cloud.ovh.com/v1alpha1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nsnapshot.storage.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:23:17.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5076" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":277,"completed":81,"skipped":1267,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:23:17.826: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
May 29 17:23:18.825: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
May 29 17:23:20.894: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369798, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369798, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369798, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369798, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 29 17:23:23.952: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:23:23.966: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:23:26.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-2599" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:9.228 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":277,"completed":82,"skipped":1275,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:23:27.057: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
May 29 17:23:27.208: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dfd44bf6-4f48-4286-aae2-4afccdd0aa5c" in namespace "projected-6875" to be "Succeeded or Failed"
May 29 17:23:27.220: INFO: Pod "downwardapi-volume-dfd44bf6-4f48-4286-aae2-4afccdd0aa5c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.006042ms
May 29 17:23:29.231: INFO: Pod "downwardapi-volume-dfd44bf6-4f48-4286-aae2-4afccdd0aa5c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022082777s
May 29 17:23:31.241: INFO: Pod "downwardapi-volume-dfd44bf6-4f48-4286-aae2-4afccdd0aa5c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032283583s
STEP: Saw pod success
May 29 17:23:31.241: INFO: Pod "downwardapi-volume-dfd44bf6-4f48-4286-aae2-4afccdd0aa5c" satisfied condition "Succeeded or Failed"
May 29 17:23:31.250: INFO: Trying to get logs from node node-cncf-lab-3 pod downwardapi-volume-dfd44bf6-4f48-4286-aae2-4afccdd0aa5c container client-container: <nil>
STEP: delete the pod
May 29 17:23:31.361: INFO: Waiting for pod downwardapi-volume-dfd44bf6-4f48-4286-aae2-4afccdd0aa5c to disappear
May 29 17:23:31.375: INFO: Pod downwardapi-volume-dfd44bf6-4f48-4286-aae2-4afccdd0aa5c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:23:31.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6875" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":83,"skipped":1283,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:23:31.413: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:23:38.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6302" for this suite.

• [SLOW TEST:7.219 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":277,"completed":84,"skipped":1308,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:23:38.636: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
May 29 17:23:45.804: INFO: Successfully updated pod "adopt-release-ghjvs"
STEP: Checking that the Job readopts the Pod
May 29 17:23:45.804: INFO: Waiting up to 15m0s for pod "adopt-release-ghjvs" in namespace "job-3703" to be "adopted"
May 29 17:23:45.813: INFO: Pod "adopt-release-ghjvs": Phase="Running", Reason="", readiness=true. Elapsed: 9.073709ms
May 29 17:23:47.828: INFO: Pod "adopt-release-ghjvs": Phase="Running", Reason="", readiness=true. Elapsed: 2.023336242s
May 29 17:23:47.828: INFO: Pod "adopt-release-ghjvs" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
May 29 17:23:48.360: INFO: Successfully updated pod "adopt-release-ghjvs"
STEP: Checking that the Job releases the Pod
May 29 17:23:48.360: INFO: Waiting up to 15m0s for pod "adopt-release-ghjvs" in namespace "job-3703" to be "released"
May 29 17:23:48.369: INFO: Pod "adopt-release-ghjvs": Phase="Running", Reason="", readiness=true. Elapsed: 9.240896ms
May 29 17:23:50.385: INFO: Pod "adopt-release-ghjvs": Phase="Running", Reason="", readiness=true. Elapsed: 2.024430771s
May 29 17:23:50.385: INFO: Pod "adopt-release-ghjvs" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:23:50.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3703" for this suite.

• [SLOW TEST:11.778 seconds]
[sig-apps] Job
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":277,"completed":85,"skipped":1326,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:23:50.415: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:23:50.533: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Creating first CR 
May 29 17:23:51.264: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-05-29T17:23:51Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-05-29T17:23:51Z]] name:name1 resourceVersion:12709893710 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:e0ece4f9-fee1-4fb8-a7d5-ce3e2e1b9d7f] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
May 29 17:24:01.293: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-05-29T17:24:01Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-05-29T17:24:01Z]] name:name2 resourceVersion:12709897666 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:640af786-76b7-4cc7-89a6-7ea79c86336c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
May 29 17:24:11.316: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-05-29T17:23:51Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-05-29T17:24:11Z]] name:name1 resourceVersion:12709901288 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:e0ece4f9-fee1-4fb8-a7d5-ce3e2e1b9d7f] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
May 29 17:24:21.333: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-05-29T17:24:01Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-05-29T17:24:21Z]] name:name2 resourceVersion:12709905202 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:640af786-76b7-4cc7-89a6-7ea79c86336c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
May 29 17:24:31.372: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-05-29T17:23:51Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-05-29T17:24:11Z]] name:name1 resourceVersion:12709909079 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:e0ece4f9-fee1-4fb8-a7d5-ce3e2e1b9d7f] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
May 29 17:24:41.483: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-05-29T17:24:01Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-05-29T17:24:21Z]] name:name2 resourceVersion:12709912938 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:640af786-76b7-4cc7-89a6-7ea79c86336c] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:24:52.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-7926" for this suite.

• [SLOW TEST:62.009 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":277,"completed":86,"skipped":1327,"failed":0}
SSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:24:52.428: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating all guestbook components
May 29 17:24:52.544: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-slave
  labels:
    app: agnhost
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: slave
    tier: backend

May 29 17:24:52.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 create -f - --namespace=kubectl-6709'
May 29 17:24:52.945: INFO: stderr: ""
May 29 17:24:52.945: INFO: stdout: "service/agnhost-slave created\n"
May 29 17:24:52.947: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-master
  labels:
    app: agnhost
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: master
    tier: backend

May 29 17:24:52.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 create -f - --namespace=kubectl-6709'
May 29 17:24:53.210: INFO: stderr: ""
May 29 17:24:53.210: INFO: stdout: "service/agnhost-master created\n"
May 29 17:24:53.210: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May 29 17:24:53.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 create -f - --namespace=kubectl-6709'
May 29 17:24:53.486: INFO: stderr: ""
May 29 17:24:53.486: INFO: stdout: "service/frontend created\n"
May 29 17:24:53.488: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

May 29 17:24:53.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 create -f - --namespace=kubectl-6709'
May 29 17:24:53.753: INFO: stderr: ""
May 29 17:24:53.753: INFO: stdout: "deployment.apps/frontend created\n"
May 29 17:24:53.754: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May 29 17:24:53.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 create -f - --namespace=kubectl-6709'
May 29 17:24:54.052: INFO: stderr: ""
May 29 17:24:54.052: INFO: stdout: "deployment.apps/agnhost-master created\n"
May 29 17:24:54.052: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--slaveof", "agnhost-master", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May 29 17:24:54.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 create -f - --namespace=kubectl-6709'
May 29 17:24:54.385: INFO: stderr: ""
May 29 17:24:54.385: INFO: stdout: "deployment.apps/agnhost-slave created\n"
STEP: validating guestbook app
May 29 17:24:54.385: INFO: Waiting for all frontend pods to be Running.
May 29 17:24:59.436: INFO: Waiting for frontend to serve content.
May 29 17:24:59.474: INFO: Trying to add a new entry to the guestbook.
May 29 17:24:59.750: INFO: Verifying that added entry can be retrieved.
May 29 17:24:59.783: INFO: Failed to get response from guestbook. err: <nil>, response: {"data":""}
STEP: using delete to clean up resources
May 29 17:25:04.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 delete --grace-period=0 --force -f - --namespace=kubectl-6709'
May 29 17:25:05.239: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 17:25:05.240: INFO: stdout: "service \"agnhost-slave\" force deleted\n"
STEP: using delete to clean up resources
May 29 17:25:05.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 delete --grace-period=0 --force -f - --namespace=kubectl-6709'
May 29 17:25:06.780: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 17:25:06.780: INFO: stdout: "service \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
May 29 17:25:06.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 delete --grace-period=0 --force -f - --namespace=kubectl-6709'
May 29 17:25:06.996: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 17:25:06.996: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 29 17:25:06.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 delete --grace-period=0 --force -f - --namespace=kubectl-6709'
May 29 17:25:07.891: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 17:25:07.891: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 29 17:25:07.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 delete --grace-period=0 --force -f - --namespace=kubectl-6709'
May 29 17:25:08.071: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 17:25:08.071: INFO: stdout: "deployment.apps \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
May 29 17:25:08.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 delete --grace-period=0 --force -f - --namespace=kubectl-6709'
May 29 17:25:08.227: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 17:25:08.227: INFO: stdout: "deployment.apps \"agnhost-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:25:08.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6709" for this suite.

• [SLOW TEST:15.832 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:310
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":277,"completed":87,"skipped":1332,"failed":0}
SSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:25:08.259: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting the proxy server
May 29 17:25:08.376: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-852825370 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:25:08.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9880" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":277,"completed":88,"skipped":1337,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:25:08.575: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-f4982445-e272-4e71-a5a5-93934363eaa3
STEP: Creating a pod to test consume configMaps
May 29 17:25:09.777: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7f8b0ab7-32ec-4453-a3c0-9a92581f7b18" in namespace "projected-4596" to be "Succeeded or Failed"
May 29 17:25:09.817: INFO: Pod "pod-projected-configmaps-7f8b0ab7-32ec-4453-a3c0-9a92581f7b18": Phase="Pending", Reason="", readiness=false. Elapsed: 39.0079ms
May 29 17:25:11.835: INFO: Pod "pod-projected-configmaps-7f8b0ab7-32ec-4453-a3c0-9a92581f7b18": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057594427s
May 29 17:25:13.846: INFO: Pod "pod-projected-configmaps-7f8b0ab7-32ec-4453-a3c0-9a92581f7b18": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.068694964s
STEP: Saw pod success
May 29 17:25:13.846: INFO: Pod "pod-projected-configmaps-7f8b0ab7-32ec-4453-a3c0-9a92581f7b18" satisfied condition "Succeeded or Failed"
May 29 17:25:13.856: INFO: Trying to get logs from node node-cncf-lab-4 pod pod-projected-configmaps-7f8b0ab7-32ec-4453-a3c0-9a92581f7b18 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 29 17:25:13.987: INFO: Waiting for pod pod-projected-configmaps-7f8b0ab7-32ec-4453-a3c0-9a92581f7b18 to disappear
May 29 17:25:13.997: INFO: Pod pod-projected-configmaps-7f8b0ab7-32ec-4453-a3c0-9a92581f7b18 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:25:13.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4596" for this suite.

• [SLOW TEST:5.456 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":89,"skipped":1366,"failed":0}
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:25:14.034: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-5650
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 29 17:25:14.142: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
May 29 17:25:14.240: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May 29 17:25:16.521: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May 29 17:25:18.251: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 17:25:20.251: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 17:25:22.263: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 17:25:24.253: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 17:25:26.251: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 17:25:28.252: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 17:25:30.252: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 17:25:32.251: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 17:25:35.107: INFO: The status of Pod netserver-0 is Running (Ready = true)
May 29 17:25:35.145: INFO: The status of Pod netserver-1 is Running (Ready = true)
May 29 17:25:35.170: INFO: The status of Pod netserver-2 is Running (Ready = true)
May 29 17:25:35.188: INFO: The status of Pod netserver-3 is Running (Ready = true)
STEP: Creating test pods
May 29 17:25:39.255: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.2.184:8080/dial?request=hostname&protocol=http&host=10.2.2.183&port=8080&tries=1'] Namespace:pod-network-test-5650 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:25:39.256: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 17:25:39.556: INFO: Waiting for responses: map[]
May 29 17:25:39.570: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.2.184:8080/dial?request=hostname&protocol=http&host=10.2.0.30&port=8080&tries=1'] Namespace:pod-network-test-5650 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:25:39.570: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 17:25:39.868: INFO: Waiting for responses: map[]
May 29 17:25:39.881: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.2.184:8080/dial?request=hostname&protocol=http&host=10.2.3.33&port=8080&tries=1'] Namespace:pod-network-test-5650 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:25:39.881: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 17:25:40.992: INFO: Waiting for responses: map[]
May 29 17:25:41.004: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.2.184:8080/dial?request=hostname&protocol=http&host=10.2.1.66&port=8080&tries=1'] Namespace:pod-network-test-5650 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:25:41.004: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 17:25:41.268: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:25:41.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5650" for this suite.

• [SLOW TEST:27.282 seconds]
[sig-network] Networking
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":277,"completed":90,"skipped":1370,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:25:41.319: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:25:53.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9001" for this suite.

• [SLOW TEST:12.671 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":277,"completed":91,"skipped":1404,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:25:53.991: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
May 29 17:25:54.180: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ec839261-0ba1-4ccc-864a-1cc68ea7befa" in namespace "downward-api-7110" to be "Succeeded or Failed"
May 29 17:25:54.203: INFO: Pod "downwardapi-volume-ec839261-0ba1-4ccc-864a-1cc68ea7befa": Phase="Pending", Reason="", readiness=false. Elapsed: 22.950649ms
May 29 17:25:56.228: INFO: Pod "downwardapi-volume-ec839261-0ba1-4ccc-864a-1cc68ea7befa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047612125s
May 29 17:25:58.460: INFO: Pod "downwardapi-volume-ec839261-0ba1-4ccc-864a-1cc68ea7befa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.279384469s
STEP: Saw pod success
May 29 17:25:58.460: INFO: Pod "downwardapi-volume-ec839261-0ba1-4ccc-864a-1cc68ea7befa" satisfied condition "Succeeded or Failed"
May 29 17:25:58.474: INFO: Trying to get logs from node node-cncf-lab-1 pod downwardapi-volume-ec839261-0ba1-4ccc-864a-1cc68ea7befa container client-container: <nil>
STEP: delete the pod
May 29 17:25:58.611: INFO: Waiting for pod downwardapi-volume-ec839261-0ba1-4ccc-864a-1cc68ea7befa to disappear
May 29 17:25:58.620: INFO: Pod downwardapi-volume-ec839261-0ba1-4ccc-864a-1cc68ea7befa no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:25:58.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7110" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":277,"completed":92,"skipped":1448,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:25:58.658: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service nodeport-service with the type=NodePort in namespace services-9644
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-9644
STEP: creating replication controller externalsvc in namespace services-9644
I0529 17:25:58.857770      20 runners.go:190] Created replication controller with name: externalsvc, namespace: services-9644, replica count: 2
I0529 17:26:01.908829      20 runners.go:190] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 17:26:04.909372      20 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
May 29 17:26:05.478: INFO: Creating new exec pod
May 29 17:26:09.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=services-9644 execpod8wrsw -- /bin/sh -x -c nslookup nodeport-service'
May 29 17:26:10.219: INFO: stderr: "+ nslookup nodeport-service\n"
May 29 17:26:10.219: INFO: stdout: "Server:\t\t10.3.0.10\nAddress:\t10.3.0.10#53\n\nnodeport-service.services-9644.svc.cluster.local\tcanonical name = externalsvc.services-9644.svc.cluster.local.\nName:\texternalsvc.services-9644.svc.cluster.local\nAddress: 10.3.70.68\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-9644, will wait for the garbage collector to delete the pods
May 29 17:26:10.306: INFO: Deleting ReplicationController externalsvc took: 22.216638ms
May 29 17:26:11.010: INFO: Terminating ReplicationController externalsvc pods took: 703.699895ms
May 29 17:26:26.364: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:26:26.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9644" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:27.791 seconds]
[sig-network] Services
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":277,"completed":93,"skipped":1480,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:26:26.451: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 29 17:26:27.655: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 29 17:26:30.131: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369987, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369987, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369987, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726369987, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 29 17:26:33.421: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:26:33.488: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2274-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:26:35.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1942" for this suite.
STEP: Destroying namespace "webhook-1942-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:9.172 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":277,"completed":94,"skipped":1540,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:26:35.625: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-8389
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-8389
I0529 17:26:35.810027      20 runners.go:190] Created replication controller with name: externalname-service, namespace: services-8389, replica count: 2
I0529 17:26:38.867932      20 runners.go:190] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 17:26:41.869004      20 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 29 17:26:41.879: INFO: Creating new exec pod
May 29 17:26:46.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=services-8389 execpodpjqfv -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
May 29 17:26:47.357: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
May 29 17:26:47.357: INFO: stdout: ""
May 29 17:26:47.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=services-8389 execpodpjqfv -- /bin/sh -x -c nc -zv -t -w 2 10.3.115.242 80'
May 29 17:26:48.212: INFO: stderr: "+ nc -zv -t -w 2 10.3.115.242 80\nConnection to 10.3.115.242 80 port [tcp/http] succeeded!\n"
May 29 17:26:48.213: INFO: stdout: ""
May 29 17:26:48.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=services-8389 execpodpjqfv -- /bin/sh -x -c nc -zv -t -w 2 51.83.111.180 31746'
May 29 17:26:48.660: INFO: stderr: "+ nc -zv -t -w 2 51.83.111.180 31746\nConnection to 51.83.111.180 31746 port [tcp/31746] succeeded!\n"
May 29 17:26:48.660: INFO: stdout: ""
May 29 17:26:48.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=services-8389 execpodpjqfv -- /bin/sh -x -c nc -zv -t -w 2 51.75.198.105 31746'
May 29 17:26:49.100: INFO: stderr: "+ nc -zv -t -w 2 51.75.198.105 31746\nConnection to 51.75.198.105 31746 port [tcp/31746] succeeded!\n"
May 29 17:26:49.100: INFO: stdout: ""
May 29 17:26:49.100: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:26:49.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8389" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:13.578 seconds]
[sig-network] Services
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":277,"completed":95,"skipped":1564,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:26:49.204: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 29 17:26:49.946: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 29 17:26:52.134: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370009, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370009, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370010, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370009, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:26:55.305: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370009, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370009, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370010, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370009, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 29 17:26:57.212: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:26:57.227: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1245-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:26:58.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-892" for this suite.
STEP: Destroying namespace "webhook-892-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:9.929 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":277,"completed":96,"skipped":1590,"failed":0}
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:26:59.136: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
May 29 17:26:59.311: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6da251bf-fa46-49bd-aec4-60f3d8193f05" in namespace "projected-9039" to be "Succeeded or Failed"
May 29 17:26:59.331: INFO: Pod "downwardapi-volume-6da251bf-fa46-49bd-aec4-60f3d8193f05": Phase="Pending", Reason="", readiness=false. Elapsed: 19.744555ms
May 29 17:27:01.345: INFO: Pod "downwardapi-volume-6da251bf-fa46-49bd-aec4-60f3d8193f05": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033148683s
May 29 17:27:03.359: INFO: Pod "downwardapi-volume-6da251bf-fa46-49bd-aec4-60f3d8193f05": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047096158s
May 29 17:27:05.372: INFO: Pod "downwardapi-volume-6da251bf-fa46-49bd-aec4-60f3d8193f05": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.06015285s
STEP: Saw pod success
May 29 17:27:05.372: INFO: Pod "downwardapi-volume-6da251bf-fa46-49bd-aec4-60f3d8193f05" satisfied condition "Succeeded or Failed"
May 29 17:27:05.381: INFO: Trying to get logs from node node-cncf-lab-1 pod downwardapi-volume-6da251bf-fa46-49bd-aec4-60f3d8193f05 container client-container: <nil>
STEP: delete the pod
May 29 17:27:06.387: INFO: Waiting for pod downwardapi-volume-6da251bf-fa46-49bd-aec4-60f3d8193f05 to disappear
May 29 17:27:06.399: INFO: Pod downwardapi-volume-6da251bf-fa46-49bd-aec4-60f3d8193f05 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:27:06.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9039" for this suite.

• [SLOW TEST:7.291 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":277,"completed":97,"skipped":1594,"failed":0}
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:27:06.432: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 29 17:27:06.551: INFO: Waiting up to 5m0s for pod "pod-339e3ae8-a094-48ed-9315-b81e5505e139" in namespace "emptydir-6868" to be "Succeeded or Failed"
May 29 17:27:06.591: INFO: Pod "pod-339e3ae8-a094-48ed-9315-b81e5505e139": Phase="Pending", Reason="", readiness=false. Elapsed: 38.989975ms
May 29 17:27:08.604: INFO: Pod "pod-339e3ae8-a094-48ed-9315-b81e5505e139": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052190539s
May 29 17:27:10.616: INFO: Pod "pod-339e3ae8-a094-48ed-9315-b81e5505e139": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.064043544s
STEP: Saw pod success
May 29 17:27:10.616: INFO: Pod "pod-339e3ae8-a094-48ed-9315-b81e5505e139" satisfied condition "Succeeded or Failed"
May 29 17:27:10.628: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-339e3ae8-a094-48ed-9315-b81e5505e139 container test-container: <nil>
STEP: delete the pod
May 29 17:27:10.698: INFO: Waiting for pod pod-339e3ae8-a094-48ed-9315-b81e5505e139 to disappear
May 29 17:27:10.707: INFO: Pod pod-339e3ae8-a094-48ed-9315-b81e5505e139 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:27:10.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6868" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":98,"skipped":1598,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:27:10.739: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:27:15.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3909" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":277,"completed":99,"skipped":1627,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:27:15.237: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-8978
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-8978
STEP: creating replication controller externalsvc in namespace services-8978
I0529 17:27:15.740079      20 runners.go:190] Created replication controller with name: externalsvc, namespace: services-8978, replica count: 2
I0529 17:27:18.792270      20 runners.go:190] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 17:27:21.793236      20 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
May 29 17:27:21.869: INFO: Creating new exec pod
May 29 17:27:25.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=services-8978 execpodp46dn -- /bin/sh -x -c nslookup clusterip-service'
May 29 17:27:26.531: INFO: stderr: "+ nslookup clusterip-service\n"
May 29 17:27:26.531: INFO: stdout: "Server:\t\t10.3.0.10\nAddress:\t10.3.0.10#53\n\nclusterip-service.services-8978.svc.cluster.local\tcanonical name = externalsvc.services-8978.svc.cluster.local.\nName:\texternalsvc.services-8978.svc.cluster.local\nAddress: 10.3.144.129\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8978, will wait for the garbage collector to delete the pods
May 29 17:27:26.619: INFO: Deleting ReplicationController externalsvc took: 25.448696ms
May 29 17:27:27.120: INFO: Terminating ReplicationController externalsvc pods took: 500.326522ms
May 29 17:27:36.276: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:27:37.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8978" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:21.862 seconds]
[sig-network] Services
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":277,"completed":100,"skipped":1645,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:27:37.099: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
May 29 17:27:37.748: INFO: Waiting up to 5m0s for pod "pod-86b1db44-fc74-4eea-86ea-80662d884341" in namespace "emptydir-8295" to be "Succeeded or Failed"
May 29 17:27:37.805: INFO: Pod "pod-86b1db44-fc74-4eea-86ea-80662d884341": Phase="Pending", Reason="", readiness=false. Elapsed: 57.303693ms
May 29 17:27:39.819: INFO: Pod "pod-86b1db44-fc74-4eea-86ea-80662d884341": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070808839s
May 29 17:27:41.854: INFO: Pod "pod-86b1db44-fc74-4eea-86ea-80662d884341": Phase="Pending", Reason="", readiness=false. Elapsed: 4.106668271s
May 29 17:27:43.866: INFO: Pod "pod-86b1db44-fc74-4eea-86ea-80662d884341": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.117946267s
STEP: Saw pod success
May 29 17:27:43.866: INFO: Pod "pod-86b1db44-fc74-4eea-86ea-80662d884341" satisfied condition "Succeeded or Failed"
May 29 17:27:45.228: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-86b1db44-fc74-4eea-86ea-80662d884341 container test-container: <nil>
STEP: delete the pod
May 29 17:27:45.683: INFO: Waiting for pod pod-86b1db44-fc74-4eea-86ea-80662d884341 to disappear
May 29 17:27:46.720: INFO: Pod pod-86b1db44-fc74-4eea-86ea-80662d884341 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:27:46.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8295" for this suite.

• [SLOW TEST:9.661 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":101,"skipped":1646,"failed":0}
SSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:27:46.766: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating replication controller my-hostname-basic-3dd4557e-58b4-4b1d-8877-af45df87ce23
May 29 17:27:46.912: INFO: Pod name my-hostname-basic-3dd4557e-58b4-4b1d-8877-af45df87ce23: Found 0 pods out of 1
May 29 17:27:52.172: INFO: Pod name my-hostname-basic-3dd4557e-58b4-4b1d-8877-af45df87ce23: Found 1 pods out of 1
May 29 17:27:52.172: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-3dd4557e-58b4-4b1d-8877-af45df87ce23" are running
May 29 17:27:52.880: INFO: Pod "my-hostname-basic-3dd4557e-58b4-4b1d-8877-af45df87ce23-q6d6l" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-29 17:27:46 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-29 17:27:50 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-29 17:27:50 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-29 17:27:46 +0000 UTC Reason: Message:}])
May 29 17:27:52.880: INFO: Trying to dial the pod
May 29 17:27:57.927: INFO: Controller my-hostname-basic-3dd4557e-58b4-4b1d-8877-af45df87ce23: Got expected result from replica 1 [my-hostname-basic-3dd4557e-58b4-4b1d-8877-af45df87ce23-q6d6l]: "my-hostname-basic-3dd4557e-58b4-4b1d-8877-af45df87ce23-q6d6l", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:27:57.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8482" for this suite.

• [SLOW TEST:11.255 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":277,"completed":102,"skipped":1650,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:27:58.026: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
May 29 17:27:58.178: INFO: PodSpec: initContainers in spec.initContainers
May 29 17:28:47.945: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-c7a4355f-1228-4e9f-908e-ac8569840b4e", GenerateName:"", Namespace:"init-container-6570", SelfLink:"/api/v1/namespaces/init-container-6570/pods/pod-init-c7a4355f-1228-4e9f-908e-ac8569840b4e", UID:"b51af9a1-120b-49bf-a028-fd88c78b55ae", ResourceVersion:"12710004899", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63726370078, loc:(*time.Location)(0x7b501e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"178205477"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.2.2.197/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc0022cd760), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0022cd780)}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc0022cd7a0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0022cd880)}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc0022cd8a0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0022cd8e0)}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-7jpt7", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0021dfe40), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-7jpt7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"Always", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-7jpt7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"Always", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.2", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-7jpt7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"Always", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0054ee6c0), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"node-cncf-lab-1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001f3bc00), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0054ee750)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0054ee770)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0054ee778), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0054ee77c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370078, loc:(*time.Location)(0x7b501e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370078, loc:(*time.Location)(0x7b501e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370078, loc:(*time.Location)(0x7b501e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370078, loc:(*time.Location)(0x7b501e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"51.83.108.252", PodIP:"10.2.2.197", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.2.2.197"}}, StartTime:(*v1.Time)(0xc0022cd920), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001f3bce0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001f3bd50)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://221ef3bccd299f6cac4bae160f66a481755081ec443aaf84774e56b4d88cd07a", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0022cd9c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0022cd980), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.2", ImageID:"", ContainerID:"", Started:(*bool)(0xc0054ee7ff)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:28:47.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6570" for this suite.

• [SLOW TEST:49.961 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":277,"completed":103,"skipped":1664,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:28:47.991: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating pod
May 29 17:28:52.250: INFO: Pod pod-hostip-3a0c70bf-4bf2-4bea-8c5c-cf5e08b75862 has hostIP: 51.178.95.196
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:28:52.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1756" for this suite.
•{"msg":"PASSED [k8s.io] Pods should get a host IP [NodeConformance] [Conformance]","total":277,"completed":104,"skipped":1671,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:28:52.286: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
May 29 17:28:52.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 create -f - --namespace=kubectl-6385'
May 29 17:28:52.799: INFO: stderr: ""
May 29 17:28:52.799: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 29 17:28:52.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6385'
May 29 17:28:52.957: INFO: stderr: ""
May 29 17:28:52.957: INFO: stdout: "update-demo-nautilus-mqrzl update-demo-nautilus-ppjhh "
May 29 17:28:52.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods update-demo-nautilus-mqrzl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6385'
May 29 17:28:53.127: INFO: stderr: ""
May 29 17:28:53.128: INFO: stdout: ""
May 29 17:28:53.128: INFO: update-demo-nautilus-mqrzl is created but not running
May 29 17:28:58.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6385'
May 29 17:28:58.297: INFO: stderr: ""
May 29 17:28:58.297: INFO: stdout: "update-demo-nautilus-mqrzl update-demo-nautilus-ppjhh "
May 29 17:28:58.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods update-demo-nautilus-mqrzl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6385'
May 29 17:28:58.450: INFO: stderr: ""
May 29 17:28:58.450: INFO: stdout: "true"
May 29 17:28:58.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods update-demo-nautilus-mqrzl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6385'
May 29 17:28:58.584: INFO: stderr: ""
May 29 17:28:58.584: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 29 17:28:58.584: INFO: validating pod update-demo-nautilus-mqrzl
May 29 17:28:58.607: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 17:28:58.607: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 17:28:58.607: INFO: update-demo-nautilus-mqrzl is verified up and running
May 29 17:28:58.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods update-demo-nautilus-ppjhh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6385'
May 29 17:28:58.771: INFO: stderr: ""
May 29 17:28:58.771: INFO: stdout: "true"
May 29 17:28:58.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods update-demo-nautilus-ppjhh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6385'
May 29 17:28:58.906: INFO: stderr: ""
May 29 17:28:58.906: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 29 17:28:58.906: INFO: validating pod update-demo-nautilus-ppjhh
May 29 17:28:58.922: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 17:28:58.922: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 17:28:58.922: INFO: update-demo-nautilus-ppjhh is verified up and running
STEP: using delete to clean up resources
May 29 17:28:58.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 delete --grace-period=0 --force -f - --namespace=kubectl-6385'
May 29 17:28:59.146: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 17:28:59.146: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 29 17:28:59.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6385'
May 29 17:28:59.346: INFO: stderr: "No resources found in kubectl-6385 namespace.\n"
May 29 17:28:59.346: INFO: stdout: ""
May 29 17:28:59.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods -l name=update-demo --namespace=kubectl-6385 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 29 17:28:59.506: INFO: stderr: ""
May 29 17:28:59.506: INFO: stdout: "update-demo-nautilus-mqrzl\nupdate-demo-nautilus-ppjhh\n"
May 29 17:29:00.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6385'
May 29 17:29:00.185: INFO: stderr: "No resources found in kubectl-6385 namespace.\n"
May 29 17:29:00.185: INFO: stdout: ""
May 29 17:29:00.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 get pods -l name=update-demo --namespace=kubectl-6385 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 29 17:29:00.347: INFO: stderr: ""
May 29 17:29:00.347: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:29:00.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6385" for this suite.

• [SLOW TEST:8.100 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:269
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":277,"completed":105,"skipped":1719,"failed":0}
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:29:00.388: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
May 29 17:29:01.154: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:29:01.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0529 17:29:01.153879      20 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-1032" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":277,"completed":106,"skipped":1719,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:29:01.188: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:29:19.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8550" for this suite.

• [SLOW TEST:18.774 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":277,"completed":107,"skipped":1770,"failed":0}
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:29:19.970: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-1affa35e-d614-490e-b1c8-5b7fd0403f2a
STEP: Creating a pod to test consume configMaps
May 29 17:29:20.202: INFO: Waiting up to 5m0s for pod "pod-configmaps-fb378be1-31fb-43bf-8a0c-ad38224bcadb" in namespace "configmap-8468" to be "Succeeded or Failed"
May 29 17:29:20.210: INFO: Pod "pod-configmaps-fb378be1-31fb-43bf-8a0c-ad38224bcadb": Phase="Pending", Reason="", readiness=false. Elapsed: 7.837124ms
May 29 17:29:22.219: INFO: Pod "pod-configmaps-fb378be1-31fb-43bf-8a0c-ad38224bcadb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017181993s
May 29 17:29:24.234: INFO: Pod "pod-configmaps-fb378be1-31fb-43bf-8a0c-ad38224bcadb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03187994s
STEP: Saw pod success
May 29 17:29:24.234: INFO: Pod "pod-configmaps-fb378be1-31fb-43bf-8a0c-ad38224bcadb" satisfied condition "Succeeded or Failed"
May 29 17:29:24.250: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-configmaps-fb378be1-31fb-43bf-8a0c-ad38224bcadb container configmap-volume-test: <nil>
STEP: delete the pod
May 29 17:29:24.374: INFO: Waiting for pod pod-configmaps-fb378be1-31fb-43bf-8a0c-ad38224bcadb to disappear
May 29 17:29:24.380: INFO: Pod pod-configmaps-fb378be1-31fb-43bf-8a0c-ad38224bcadb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:29:24.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8468" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":277,"completed":108,"skipped":1776,"failed":0}

------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:29:24.406: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 29 17:29:24.562: INFO: Waiting up to 5m0s for pod "pod-e911b215-fd41-44e5-bf14-e01de89641a0" in namespace "emptydir-2065" to be "Succeeded or Failed"
May 29 17:29:24.576: INFO: Pod "pod-e911b215-fd41-44e5-bf14-e01de89641a0": Phase="Pending", Reason="", readiness=false. Elapsed: 13.730609ms
May 29 17:29:26.596: INFO: Pod "pod-e911b215-fd41-44e5-bf14-e01de89641a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033160337s
May 29 17:29:28.609: INFO: Pod "pod-e911b215-fd41-44e5-bf14-e01de89641a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045998887s
STEP: Saw pod success
May 29 17:29:28.609: INFO: Pod "pod-e911b215-fd41-44e5-bf14-e01de89641a0" satisfied condition "Succeeded or Failed"
May 29 17:29:28.623: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-e911b215-fd41-44e5-bf14-e01de89641a0 container test-container: <nil>
STEP: delete the pod
May 29 17:29:28.993: INFO: Waiting for pod pod-e911b215-fd41-44e5-bf14-e01de89641a0 to disappear
May 29 17:29:29.004: INFO: Pod pod-e911b215-fd41-44e5-bf14-e01de89641a0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:29:29.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2065" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":109,"skipped":1776,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:29:29.037: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
May 29 17:29:29.205: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 29 17:29:29.796: INFO: Waiting for terminating namespaces to be deleted...
May 29 17:29:29.833: INFO: 
Logging pods the kubelet thinks is on node node-cncf-lab-1 before test
May 29 17:29:29.902: INFO: kube-proxy-24chw from kube-system started at 2020-05-29 12:57:00 +0000 UTC (1 container statuses recorded)
May 29 17:29:29.902: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:29:29.902: INFO: wormhole-b4h5r from kube-system started at 2020-05-29 12:57:00 +0000 UTC (1 container statuses recorded)
May 29 17:29:29.902: INFO: 	Container wormhole ready: true, restart count 0
May 29 17:29:29.902: INFO: canal-6vpdg from kube-system started at 2020-05-29 12:57:00 +0000 UTC (2 container statuses recorded)
May 29 17:29:29.902: INFO: 	Container calico-node ready: true, restart count 0
May 29 17:29:29.902: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:29:29.902: INFO: sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-dngk9 from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:29:29.902: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:29:29.902: INFO: 	Container systemd-logs ready: true, restart count 0
May 29 17:29:29.902: INFO: 
Logging pods the kubelet thinks is on node node-cncf-lab-2 before test
May 29 17:29:30.040: INFO: coredns-78ff568f7c-d8dj2 from kube-system started at 2020-05-29 12:53:14 +0000 UTC (1 container statuses recorded)
May 29 17:29:30.040: INFO: 	Container coredns ready: true, restart count 0
May 29 17:29:30.040: INFO: kube-proxy-88gmf from kube-system started at 2020-05-29 12:52:43 +0000 UTC (1 container statuses recorded)
May 29 17:29:30.040: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:29:30.040: INFO: metrics-server-79cfd68c87-l6wn9 from kube-system started at 2020-05-29 12:53:03 +0000 UTC (1 container statuses recorded)
May 29 17:29:30.041: INFO: 	Container metrics-server ready: true, restart count 0
May 29 17:29:30.041: INFO: sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-pvwlk from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:29:30.041: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:29:30.041: INFO: 	Container systemd-logs ready: true, restart count 0
May 29 17:29:30.041: INFO: canal-xdv24 from kube-system started at 2020-05-29 12:52:43 +0000 UTC (2 container statuses recorded)
May 29 17:29:30.042: INFO: 	Container calico-node ready: true, restart count 0
May 29 17:29:30.042: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:29:30.042: INFO: kube-dns-autoscaler-579dbcdc47-vzwfl from kube-system started at 2020-05-29 12:53:14 +0000 UTC (1 container statuses recorded)
May 29 17:29:30.042: INFO: 	Container autoscaler ready: true, restart count 0
May 29 17:29:30.042: INFO: coredns-78ff568f7c-8tdx9 from kube-system started at 2020-05-29 12:54:56 +0000 UTC (1 container statuses recorded)
May 29 17:29:30.042: INFO: 	Container coredns ready: true, restart count 0
May 29 17:29:30.043: INFO: wormhole-rbswg from kube-system started at 2020-05-29 12:52:43 +0000 UTC (1 container statuses recorded)
May 29 17:29:30.043: INFO: 	Container wormhole ready: true, restart count 0
May 29 17:29:30.043: INFO: 
Logging pods the kubelet thinks is on node node-cncf-lab-3 before test
May 29 17:29:30.144: INFO: sonobuoy from sonobuoy started at 2020-05-29 16:59:22 +0000 UTC (1 container statuses recorded)
May 29 17:29:30.144: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 29 17:29:30.144: INFO: sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-kp7d8 from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:29:30.144: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:29:30.144: INFO: 	Container systemd-logs ready: true, restart count 0
May 29 17:29:30.144: INFO: canal-lh9kw from kube-system started at 2020-05-29 12:59:04 +0000 UTC (2 container statuses recorded)
May 29 17:29:30.144: INFO: 	Container calico-node ready: true, restart count 0
May 29 17:29:30.144: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:29:30.144: INFO: kube-proxy-7bqtd from kube-system started at 2020-05-29 12:59:04 +0000 UTC (1 container statuses recorded)
May 29 17:29:30.144: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:29:30.144: INFO: wormhole-8llxp from kube-system started at 2020-05-29 12:59:04 +0000 UTC (1 container statuses recorded)
May 29 17:29:30.144: INFO: 	Container wormhole ready: true, restart count 0
May 29 17:29:30.144: INFO: 
Logging pods the kubelet thinks is on node node-cncf-lab-4 before test
May 29 17:29:30.245: INFO: canal-7v9cn from kube-system started at 2020-05-29 12:54:56 +0000 UTC (2 container statuses recorded)
May 29 17:29:30.245: INFO: 	Container calico-node ready: true, restart count 0
May 29 17:29:30.245: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:29:30.245: INFO: sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-7449p from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:29:30.245: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:29:30.245: INFO: 	Container systemd-logs ready: true, restart count 0
May 29 17:29:30.245: INFO: wormhole-n2mpq from kube-system started at 2020-05-29 12:54:56 +0000 UTC (1 container statuses recorded)
May 29 17:29:30.245: INFO: 	Container wormhole ready: true, restart count 0
May 29 17:29:30.245: INFO: kube-proxy-rkjk6 from kube-system started at 2020-05-29 12:54:56 +0000 UTC (1 container statuses recorded)
May 29 17:29:30.245: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:29:30.245: INFO: sonobuoy-e2e-job-1012d486abe04715 from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:29:30.246: INFO: 	Container e2e ready: true, restart count 0
May 29 17:29:30.246: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: verifying the node has the label node node-cncf-lab-1
STEP: verifying the node has the label node node-cncf-lab-2
STEP: verifying the node has the label node node-cncf-lab-3
STEP: verifying the node has the label node node-cncf-lab-4
May 29 17:29:30.579: INFO: Pod canal-6vpdg requesting resource cpu=250m on Node node-cncf-lab-1
May 29 17:29:30.579: INFO: Pod canal-7v9cn requesting resource cpu=250m on Node node-cncf-lab-4
May 29 17:29:30.579: INFO: Pod canal-lh9kw requesting resource cpu=250m on Node node-cncf-lab-3
May 29 17:29:30.579: INFO: Pod canal-xdv24 requesting resource cpu=250m on Node node-cncf-lab-2
May 29 17:29:30.579: INFO: Pod coredns-78ff568f7c-8tdx9 requesting resource cpu=100m on Node node-cncf-lab-2
May 29 17:29:30.579: INFO: Pod coredns-78ff568f7c-d8dj2 requesting resource cpu=100m on Node node-cncf-lab-2
May 29 17:29:30.579: INFO: Pod kube-dns-autoscaler-579dbcdc47-vzwfl requesting resource cpu=20m on Node node-cncf-lab-2
May 29 17:29:30.579: INFO: Pod kube-proxy-24chw requesting resource cpu=100m on Node node-cncf-lab-1
May 29 17:29:30.579: INFO: Pod kube-proxy-7bqtd requesting resource cpu=100m on Node node-cncf-lab-3
May 29 17:29:30.579: INFO: Pod kube-proxy-88gmf requesting resource cpu=100m on Node node-cncf-lab-2
May 29 17:29:30.579: INFO: Pod kube-proxy-rkjk6 requesting resource cpu=100m on Node node-cncf-lab-4
May 29 17:29:30.579: INFO: Pod metrics-server-79cfd68c87-l6wn9 requesting resource cpu=0m on Node node-cncf-lab-2
May 29 17:29:30.579: INFO: Pod wormhole-8llxp requesting resource cpu=0m on Node node-cncf-lab-3
May 29 17:29:30.579: INFO: Pod wormhole-b4h5r requesting resource cpu=0m on Node node-cncf-lab-1
May 29 17:29:30.579: INFO: Pod wormhole-n2mpq requesting resource cpu=0m on Node node-cncf-lab-4
May 29 17:29:30.579: INFO: Pod wormhole-rbswg requesting resource cpu=0m on Node node-cncf-lab-2
May 29 17:29:30.579: INFO: Pod sonobuoy requesting resource cpu=0m on Node node-cncf-lab-3
May 29 17:29:30.579: INFO: Pod sonobuoy-e2e-job-1012d486abe04715 requesting resource cpu=0m on Node node-cncf-lab-4
May 29 17:29:30.579: INFO: Pod sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-7449p requesting resource cpu=0m on Node node-cncf-lab-4
May 29 17:29:30.579: INFO: Pod sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-dngk9 requesting resource cpu=0m on Node node-cncf-lab-1
May 29 17:29:30.579: INFO: Pod sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-kp7d8 requesting resource cpu=0m on Node node-cncf-lab-3
May 29 17:29:30.579: INFO: Pod sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-pvwlk requesting resource cpu=0m on Node node-cncf-lab-2
STEP: Starting Pods to consume most of the cluster CPU.
May 29 17:29:30.579: INFO: Creating a pod which consumes cpu=1085m on Node node-cncf-lab-1
May 29 17:29:30.646: INFO: Creating a pod which consumes cpu=931m on Node node-cncf-lab-2
May 29 17:29:30.673: INFO: Creating a pod which consumes cpu=1085m on Node node-cncf-lab-3
May 29 17:29:30.705: INFO: Creating a pod which consumes cpu=1085m on Node node-cncf-lab-4
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8c6d7ce8-025f-4274-8a15-48cf4b953d71.16138ff3d216621f], Reason = [Scheduled], Message = [Successfully assigned sched-pred-213/filler-pod-8c6d7ce8-025f-4274-8a15-48cf4b953d71 to node-cncf-lab-4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8c6d7ce8-025f-4274-8a15-48cf4b953d71.16138ff46f5ce516], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.2"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8c6d7ce8-025f-4274-8a15-48cf4b953d71.16138ff496aab7d5], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.2"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8c6d7ce8-025f-4274-8a15-48cf4b953d71.16138ff49b3c0398], Reason = [Created], Message = [Created container filler-pod-8c6d7ce8-025f-4274-8a15-48cf4b953d71]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8c6d7ce8-025f-4274-8a15-48cf4b953d71.16138ff4a6846e52], Reason = [Started], Message = [Started container filler-pod-8c6d7ce8-025f-4274-8a15-48cf4b953d71]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ba84df7c-3578-4c83-9671-9c699322482f.16138ff3d086287e], Reason = [Scheduled], Message = [Successfully assigned sched-pred-213/filler-pod-ba84df7c-3578-4c83-9671-9c699322482f to node-cncf-lab-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ba84df7c-3578-4c83-9671-9c699322482f.16138ff4641a5037], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.2"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ba84df7c-3578-4c83-9671-9c699322482f.16138ff4853d421a], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.2"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ba84df7c-3578-4c83-9671-9c699322482f.16138ff48a112000], Reason = [Created], Message = [Created container filler-pod-ba84df7c-3578-4c83-9671-9c699322482f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ba84df7c-3578-4c83-9671-9c699322482f.16138ff4938a601b], Reason = [Started], Message = [Started container filler-pod-ba84df7c-3578-4c83-9671-9c699322482f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c3779b36-467d-4deb-801e-aa9b0874398f.16138ff3cec38520], Reason = [Scheduled], Message = [Successfully assigned sched-pred-213/filler-pod-c3779b36-467d-4deb-801e-aa9b0874398f to node-cncf-lab-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c3779b36-467d-4deb-801e-aa9b0874398f.16138ff47c672108], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.2"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c3779b36-467d-4deb-801e-aa9b0874398f.16138ff49f387ab8], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.2"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c3779b36-467d-4deb-801e-aa9b0874398f.16138ff4a4713fbf], Reason = [Created], Message = [Created container filler-pod-c3779b36-467d-4deb-801e-aa9b0874398f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c3779b36-467d-4deb-801e-aa9b0874398f.16138ff4af4e6e3c], Reason = [Started], Message = [Started container filler-pod-c3779b36-467d-4deb-801e-aa9b0874398f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-df34e914-d26a-4a05-b16d-0f1746a12562.16138ff3cd313268], Reason = [Scheduled], Message = [Successfully assigned sched-pred-213/filler-pod-df34e914-d26a-4a05-b16d-0f1746a12562 to node-cncf-lab-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-df34e914-d26a-4a05-b16d-0f1746a12562.16138ff46f5bfe4f], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.2"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-df34e914-d26a-4a05-b16d-0f1746a12562.16138ff4974712e4], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.2"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-df34e914-d26a-4a05-b16d-0f1746a12562.16138ff49be2f316], Reason = [Created], Message = [Created container filler-pod-df34e914-d26a-4a05-b16d-0f1746a12562]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-df34e914-d26a-4a05-b16d-0f1746a12562.16138ff4a7a113f6], Reason = [Started], Message = [Started container filler-pod-df34e914-d26a-4a05-b16d-0f1746a12562]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.16138ff53e8bc621], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 Insufficient cpu.]
STEP: removing the label node off the node node-cncf-lab-4
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node node-cncf-lab-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node node-cncf-lab-2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node node-cncf-lab-3
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:29:38.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-213" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:9.109 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":277,"completed":110,"skipped":1794,"failed":0}
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:29:38.146: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:29:51.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6925" for this suite.

• [SLOW TEST:14.169 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":277,"completed":111,"skipped":1797,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should patch a secret [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:29:52.321: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a secret [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:29:52.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9546" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should patch a secret [Conformance]","total":277,"completed":112,"skipped":1810,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:29:52.669: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
May 29 17:29:52.895: INFO: Waiting up to 5m0s for pod "downward-api-e3d824ee-8139-4650-b496-fb55a655408f" in namespace "downward-api-9050" to be "Succeeded or Failed"
May 29 17:29:52.912: INFO: Pod "downward-api-e3d824ee-8139-4650-b496-fb55a655408f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.9522ms
May 29 17:29:54.925: INFO: Pod "downward-api-e3d824ee-8139-4650-b496-fb55a655408f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029942533s
May 29 17:29:56.935: INFO: Pod "downward-api-e3d824ee-8139-4650-b496-fb55a655408f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039343472s
May 29 17:29:58.948: INFO: Pod "downward-api-e3d824ee-8139-4650-b496-fb55a655408f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.052627228s
STEP: Saw pod success
May 29 17:29:58.949: INFO: Pod "downward-api-e3d824ee-8139-4650-b496-fb55a655408f" satisfied condition "Succeeded or Failed"
May 29 17:29:59.281: INFO: Trying to get logs from node node-cncf-lab-1 pod downward-api-e3d824ee-8139-4650-b496-fb55a655408f container dapi-container: <nil>
STEP: delete the pod
May 29 17:29:59.360: INFO: Waiting for pod downward-api-e3d824ee-8139-4650-b496-fb55a655408f to disappear
May 29 17:29:59.371: INFO: Pod downward-api-e3d824ee-8139-4650-b496-fb55a655408f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:29:59.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9050" for this suite.

• [SLOW TEST:6.738 seconds]
[sig-node] Downward API
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:34
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":277,"completed":113,"skipped":1825,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:29:59.412: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 29 17:30:01.524: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 29 17:30:03.632: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370201, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370201, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370201, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370201, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:30:05.645: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370201, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370201, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370201, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370201, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 29 17:30:08.698: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
May 29 17:30:09.971: INFO: Waiting for webhook configuration to be ready...
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:30:20.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5094" for this suite.
STEP: Destroying namespace "webhook-5094-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:21.122 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":277,"completed":114,"skipped":1852,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:30:20.536: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:30:20.653: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:30:24.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9368" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":277,"completed":115,"skipped":1854,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:30:24.787: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
May 29 17:30:24.913: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 29 17:30:24.959: INFO: Waiting for terminating namespaces to be deleted...
May 29 17:30:24.971: INFO: 
Logging pods the kubelet thinks is on node node-cncf-lab-1 before test
May 29 17:30:24.996: INFO: wormhole-b4h5r from kube-system started at 2020-05-29 12:57:00 +0000 UTC (1 container statuses recorded)
May 29 17:30:24.996: INFO: 	Container wormhole ready: true, restart count 0
May 29 17:30:24.996: INFO: canal-6vpdg from kube-system started at 2020-05-29 12:57:00 +0000 UTC (2 container statuses recorded)
May 29 17:30:24.996: INFO: 	Container calico-node ready: true, restart count 0
May 29 17:30:24.996: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:30:24.996: INFO: sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-dngk9 from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:30:24.997: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:30:24.997: INFO: 	Container systemd-logs ready: true, restart count 0
May 29 17:30:24.997: INFO: kube-proxy-24chw from kube-system started at 2020-05-29 12:57:00 +0000 UTC (1 container statuses recorded)
May 29 17:30:24.997: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:30:24.997: INFO: 
Logging pods the kubelet thinks is on node node-cncf-lab-2 before test
May 29 17:30:25.024: INFO: canal-xdv24 from kube-system started at 2020-05-29 12:52:43 +0000 UTC (2 container statuses recorded)
May 29 17:30:25.024: INFO: 	Container calico-node ready: true, restart count 0
May 29 17:30:25.024: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:30:25.024: INFO: kube-dns-autoscaler-579dbcdc47-vzwfl from kube-system started at 2020-05-29 12:53:14 +0000 UTC (1 container statuses recorded)
May 29 17:30:25.024: INFO: 	Container autoscaler ready: true, restart count 0
May 29 17:30:25.024: INFO: coredns-78ff568f7c-8tdx9 from kube-system started at 2020-05-29 12:54:56 +0000 UTC (1 container statuses recorded)
May 29 17:30:25.025: INFO: 	Container coredns ready: true, restart count 0
May 29 17:30:25.025: INFO: wormhole-rbswg from kube-system started at 2020-05-29 12:52:43 +0000 UTC (1 container statuses recorded)
May 29 17:30:25.025: INFO: 	Container wormhole ready: true, restart count 0
May 29 17:30:25.025: INFO: coredns-78ff568f7c-d8dj2 from kube-system started at 2020-05-29 12:53:14 +0000 UTC (1 container statuses recorded)
May 29 17:30:25.025: INFO: 	Container coredns ready: true, restart count 0
May 29 17:30:25.025: INFO: kube-proxy-88gmf from kube-system started at 2020-05-29 12:52:43 +0000 UTC (1 container statuses recorded)
May 29 17:30:25.025: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:30:25.025: INFO: metrics-server-79cfd68c87-l6wn9 from kube-system started at 2020-05-29 12:53:03 +0000 UTC (1 container statuses recorded)
May 29 17:30:25.025: INFO: 	Container metrics-server ready: true, restart count 0
May 29 17:30:25.025: INFO: sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-pvwlk from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:30:25.025: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:30:25.025: INFO: 	Container systemd-logs ready: true, restart count 0
May 29 17:30:25.025: INFO: 
Logging pods the kubelet thinks is on node node-cncf-lab-3 before test
May 29 17:30:25.853: INFO: sonobuoy from sonobuoy started at 2020-05-29 16:59:22 +0000 UTC (1 container statuses recorded)
May 29 17:30:25.853: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 29 17:30:25.853: INFO: sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-kp7d8 from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:30:25.853: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:30:25.853: INFO: 	Container systemd-logs ready: true, restart count 0
May 29 17:30:25.853: INFO: canal-lh9kw from kube-system started at 2020-05-29 12:59:04 +0000 UTC (2 container statuses recorded)
May 29 17:30:25.853: INFO: 	Container calico-node ready: true, restart count 0
May 29 17:30:25.853: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:30:25.853: INFO: kube-proxy-7bqtd from kube-system started at 2020-05-29 12:59:04 +0000 UTC (1 container statuses recorded)
May 29 17:30:25.853: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:30:25.853: INFO: wormhole-8llxp from kube-system started at 2020-05-29 12:59:04 +0000 UTC (1 container statuses recorded)
May 29 17:30:25.853: INFO: 	Container wormhole ready: true, restart count 0
May 29 17:30:25.853: INFO: 
Logging pods the kubelet thinks is on node node-cncf-lab-4 before test
May 29 17:30:25.884: INFO: wormhole-n2mpq from kube-system started at 2020-05-29 12:54:56 +0000 UTC (1 container statuses recorded)
May 29 17:30:25.884: INFO: 	Container wormhole ready: true, restart count 0
May 29 17:30:25.884: INFO: kube-proxy-rkjk6 from kube-system started at 2020-05-29 12:54:56 +0000 UTC (1 container statuses recorded)
May 29 17:30:25.884: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:30:25.885: INFO: sonobuoy-e2e-job-1012d486abe04715 from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:30:25.885: INFO: 	Container e2e ready: true, restart count 0
May 29 17:30:25.885: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:30:25.885: INFO: canal-7v9cn from kube-system started at 2020-05-29 12:54:56 +0000 UTC (2 container statuses recorded)
May 29 17:30:25.885: INFO: 	Container calico-node ready: true, restart count 0
May 29 17:30:25.885: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:30:25.885: INFO: sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-7449p from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:30:25.885: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:30:25.885: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.16139000abc0fd54], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:30:26.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3015" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":277,"completed":116,"skipped":1903,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:30:26.984: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-2f13df52-3c1f-4e92-8e94-035051c459b0
STEP: Creating a pod to test consume configMaps
May 29 17:30:27.726: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ed6d57ba-1385-4ed0-8233-7a2ffdb63a43" in namespace "projected-6543" to be "Succeeded or Failed"
May 29 17:30:27.745: INFO: Pod "pod-projected-configmaps-ed6d57ba-1385-4ed0-8233-7a2ffdb63a43": Phase="Pending", Reason="", readiness=false. Elapsed: 18.784839ms
May 29 17:30:29.755: INFO: Pod "pod-projected-configmaps-ed6d57ba-1385-4ed0-8233-7a2ffdb63a43": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028818709s
May 29 17:30:31.768: INFO: Pod "pod-projected-configmaps-ed6d57ba-1385-4ed0-8233-7a2ffdb63a43": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041347232s
STEP: Saw pod success
May 29 17:30:31.768: INFO: Pod "pod-projected-configmaps-ed6d57ba-1385-4ed0-8233-7a2ffdb63a43" satisfied condition "Succeeded or Failed"
May 29 17:30:31.779: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-projected-configmaps-ed6d57ba-1385-4ed0-8233-7a2ffdb63a43 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 29 17:30:31.845: INFO: Waiting for pod pod-projected-configmaps-ed6d57ba-1385-4ed0-8233-7a2ffdb63a43 to disappear
May 29 17:30:31.873: INFO: Pod pod-projected-configmaps-ed6d57ba-1385-4ed0-8233-7a2ffdb63a43 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:30:31.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6543" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":117,"skipped":1918,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:30:31.904: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:30:39.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8634" for this suite.
STEP: Destroying namespace "nsdeletetest-7673" for this suite.
May 29 17:30:39.382: INFO: Namespace nsdeletetest-7673 was already deleted
STEP: Destroying namespace "nsdeletetest-9856" for this suite.

• [SLOW TEST:7.492 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":277,"completed":118,"skipped":1928,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:30:39.411: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:30:51.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1277" for this suite.

• [SLOW TEST:12.554 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":277,"completed":119,"skipped":1963,"failed":0}
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:30:51.965: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-s72k
STEP: Creating a pod to test atomic-volume-subpath
May 29 17:30:52.788: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-s72k" in namespace "subpath-4310" to be "Succeeded or Failed"
May 29 17:30:52.796: INFO: Pod "pod-subpath-test-configmap-s72k": Phase="Pending", Reason="", readiness=false. Elapsed: 7.833853ms
May 29 17:30:54.809: INFO: Pod "pod-subpath-test-configmap-s72k": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021001407s
May 29 17:30:56.822: INFO: Pod "pod-subpath-test-configmap-s72k": Phase="Running", Reason="", readiness=true. Elapsed: 4.034098578s
May 29 17:30:58.832: INFO: Pod "pod-subpath-test-configmap-s72k": Phase="Running", Reason="", readiness=true. Elapsed: 6.044400636s
May 29 17:31:00.846: INFO: Pod "pod-subpath-test-configmap-s72k": Phase="Running", Reason="", readiness=true. Elapsed: 8.05789795s
May 29 17:31:02.876: INFO: Pod "pod-subpath-test-configmap-s72k": Phase="Running", Reason="", readiness=true. Elapsed: 10.088441951s
May 29 17:31:04.891: INFO: Pod "pod-subpath-test-configmap-s72k": Phase="Running", Reason="", readiness=true. Elapsed: 12.102758563s
May 29 17:31:06.901: INFO: Pod "pod-subpath-test-configmap-s72k": Phase="Running", Reason="", readiness=true. Elapsed: 14.113276355s
May 29 17:31:08.918: INFO: Pod "pod-subpath-test-configmap-s72k": Phase="Running", Reason="", readiness=true. Elapsed: 16.13035339s
May 29 17:31:10.938: INFO: Pod "pod-subpath-test-configmap-s72k": Phase="Running", Reason="", readiness=true. Elapsed: 18.150294451s
May 29 17:31:12.952: INFO: Pod "pod-subpath-test-configmap-s72k": Phase="Running", Reason="", readiness=true. Elapsed: 20.164609061s
May 29 17:31:14.965: INFO: Pod "pod-subpath-test-configmap-s72k": Phase="Running", Reason="", readiness=true. Elapsed: 22.177436768s
May 29 17:31:16.978: INFO: Pod "pod-subpath-test-configmap-s72k": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.190463973s
STEP: Saw pod success
May 29 17:31:16.978: INFO: Pod "pod-subpath-test-configmap-s72k" satisfied condition "Succeeded or Failed"
May 29 17:31:16.995: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-subpath-test-configmap-s72k container test-container-subpath-configmap-s72k: <nil>
STEP: delete the pod
May 29 17:31:17.232: INFO: Waiting for pod pod-subpath-test-configmap-s72k to disappear
May 29 17:31:17.244: INFO: Pod pod-subpath-test-configmap-s72k no longer exists
STEP: Deleting pod pod-subpath-test-configmap-s72k
May 29 17:31:17.244: INFO: Deleting pod "pod-subpath-test-configmap-s72k" in namespace "subpath-4310"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:31:17.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4310" for this suite.

• [SLOW TEST:25.333 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [LinuxOnly] [Conformance]","total":277,"completed":120,"skipped":1966,"failed":0}
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:31:17.307: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-44fda585-4856-42a2-9997-fb64ae0b2a56 in namespace container-probe-4068
May 29 17:31:21.497: INFO: Started pod busybox-44fda585-4856-42a2-9997-fb64ae0b2a56 in namespace container-probe-4068
STEP: checking the pod's current state and verifying that restartCount is present
May 29 17:31:21.510: INFO: Initial restart count of pod busybox-44fda585-4856-42a2-9997-fb64ae0b2a56 is 0
May 29 17:32:15.827: INFO: Restart count of pod container-probe-4068/busybox-44fda585-4856-42a2-9997-fb64ae0b2a56 is now 1 (54.316919762s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:32:15.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4068" for this suite.

• [SLOW TEST:58.686 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":277,"completed":121,"skipped":1968,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:32:15.995: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:32:16.161: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:32:25.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-210" for this suite.

• [SLOW TEST:9.278 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:48
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":277,"completed":122,"skipped":1983,"failed":0}
SSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:32:25.273: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:32:25.391: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: creating replication controller svc-latency-rc in namespace svc-latency-5733
I0529 17:32:25.432462      20 runners.go:190] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5733, replica count: 1
I0529 17:32:26.483184      20 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 17:32:27.483802      20 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 17:32:28.484184      20 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 29 17:32:28.662: INFO: Created: latency-svc-vscg6
May 29 17:32:28.665: INFO: Got endpoints: latency-svc-vscg6 [80.697462ms]
May 29 17:32:28.700: INFO: Created: latency-svc-lttnn
May 29 17:32:28.713: INFO: Got endpoints: latency-svc-lttnn [48.204279ms]
May 29 17:32:28.898: INFO: Created: latency-svc-sp2g9
May 29 17:32:28.919: INFO: Got endpoints: latency-svc-sp2g9 [254.039169ms]
May 29 17:32:28.939: INFO: Created: latency-svc-sg5hw
May 29 17:32:28.959: INFO: Got endpoints: latency-svc-sg5hw [293.50991ms]
May 29 17:32:28.961: INFO: Created: latency-svc-cdgzr
May 29 17:32:28.977: INFO: Got endpoints: latency-svc-cdgzr [311.384643ms]
May 29 17:32:28.978: INFO: Created: latency-svc-4k6gl
May 29 17:32:28.985: INFO: Got endpoints: latency-svc-4k6gl [318.990048ms]
May 29 17:32:28.988: INFO: Created: latency-svc-8tzs4
May 29 17:32:29.001: INFO: Got endpoints: latency-svc-8tzs4 [335.707942ms]
May 29 17:32:29.003: INFO: Created: latency-svc-l89hb
May 29 17:32:29.016: INFO: Got endpoints: latency-svc-l89hb [348.722744ms]
May 29 17:32:29.021: INFO: Created: latency-svc-9js6p
May 29 17:32:29.028: INFO: Got endpoints: latency-svc-9js6p [361.879322ms]
May 29 17:32:29.048: INFO: Created: latency-svc-nvkwj
May 29 17:32:29.069: INFO: Got endpoints: latency-svc-nvkwj [403.477843ms]
May 29 17:32:29.121: INFO: Created: latency-svc-2kpkz
May 29 17:32:29.121: INFO: Created: latency-svc-x4p5z
May 29 17:32:29.127: INFO: Got endpoints: latency-svc-x4p5z [460.51247ms]
May 29 17:32:29.129: INFO: Got endpoints: latency-svc-2kpkz [462.743488ms]
May 29 17:32:29.129: INFO: Created: latency-svc-lnjtb
May 29 17:32:29.135: INFO: Got endpoints: latency-svc-lnjtb [468.928513ms]
May 29 17:32:29.149: INFO: Created: latency-svc-lgdc5
May 29 17:32:29.161: INFO: Got endpoints: latency-svc-lgdc5 [495.402908ms]
May 29 17:32:29.229: INFO: Created: latency-svc-dklkq
May 29 17:32:29.246: INFO: Got endpoints: latency-svc-dklkq [579.149477ms]
May 29 17:32:29.306: INFO: Created: latency-svc-58cmb
May 29 17:32:29.307: INFO: Got endpoints: latency-svc-58cmb [640.177061ms]
May 29 17:32:29.318: INFO: Created: latency-svc-7fxq9
May 29 17:32:29.328: INFO: Got endpoints: latency-svc-7fxq9 [614.281114ms]
May 29 17:32:29.406: INFO: Created: latency-svc-w5jd5
May 29 17:32:29.414: INFO: Got endpoints: latency-svc-w5jd5 [494.8592ms]
May 29 17:32:29.418: INFO: Created: latency-svc-dws9t
May 29 17:32:29.427: INFO: Got endpoints: latency-svc-dws9t [467.400741ms]
May 29 17:32:29.430: INFO: Created: latency-svc-8fsj9
May 29 17:32:29.444: INFO: Got endpoints: latency-svc-8fsj9 [466.161558ms]
May 29 17:32:29.445: INFO: Created: latency-svc-6s9w5
May 29 17:32:29.453: INFO: Got endpoints: latency-svc-6s9w5 [467.965138ms]
May 29 17:32:29.457: INFO: Created: latency-svc-w5vj9
May 29 17:32:29.466: INFO: Got endpoints: latency-svc-w5vj9 [463.987048ms]
May 29 17:32:29.474: INFO: Created: latency-svc-hkgpq
May 29 17:32:29.485: INFO: Got endpoints: latency-svc-hkgpq [468.324549ms]
May 29 17:32:29.492: INFO: Created: latency-svc-rf6jb
May 29 17:32:29.502: INFO: Got endpoints: latency-svc-rf6jb [473.496152ms]
May 29 17:32:29.506: INFO: Created: latency-svc-7jp89
May 29 17:32:29.530: INFO: Got endpoints: latency-svc-7jp89 [460.135432ms]
May 29 17:32:29.535: INFO: Created: latency-svc-2vvqh
May 29 17:32:29.535: INFO: Created: latency-svc-vnp6h
May 29 17:32:29.536: INFO: Got endpoints: latency-svc-vnp6h [408.895955ms]
May 29 17:32:29.553: INFO: Created: latency-svc-pm77n
May 29 17:32:29.556: INFO: Got endpoints: latency-svc-2vvqh [426.844088ms]
May 29 17:32:29.574: INFO: Got endpoints: latency-svc-pm77n [438.815563ms]
May 29 17:32:29.575: INFO: Created: latency-svc-l8d26
May 29 17:32:29.575: INFO: Got endpoints: latency-svc-l8d26 [413.803518ms]
May 29 17:32:29.585: INFO: Created: latency-svc-fbpdn
May 29 17:32:29.593: INFO: Created: latency-svc-db9sn
May 29 17:32:29.599: INFO: Got endpoints: latency-svc-fbpdn [353.780991ms]
May 29 17:32:29.611: INFO: Got endpoints: latency-svc-db9sn [302.810762ms]
May 29 17:32:29.619: INFO: Created: latency-svc-vb78q
May 29 17:32:29.632: INFO: Got endpoints: latency-svc-vb78q [304.142865ms]
May 29 17:32:29.635: INFO: Created: latency-svc-gtgf2
May 29 17:32:29.641: INFO: Got endpoints: latency-svc-gtgf2 [226.86876ms]
May 29 17:32:29.645: INFO: Created: latency-svc-gpbj2
May 29 17:32:29.653: INFO: Got endpoints: latency-svc-gpbj2 [225.9537ms]
May 29 17:32:29.662: INFO: Created: latency-svc-5qtwk
May 29 17:32:29.672: INFO: Got endpoints: latency-svc-5qtwk [227.169489ms]
May 29 17:32:29.678: INFO: Created: latency-svc-vhrr6
May 29 17:32:29.686: INFO: Got endpoints: latency-svc-vhrr6 [232.102512ms]
May 29 17:32:29.690: INFO: Created: latency-svc-q9jfw
May 29 17:32:29.701: INFO: Got endpoints: latency-svc-q9jfw [235.385342ms]
May 29 17:32:29.705: INFO: Created: latency-svc-b46zx
May 29 17:32:29.718: INFO: Got endpoints: latency-svc-b46zx [231.945441ms]
May 29 17:32:29.725: INFO: Created: latency-svc-vlj4p
May 29 17:32:29.743: INFO: Created: latency-svc-ltv4b
May 29 17:32:29.744: INFO: Got endpoints: latency-svc-vlj4p [241.301209ms]
May 29 17:32:29.750: INFO: Got endpoints: latency-svc-ltv4b [216.348863ms]
May 29 17:32:29.756: INFO: Created: latency-svc-4tsgq
May 29 17:32:29.768: INFO: Created: latency-svc-bkgsw
May 29 17:32:29.768: INFO: Got endpoints: latency-svc-4tsgq [232.810109ms]
May 29 17:32:29.779: INFO: Got endpoints: latency-svc-bkgsw [222.753175ms]
May 29 17:32:29.781: INFO: Created: latency-svc-8v96t
May 29 17:32:29.788: INFO: Got endpoints: latency-svc-8v96t [212.182881ms]
May 29 17:32:29.791: INFO: Created: latency-svc-5s9kg
May 29 17:32:29.808: INFO: Got endpoints: latency-svc-5s9kg [38.808118ms]
May 29 17:32:29.810: INFO: Created: latency-svc-k664s
May 29 17:32:29.815: INFO: Got endpoints: latency-svc-k664s [240.965767ms]
May 29 17:32:29.821: INFO: Created: latency-svc-vmczc
May 29 17:32:29.835: INFO: Got endpoints: latency-svc-vmczc [235.240357ms]
May 29 17:32:29.839: INFO: Created: latency-svc-7bgtx
May 29 17:32:29.860: INFO: Got endpoints: latency-svc-7bgtx [248.545708ms]
May 29 17:32:29.861: INFO: Created: latency-svc-pf5kb
May 29 17:32:29.871: INFO: Got endpoints: latency-svc-pf5kb [237.789862ms]
May 29 17:32:29.875: INFO: Created: latency-svc-bxxf9
May 29 17:32:29.888: INFO: Got endpoints: latency-svc-bxxf9 [245.651777ms]
May 29 17:32:29.894: INFO: Created: latency-svc-dpx9c
May 29 17:32:29.908: INFO: Got endpoints: latency-svc-dpx9c [254.58881ms]
May 29 17:32:29.918: INFO: Created: latency-svc-vjhll
May 29 17:32:29.925: INFO: Got endpoints: latency-svc-vjhll [252.688761ms]
May 29 17:32:29.940: INFO: Created: latency-svc-lf596
May 29 17:32:29.941: INFO: Got endpoints: latency-svc-lf596 [254.743092ms]
May 29 17:32:29.946: INFO: Created: latency-svc-s2jdd
May 29 17:32:29.961: INFO: Created: latency-svc-s8ct4
May 29 17:32:29.965: INFO: Got endpoints: latency-svc-s2jdd [262.395511ms]
May 29 17:32:29.974: INFO: Created: latency-svc-4g5ft
May 29 17:32:29.986: INFO: Created: latency-svc-dmkfl
May 29 17:32:30.002: INFO: Created: latency-svc-vfm99
May 29 17:32:30.071: INFO: Created: latency-svc-hkvdv
May 29 17:32:30.072: INFO: Got endpoints: latency-svc-s8ct4 [354.078727ms]
May 29 17:32:30.073: INFO: Created: latency-svc-2t5dl
May 29 17:32:30.084: INFO: Created: latency-svc-fhcrz
May 29 17:32:30.093: INFO: Created: latency-svc-rfl5t
May 29 17:32:30.123: INFO: Got endpoints: latency-svc-4g5ft [378.701048ms]
May 29 17:32:30.129: INFO: Created: latency-svc-7pmwm
May 29 17:32:30.225: INFO: Got endpoints: latency-svc-dmkfl [474.675387ms]
May 29 17:32:30.360: INFO: Got endpoints: latency-svc-vfm99 [579.65161ms]
May 29 17:32:30.361: INFO: Got endpoints: latency-svc-2t5dl [573.407583ms]
May 29 17:32:30.363: INFO: Got endpoints: latency-svc-fhcrz [555.386038ms]
May 29 17:32:30.368: INFO: Got endpoints: latency-svc-rfl5t [551.865895ms]
May 29 17:32:30.372: INFO: Got endpoints: latency-svc-hkvdv [535.955571ms]
May 29 17:32:30.388: INFO: Created: latency-svc-pf2c8
May 29 17:32:30.407: INFO: Created: latency-svc-7bmxq
May 29 17:32:30.426: INFO: Created: latency-svc-ml9nc
May 29 17:32:30.428: INFO: Got endpoints: latency-svc-7pmwm [567.818792ms]
May 29 17:32:30.445: INFO: Created: latency-svc-g284s
May 29 17:32:30.457: INFO: Created: latency-svc-bxbdr
May 29 17:32:30.461: INFO: Got endpoints: latency-svc-pf2c8 [589.551286ms]
May 29 17:32:30.468: INFO: Created: latency-svc-4g47p
May 29 17:32:30.485: INFO: Created: latency-svc-tbh7j
May 29 17:32:30.495: INFO: Created: latency-svc-tg6qj
May 29 17:32:30.510: INFO: Got endpoints: latency-svc-7bmxq [621.314394ms]
May 29 17:32:30.517: INFO: Created: latency-svc-pzxlq
May 29 17:32:30.532: INFO: Created: latency-svc-64prm
May 29 17:32:30.564: INFO: Created: latency-svc-dknlt
May 29 17:32:30.573: INFO: Got endpoints: latency-svc-ml9nc [664.203826ms]
May 29 17:32:30.576: INFO: Created: latency-svc-8lmv6
May 29 17:32:30.595: INFO: Created: latency-svc-2ggv2
May 29 17:32:30.608: INFO: Got endpoints: latency-svc-g284s [681.945701ms]
May 29 17:32:30.611: INFO: Created: latency-svc-grjnl
May 29 17:32:30.624: INFO: Created: latency-svc-8kvct
May 29 17:32:30.639: INFO: Created: latency-svc-8pmvp
May 29 17:32:30.648: INFO: Created: latency-svc-kmqsn
May 29 17:32:30.666: INFO: Created: latency-svc-lq88p
May 29 17:32:30.667: INFO: Got endpoints: latency-svc-bxbdr [725.183588ms]
May 29 17:32:30.686: INFO: Created: latency-svc-h474r
May 29 17:32:30.694: INFO: Created: latency-svc-h8ssm
May 29 17:32:30.708: INFO: Got endpoints: latency-svc-4g47p [743.179575ms]
May 29 17:32:30.735: INFO: Created: latency-svc-q2mp5
May 29 17:32:30.788: INFO: Got endpoints: latency-svc-tbh7j [715.753554ms]
May 29 17:32:30.811: INFO: Got endpoints: latency-svc-tg6qj [686.526623ms]
May 29 17:32:30.828: INFO: Created: latency-svc-jjffv
May 29 17:32:30.855: INFO: Created: latency-svc-fwh6t
May 29 17:32:30.869: INFO: Got endpoints: latency-svc-pzxlq [643.60671ms]
May 29 17:32:30.921: INFO: Got endpoints: latency-svc-64prm [560.200239ms]
May 29 17:32:30.935: INFO: Created: latency-svc-vcgrd
May 29 17:32:30.959: INFO: Got endpoints: latency-svc-dknlt [596.697143ms]
May 29 17:32:30.965: INFO: Created: latency-svc-7tg69
May 29 17:32:30.999: INFO: Created: latency-svc-lcc6s
May 29 17:32:32.172: INFO: Got endpoints: latency-svc-8lmv6 [1.808356415s]
May 29 17:32:32.184: INFO: Got endpoints: latency-svc-2ggv2 [1.816317474s]
May 29 17:32:32.186: INFO: Got endpoints: latency-svc-8pmvp [1.7249618s]
May 29 17:32:32.187: INFO: Got endpoints: latency-svc-grjnl [1.815902501s]
May 29 17:32:32.188: INFO: Got endpoints: latency-svc-8kvct [1.759943299s]
May 29 17:32:32.189: INFO: Got endpoints: latency-svc-kmqsn [1.679239934s]
May 29 17:32:32.199: INFO: Got endpoints: latency-svc-q2mp5 [1.490753523s]
May 29 17:32:32.200: INFO: Got endpoints: latency-svc-lq88p [1.626697778s]
May 29 17:32:32.201: INFO: Got endpoints: latency-svc-h474r [1.592255415s]
May 29 17:32:32.201: INFO: Got endpoints: latency-svc-h8ssm [1.534301407s]
May 29 17:32:32.209: INFO: Got endpoints: latency-svc-fwh6t [1.398289565s]
May 29 17:32:32.211: INFO: Got endpoints: latency-svc-jjffv [1.422115341s]
May 29 17:32:32.221: INFO: Got endpoints: latency-svc-7tg69 [1.300430634s]
May 29 17:32:32.222: INFO: Got endpoints: latency-svc-vcgrd [1.352759685s]
May 29 17:32:32.226: INFO: Got endpoints: latency-svc-lcc6s [1.266789226s]
May 29 17:32:32.306: INFO: Created: latency-svc-rw7xw
May 29 17:32:33.442: INFO: Created: latency-svc-pdb26
May 29 17:32:33.999: INFO: Got endpoints: latency-svc-rw7xw [1.826445277s]
May 29 17:32:34.465: INFO: Got endpoints: latency-svc-pdb26 [2.281342842s]
May 29 17:32:34.487: INFO: Created: latency-svc-567lr
May 29 17:32:34.545: INFO: Got endpoints: latency-svc-567lr [2.358944705s]
May 29 17:32:34.922: INFO: Created: latency-svc-jgzhg
May 29 17:32:35.024: INFO: Got endpoints: latency-svc-jgzhg [2.836295919s]
May 29 17:32:35.029: INFO: Created: latency-svc-cz8qf
May 29 17:32:35.052: INFO: Got endpoints: latency-svc-cz8qf [2.862874364s]
May 29 17:32:35.278: INFO: Created: latency-svc-xsbs6
May 29 17:32:35.286: INFO: Got endpoints: latency-svc-xsbs6 [3.087038971s]
May 29 17:32:35.298: INFO: Created: latency-svc-249s8
May 29 17:32:35.308: INFO: Got endpoints: latency-svc-249s8 [3.106449991s]
May 29 17:32:35.309: INFO: Created: latency-svc-hjx5n
May 29 17:32:35.309: INFO: Got endpoints: latency-svc-hjx5n [3.121756941s]
May 29 17:32:35.327: INFO: Created: latency-svc-tdrvp
May 29 17:32:35.335: INFO: Got endpoints: latency-svc-tdrvp [3.133845362s]
May 29 17:32:35.343: INFO: Created: latency-svc-cvkbl
May 29 17:32:35.356: INFO: Got endpoints: latency-svc-cvkbl [3.156008146s]
May 29 17:32:35.360: INFO: Created: latency-svc-jcqs4
May 29 17:32:35.363: INFO: Got endpoints: latency-svc-jcqs4 [3.153055772s]
May 29 17:32:35.369: INFO: Created: latency-svc-zc7gk
May 29 17:32:35.378: INFO: Got endpoints: latency-svc-zc7gk [3.166470683s]
May 29 17:32:35.390: INFO: Created: latency-svc-8pwcz
May 29 17:32:35.408: INFO: Got endpoints: latency-svc-8pwcz [3.18564093s]
May 29 17:32:35.408: INFO: Created: latency-svc-744w7
May 29 17:32:35.421: INFO: Created: latency-svc-k7l9j
May 29 17:32:35.422: INFO: Got endpoints: latency-svc-744w7 [3.198969386s]
May 29 17:32:35.432: INFO: Got endpoints: latency-svc-k7l9j [3.205925729s]
May 29 17:32:35.436: INFO: Created: latency-svc-h6v59
May 29 17:32:35.447: INFO: Got endpoints: latency-svc-h6v59 [1.448041981s]
May 29 17:32:35.466: INFO: Created: latency-svc-htn7w
May 29 17:32:35.478: INFO: Got endpoints: latency-svc-htn7w [1.012593649s]
May 29 17:32:35.481: INFO: Created: latency-svc-l25c2
May 29 17:32:35.496: INFO: Created: latency-svc-5krfc
May 29 17:32:35.497: INFO: Got endpoints: latency-svc-l25c2 [951.947797ms]
May 29 17:32:35.503: INFO: Got endpoints: latency-svc-5krfc [478.642739ms]
May 29 17:32:35.508: INFO: Created: latency-svc-w566l
May 29 17:32:35.516: INFO: Got endpoints: latency-svc-w566l [463.999769ms]
May 29 17:32:35.525: INFO: Created: latency-svc-cxckj
May 29 17:32:35.536: INFO: Created: latency-svc-fw28f
May 29 17:32:35.538: INFO: Got endpoints: latency-svc-cxckj [251.929033ms]
May 29 17:32:35.549: INFO: Got endpoints: latency-svc-fw28f [240.91233ms]
May 29 17:32:35.551: INFO: Created: latency-svc-pm4l2
May 29 17:32:35.560: INFO: Got endpoints: latency-svc-pm4l2 [250.304881ms]
May 29 17:32:35.563: INFO: Created: latency-svc-pwt9k
May 29 17:32:35.581: INFO: Got endpoints: latency-svc-pwt9k [245.981561ms]
May 29 17:32:35.586: INFO: Created: latency-svc-g9xdw
May 29 17:32:35.596: INFO: Got endpoints: latency-svc-g9xdw [239.604028ms]
May 29 17:32:35.602: INFO: Created: latency-svc-vxm7f
May 29 17:32:35.644: INFO: Created: latency-svc-h6nj4
May 29 17:32:36.168: INFO: Got endpoints: latency-svc-vxm7f [804.901894ms]
May 29 17:32:36.243: INFO: Got endpoints: latency-svc-h6nj4 [864.868339ms]
May 29 17:32:36.277: INFO: Created: latency-svc-w2nmj
May 29 17:32:36.277: INFO: Got endpoints: latency-svc-w2nmj [868.746206ms]
May 29 17:32:36.333: INFO: Created: latency-svc-7w8gn
May 29 17:32:36.402: INFO: Created: latency-svc-tbx4n
May 29 17:32:36.592: INFO: Got endpoints: latency-svc-7w8gn [1.169505401s]
May 29 17:32:36.631: INFO: Got endpoints: latency-svc-tbx4n [1.197418896s]
May 29 17:32:36.639: INFO: Created: latency-svc-c8fdv
May 29 17:32:36.652: INFO: Got endpoints: latency-svc-c8fdv [1.204018085s]
May 29 17:32:36.674: INFO: Created: latency-svc-9hd9h
May 29 17:32:36.679: INFO: Got endpoints: latency-svc-9hd9h [1.19966903s]
May 29 17:32:36.686: INFO: Created: latency-svc-dzgsf
May 29 17:32:36.699: INFO: Got endpoints: latency-svc-dzgsf [1.202071594s]
May 29 17:32:36.747: INFO: Created: latency-svc-mfnsx
May 29 17:32:36.765: INFO: Got endpoints: latency-svc-mfnsx [1.262298834s]
May 29 17:32:36.776: INFO: Created: latency-svc-mq8r4
May 29 17:32:36.793: INFO: Got endpoints: latency-svc-mq8r4 [1.276958651s]
May 29 17:32:36.816: INFO: Created: latency-svc-vvzxl
May 29 17:32:36.819: INFO: Created: latency-svc-2sldl
May 29 17:32:36.821: INFO: Got endpoints: latency-svc-2sldl [1.282003476s]
May 29 17:32:36.834: INFO: Got endpoints: latency-svc-vvzxl [1.284845687s]
May 29 17:32:36.863: INFO: Created: latency-svc-7cf8g
May 29 17:32:36.866: INFO: Got endpoints: latency-svc-7cf8g [1.305446751s]
May 29 17:32:36.911: INFO: Created: latency-svc-8w6dq
May 29 17:32:36.915: INFO: Got endpoints: latency-svc-8w6dq [1.333322797s]
May 29 17:32:36.932: INFO: Created: latency-svc-6hm9q
May 29 17:32:36.938: INFO: Got endpoints: latency-svc-6hm9q [1.342167309s]
May 29 17:32:36.943: INFO: Created: latency-svc-bdl7v
May 29 17:32:36.955: INFO: Got endpoints: latency-svc-bdl7v [786.733144ms]
May 29 17:32:36.980: INFO: Created: latency-svc-rgzl4
May 29 17:32:36.995: INFO: Created: latency-svc-cddbp
May 29 17:32:36.995: INFO: Got endpoints: latency-svc-rgzl4 [751.992233ms]
May 29 17:32:37.031: INFO: Got endpoints: latency-svc-cddbp [754.051412ms]
May 29 17:32:37.064: INFO: Created: latency-svc-46qlq
May 29 17:32:37.078: INFO: Got endpoints: latency-svc-46qlq [485.995203ms]
May 29 17:32:37.127: INFO: Created: latency-svc-vhqvl
May 29 17:32:37.133: INFO: Created: latency-svc-z9j2p
May 29 17:32:37.133: INFO: Created: latency-svc-rjq64
May 29 17:32:37.144: INFO: Got endpoints: latency-svc-z9j2p [491.722453ms]
May 29 17:32:37.145: INFO: Got endpoints: latency-svc-vhqvl [513.851386ms]
May 29 17:32:37.147: INFO: Got endpoints: latency-svc-rjq64 [467.263372ms]
May 29 17:32:37.199: INFO: Created: latency-svc-9pbml
May 29 17:32:37.201: INFO: Created: latency-svc-qs67n
May 29 17:32:37.202: INFO: Got endpoints: latency-svc-9pbml [501.723564ms]
May 29 17:32:37.224: INFO: Got endpoints: latency-svc-qs67n [457.924418ms]
May 29 17:32:37.255: INFO: Created: latency-svc-9dmxb
May 29 17:32:37.258: INFO: Got endpoints: latency-svc-9dmxb [462.592091ms]
May 29 17:32:37.288: INFO: Created: latency-svc-v8hqb
May 29 17:32:37.294: INFO: Created: latency-svc-ndv4j
May 29 17:32:37.295: INFO: Got endpoints: latency-svc-v8hqb [473.824689ms]
May 29 17:32:37.303: INFO: Got endpoints: latency-svc-ndv4j [466.803245ms]
May 29 17:32:37.352: INFO: Created: latency-svc-t2d47
May 29 17:32:37.367: INFO: Got endpoints: latency-svc-t2d47 [501.618199ms]
May 29 17:32:37.380: INFO: Created: latency-svc-wmhdr
May 29 17:32:37.390: INFO: Got endpoints: latency-svc-wmhdr [475.475112ms]
May 29 17:32:37.398: INFO: Created: latency-svc-2shpl
May 29 17:32:37.408: INFO: Got endpoints: latency-svc-2shpl [466.413791ms]
May 29 17:32:37.410: INFO: Created: latency-svc-zjhvs
May 29 17:32:37.420: INFO: Got endpoints: latency-svc-zjhvs [463.276051ms]
May 29 17:32:37.432: INFO: Created: latency-svc-gbkkv
May 29 17:32:37.436: INFO: Got endpoints: latency-svc-gbkkv [440.960529ms]
May 29 17:32:37.442: INFO: Created: latency-svc-48pp9
May 29 17:32:37.460: INFO: Created: latency-svc-8mcr2
May 29 17:32:37.460: INFO: Got endpoints: latency-svc-48pp9 [428.494898ms]
May 29 17:32:37.468: INFO: Got endpoints: latency-svc-8mcr2 [389.70498ms]
May 29 17:32:37.479: INFO: Created: latency-svc-l6f4r
May 29 17:32:37.485: INFO: Got endpoints: latency-svc-l6f4r [340.948305ms]
May 29 17:32:37.487: INFO: Created: latency-svc-bs8v8
May 29 17:32:37.498: INFO: Got endpoints: latency-svc-bs8v8 [352.776896ms]
May 29 17:32:37.502: INFO: Created: latency-svc-2r9xw
May 29 17:32:37.518: INFO: Got endpoints: latency-svc-2r9xw [371.086319ms]
May 29 17:32:37.521: INFO: Created: latency-svc-wzh75
May 29 17:32:37.540: INFO: Got endpoints: latency-svc-wzh75 [336.254388ms]
May 29 17:32:37.541: INFO: Created: latency-svc-g7wr7
May 29 17:32:37.548: INFO: Got endpoints: latency-svc-g7wr7 [322.887579ms]
May 29 17:32:37.552: INFO: Created: latency-svc-l6mkt
May 29 17:32:37.571: INFO: Got endpoints: latency-svc-l6mkt [312.983393ms]
May 29 17:32:37.571: INFO: Created: latency-svc-sq6zg
May 29 17:32:37.582: INFO: Got endpoints: latency-svc-sq6zg [286.856593ms]
May 29 17:32:37.583: INFO: Created: latency-svc-6dv4d
May 29 17:32:37.592: INFO: Got endpoints: latency-svc-6dv4d [288.936681ms]
May 29 17:32:37.594: INFO: Created: latency-svc-hwv29
May 29 17:32:37.609: INFO: Got endpoints: latency-svc-hwv29 [240.882884ms]
May 29 17:32:37.612: INFO: Created: latency-svc-md6xj
May 29 17:32:37.622: INFO: Got endpoints: latency-svc-md6xj [231.691895ms]
May 29 17:32:37.626: INFO: Created: latency-svc-cf8t7
May 29 17:32:37.636: INFO: Got endpoints: latency-svc-cf8t7 [227.875593ms]
May 29 17:32:37.639: INFO: Created: latency-svc-t9cwj
May 29 17:32:37.668: INFO: Got endpoints: latency-svc-t9cwj [247.019993ms]
May 29 17:32:37.673: INFO: Created: latency-svc-jsdlr
May 29 17:32:37.676: INFO: Created: latency-svc-6lk7g
May 29 17:32:37.691: INFO: Created: latency-svc-46b2r
May 29 17:32:37.691: INFO: Got endpoints: latency-svc-jsdlr [228.99942ms]
May 29 17:32:37.691: INFO: Got endpoints: latency-svc-6lk7g [253.703111ms]
May 29 17:32:37.700: INFO: Got endpoints: latency-svc-46b2r [231.856847ms]
May 29 17:32:37.705: INFO: Created: latency-svc-svbrx
May 29 17:32:37.722: INFO: Created: latency-svc-ddwvr
May 29 17:32:37.722: INFO: Got endpoints: latency-svc-svbrx [236.469525ms]
May 29 17:32:37.729: INFO: Got endpoints: latency-svc-ddwvr [230.407876ms]
May 29 17:32:37.734: INFO: Created: latency-svc-j48wx
May 29 17:32:37.742: INFO: Got endpoints: latency-svc-j48wx [223.205163ms]
May 29 17:32:37.744: INFO: Created: latency-svc-ntgvs
May 29 17:32:37.756: INFO: Created: latency-svc-wgtj7
May 29 17:32:37.757: INFO: Got endpoints: latency-svc-ntgvs [216.020664ms]
May 29 17:32:37.770: INFO: Got endpoints: latency-svc-wgtj7 [221.312595ms]
May 29 17:32:37.777: INFO: Created: latency-svc-z95v6
May 29 17:32:37.783: INFO: Got endpoints: latency-svc-z95v6 [211.837291ms]
May 29 17:32:37.787: INFO: Created: latency-svc-xw9x2
May 29 17:32:37.811: INFO: Got endpoints: latency-svc-xw9x2 [228.158301ms]
May 29 17:32:37.812: INFO: Created: latency-svc-kbcrh
May 29 17:32:37.814: INFO: Got endpoints: latency-svc-kbcrh [221.982995ms]
May 29 17:32:37.821: INFO: Created: latency-svc-rhrsm
May 29 17:32:37.832: INFO: Got endpoints: latency-svc-rhrsm [223.054668ms]
May 29 17:32:37.833: INFO: Created: latency-svc-spgk4
May 29 17:32:37.851: INFO: Created: latency-svc-2fjdn
May 29 17:32:37.851: INFO: Got endpoints: latency-svc-spgk4 [228.462354ms]
May 29 17:32:37.864: INFO: Created: latency-svc-4h8nr
May 29 17:32:37.884: INFO: Created: latency-svc-z2645
May 29 17:32:37.909: INFO: Got endpoints: latency-svc-2fjdn [272.203461ms]
May 29 17:32:37.911: INFO: Created: latency-svc-6559s
May 29 17:32:37.912: INFO: Created: latency-svc-v2vxt
May 29 17:32:37.923: INFO: Created: latency-svc-bbpss
May 29 17:32:37.939: INFO: Created: latency-svc-wg8dm
May 29 17:32:37.950: INFO: Got endpoints: latency-svc-4h8nr [281.950614ms]
May 29 17:32:37.956: INFO: Created: latency-svc-btvvg
May 29 17:32:37.987: INFO: Created: latency-svc-gjv9d
May 29 17:32:38.003: INFO: Created: latency-svc-xmg76
May 29 17:32:38.003: INFO: Got endpoints: latency-svc-z2645 [312.367413ms]
May 29 17:32:38.015: INFO: Created: latency-svc-xw24n
May 29 17:32:38.034: INFO: Created: latency-svc-zrdrw
May 29 17:32:38.052: INFO: Got endpoints: latency-svc-6559s [361.007884ms]
May 29 17:32:38.057: INFO: Created: latency-svc-9f2z5
May 29 17:32:38.072: INFO: Created: latency-svc-l6r64
May 29 17:32:38.097: INFO: Created: latency-svc-q6hj9
May 29 17:32:38.102: INFO: Got endpoints: latency-svc-v2vxt [401.262281ms]
May 29 17:32:38.110: INFO: Created: latency-svc-8mqw6
May 29 17:32:38.122: INFO: Created: latency-svc-6kzvr
May 29 17:32:38.137: INFO: Created: latency-svc-rnhzx
May 29 17:32:38.151: INFO: Got endpoints: latency-svc-bbpss [428.870549ms]
May 29 17:32:38.156: INFO: Created: latency-svc-4rxwr
May 29 17:32:38.166: INFO: Created: latency-svc-5vnsh
May 29 17:32:38.182: INFO: Created: latency-svc-6zs8x
May 29 17:32:38.211: INFO: Got endpoints: latency-svc-wg8dm [481.836425ms]
May 29 17:32:38.242: INFO: Created: latency-svc-tvfhg
May 29 17:32:38.252: INFO: Got endpoints: latency-svc-btvvg [509.380527ms]
May 29 17:32:38.313: INFO: Got endpoints: latency-svc-gjv9d [555.510123ms]
May 29 17:32:38.334: INFO: Created: latency-svc-q6fvl
May 29 17:32:38.358: INFO: Got endpoints: latency-svc-xmg76 [587.709816ms]
May 29 17:32:38.409: INFO: Got endpoints: latency-svc-xw24n [625.429665ms]
May 29 17:32:38.426: INFO: Created: latency-svc-cghjk
May 29 17:32:38.442: INFO: Created: latency-svc-z9fxf
May 29 17:32:38.451: INFO: Got endpoints: latency-svc-zrdrw [636.715136ms]
May 29 17:32:38.453: INFO: Created: latency-svc-g65gq
May 29 17:32:38.489: INFO: Created: latency-svc-r2cs6
May 29 17:32:38.504: INFO: Got endpoints: latency-svc-9f2z5 [692.064647ms]
May 29 17:32:38.540: INFO: Created: latency-svc-bgqnr
May 29 17:32:38.551: INFO: Got endpoints: latency-svc-l6r64 [719.271506ms]
May 29 17:32:38.587: INFO: Created: latency-svc-d76xj
May 29 17:32:38.600: INFO: Got endpoints: latency-svc-q6hj9 [748.888331ms]
May 29 17:32:38.655: INFO: Got endpoints: latency-svc-8mqw6 [745.776756ms]
May 29 17:32:38.723: INFO: Got endpoints: latency-svc-6kzvr [772.615033ms]
May 29 17:32:38.749: INFO: Got endpoints: latency-svc-rnhzx [745.994695ms]
May 29 17:32:38.801: INFO: Got endpoints: latency-svc-4rxwr [748.310473ms]
May 29 17:32:38.852: INFO: Got endpoints: latency-svc-5vnsh [749.784079ms]
May 29 17:32:38.901: INFO: Got endpoints: latency-svc-6zs8x [747.416806ms]
May 29 17:32:38.956: INFO: Got endpoints: latency-svc-tvfhg [743.836066ms]
May 29 17:32:39.002: INFO: Got endpoints: latency-svc-q6fvl [749.117366ms]
May 29 17:32:39.077: INFO: Got endpoints: latency-svc-cghjk [763.824599ms]
May 29 17:32:39.102: INFO: Got endpoints: latency-svc-z9fxf [692.546769ms]
May 29 17:32:39.155: INFO: Got endpoints: latency-svc-g65gq [797.500005ms]
May 29 17:32:39.202: INFO: Got endpoints: latency-svc-r2cs6 [750.665909ms]
May 29 17:32:39.256: INFO: Got endpoints: latency-svc-bgqnr [751.95982ms]
May 29 17:32:39.301: INFO: Got endpoints: latency-svc-d76xj [748.771266ms]
May 29 17:32:39.301: INFO: Latencies: [38.808118ms 48.204279ms 211.837291ms 212.182881ms 216.020664ms 216.348863ms 221.312595ms 221.982995ms 222.753175ms 223.054668ms 223.205163ms 225.9537ms 226.86876ms 227.169489ms 227.875593ms 228.158301ms 228.462354ms 228.99942ms 230.407876ms 231.691895ms 231.856847ms 231.945441ms 232.102512ms 232.810109ms 235.240357ms 235.385342ms 236.469525ms 237.789862ms 239.604028ms 240.882884ms 240.91233ms 240.965767ms 241.301209ms 245.651777ms 245.981561ms 247.019993ms 248.545708ms 250.304881ms 251.929033ms 252.688761ms 253.703111ms 254.039169ms 254.58881ms 254.743092ms 262.395511ms 272.203461ms 281.950614ms 286.856593ms 288.936681ms 293.50991ms 302.810762ms 304.142865ms 311.384643ms 312.367413ms 312.983393ms 318.990048ms 322.887579ms 335.707942ms 336.254388ms 340.948305ms 348.722744ms 352.776896ms 353.780991ms 354.078727ms 361.007884ms 361.879322ms 371.086319ms 378.701048ms 389.70498ms 401.262281ms 403.477843ms 408.895955ms 413.803518ms 426.844088ms 428.494898ms 428.870549ms 438.815563ms 440.960529ms 457.924418ms 460.135432ms 460.51247ms 462.592091ms 462.743488ms 463.276051ms 463.987048ms 463.999769ms 466.161558ms 466.413791ms 466.803245ms 467.263372ms 467.400741ms 467.965138ms 468.324549ms 468.928513ms 473.496152ms 473.824689ms 474.675387ms 475.475112ms 478.642739ms 481.836425ms 485.995203ms 491.722453ms 494.8592ms 495.402908ms 501.618199ms 501.723564ms 509.380527ms 513.851386ms 535.955571ms 551.865895ms 555.386038ms 555.510123ms 560.200239ms 567.818792ms 573.407583ms 579.149477ms 579.65161ms 587.709816ms 589.551286ms 596.697143ms 614.281114ms 621.314394ms 625.429665ms 636.715136ms 640.177061ms 643.60671ms 664.203826ms 681.945701ms 686.526623ms 692.064647ms 692.546769ms 715.753554ms 719.271506ms 725.183588ms 743.179575ms 743.836066ms 745.776756ms 745.994695ms 747.416806ms 748.310473ms 748.771266ms 748.888331ms 749.117366ms 749.784079ms 750.665909ms 751.95982ms 751.992233ms 754.051412ms 763.824599ms 772.615033ms 786.733144ms 797.500005ms 804.901894ms 864.868339ms 868.746206ms 951.947797ms 1.012593649s 1.169505401s 1.197418896s 1.19966903s 1.202071594s 1.204018085s 1.262298834s 1.266789226s 1.276958651s 1.282003476s 1.284845687s 1.300430634s 1.305446751s 1.333322797s 1.342167309s 1.352759685s 1.398289565s 1.422115341s 1.448041981s 1.490753523s 1.534301407s 1.592255415s 1.626697778s 1.679239934s 1.7249618s 1.759943299s 1.808356415s 1.815902501s 1.816317474s 1.826445277s 2.281342842s 2.358944705s 2.836295919s 2.862874364s 3.087038971s 3.106449991s 3.121756941s 3.133845362s 3.153055772s 3.156008146s 3.166470683s 3.18564093s 3.198969386s 3.205925729s]
May 29 17:32:39.301: INFO: 50 %ile: 485.995203ms
May 29 17:32:39.301: INFO: 90 %ile: 1.7249618s
May 29 17:32:39.301: INFO: 99 %ile: 3.198969386s
May 29 17:32:39.301: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:32:39.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-5733" for this suite.

• [SLOW TEST:14.071 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":277,"completed":123,"skipped":1990,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:32:39.345: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-845d925e-1bfa-42ce-b366-f3c725706df5 in namespace container-probe-338
May 29 17:32:43.504: INFO: Started pod liveness-845d925e-1bfa-42ce-b366-f3c725706df5 in namespace container-probe-338
STEP: checking the pod's current state and verifying that restartCount is present
May 29 17:32:43.517: INFO: Initial restart count of pod liveness-845d925e-1bfa-42ce-b366-f3c725706df5 is 0
May 29 17:33:01.906: INFO: Restart count of pod container-probe-338/liveness-845d925e-1bfa-42ce-b366-f3c725706df5 is now 1 (18.388867113s elapsed)
May 29 17:33:22.487: INFO: Restart count of pod container-probe-338/liveness-845d925e-1bfa-42ce-b366-f3c725706df5 is now 2 (38.970316808s elapsed)
May 29 17:33:43.264: INFO: Restart count of pod container-probe-338/liveness-845d925e-1bfa-42ce-b366-f3c725706df5 is now 3 (59.746789237s elapsed)
May 29 17:34:03.402: INFO: Restart count of pod container-probe-338/liveness-845d925e-1bfa-42ce-b366-f3c725706df5 is now 4 (1m19.885234185s elapsed)
May 29 17:35:06.064: INFO: Restart count of pod container-probe-338/liveness-845d925e-1bfa-42ce-b366-f3c725706df5 is now 5 (2m22.546938807s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:35:07.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-338" for this suite.

• [SLOW TEST:147.749 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":277,"completed":124,"skipped":1999,"failed":0}
SS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:35:07.095: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6670.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6670.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 29 17:35:14.080: INFO: DNS probes using dns-6670/dns-test-8be3b671-c343-400b-bed2-3fd5c16ecfb0 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:35:14.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6670" for this suite.

• [SLOW TEST:7.071 seconds]
[sig-network] DNS
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":277,"completed":125,"skipped":2001,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:35:14.193: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:35:14.421: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
May 29 17:35:14.458: INFO: Number of nodes with available pods: 0
May 29 17:35:14.458: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
May 29 17:35:14.510: INFO: Number of nodes with available pods: 0
May 29 17:35:14.511: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:35:15.521: INFO: Number of nodes with available pods: 0
May 29 17:35:15.522: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:35:16.528: INFO: Number of nodes with available pods: 0
May 29 17:35:16.528: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:35:17.530: INFO: Number of nodes with available pods: 0
May 29 17:35:17.530: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:35:18.523: INFO: Number of nodes with available pods: 1
May 29 17:35:18.523: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
May 29 17:35:18.597: INFO: Number of nodes with available pods: 0
May 29 17:35:18.597: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
May 29 17:35:18.638: INFO: Number of nodes with available pods: 0
May 29 17:35:18.638: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:35:19.661: INFO: Number of nodes with available pods: 0
May 29 17:35:19.661: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:35:20.659: INFO: Number of nodes with available pods: 0
May 29 17:35:20.659: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:35:21.654: INFO: Number of nodes with available pods: 0
May 29 17:35:21.654: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:35:22.654: INFO: Number of nodes with available pods: 0
May 29 17:35:22.655: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:35:23.671: INFO: Number of nodes with available pods: 0
May 29 17:35:23.671: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:35:24.656: INFO: Number of nodes with available pods: 0
May 29 17:35:24.656: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:35:25.649: INFO: Number of nodes with available pods: 0
May 29 17:35:25.649: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:35:26.651: INFO: Number of nodes with available pods: 0
May 29 17:35:26.652: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:35:27.651: INFO: Number of nodes with available pods: 0
May 29 17:35:27.651: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:35:28.651: INFO: Number of nodes with available pods: 0
May 29 17:35:28.651: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:35:29.649: INFO: Number of nodes with available pods: 1
May 29 17:35:29.649: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2441, will wait for the garbage collector to delete the pods
May 29 17:35:29.760: INFO: Deleting DaemonSet.extensions daemon-set took: 28.922229ms
May 29 17:35:30.260: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.545436ms
May 29 17:35:36.978: INFO: Number of nodes with available pods: 0
May 29 17:35:36.978: INFO: Number of running nodes: 0, number of available pods: 0
May 29 17:35:36.986: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2441/daemonsets","resourceVersion":"12710156616"},"items":null}

May 29 17:35:37.006: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2441/pods","resourceVersion":"12710156617"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:35:37.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2441" for this suite.

• [SLOW TEST:23.052 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":277,"completed":126,"skipped":2066,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:35:37.248: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
May 29 17:35:37.615: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3540 /api/v1/namespaces/watch-3540/configmaps/e2e-watch-test-watch-closed 726e2fd2-6a49-498a-a10e-3538ea406cf9 12710157021 0 2020-05-29 17:35:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-05-29 17:35:37 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
May 29 17:35:37.616: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3540 /api/v1/namespaces/watch-3540/configmaps/e2e-watch-test-watch-closed 726e2fd2-6a49-498a-a10e-3538ea406cf9 12710157027 0 2020-05-29 17:35:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-05-29 17:35:37 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
May 29 17:35:37.688: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3540 /api/v1/namespaces/watch-3540/configmaps/e2e-watch-test-watch-closed 726e2fd2-6a49-498a-a10e-3538ea406cf9 12710157037 0 2020-05-29 17:35:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-05-29 17:35:37 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
May 29 17:35:37.689: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3540 /api/v1/namespaces/watch-3540/configmaps/e2e-watch-test-watch-closed 726e2fd2-6a49-498a-a10e-3538ea406cf9 12710157048 0 2020-05-29 17:35:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-05-29 17:35:37 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:35:37.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3540" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":277,"completed":127,"skipped":2082,"failed":0}
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:35:37.719: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:35:37.938: INFO: (0) /api/v1/nodes/node-cncf-lab-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 74.574504ms)
May 29 17:35:37.972: INFO: (1) /api/v1/nodes/node-cncf-lab-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 33.730804ms)
May 29 17:35:37.994: INFO: (2) /api/v1/nodes/node-cncf-lab-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 21.392245ms)
May 29 17:35:38.015: INFO: (3) /api/v1/nodes/node-cncf-lab-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 20.944318ms)
May 29 17:35:38.032: INFO: (4) /api/v1/nodes/node-cncf-lab-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 16.022307ms)
May 29 17:35:38.054: INFO: (5) /api/v1/nodes/node-cncf-lab-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 22.514852ms)
May 29 17:35:38.068: INFO: (6) /api/v1/nodes/node-cncf-lab-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.561304ms)
May 29 17:35:38.082: INFO: (7) /api/v1/nodes/node-cncf-lab-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.211682ms)
May 29 17:35:38.097: INFO: (8) /api/v1/nodes/node-cncf-lab-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.163364ms)
May 29 17:35:38.112: INFO: (9) /api/v1/nodes/node-cncf-lab-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 15.147726ms)
May 29 17:35:38.128: INFO: (10) /api/v1/nodes/node-cncf-lab-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.791198ms)
May 29 17:35:38.147: INFO: (11) /api/v1/nodes/node-cncf-lab-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 19.487056ms)
May 29 17:35:38.164: INFO: (12) /api/v1/nodes/node-cncf-lab-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 15.366249ms)
May 29 17:35:38.179: INFO: (13) /api/v1/nodes/node-cncf-lab-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.119057ms)
May 29 17:35:38.195: INFO: (14) /api/v1/nodes/node-cncf-lab-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 15.933802ms)
May 29 17:35:38.209: INFO: (15) /api/v1/nodes/node-cncf-lab-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.56749ms)
May 29 17:35:38.226: INFO: (16) /api/v1/nodes/node-cncf-lab-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 16.622846ms)
May 29 17:35:38.245: INFO: (17) /api/v1/nodes/node-cncf-lab-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 19.015293ms)
May 29 17:35:38.259: INFO: (18) /api/v1/nodes/node-cncf-lab-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.527277ms)
May 29 17:35:38.275: INFO: (19) /api/v1/nodes/node-cncf-lab-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 15.487587ms)
[AfterEach] version v1
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:35:38.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-309" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]","total":277,"completed":128,"skipped":2089,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:35:38.308: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-secret-4pzz
STEP: Creating a pod to test atomic-volume-subpath
May 29 17:35:38.628: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-4pzz" in namespace "subpath-2422" to be "Succeeded or Failed"
May 29 17:35:38.638: INFO: Pod "pod-subpath-test-secret-4pzz": Phase="Pending", Reason="", readiness=false. Elapsed: 9.87621ms
May 29 17:35:40.651: INFO: Pod "pod-subpath-test-secret-4pzz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022917852s
May 29 17:35:42.663: INFO: Pod "pod-subpath-test-secret-4pzz": Phase="Running", Reason="", readiness=true. Elapsed: 4.03482574s
May 29 17:35:44.674: INFO: Pod "pod-subpath-test-secret-4pzz": Phase="Running", Reason="", readiness=true. Elapsed: 6.045331691s
May 29 17:35:46.687: INFO: Pod "pod-subpath-test-secret-4pzz": Phase="Running", Reason="", readiness=true. Elapsed: 8.058537399s
May 29 17:35:48.698: INFO: Pod "pod-subpath-test-secret-4pzz": Phase="Running", Reason="", readiness=true. Elapsed: 10.06922433s
May 29 17:35:50.709: INFO: Pod "pod-subpath-test-secret-4pzz": Phase="Running", Reason="", readiness=true. Elapsed: 12.080417846s
May 29 17:35:52.724: INFO: Pod "pod-subpath-test-secret-4pzz": Phase="Running", Reason="", readiness=true. Elapsed: 14.095340111s
May 29 17:35:54.736: INFO: Pod "pod-subpath-test-secret-4pzz": Phase="Running", Reason="", readiness=true. Elapsed: 16.108012653s
May 29 17:35:56.749: INFO: Pod "pod-subpath-test-secret-4pzz": Phase="Running", Reason="", readiness=true. Elapsed: 18.120216116s
May 29 17:35:58.773: INFO: Pod "pod-subpath-test-secret-4pzz": Phase="Running", Reason="", readiness=true. Elapsed: 20.144526949s
May 29 17:36:00.786: INFO: Pod "pod-subpath-test-secret-4pzz": Phase="Running", Reason="", readiness=true. Elapsed: 22.157747193s
May 29 17:36:02.797: INFO: Pod "pod-subpath-test-secret-4pzz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.168190458s
STEP: Saw pod success
May 29 17:36:02.797: INFO: Pod "pod-subpath-test-secret-4pzz" satisfied condition "Succeeded or Failed"
May 29 17:36:02.828: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-subpath-test-secret-4pzz container test-container-subpath-secret-4pzz: <nil>
STEP: delete the pod
May 29 17:36:02.952: INFO: Waiting for pod pod-subpath-test-secret-4pzz to disappear
May 29 17:36:02.961: INFO: Pod pod-subpath-test-secret-4pzz no longer exists
STEP: Deleting pod pod-subpath-test-secret-4pzz
May 29 17:36:02.961: INFO: Deleting pod "pod-subpath-test-secret-4pzz" in namespace "subpath-2422"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:36:02.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2422" for this suite.

• [SLOW TEST:24.693 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [LinuxOnly] [Conformance]","total":277,"completed":129,"skipped":2098,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:36:03.008: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-339b9006-2bc7-4c98-9f4f-612eb87830d3
STEP: Creating a pod to test consume secrets
May 29 17:36:03.172: INFO: Waiting up to 5m0s for pod "pod-secrets-ae989433-8027-4124-b614-20f094e8dc43" in namespace "secrets-2726" to be "Succeeded or Failed"
May 29 17:36:03.182: INFO: Pod "pod-secrets-ae989433-8027-4124-b614-20f094e8dc43": Phase="Pending", Reason="", readiness=false. Elapsed: 9.427977ms
May 29 17:36:05.193: INFO: Pod "pod-secrets-ae989433-8027-4124-b614-20f094e8dc43": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020594398s
May 29 17:36:07.205: INFO: Pod "pod-secrets-ae989433-8027-4124-b614-20f094e8dc43": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032270577s
STEP: Saw pod success
May 29 17:36:07.205: INFO: Pod "pod-secrets-ae989433-8027-4124-b614-20f094e8dc43" satisfied condition "Succeeded or Failed"
May 29 17:36:07.219: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-secrets-ae989433-8027-4124-b614-20f094e8dc43 container secret-volume-test: <nil>
STEP: delete the pod
May 29 17:36:07.943: INFO: Waiting for pod pod-secrets-ae989433-8027-4124-b614-20f094e8dc43 to disappear
May 29 17:36:07.957: INFO: Pod pod-secrets-ae989433-8027-4124-b614-20f094e8dc43 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:36:07.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2726" for this suite.

• [SLOW TEST:5.058 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":130,"skipped":2128,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:36:08.067: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 29 17:36:08.778: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
May 29 17:36:10.822: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370568, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370568, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370568, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370568, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 29 17:36:13.868: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:36:14.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4005" for this suite.
STEP: Destroying namespace "webhook-4005-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.240 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":277,"completed":131,"skipped":2135,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:36:14.314: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:36:14.464: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:36:18.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8615" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":277,"completed":132,"skipped":2150,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:36:18.807: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
May 29 17:36:18.938: INFO: Waiting up to 5m0s for pod "downwardapi-volume-822d0dee-0773-4df5-b556-e58e36000d4a" in namespace "projected-3936" to be "Succeeded or Failed"
May 29 17:36:18.951: INFO: Pod "downwardapi-volume-822d0dee-0773-4df5-b556-e58e36000d4a": Phase="Pending", Reason="", readiness=false. Elapsed: 12.415833ms
May 29 17:36:20.962: INFO: Pod "downwardapi-volume-822d0dee-0773-4df5-b556-e58e36000d4a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024025034s
May 29 17:36:22.979: INFO: Pod "downwardapi-volume-822d0dee-0773-4df5-b556-e58e36000d4a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040922854s
STEP: Saw pod success
May 29 17:36:22.979: INFO: Pod "downwardapi-volume-822d0dee-0773-4df5-b556-e58e36000d4a" satisfied condition "Succeeded or Failed"
May 29 17:36:22.994: INFO: Trying to get logs from node node-cncf-lab-1 pod downwardapi-volume-822d0dee-0773-4df5-b556-e58e36000d4a container client-container: <nil>
STEP: delete the pod
May 29 17:36:23.075: INFO: Waiting for pod downwardapi-volume-822d0dee-0773-4df5-b556-e58e36000d4a to disappear
May 29 17:36:23.083: INFO: Pod downwardapi-volume-822d0dee-0773-4df5-b556-e58e36000d4a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:36:23.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3936" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":277,"completed":133,"skipped":2185,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:36:23.113: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:36:23.218: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
May 29 17:36:26.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 --namespace=crd-publish-openapi-1937 create -f -'
May 29 17:36:27.532: INFO: stderr: ""
May 29 17:36:27.532: INFO: stdout: "e2e-test-crd-publish-openapi-3064-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
May 29 17:36:27.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 --namespace=crd-publish-openapi-1937 delete e2e-test-crd-publish-openapi-3064-crds test-foo'
May 29 17:36:28.761: INFO: stderr: ""
May 29 17:36:28.761: INFO: stdout: "e2e-test-crd-publish-openapi-3064-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
May 29 17:36:28.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 --namespace=crd-publish-openapi-1937 apply -f -'
May 29 17:36:29.125: INFO: stderr: ""
May 29 17:36:29.125: INFO: stdout: "e2e-test-crd-publish-openapi-3064-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
May 29 17:36:29.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 --namespace=crd-publish-openapi-1937 delete e2e-test-crd-publish-openapi-3064-crds test-foo'
May 29 17:36:29.311: INFO: stderr: ""
May 29 17:36:29.311: INFO: stdout: "e2e-test-crd-publish-openapi-3064-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
May 29 17:36:29.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 --namespace=crd-publish-openapi-1937 create -f -'
May 29 17:36:29.569: INFO: rc: 1
May 29 17:36:29.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 --namespace=crd-publish-openapi-1937 apply -f -'
May 29 17:36:29.777: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
May 29 17:36:29.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 --namespace=crd-publish-openapi-1937 create -f -'
May 29 17:36:30.005: INFO: rc: 1
May 29 17:36:30.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 --namespace=crd-publish-openapi-1937 apply -f -'
May 29 17:36:30.256: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
May 29 17:36:30.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 explain e2e-test-crd-publish-openapi-3064-crds'
May 29 17:36:30.490: INFO: stderr: ""
May 29 17:36:30.490: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3064-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
May 29 17:36:30.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 explain e2e-test-crd-publish-openapi-3064-crds.metadata'
May 29 17:36:30.755: INFO: stderr: ""
May 29 17:36:30.755: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3064-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
May 29 17:36:30.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 explain e2e-test-crd-publish-openapi-3064-crds.spec'
May 29 17:36:31.022: INFO: stderr: ""
May 29 17:36:31.022: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3064-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
May 29 17:36:31.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 explain e2e-test-crd-publish-openapi-3064-crds.spec.bars'
May 29 17:36:31.317: INFO: stderr: ""
May 29 17:36:31.317: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3064-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
May 29 17:36:31.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 explain e2e-test-crd-publish-openapi-3064-crds.spec.bars2'
May 29 17:36:31.528: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:36:35.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1937" for this suite.

• [SLOW TEST:12.614 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":277,"completed":134,"skipped":2255,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:36:35.729: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1265.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-1265.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1265.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1265.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-1265.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1265.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 29 17:36:51.868: INFO: DNS probes using dns-1265/dns-test-69506382-088c-4a50-abbf-2d0f69575e75 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:36:52.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1265" for this suite.

• [SLOW TEST:16.386 seconds]
[sig-network] DNS
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":277,"completed":135,"skipped":2283,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:36:52.117: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
May 29 17:36:52.362: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 17:36:56.066: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:37:11.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9811" for this suite.

• [SLOW TEST:19.146 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":277,"completed":136,"skipped":2286,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:37:11.265: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
May 29 17:37:11.539: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6062 /api/v1/namespaces/watch-6062/configmaps/e2e-watch-test-resource-version b287e133-5ca5-4ab9-8cd1-d405974dfbdf 12710192217 0 2020-05-29 17:37:11 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-05-29 17:37:11 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
May 29 17:37:11.539: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6062 /api/v1/namespaces/watch-6062/configmaps/e2e-watch-test-resource-version b287e133-5ca5-4ab9-8cd1-d405974dfbdf 12710192256 0 2020-05-29 17:37:11 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-05-29 17:37:11 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:37:11.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6062" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":277,"completed":137,"skipped":2309,"failed":0}
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:37:11.573: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 29 17:37:12.888: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 29 17:37:14.923: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370632, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370632, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370633, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726370632, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 29 17:37:17.973: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:37:18.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3221" for this suite.
STEP: Destroying namespace "webhook-3221-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.821 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":277,"completed":138,"skipped":2313,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:37:18.398: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May 29 17:37:22.610: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:37:22.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1268" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":139,"skipped":2347,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:37:22.690: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
May 29 17:37:28.912: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-1526 PodName:pod-sharedvolume-6fbfe60c-a43b-4574-8165-95558dae6807 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:37:28.912: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 17:37:29.176: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:37:29.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1526" for this suite.

• [SLOW TEST:6.530 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":277,"completed":140,"skipped":2372,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:37:29.221: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-f88bce88-96fb-4c3c-a9ab-6176562aa04b
STEP: Creating a pod to test consume secrets
May 29 17:37:29.381: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3a058f5d-5a93-4678-b638-2632e46e4f79" in namespace "projected-5962" to be "Succeeded or Failed"
May 29 17:37:29.400: INFO: Pod "pod-projected-secrets-3a058f5d-5a93-4678-b638-2632e46e4f79": Phase="Pending", Reason="", readiness=false. Elapsed: 19.566568ms
May 29 17:37:31.410: INFO: Pod "pod-projected-secrets-3a058f5d-5a93-4678-b638-2632e46e4f79": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029215264s
May 29 17:37:33.427: INFO: Pod "pod-projected-secrets-3a058f5d-5a93-4678-b638-2632e46e4f79": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045944245s
STEP: Saw pod success
May 29 17:37:33.427: INFO: Pod "pod-projected-secrets-3a058f5d-5a93-4678-b638-2632e46e4f79" satisfied condition "Succeeded or Failed"
May 29 17:37:33.435: INFO: Trying to get logs from node node-cncf-lab-3 pod pod-projected-secrets-3a058f5d-5a93-4678-b638-2632e46e4f79 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 29 17:37:33.544: INFO: Waiting for pod pod-projected-secrets-3a058f5d-5a93-4678-b638-2632e46e4f79 to disappear
May 29 17:37:33.555: INFO: Pod pod-projected-secrets-3a058f5d-5a93-4678-b638-2632e46e4f79 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:37:33.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5962" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":141,"skipped":2383,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:37:33.588: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
May 29 17:37:33.733: INFO: Created pod &Pod{ObjectMeta:{dns-2237  dns-2237 /api/v1/namespaces/dns-2237/pods/dns-2237 101c7b4c-5846-4c57-8051-17deedf8f7ac 12710201204 0 2020-05-29 17:37:33 +0000 UTC <nil> <nil> map[] map[] [] []  [{e2e.test Update v1 2020-05-29 17:37:33 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 67 111 110 102 105 103 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 115 101 114 118 101 114 115 34 58 123 125 44 34 102 58 115 101 97 114 99 104 101 115 34 58 123 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-g9g4d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-g9g4d,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-g9g4d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:37:33.754: INFO: The status of Pod dns-2237 is Pending, waiting for it to be Running (with Ready = true)
May 29 17:37:35.769: INFO: The status of Pod dns-2237 is Pending, waiting for it to be Running (with Ready = true)
May 29 17:37:37.767: INFO: The status of Pod dns-2237 is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
May 29 17:37:37.767: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-2237 PodName:dns-2237 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:37:37.767: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Verifying customized DNS server is configured on pod...
May 29 17:37:38.306: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-2237 PodName:dns-2237 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:37:38.306: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 17:37:38.564: INFO: Deleting pod dns-2237...
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:37:38.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2237" for this suite.

• [SLOW TEST:5.476 seconds]
[sig-network] DNS
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":277,"completed":142,"skipped":2412,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:37:39.068: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
May 29 17:38:19.418: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0529 17:38:19.418749      20 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:38:19.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5384" for this suite.

• [SLOW TEST:40.430 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":277,"completed":143,"skipped":2429,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:38:19.499: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-d18e313a-f75e-480d-a25f-9845a2b2fe77 in namespace container-probe-4607
May 29 17:38:23.651: INFO: Started pod liveness-d18e313a-f75e-480d-a25f-9845a2b2fe77 in namespace container-probe-4607
STEP: checking the pod's current state and verifying that restartCount is present
May 29 17:38:23.813: INFO: Initial restart count of pod liveness-d18e313a-f75e-480d-a25f-9845a2b2fe77 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:42:25.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4607" for this suite.

• [SLOW TEST:245.751 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":277,"completed":144,"skipped":2453,"failed":0}
SS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:42:25.259: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:42:29.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8121" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":277,"completed":145,"skipped":2455,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:42:29.844: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:157
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:42:29.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4409" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":277,"completed":146,"skipped":2493,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:42:30.032: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Starting the proxy
May 29 17:42:30.169: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-852825370 proxy --unix-socket=/tmp/kubectl-proxy-unix928374113/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:42:30.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3195" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":277,"completed":147,"skipped":2509,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:42:30.323: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:42:34.603: INFO: Waiting up to 5m0s for pod "client-envvars-a5214a22-b212-42db-afd3-5c746e07bc2c" in namespace "pods-8739" to be "Succeeded or Failed"
May 29 17:42:34.623: INFO: Pod "client-envvars-a5214a22-b212-42db-afd3-5c746e07bc2c": Phase="Pending", Reason="", readiness=false. Elapsed: 19.523956ms
May 29 17:42:36.635: INFO: Pod "client-envvars-a5214a22-b212-42db-afd3-5c746e07bc2c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031015374s
May 29 17:42:38.994: INFO: Pod "client-envvars-a5214a22-b212-42db-afd3-5c746e07bc2c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.390257875s
STEP: Saw pod success
May 29 17:42:38.994: INFO: Pod "client-envvars-a5214a22-b212-42db-afd3-5c746e07bc2c" satisfied condition "Succeeded or Failed"
May 29 17:42:39.009: INFO: Trying to get logs from node node-cncf-lab-1 pod client-envvars-a5214a22-b212-42db-afd3-5c746e07bc2c container env3cont: <nil>
STEP: delete the pod
May 29 17:42:39.133: INFO: Waiting for pod client-envvars-a5214a22-b212-42db-afd3-5c746e07bc2c to disappear
May 29 17:42:39.144: INFO: Pod client-envvars-a5214a22-b212-42db-afd3-5c746e07bc2c no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:42:39.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8739" for this suite.

• [SLOW TEST:8.856 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":277,"completed":148,"skipped":2523,"failed":0}
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:42:39.179: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
May 29 17:42:39.287: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:42:46.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6680" for this suite.

• [SLOW TEST:7.138 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":277,"completed":149,"skipped":2523,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:42:46.319: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:42:46.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2119" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":277,"completed":150,"skipped":2538,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:42:46.512: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name projected-secret-test-d9a0b03d-0420-4096-8c52-adec8020aa77
STEP: Creating a pod to test consume secrets
May 29 17:42:46.701: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ecc4ec50-1c18-4280-b98c-fa39c3b5f31b" in namespace "projected-8445" to be "Succeeded or Failed"
May 29 17:42:46.712: INFO: Pod "pod-projected-secrets-ecc4ec50-1c18-4280-b98c-fa39c3b5f31b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.468164ms
May 29 17:42:48.724: INFO: Pod "pod-projected-secrets-ecc4ec50-1c18-4280-b98c-fa39c3b5f31b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022962233s
May 29 17:42:50.734: INFO: Pod "pod-projected-secrets-ecc4ec50-1c18-4280-b98c-fa39c3b5f31b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033314974s
STEP: Saw pod success
May 29 17:42:50.734: INFO: Pod "pod-projected-secrets-ecc4ec50-1c18-4280-b98c-fa39c3b5f31b" satisfied condition "Succeeded or Failed"
May 29 17:42:50.744: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-projected-secrets-ecc4ec50-1c18-4280-b98c-fa39c3b5f31b container secret-volume-test: <nil>
STEP: delete the pod
May 29 17:42:50.807: INFO: Waiting for pod pod-projected-secrets-ecc4ec50-1c18-4280-b98c-fa39c3b5f31b to disappear
May 29 17:42:50.818: INFO: Pod pod-projected-secrets-ecc4ec50-1c18-4280-b98c-fa39c3b5f31b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:42:50.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8445" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":277,"completed":151,"skipped":2545,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:42:50.874: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:42:51.075: INFO: Waiting up to 5m0s for pod "busybox-user-65534-92e78ce3-f602-43a1-b8a8-f3eb4bc37143" in namespace "security-context-test-3526" to be "Succeeded or Failed"
May 29 17:42:51.131: INFO: Pod "busybox-user-65534-92e78ce3-f602-43a1-b8a8-f3eb4bc37143": Phase="Pending", Reason="", readiness=false. Elapsed: 56.219322ms
May 29 17:42:53.147: INFO: Pod "busybox-user-65534-92e78ce3-f602-43a1-b8a8-f3eb4bc37143": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072094392s
May 29 17:42:55.746: INFO: Pod "busybox-user-65534-92e78ce3-f602-43a1-b8a8-f3eb4bc37143": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.671565881s
May 29 17:42:55.746: INFO: Pod "busybox-user-65534-92e78ce3-f602-43a1-b8a8-f3eb4bc37143" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:42:55.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3526" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":152,"skipped":2572,"failed":0}
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:42:55.801: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-49ad76bf-0544-4917-aa87-6f8d2d93c911
STEP: Creating a pod to test consume configMaps
May 29 17:42:55.984: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a2199055-9a36-447c-ba71-a5c5fc0a7e44" in namespace "projected-5158" to be "Succeeded or Failed"
May 29 17:42:55.994: INFO: Pod "pod-projected-configmaps-a2199055-9a36-447c-ba71-a5c5fc0a7e44": Phase="Pending", Reason="", readiness=false. Elapsed: 10.143922ms
May 29 17:42:58.008: INFO: Pod "pod-projected-configmaps-a2199055-9a36-447c-ba71-a5c5fc0a7e44": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024030116s
May 29 17:43:00.027: INFO: Pod "pod-projected-configmaps-a2199055-9a36-447c-ba71-a5c5fc0a7e44": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042805656s
STEP: Saw pod success
May 29 17:43:00.027: INFO: Pod "pod-projected-configmaps-a2199055-9a36-447c-ba71-a5c5fc0a7e44" satisfied condition "Succeeded or Failed"
May 29 17:43:00.041: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-projected-configmaps-a2199055-9a36-447c-ba71-a5c5fc0a7e44 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 29 17:43:00.096: INFO: Waiting for pod pod-projected-configmaps-a2199055-9a36-447c-ba71-a5c5fc0a7e44 to disappear
May 29 17:43:00.105: INFO: Pod pod-projected-configmaps-a2199055-9a36-447c-ba71-a5c5fc0a7e44 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:43:00.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5158" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":277,"completed":153,"skipped":2576,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:43:00.167: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 29 17:43:00.783: INFO: Number of nodes with available pods: 0
May 29 17:43:00.783: INFO: Node node-cncf-lab-1 is running more than one daemon pod
May 29 17:43:01.815: INFO: Number of nodes with available pods: 0
May 29 17:43:01.815: INFO: Node node-cncf-lab-1 is running more than one daemon pod
May 29 17:43:02.845: INFO: Number of nodes with available pods: 0
May 29 17:43:02.846: INFO: Node node-cncf-lab-1 is running more than one daemon pod
May 29 17:43:03.810: INFO: Number of nodes with available pods: 0
May 29 17:43:03.810: INFO: Node node-cncf-lab-1 is running more than one daemon pod
May 29 17:43:04.813: INFO: Number of nodes with available pods: 3
May 29 17:43:04.813: INFO: Node node-cncf-lab-1 is running more than one daemon pod
May 29 17:43:05.806: INFO: Number of nodes with available pods: 4
May 29 17:43:05.806: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Stop a daemon pod, check that the daemon pod is revived.
May 29 17:43:05.870: INFO: Number of nodes with available pods: 3
May 29 17:43:05.870: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:43:07.589: INFO: Number of nodes with available pods: 3
May 29 17:43:07.589: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:43:07.902: INFO: Number of nodes with available pods: 3
May 29 17:43:07.902: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:43:08.896: INFO: Number of nodes with available pods: 3
May 29 17:43:08.897: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:43:09.900: INFO: Number of nodes with available pods: 3
May 29 17:43:09.900: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:43:10.947: INFO: Number of nodes with available pods: 3
May 29 17:43:10.947: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:43:11.900: INFO: Number of nodes with available pods: 3
May 29 17:43:11.900: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:43:12.906: INFO: Number of nodes with available pods: 3
May 29 17:43:12.906: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:43:13.898: INFO: Number of nodes with available pods: 3
May 29 17:43:13.898: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:43:14.964: INFO: Number of nodes with available pods: 3
May 29 17:43:14.964: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:43:15.900: INFO: Number of nodes with available pods: 3
May 29 17:43:15.900: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:43:16.907: INFO: Number of nodes with available pods: 3
May 29 17:43:16.908: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:43:18.789: INFO: Number of nodes with available pods: 3
May 29 17:43:18.790: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:43:18.896: INFO: Number of nodes with available pods: 3
May 29 17:43:18.896: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:43:19.910: INFO: Number of nodes with available pods: 3
May 29 17:43:19.910: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:43:21.093: INFO: Number of nodes with available pods: 4
May 29 17:43:21.093: INFO: Number of running nodes: 4, number of available pods: 4
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-538, will wait for the garbage collector to delete the pods
May 29 17:43:21.432: INFO: Deleting DaemonSet.extensions daemon-set took: 48.290907ms
May 29 17:43:22.032: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.339197ms
May 29 17:43:33.143: INFO: Number of nodes with available pods: 0
May 29 17:43:33.143: INFO: Number of running nodes: 0, number of available pods: 0
May 29 17:43:33.153: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-538/daemonsets","resourceVersion":"12710338950"},"items":null}

May 29 17:43:33.166: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-538/pods","resourceVersion":"12710338952"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:43:33.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-538" for this suite.

• [SLOW TEST:33.092 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":277,"completed":154,"skipped":2612,"failed":0}
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:43:33.261: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test env composition
May 29 17:43:33.421: INFO: Waiting up to 5m0s for pod "var-expansion-e522fdc9-7890-4cb1-a1f8-d14dad098a56" in namespace "var-expansion-4454" to be "Succeeded or Failed"
May 29 17:43:33.439: INFO: Pod "var-expansion-e522fdc9-7890-4cb1-a1f8-d14dad098a56": Phase="Pending", Reason="", readiness=false. Elapsed: 17.339606ms
May 29 17:43:35.480: INFO: Pod "var-expansion-e522fdc9-7890-4cb1-a1f8-d14dad098a56": Phase="Pending", Reason="", readiness=false. Elapsed: 2.058236325s
May 29 17:43:37.492: INFO: Pod "var-expansion-e522fdc9-7890-4cb1-a1f8-d14dad098a56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.070403529s
STEP: Saw pod success
May 29 17:43:37.492: INFO: Pod "var-expansion-e522fdc9-7890-4cb1-a1f8-d14dad098a56" satisfied condition "Succeeded or Failed"
May 29 17:43:37.504: INFO: Trying to get logs from node node-cncf-lab-1 pod var-expansion-e522fdc9-7890-4cb1-a1f8-d14dad098a56 container dapi-container: <nil>
STEP: delete the pod
May 29 17:43:38.184: INFO: Waiting for pod var-expansion-e522fdc9-7890-4cb1-a1f8-d14dad098a56 to disappear
May 29 17:43:38.200: INFO: Pod var-expansion-e522fdc9-7890-4cb1-a1f8-d14dad098a56 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:43:38.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4454" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":277,"completed":155,"skipped":2614,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:43:38.242: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-6104.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-6104.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-6104.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-6104.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6104.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-6104.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-6104.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-6104.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-6104.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6104.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 29 17:43:44.461: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:44.475: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:44.488: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:44.500: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:44.541: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:44.557: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:44.569: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:44.585: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:44.620: INFO: Lookups using dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6104.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6104.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local jessie_udp@dns-test-service-2.dns-6104.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6104.svc.cluster.local]

May 29 17:43:49.643: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:49.659: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:49.674: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:49.691: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:49.736: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:49.750: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:49.763: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:49.777: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:49.821: INFO: Lookups using dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6104.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6104.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local jessie_udp@dns-test-service-2.dns-6104.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6104.svc.cluster.local]

May 29 17:43:54.674: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:54.699: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:54.712: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:54.724: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:54.776: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:54.788: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:54.802: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:54.817: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:54.843: INFO: Lookups using dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6104.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6104.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local jessie_udp@dns-test-service-2.dns-6104.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6104.svc.cluster.local]

May 29 17:43:59.641: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:59.653: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:59.670: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:59.682: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:59.751: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:59.763: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:59.777: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:59.791: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:43:59.831: INFO: Lookups using dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6104.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6104.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local jessie_udp@dns-test-service-2.dns-6104.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6104.svc.cluster.local]

May 29 17:44:04.638: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:44:04.653: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:44:04.668: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:44:04.682: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:44:04.726: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:44:04.739: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:44:04.759: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:44:04.772: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:44:04.798: INFO: Lookups using dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6104.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6104.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local jessie_udp@dns-test-service-2.dns-6104.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6104.svc.cluster.local]

May 29 17:44:09.675: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:44:09.690: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:44:09.708: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:44:09.740: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:44:09.806: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:44:09.827: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:44:10.519: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:44:10.535: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6104.svc.cluster.local from pod dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c: the server could not find the requested resource (get pods dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c)
May 29 17:44:10.778: INFO: Lookups using dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6104.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6104.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6104.svc.cluster.local jessie_udp@dns-test-service-2.dns-6104.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6104.svc.cluster.local]

May 29 17:44:15.329: INFO: DNS probes using dns-6104/dns-test-df90e258-cb87-4eb9-932c-ab90c00e397c succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:44:15.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6104" for this suite.

• [SLOW TEST:37.197 seconds]
[sig-network] DNS
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":277,"completed":156,"skipped":2639,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:44:15.453: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:44:15.593: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:44:19.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5518" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":277,"completed":157,"skipped":2657,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:44:19.774: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
May 29 17:44:20.017: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:44:39.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2999" for this suite.

• [SLOW TEST:19.984 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":277,"completed":158,"skipped":2663,"failed":0}
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:44:39.760: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
May 29 17:44:39.907: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dd2b9ba6-ef9c-4074-8582-9f95d175665b" in namespace "downward-api-9471" to be "Succeeded or Failed"
May 29 17:44:39.922: INFO: Pod "downwardapi-volume-dd2b9ba6-ef9c-4074-8582-9f95d175665b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.31002ms
May 29 17:44:41.950: INFO: Pod "downwardapi-volume-dd2b9ba6-ef9c-4074-8582-9f95d175665b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041885386s
May 29 17:44:43.977: INFO: Pod "downwardapi-volume-dd2b9ba6-ef9c-4074-8582-9f95d175665b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.069155277s
STEP: Saw pod success
May 29 17:44:43.978: INFO: Pod "downwardapi-volume-dd2b9ba6-ef9c-4074-8582-9f95d175665b" satisfied condition "Succeeded or Failed"
May 29 17:44:44.005: INFO: Trying to get logs from node node-cncf-lab-1 pod downwardapi-volume-dd2b9ba6-ef9c-4074-8582-9f95d175665b container client-container: <nil>
STEP: delete the pod
May 29 17:44:44.159: INFO: Waiting for pod downwardapi-volume-dd2b9ba6-ef9c-4074-8582-9f95d175665b to disappear
May 29 17:44:44.172: INFO: Pod downwardapi-volume-dd2b9ba6-ef9c-4074-8582-9f95d175665b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:44:44.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9471" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":277,"completed":159,"skipped":2668,"failed":0}
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:44:44.204: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:44:48.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7573" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":277,"completed":160,"skipped":2674,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:44:48.540: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 29 17:44:49.665: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 29 17:44:51.694: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726371089, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726371089, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726371089, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726371089, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 29 17:44:54.849: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:44:55.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5677" for this suite.
STEP: Destroying namespace "webhook-5677-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.640 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":277,"completed":161,"skipped":2719,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:44:55.181: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 29 17:44:55.837: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 29 17:44:57.924: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726371095, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726371095, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726371095, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726371095, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 29 17:45:01.991: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:45:02.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-430" for this suite.
STEP: Destroying namespace "webhook-430-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:8.201 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":277,"completed":162,"skipped":2725,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:45:03.382: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:45:03.498: INFO: Creating deployment "webserver-deployment"
May 29 17:45:03.518: INFO: Waiting for observed generation 1
May 29 17:45:05.552: INFO: Waiting for all required pods to come up
May 29 17:45:05.565: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
May 29 17:45:11.730: INFO: Waiting for deployment "webserver-deployment" to complete
May 29 17:45:11.766: INFO: Updating deployment "webserver-deployment" with a non-existent image
May 29 17:45:11.796: INFO: Updating deployment webserver-deployment
May 29 17:45:11.796: INFO: Waiting for observed generation 2
May 29 17:45:13.820: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
May 29 17:45:13.837: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
May 29 17:45:14.009: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
May 29 17:45:14.101: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
May 29 17:45:14.101: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
May 29 17:45:14.119: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
May 29 17:45:14.142: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
May 29 17:45:14.143: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
May 29 17:45:14.167: INFO: Updating deployment webserver-deployment
May 29 17:45:14.167: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
May 29 17:45:14.185: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
May 29 17:45:16.211: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
May 29 17:45:16.368: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-7913 /apis/apps/v1/namespaces/deployment-7913/deployments/webserver-deployment 3ad292e7-935c-4fc9-ab4d-5b99ee0e79b7 12710376511 3 2020-05-29 17:45:03 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0040e8058 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-05-29 17:45:14 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-6676bcd6d4" is progressing.,LastUpdateTime:2020-05-29 17:45:14 +0000 UTC,LastTransitionTime:2020-05-29 17:45:03 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

May 29 17:45:16.649: INFO: New ReplicaSet "webserver-deployment-6676bcd6d4" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-6676bcd6d4  deployment-7913 /apis/apps/v1/namespaces/deployment-7913/replicasets/webserver-deployment-6676bcd6d4 33a438f7-75a6-4226-8b3b-cba66dda6ec5 12710376504 3 2020-05-29 17:45:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 3ad292e7-935c-4fc9-ab4d-5b99ee0e79b7 0xc00484e937 0xc00484e938}] []  [{kube-controller-manager Update apps/v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 97 100 50 57 50 101 55 45 57 51 53 99 45 52 102 99 57 45 97 98 52 100 45 53 98 57 57 101 101 48 101 55 57 98 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 6676bcd6d4,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00484e9b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May 29 17:45:16.649: INFO: All old ReplicaSets of Deployment "webserver-deployment":
May 29 17:45:16.649: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-84855cf797  deployment-7913 /apis/apps/v1/namespaces/deployment-7913/replicasets/webserver-deployment-84855cf797 024d513c-5c14-4052-bff8-b19b7421f21b 12710376489 3 2020-05-29 17:45:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 3ad292e7-935c-4fc9-ab4d-5b99ee0e79b7 0xc00484ea37 0xc00484ea38}] []  [{kube-controller-manager Update apps/v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 97 100 50 57 50 101 55 45 57 51 53 99 45 52 102 99 57 45 97 98 52 100 45 53 98 57 57 101 101 48 101 55 57 98 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 84855cf797,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00484eaa8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
May 29 17:45:17.078: INFO: Pod "webserver-deployment-6676bcd6d4-482dv" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-482dv webserver-deployment-6676bcd6d4- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-6676bcd6d4-482dv 4d9b6be8-038d-4ac5-8606-b8760ace7f57 12710377184 0 2020-05-29 17:45:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:10.2.0.42/32] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 33a438f7-75a6-4226-8b3b-cba66dda6ec5 0xc0040e85e7 0xc0040e85e8}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 51 97 52 51 56 102 55 45 55 53 97 54 45 52 50 50 54 45 56 98 51 98 45 99 98 97 54 54 100 100 97 54 101 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.83.111.180,PodIP:,StartTime:2020-05-29 17:45:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.089: INFO: Pod "webserver-deployment-6676bcd6d4-6r66l" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-6r66l webserver-deployment-6676bcd6d4- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-6676bcd6d4-6r66l e7e4ccaa-0470-4e56-be12-1d06b3a63767 12710377052 0 2020-05-29 17:45:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:10.2.1.75/32] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 33a438f7-75a6-4226-8b3b-cba66dda6ec5 0xc0040e87c7 0xc0040e87c8}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:11 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 51 97 52 51 56 102 55 45 55 53 97 54 45 52 50 50 54 45 56 98 51 98 45 99 98 97 54 54 100 100 97 54 101 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:13 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.75.198.105,PodIP:,StartTime:2020-05-29 17:45:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login',},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.090: INFO: Pod "webserver-deployment-6676bcd6d4-88nb4" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-88nb4 webserver-deployment-6676bcd6d4- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-6676bcd6d4-88nb4 fe606159-3eb7-47e7-9123-4fb960c2957d 12710376520 0 2020-05-29 17:45:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 33a438f7-75a6-4226-8b3b-cba66dda6ec5 0xc0040e89c7 0xc0040e89c8}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 51 97 52 51 56 102 55 45 55 53 97 54 45 52 50 50 54 45 56 98 51 98 45 99 98 97 54 54 100 100 97 54 101 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.83.108.252,PodIP:,StartTime:2020-05-29 17:45:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.092: INFO: Pod "webserver-deployment-6676bcd6d4-h2cdc" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-h2cdc webserver-deployment-6676bcd6d4- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-6676bcd6d4-h2cdc 30ca5852-f7e7-44db-89bc-8286f0fe52bf 12710377182 0 2020-05-29 17:45:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:10.2.0.40/32] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 33a438f7-75a6-4226-8b3b-cba66dda6ec5 0xc0040e8bb7 0xc0040e8bb8}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 51 97 52 51 56 102 55 45 55 53 97 54 45 52 50 50 54 45 56 98 51 98 45 99 98 97 54 54 100 100 97 54 101 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.83.111.180,PodIP:,StartTime:2020-05-29 17:45:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.093: INFO: Pod "webserver-deployment-6676bcd6d4-hk54j" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-hk54j webserver-deployment-6676bcd6d4- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-6676bcd6d4-hk54j 97d99267-0964-495f-8734-aa73f23378ab 12710376475 0 2020-05-29 17:45:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 33a438f7-75a6-4226-8b3b-cba66dda6ec5 0xc0040e8da7 0xc0040e8da8}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 51 97 52 51 56 102 55 45 55 53 97 54 45 52 50 50 54 45 56 98 51 98 45 99 98 97 54 54 100 100 97 54 101 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.178.95.196,PodIP:,StartTime:2020-05-29 17:45:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.093: INFO: Pod "webserver-deployment-6676bcd6d4-hv4fz" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-hv4fz webserver-deployment-6676bcd6d4- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-6676bcd6d4-hv4fz 3b64e2c4-dae6-46d4-8153-bc1a9c31218e 12710377261 0 2020-05-29 17:45:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:10.2.3.56/32] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 33a438f7-75a6-4226-8b3b-cba66dda6ec5 0xc0040e9007 0xc0040e9008}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 51 97 52 51 56 102 55 45 55 53 97 54 45 52 50 50 54 45 56 98 51 98 45 99 98 97 54 54 100 100 97 54 101 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.178.95.196,PodIP:,StartTime:2020-05-29 17:45:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.093: INFO: Pod "webserver-deployment-6676bcd6d4-j7z5q" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-j7z5q webserver-deployment-6676bcd6d4- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-6676bcd6d4-j7z5q 74583829-8660-4c40-b1e4-bd4cadf145e8 12710377279 0 2020-05-29 17:45:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:10.2.2.240/32] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 33a438f7-75a6-4226-8b3b-cba66dda6ec5 0xc0040e9237 0xc0040e9238}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:11 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 51 97 52 51 56 102 55 45 55 53 97 54 45 52 50 50 54 45 56 98 51 98 45 99 98 97 54 54 100 100 97 54 101 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.83.108.252,PodIP:,StartTime:2020-05-29 17:45:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login',},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.094: INFO: Pod "webserver-deployment-6676bcd6d4-ljz4k" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-ljz4k webserver-deployment-6676bcd6d4- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-6676bcd6d4-ljz4k 7357955c-aa9b-4770-82bd-21a16c2bb3b8 12710376846 0 2020-05-29 17:45:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:10.2.3.54/32] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 33a438f7-75a6-4226-8b3b-cba66dda6ec5 0xc0040e94b7 0xc0040e94b8}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:11 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 51 97 52 51 56 102 55 45 55 53 97 54 45 52 50 50 54 45 56 98 51 98 45 99 98 97 54 54 100 100 97 54 101 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:13 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 46 51 46 53 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.178.95.196,PodIP:10.2.3.54,StartTime:2020-05-29 17:45:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login',},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.3.54,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.094: INFO: Pod "webserver-deployment-6676bcd6d4-p7g9m" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-p7g9m webserver-deployment-6676bcd6d4- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-6676bcd6d4-p7g9m ed4e90e9-37c8-426d-a48a-c96bc70326f7 12710375911 0 2020-05-29 17:45:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:10.2.2.239/32] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 33a438f7-75a6-4226-8b3b-cba66dda6ec5 0xc0040e9797 0xc0040e9798}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:11 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 51 97 52 51 56 102 55 45 55 53 97 54 45 52 50 50 54 45 56 98 51 98 45 99 98 97 54 54 100 100 97 54 101 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:12 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:13 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.83.108.252,PodIP:,StartTime:2020-05-29 17:45:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.094: INFO: Pod "webserver-deployment-6676bcd6d4-rpj8f" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-rpj8f webserver-deployment-6676bcd6d4- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-6676bcd6d4-rpj8f 141a0e7e-05c8-4198-bf6e-70e311f1b708 12710377263 0 2020-05-29 17:45:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:10.2.2.244/32] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 33a438f7-75a6-4226-8b3b-cba66dda6ec5 0xc0040e99d7 0xc0040e99d8}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 51 97 52 51 56 102 55 45 55 53 97 54 45 52 50 50 54 45 56 98 51 98 45 99 98 97 54 54 100 100 97 54 101 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.83.108.252,PodIP:,StartTime:2020-05-29 17:45:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.094: INFO: Pod "webserver-deployment-6676bcd6d4-tg2rp" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-tg2rp webserver-deployment-6676bcd6d4- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-6676bcd6d4-tg2rp 58ac45eb-cd04-4039-b10c-3d55299099dc 12710377262 0 2020-05-29 17:45:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:10.2.1.78/32] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 33a438f7-75a6-4226-8b3b-cba66dda6ec5 0xc0040e9c07 0xc0040e9c08}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 51 97 52 51 56 102 55 45 55 53 97 54 45 52 50 50 54 45 56 98 51 98 45 99 98 97 54 54 100 100 97 54 101 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.75.198.105,PodIP:,StartTime:2020-05-29 17:45:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.095: INFO: Pod "webserver-deployment-6676bcd6d4-tk985" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-tk985 webserver-deployment-6676bcd6d4- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-6676bcd6d4-tk985 a1816e90-4622-43a6-9c30-0b50a9975aac 12710377102 0 2020-05-29 17:45:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:10.2.2.238/32] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 33a438f7-75a6-4226-8b3b-cba66dda6ec5 0xc0040e9df7 0xc0040e9df8}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:11 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 51 97 52 51 56 102 55 45 55 53 97 54 45 52 50 50 54 45 56 98 51 98 45 99 98 97 54 54 100 100 97 54 101 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:13 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 46 50 46 50 51 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.83.108.252,PodIP:10.2.2.238,StartTime:2020-05-29 17:45:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login',},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.2.238,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.095: INFO: Pod "webserver-deployment-6676bcd6d4-xnvcr" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-xnvcr webserver-deployment-6676bcd6d4- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-6676bcd6d4-xnvcr 73abf5a2-4bd0-454e-a3ce-09fe8174b43f 12710377237 0 2020-05-29 17:45:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:10.2.2.242/32] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 33a438f7-75a6-4226-8b3b-cba66dda6ec5 0xc0040e9ff7 0xc0040e9ff8}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 51 97 52 51 56 102 55 45 55 53 97 54 45 52 50 50 54 45 56 98 51 98 45 99 98 97 54 54 100 100 97 54 101 99 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.83.108.252,PodIP:,StartTime:2020-05-29 17:45:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.095: INFO: Pod "webserver-deployment-84855cf797-2n82n" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-2n82n webserver-deployment-84855cf797- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-84855cf797-2n82n 774f9f83-7cbc-4402-aebb-e77cdcce958e 12710377187 0 2020-05-29 17:45:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:10.2.0.41/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 024d513c-5c14-4052-bff8-b19b7421f21b 0xc003fa0217 0xc003fa0218}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 50 52 100 53 49 51 99 45 53 99 49 52 45 52 48 53 50 45 98 102 102 56 45 98 49 57 98 55 52 50 49 102 50 49 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.83.111.180,PodIP:,StartTime:2020-05-29 17:45:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.095: INFO: Pod "webserver-deployment-84855cf797-2rstm" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-2rstm webserver-deployment-84855cf797- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-84855cf797-2rstm 2133d350-6b70-4fca-82dd-f61254c6a4bf 12710373520 0 2020-05-29 17:45:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:10.2.3.51/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 024d513c-5c14-4052-bff8-b19b7421f21b 0xc003fa0427 0xc003fa0428}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 50 52 100 53 49 51 99 45 53 99 49 52 45 52 48 53 50 45 98 102 102 56 45 98 49 57 98 55 52 50 49 102 50 49 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:06 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 46 51 46 53 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.178.95.196,PodIP:10.2.3.51,StartTime:2020-05-29 17:45:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-29 17:45:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://62504c649df757777f8fadd822bcaa25909c99dfc46d14a8a7b31f47e28ee7a3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.3.51,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.096: INFO: Pod "webserver-deployment-84855cf797-2zmg7" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-2zmg7 webserver-deployment-84855cf797- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-84855cf797-2zmg7 30eb5a39-2732-4075-9df5-e8d5a6292f33 12710377185 0 2020-05-29 17:45:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:10.2.2.241/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 024d513c-5c14-4052-bff8-b19b7421f21b 0xc003fa05f7 0xc003fa05f8}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 50 52 100 53 49 51 99 45 53 99 49 52 45 52 48 53 50 45 98 102 102 56 45 98 49 57 98 55 52 50 49 102 50 49 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.83.108.252,PodIP:,StartTime:2020-05-29 17:45:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.096: INFO: Pod "webserver-deployment-84855cf797-7q27c" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-7q27c webserver-deployment-84855cf797- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-84855cf797-7q27c 292c6f6f-041b-42a6-9bc4-32caf6f28225 12710377271 0 2020-05-29 17:45:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:10.2.3.57/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 024d513c-5c14-4052-bff8-b19b7421f21b 0xc003fa07f7 0xc003fa07f8}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 50 52 100 53 49 51 99 45 53 99 49 52 45 52 48 53 50 45 98 102 102 56 45 98 49 57 98 55 52 50 49 102 50 49 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.178.95.196,PodIP:,StartTime:2020-05-29 17:45:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.096: INFO: Pod "webserver-deployment-84855cf797-b9kdq" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-b9kdq webserver-deployment-84855cf797- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-84855cf797-b9kdq de36062d-ba30-4ed9-9996-035ad4d636e3 12710376747 0 2020-05-29 17:45:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:10.2.1.76/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 024d513c-5c14-4052-bff8-b19b7421f21b 0xc003fa09d7 0xc003fa09d8}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 50 52 100 53 49 51 99 45 53 99 49 52 45 52 48 53 50 45 98 102 102 56 45 98 49 57 98 55 52 50 49 102 50 49 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:15 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.75.198.105,PodIP:,StartTime:2020-05-29 17:45:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.097: INFO: Pod "webserver-deployment-84855cf797-c9n84" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-c9n84 webserver-deployment-84855cf797- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-84855cf797-c9n84 f09630a2-ebdd-4800-869e-f1ae6dc27901 12710374866 0 2020-05-29 17:45:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:10.2.3.53/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 024d513c-5c14-4052-bff8-b19b7421f21b 0xc003fa0bd7 0xc003fa0bd8}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 50 52 100 53 49 51 99 45 53 99 49 52 45 52 48 53 50 45 98 102 102 56 45 98 49 57 98 55 52 50 49 102 50 49 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:05 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:10 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 46 51 46 53 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.178.95.196,PodIP:10.2.3.53,StartTime:2020-05-29 17:45:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-29 17:45:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://9c74bec8f43dd171a2a77e29e701ae85f46449c16b8bcb836a57f60944db84f6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.3.53,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.097: INFO: Pod "webserver-deployment-84855cf797-d47nv" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-d47nv webserver-deployment-84855cf797- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-84855cf797-d47nv 7c2251fe-00d7-4396-a98d-f1d85dc96dda 12710377159 0 2020-05-29 17:45:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:10.2.0.39/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 024d513c-5c14-4052-bff8-b19b7421f21b 0xc003fa0de7 0xc003fa0de8}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 50 52 100 53 49 51 99 45 53 99 49 52 45 52 48 53 50 45 98 102 102 56 45 98 49 57 98 55 52 50 49 102 50 49 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.83.111.180,PodIP:,StartTime:2020-05-29 17:45:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.097: INFO: Pod "webserver-deployment-84855cf797-fkw5s" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-fkw5s webserver-deployment-84855cf797- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-84855cf797-fkw5s cf29fabc-6bd8-47b9-8eb4-bece004c567b 12710376763 0 2020-05-29 17:45:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:10.2.1.77/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 024d513c-5c14-4052-bff8-b19b7421f21b 0xc003fa1017 0xc003fa1018}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 50 52 100 53 49 51 99 45 53 99 49 52 45 52 48 53 50 45 98 102 102 56 45 98 49 57 98 55 52 50 49 102 50 49 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:15 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.75.198.105,PodIP:,StartTime:2020-05-29 17:45:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.097: INFO: Pod "webserver-deployment-84855cf797-ghkrh" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-ghkrh webserver-deployment-84855cf797- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-84855cf797-ghkrh 5997de7d-6730-4e18-b9b7-4ce9fd659fd5 12710376848 0 2020-05-29 17:45:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:10.2.3.55/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 024d513c-5c14-4052-bff8-b19b7421f21b 0xc003fa1287 0xc003fa1288}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 50 52 100 53 49 51 99 45 53 99 49 52 45 52 48 53 50 45 98 102 102 56 45 98 49 57 98 55 52 50 49 102 50 49 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.178.95.196,PodIP:,StartTime:2020-05-29 17:45:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.098: INFO: Pod "webserver-deployment-84855cf797-hgg6v" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-hgg6v webserver-deployment-84855cf797- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-84855cf797-hgg6v 25fe7021-ad89-4aa3-8b2b-930bddd74551 12710376516 0 2020-05-29 17:45:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 024d513c-5c14-4052-bff8-b19b7421f21b 0xc003fa1477 0xc003fa1478}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 50 52 100 53 49 51 99 45 53 99 49 52 45 52 48 53 50 45 98 102 102 56 45 98 49 57 98 55 52 50 49 102 50 49 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.178.95.196,PodIP:,StartTime:2020-05-29 17:45:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.098: INFO: Pod "webserver-deployment-84855cf797-jdz8q" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-jdz8q webserver-deployment-84855cf797- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-84855cf797-jdz8q 039b8c69-44c7-4775-990e-6e5e8108bca7 12710377259 0 2020-05-29 17:45:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:10.2.2.243/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 024d513c-5c14-4052-bff8-b19b7421f21b 0xc003fa1657 0xc003fa1658}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 50 52 100 53 49 51 99 45 53 99 49 52 45 52 48 53 50 45 98 102 102 56 45 98 49 57 98 55 52 50 49 102 50 49 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.83.108.252,PodIP:,StartTime:2020-05-29 17:45:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.108: INFO: Pod "webserver-deployment-84855cf797-jpsg6" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-jpsg6 webserver-deployment-84855cf797- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-84855cf797-jpsg6 6737b3d1-8353-43c5-bf85-36ece2acb906 12710376734 0 2020-05-29 17:45:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:10.2.0.38/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 024d513c-5c14-4052-bff8-b19b7421f21b 0xc003fa1887 0xc003fa1888}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 50 52 100 53 49 51 99 45 53 99 49 52 45 52 48 53 50 45 98 102 102 56 45 98 49 57 98 55 52 50 49 102 50 49 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:15 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.83.111.180,PodIP:,StartTime:2020-05-29 17:45:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.108: INFO: Pod "webserver-deployment-84855cf797-lzv94" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-lzv94 webserver-deployment-84855cf797- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-84855cf797-lzv94 88635d14-9a8a-4b2f-b4d6-28be3e7c5f02 12710373603 0 2020-05-29 17:45:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:10.2.2.234/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 024d513c-5c14-4052-bff8-b19b7421f21b 0xc003fa1a47 0xc003fa1a48}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 50 52 100 53 49 51 99 45 53 99 49 52 45 52 48 53 50 45 98 102 102 56 45 98 49 57 98 55 52 50 49 102 50 49 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:07 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 46 50 46 50 51 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.83.108.252,PodIP:10.2.2.234,StartTime:2020-05-29 17:45:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-29 17:45:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://81916e85dfa4efd82f866d7f18bf7e306a2b1ef295c3ae7cf955650b0c1a40ec,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.2.234,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.108: INFO: Pod "webserver-deployment-84855cf797-pkwlm" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-pkwlm webserver-deployment-84855cf797- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-84855cf797-pkwlm ffbe5ae3-481c-43ed-b2cc-2ddabd7ebf4e 12710374254 0 2020-05-29 17:45:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:10.2.1.73/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 024d513c-5c14-4052-bff8-b19b7421f21b 0xc003fa1c77 0xc003fa1c78}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 50 52 100 53 49 51 99 45 53 99 49 52 45 52 48 53 50 45 98 102 102 56 45 98 49 57 98 55 52 50 49 102 50 49 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:05 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:08 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 46 49 46 55 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.75.198.105,PodIP:10.2.1.73,StartTime:2020-05-29 17:45:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-29 17:45:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://fb3ef9a33c478ba265adc7a72019ae8d863aa46fbe720d57ce18626a1a8aa350,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.1.73,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.109: INFO: Pod "webserver-deployment-84855cf797-qm5xt" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-qm5xt webserver-deployment-84855cf797- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-84855cf797-qm5xt 9fc86926-6b7a-4903-b25d-56388562f369 12710376481 0 2020-05-29 17:45:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 024d513c-5c14-4052-bff8-b19b7421f21b 0xc003fa1e77 0xc003fa1e78}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 50 52 100 53 49 51 99 45 53 99 49 52 45 52 48 53 50 45 98 102 102 56 45 98 49 57 98 55 52 50 49 102 50 49 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.75.198.105,PodIP:,StartTime:2020-05-29 17:45:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.109: INFO: Pod "webserver-deployment-84855cf797-rhpx8" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-rhpx8 webserver-deployment-84855cf797- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-84855cf797-rhpx8 4e624bda-e893-491b-9564-6676fa4e8eb7 12710376458 0 2020-05-29 17:45:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 024d513c-5c14-4052-bff8-b19b7421f21b 0xc00401a097 0xc00401a098}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 50 52 100 53 49 51 99 45 53 99 49 52 45 52 48 53 50 45 98 102 102 56 45 98 49 57 98 55 52 50 49 102 50 49 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.75.198.105,PodIP:,StartTime:2020-05-29 17:45:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.109: INFO: Pod "webserver-deployment-84855cf797-rpm7k" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-rpm7k webserver-deployment-84855cf797- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-84855cf797-rpm7k 20de2e71-1e94-4986-8e7a-ec807074e1d2 12710374104 0 2020-05-29 17:45:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:10.2.2.235/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 024d513c-5c14-4052-bff8-b19b7421f21b 0xc00401a2d7 0xc00401a2d8}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 50 52 100 53 49 51 99 45 53 99 49 52 45 52 48 53 50 45 98 102 102 56 45 98 49 57 98 55 52 50 49 102 50 49 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:05 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:08 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 46 50 46 50 51 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.83.108.252,PodIP:10.2.2.235,StartTime:2020-05-29 17:45:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-29 17:45:07 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://d4636c1357f0f260e35b4dfe8de3a81edbc99888c414df7e00cc40a6d103ef9d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.2.235,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.109: INFO: Pod "webserver-deployment-84855cf797-vr6qk" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-vr6qk webserver-deployment-84855cf797- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-84855cf797-vr6qk 1101aa1d-90b6-4e89-8827-23057c28ab54 12710373452 0 2020-05-29 17:45:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:10.2.0.37/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 024d513c-5c14-4052-bff8-b19b7421f21b 0xc00401a4f7 0xc00401a4f8}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 50 52 100 53 49 51 99 45 53 99 49 52 45 52 48 53 50 45 98 102 102 56 45 98 49 57 98 55 52 50 49 102 50 49 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:06 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 46 48 46 51 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.83.111.180,PodIP:10.2.0.37,StartTime:2020-05-29 17:45:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-29 17:45:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://2afd1efd43806900c956f1a339b06274ba1b5f8d6124460a5d960144aa7d9d74,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.0.37,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.110: INFO: Pod "webserver-deployment-84855cf797-wrw4z" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-wrw4z webserver-deployment-84855cf797- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-84855cf797-wrw4z 95ea7256-0819-4df2-bfd7-c3a76de31d60 12710373978 0 2020-05-29 17:45:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:10.2.1.74/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 024d513c-5c14-4052-bff8-b19b7421f21b 0xc00401a6f7 0xc00401a6f8}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 50 52 100 53 49 51 99 45 53 99 49 52 45 52 48 53 50 45 98 102 102 56 45 98 49 57 98 55 52 50 49 102 50 49 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:05 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:07 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 46 49 46 55 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.75.198.105,PodIP:10.2.1.74,StartTime:2020-05-29 17:45:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-29 17:45:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://59cb836c74a679c0ff2ca9c0723e6914fa851ee0963ff069410678a7794f7b33,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.1.74,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 29 17:45:17.110: INFO: Pod "webserver-deployment-84855cf797-xmgfz" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-xmgfz webserver-deployment-84855cf797- deployment-7913 /api/v1/namespaces/deployment-7913/pods/webserver-deployment-84855cf797-xmgfz 3e841230-6a80-4f9b-8ef2-2ac5d526f76f 12710374392 0 2020-05-29 17:45:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:10.2.3.52/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 024d513c-5c14-4052-bff8-b19b7421f21b 0xc00401a8d7 0xc00401a8d8}] []  [{kube-controller-manager Update v1 2020-05-29 17:45:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 50 52 100 53 49 51 99 45 53 99 49 52 45 52 48 53 50 45 98 102 102 56 45 98 49 57 98 55 52 50 49 102 50 49 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:45:05 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-05-29 17:45:09 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 46 51 46 53 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bzhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bzhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bzhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:45:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.178.95.196,PodIP:10.2.3.52,StartTime:2020-05-29 17:45:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-29 17:45:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://ce3ddaa95138103356b1668ec0664e6be5d3880654948cf65b4133bfad27c5c6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.3.52,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:45:17.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7913" for this suite.

• [SLOW TEST:13.826 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":277,"completed":163,"skipped":2734,"failed":0}
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:45:17.208: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
May 29 17:45:17.467: INFO: Waiting up to 5m0s for pod "pod-e70ed868-4a26-4511-8887-1faa148e3d7a" in namespace "emptydir-2104" to be "Succeeded or Failed"
May 29 17:45:17.481: INFO: Pod "pod-e70ed868-4a26-4511-8887-1faa148e3d7a": Phase="Pending", Reason="", readiness=false. Elapsed: 13.278714ms
May 29 17:45:19.493: INFO: Pod "pod-e70ed868-4a26-4511-8887-1faa148e3d7a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025328596s
May 29 17:45:21.505: INFO: Pod "pod-e70ed868-4a26-4511-8887-1faa148e3d7a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038006799s
May 29 17:45:23.539: INFO: Pod "pod-e70ed868-4a26-4511-8887-1faa148e3d7a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.071675993s
May 29 17:45:25.652: INFO: Pod "pod-e70ed868-4a26-4511-8887-1faa148e3d7a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.184878182s
May 29 17:45:27.665: INFO: Pod "pod-e70ed868-4a26-4511-8887-1faa148e3d7a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.197738014s
STEP: Saw pod success
May 29 17:45:27.665: INFO: Pod "pod-e70ed868-4a26-4511-8887-1faa148e3d7a" satisfied condition "Succeeded or Failed"
May 29 17:45:27.677: INFO: Trying to get logs from node node-cncf-lab-2 pod pod-e70ed868-4a26-4511-8887-1faa148e3d7a container test-container: <nil>
STEP: delete the pod
May 29 17:45:28.767: INFO: Waiting for pod pod-e70ed868-4a26-4511-8887-1faa148e3d7a to disappear
May 29 17:45:28.811: INFO: Pod pod-e70ed868-4a26-4511-8887-1faa148e3d7a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:45:28.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2104" for this suite.

• [SLOW TEST:11.639 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":164,"skipped":2734,"failed":0}
SSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:45:28.848: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
May 29 17:45:34.186: INFO: Successfully updated pod "annotationupdated4ee7ab4-5b61-4884-9cc1-d2be7b7e215e"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:45:36.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5680" for this suite.

• [SLOW TEST:7.873 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":277,"completed":165,"skipped":2737,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:45:36.725: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-9810
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating statefulset ss in namespace statefulset-9810
May 29 17:45:36.898: INFO: Found 0 stateful pods, waiting for 1
May 29 17:45:46.913: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
May 29 17:45:46.980: INFO: Deleting all statefulset in ns statefulset-9810
May 29 17:45:47.006: INFO: Scaling statefulset ss to 0
May 29 17:45:57.054: INFO: Waiting for statefulset status.replicas updated to 0
May 29 17:45:57.281: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:45:57.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9810" for this suite.

• [SLOW TEST:20.699 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":277,"completed":166,"skipped":2767,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:45:57.424: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:45:57.567: INFO: Pod name cleanup-pod: Found 0 pods out of 1
May 29 17:46:02.582: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 29 17:46:02.582: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
May 29 17:46:07.323: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-9790 /apis/apps/v1/namespaces/deployment-9790/deployments/test-cleanup-deployment 712cc8ec-d018-4a6e-bec4-9dd399b5d726 12710396129 1 2020-05-29 17:46:02 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 2020-05-29 17:46:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-05-29 17:46:06 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005c451d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-05-29 17:46:03 +0000 UTC,LastTransitionTime:2020-05-29 17:46:03 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-b4867b47f" has successfully progressed.,LastUpdateTime:2020-05-29 17:46:06 +0000 UTC,LastTransitionTime:2020-05-29 17:46:03 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

May 29 17:46:07.388: INFO: New ReplicaSet "test-cleanup-deployment-b4867b47f" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-b4867b47f  deployment-9790 /apis/apps/v1/namespaces/deployment-9790/replicasets/test-cleanup-deployment-b4867b47f 3268cf25-c097-467b-a918-69dd844621cd 12710396056 1 2020-05-29 17:46:03 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 712cc8ec-d018-4a6e-bec4-9dd399b5d726 0xc005c456e0 0xc005c456e1}] []  [{kube-controller-manager Update apps/v1 2020-05-29 17:46:06 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 55 49 50 99 99 56 101 99 45 100 48 49 56 45 52 97 54 101 45 98 101 99 52 45 57 100 100 51 57 57 98 53 100 55 50 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: b4867b47f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005c45768 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May 29 17:46:07.415: INFO: Pod "test-cleanup-deployment-b4867b47f-m66pn" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-b4867b47f-m66pn test-cleanup-deployment-b4867b47f- deployment-9790 /api/v1/namespaces/deployment-9790/pods/test-cleanup-deployment-b4867b47f-m66pn bb3471c5-c0fc-436c-af8b-44f74dc3cf06 12710396053 0 2020-05-29 17:46:03 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[cni.projectcalico.org/podIP:10.2.2.251/32] [{apps/v1 ReplicaSet test-cleanup-deployment-b4867b47f 3268cf25-c097-467b-a918-69dd844621cd 0xc005a5ddc0 0xc005a5ddc1}] []  [{kube-controller-manager Update v1 2020-05-29 17:46:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 50 54 56 99 102 50 53 45 99 48 57 55 45 52 54 55 98 45 97 57 49 56 45 54 57 100 100 56 52 52 54 50 49 99 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-05-29 17:46:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-05-29 17:46:06 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 46 50 46 50 53 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-5j6qn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-5j6qn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-5j6qn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:46:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:46:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:46:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 17:46:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.83.108.252,PodIP:10.2.2.251,StartTime:2020-05-29 17:46:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-29 17:46:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://b8800a64c7c07ade29de18b5d6c263fbc3aa691dae7430a1344f5c94eec962b4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.2.251,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:46:07.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9790" for this suite.

• [SLOW TEST:10.060 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":277,"completed":167,"skipped":2775,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:46:07.488: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
May 29 17:46:07.663: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 29 17:46:07.709: INFO: Waiting for terminating namespaces to be deleted...
May 29 17:46:07.721: INFO: 
Logging pods the kubelet thinks is on node node-cncf-lab-1 before test
May 29 17:46:07.753: INFO: test-cleanup-deployment-b4867b47f-m66pn from deployment-9790 started at 2020-05-29 17:46:03 +0000 UTC (1 container statuses recorded)
May 29 17:46:07.753: INFO: 	Container agnhost ready: true, restart count 0
May 29 17:46:07.753: INFO: kube-proxy-24chw from kube-system started at 2020-05-29 12:57:00 +0000 UTC (1 container statuses recorded)
May 29 17:46:07.753: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:46:07.753: INFO: wormhole-b4h5r from kube-system started at 2020-05-29 12:57:00 +0000 UTC (1 container statuses recorded)
May 29 17:46:07.753: INFO: 	Container wormhole ready: true, restart count 0
May 29 17:46:07.754: INFO: sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-dngk9 from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:46:07.754: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:46:07.754: INFO: 	Container systemd-logs ready: true, restart count 0
May 29 17:46:07.754: INFO: canal-6vpdg from kube-system started at 2020-05-29 12:57:00 +0000 UTC (2 container statuses recorded)
May 29 17:46:07.754: INFO: 	Container calico-node ready: true, restart count 0
May 29 17:46:07.754: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:46:07.754: INFO: 
Logging pods the kubelet thinks is on node node-cncf-lab-2 before test
May 29 17:46:07.786: INFO: wormhole-rbswg from kube-system started at 2020-05-29 12:52:43 +0000 UTC (1 container statuses recorded)
May 29 17:46:07.786: INFO: 	Container wormhole ready: true, restart count 0
May 29 17:46:07.786: INFO: coredns-78ff568f7c-d8dj2 from kube-system started at 2020-05-29 12:53:14 +0000 UTC (1 container statuses recorded)
May 29 17:46:07.787: INFO: 	Container coredns ready: true, restart count 0
May 29 17:46:07.787: INFO: kube-proxy-88gmf from kube-system started at 2020-05-29 12:52:43 +0000 UTC (1 container statuses recorded)
May 29 17:46:07.787: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:46:07.787: INFO: metrics-server-79cfd68c87-l6wn9 from kube-system started at 2020-05-29 12:53:03 +0000 UTC (1 container statuses recorded)
May 29 17:46:07.787: INFO: 	Container metrics-server ready: true, restart count 0
May 29 17:46:07.787: INFO: sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-pvwlk from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:46:07.788: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:46:07.788: INFO: 	Container systemd-logs ready: true, restart count 0
May 29 17:46:07.788: INFO: canal-xdv24 from kube-system started at 2020-05-29 12:52:43 +0000 UTC (2 container statuses recorded)
May 29 17:46:07.788: INFO: 	Container calico-node ready: true, restart count 0
May 29 17:46:07.788: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:46:07.789: INFO: kube-dns-autoscaler-579dbcdc47-vzwfl from kube-system started at 2020-05-29 12:53:14 +0000 UTC (1 container statuses recorded)
May 29 17:46:07.789: INFO: 	Container autoscaler ready: true, restart count 0
May 29 17:46:07.789: INFO: coredns-78ff568f7c-8tdx9 from kube-system started at 2020-05-29 12:54:56 +0000 UTC (1 container statuses recorded)
May 29 17:46:07.789: INFO: 	Container coredns ready: true, restart count 0
May 29 17:46:07.789: INFO: 
Logging pods the kubelet thinks is on node node-cncf-lab-3 before test
May 29 17:46:07.815: INFO: sonobuoy from sonobuoy started at 2020-05-29 16:59:22 +0000 UTC (1 container statuses recorded)
May 29 17:46:07.815: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 29 17:46:07.816: INFO: sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-kp7d8 from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:46:07.816: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:46:07.816: INFO: 	Container systemd-logs ready: true, restart count 0
May 29 17:46:07.816: INFO: canal-lh9kw from kube-system started at 2020-05-29 12:59:04 +0000 UTC (2 container statuses recorded)
May 29 17:46:07.817: INFO: 	Container calico-node ready: true, restart count 0
May 29 17:46:07.817: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:46:07.817: INFO: kube-proxy-7bqtd from kube-system started at 2020-05-29 12:59:04 +0000 UTC (1 container statuses recorded)
May 29 17:46:07.817: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:46:07.817: INFO: wormhole-8llxp from kube-system started at 2020-05-29 12:59:04 +0000 UTC (1 container statuses recorded)
May 29 17:46:07.817: INFO: 	Container wormhole ready: true, restart count 0
May 29 17:46:07.818: INFO: 
Logging pods the kubelet thinks is on node node-cncf-lab-4 before test
May 29 17:46:07.913: INFO: wormhole-n2mpq from kube-system started at 2020-05-29 12:54:56 +0000 UTC (1 container statuses recorded)
May 29 17:46:07.913: INFO: 	Container wormhole ready: true, restart count 0
May 29 17:46:07.913: INFO: kube-proxy-rkjk6 from kube-system started at 2020-05-29 12:54:56 +0000 UTC (1 container statuses recorded)
May 29 17:46:07.913: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:46:07.913: INFO: sonobuoy-e2e-job-1012d486abe04715 from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:46:07.913: INFO: 	Container e2e ready: true, restart count 0
May 29 17:46:07.913: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:46:07.913: INFO: canal-7v9cn from kube-system started at 2020-05-29 12:54:56 +0000 UTC (2 container statuses recorded)
May 29 17:46:07.913: INFO: 	Container calico-node ready: true, restart count 0
May 29 17:46:07.914: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:46:07.914: INFO: sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-7449p from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:46:07.914: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:46:07.914: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-7a0ece8c-13ce-46f1-ac7e-8059ab4da338 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-7a0ece8c-13ce-46f1-ac7e-8059ab4da338 off the node node-cncf-lab-3
STEP: verifying the node doesn't have the label kubernetes.io/e2e-7a0ece8c-13ce-46f1-ac7e-8059ab4da338
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:46:26.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7733" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:19.130 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]","total":277,"completed":168,"skipped":2789,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:46:26.619: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a Namespace
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:46:26.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3029" for this suite.
STEP: Destroying namespace "nspatchtest-bef460d4-a593-4cbf-8a38-278c01b5d2c7-4326" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":277,"completed":169,"skipped":2804,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:46:27.001: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-bc389475-2eeb-4086-89ed-51f29df98cc7
STEP: Creating secret with name s-test-opt-upd-5137793a-4329-4e9b-a535-767fc3b9a948
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-bc389475-2eeb-4086-89ed-51f29df98cc7
STEP: Updating secret s-test-opt-upd-5137793a-4329-4e9b-a535-767fc3b9a948
STEP: Creating secret with name s-test-opt-create-e149f4fc-c2fb-4fc3-913a-749acf8a2133
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:47:44.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8561" for this suite.

• [SLOW TEST:77.639 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":170,"skipped":2819,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:47:44.647: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May 29 17:47:50.039: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:47:50.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3936" for this suite.

• [SLOW TEST:5.480 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  blackbox test
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
    on terminated container
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:133
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":171,"skipped":2844,"failed":0}
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:47:50.128: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:47:50.261: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-37860da7-a6b2-4608-8488-e45bde0980a8" in namespace "security-context-test-9434" to be "Succeeded or Failed"
May 29 17:47:50.274: INFO: Pod "busybox-privileged-false-37860da7-a6b2-4608-8488-e45bde0980a8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.406416ms
May 29 17:47:52.313: INFO: Pod "busybox-privileged-false-37860da7-a6b2-4608-8488-e45bde0980a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05159659s
May 29 17:47:54.327: INFO: Pod "busybox-privileged-false-37860da7-a6b2-4608-8488-e45bde0980a8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.06542561s
May 29 17:47:56.340: INFO: Pod "busybox-privileged-false-37860da7-a6b2-4608-8488-e45bde0980a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.07859931s
May 29 17:47:56.341: INFO: Pod "busybox-privileged-false-37860da7-a6b2-4608-8488-e45bde0980a8" satisfied condition "Succeeded or Failed"
May 29 17:47:56.768: INFO: Got logs for pod "busybox-privileged-false-37860da7-a6b2-4608-8488-e45bde0980a8": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:47:56.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9434" for this suite.

• [SLOW TEST:6.714 seconds]
[k8s.io] Security Context
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  When creating a pod with privileged
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:227
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":172,"skipped":2844,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:47:56.842: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
May 29 17:47:57.067: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9553f7a9-ef00-4035-85c4-9a5bad9fa999" in namespace "projected-4660" to be "Succeeded or Failed"
May 29 17:47:57.103: INFO: Pod "downwardapi-volume-9553f7a9-ef00-4035-85c4-9a5bad9fa999": Phase="Pending", Reason="", readiness=false. Elapsed: 35.964835ms
May 29 17:47:59.118: INFO: Pod "downwardapi-volume-9553f7a9-ef00-4035-85c4-9a5bad9fa999": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050566042s
May 29 17:48:01.134: INFO: Pod "downwardapi-volume-9553f7a9-ef00-4035-85c4-9a5bad9fa999": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067129379s
STEP: Saw pod success
May 29 17:48:01.134: INFO: Pod "downwardapi-volume-9553f7a9-ef00-4035-85c4-9a5bad9fa999" satisfied condition "Succeeded or Failed"
May 29 17:48:01.142: INFO: Trying to get logs from node node-cncf-lab-1 pod downwardapi-volume-9553f7a9-ef00-4035-85c4-9a5bad9fa999 container client-container: <nil>
STEP: delete the pod
May 29 17:48:01.234: INFO: Waiting for pod downwardapi-volume-9553f7a9-ef00-4035-85c4-9a5bad9fa999 to disappear
May 29 17:48:01.247: INFO: Pod downwardapi-volume-9553f7a9-ef00-4035-85c4-9a5bad9fa999 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:48:01.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4660" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":173,"skipped":2856,"failed":0}
SSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:48:01.291: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:48:01.403: INFO: Creating ReplicaSet my-hostname-basic-79efa3ba-ff70-4fbb-a286-9a36f9c745fe
May 29 17:48:01.452: INFO: Pod name my-hostname-basic-79efa3ba-ff70-4fbb-a286-9a36f9c745fe: Found 0 pods out of 1
May 29 17:48:06.464: INFO: Pod name my-hostname-basic-79efa3ba-ff70-4fbb-a286-9a36f9c745fe: Found 1 pods out of 1
May 29 17:48:06.464: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-79efa3ba-ff70-4fbb-a286-9a36f9c745fe" is running
May 29 17:48:06.474: INFO: Pod "my-hostname-basic-79efa3ba-ff70-4fbb-a286-9a36f9c745fe-t7cps" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-29 17:48:01 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-29 17:48:04 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-29 17:48:04 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-29 17:48:01 +0000 UTC Reason: Message:}])
May 29 17:48:06.474: INFO: Trying to dial the pod
May 29 17:48:13.936: INFO: Controller my-hostname-basic-79efa3ba-ff70-4fbb-a286-9a36f9c745fe: Got expected result from replica 1 [my-hostname-basic-79efa3ba-ff70-4fbb-a286-9a36f9c745fe-t7cps]: "my-hostname-basic-79efa3ba-ff70-4fbb-a286-9a36f9c745fe-t7cps", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:48:13.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9157" for this suite.

• [SLOW TEST:12.701 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":277,"completed":174,"skipped":2862,"failed":0}
SS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:48:13.992: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
STEP: reading a file in the container
May 29 17:48:19.277: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-671 pod-service-account-291ba7b5-287f-4aed-8e51-0247c41a5aff -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
May 29 17:48:19.902: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-671 pod-service-account-291ba7b5-287f-4aed-8e51-0247c41a5aff -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
May 29 17:48:20.879: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-671 pod-service-account-291ba7b5-287f-4aed-8e51-0247c41a5aff -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:48:21.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-671" for this suite.

• [SLOW TEST:7.379 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":277,"completed":175,"skipped":2864,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:48:21.372: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
May 29 17:48:21.572: INFO: Waiting up to 5m0s for pod "downwardapi-volume-66ef8764-52b3-4c28-a3b9-933ac8320cee" in namespace "projected-9316" to be "Succeeded or Failed"
May 29 17:48:21.601: INFO: Pod "downwardapi-volume-66ef8764-52b3-4c28-a3b9-933ac8320cee": Phase="Pending", Reason="", readiness=false. Elapsed: 29.202632ms
May 29 17:48:23.614: INFO: Pod "downwardapi-volume-66ef8764-52b3-4c28-a3b9-933ac8320cee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042161687s
May 29 17:48:25.626: INFO: Pod "downwardapi-volume-66ef8764-52b3-4c28-a3b9-933ac8320cee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054295844s
STEP: Saw pod success
May 29 17:48:25.626: INFO: Pod "downwardapi-volume-66ef8764-52b3-4c28-a3b9-933ac8320cee" satisfied condition "Succeeded or Failed"
May 29 17:48:25.649: INFO: Trying to get logs from node node-cncf-lab-1 pod downwardapi-volume-66ef8764-52b3-4c28-a3b9-933ac8320cee container client-container: <nil>
STEP: delete the pod
May 29 17:48:25.741: INFO: Waiting for pod downwardapi-volume-66ef8764-52b3-4c28-a3b9-933ac8320cee to disappear
May 29 17:48:25.750: INFO: Pod downwardapi-volume-66ef8764-52b3-4c28-a3b9-933ac8320cee no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:48:25.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9316" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":277,"completed":176,"skipped":2885,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:48:25.809: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0529 17:48:32.040644      20 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 29 17:48:32.040: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:48:32.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3763" for this suite.

• [SLOW TEST:6.264 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":277,"completed":177,"skipped":2929,"failed":0}
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:48:32.082: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:48:50.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3753" for this suite.

• [SLOW TEST:17.999 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":277,"completed":178,"skipped":2931,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:48:50.083: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-f88dc19a-025d-4ff7-8538-3c49cb74c06c
STEP: Creating a pod to test consume secrets
May 29 17:48:50.272: INFO: Waiting up to 5m0s for pod "pod-secrets-e9f06324-1003-493f-8479-5ef79fe64a76" in namespace "secrets-9430" to be "Succeeded or Failed"
May 29 17:48:50.285: INFO: Pod "pod-secrets-e9f06324-1003-493f-8479-5ef79fe64a76": Phase="Pending", Reason="", readiness=false. Elapsed: 12.981316ms
May 29 17:48:52.313: INFO: Pod "pod-secrets-e9f06324-1003-493f-8479-5ef79fe64a76": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041077325s
May 29 17:48:54.330: INFO: Pod "pod-secrets-e9f06324-1003-493f-8479-5ef79fe64a76": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057986721s
STEP: Saw pod success
May 29 17:48:54.330: INFO: Pod "pod-secrets-e9f06324-1003-493f-8479-5ef79fe64a76" satisfied condition "Succeeded or Failed"
May 29 17:48:54.428: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-secrets-e9f06324-1003-493f-8479-5ef79fe64a76 container secret-volume-test: <nil>
STEP: delete the pod
May 29 17:48:54.562: INFO: Waiting for pod pod-secrets-e9f06324-1003-493f-8479-5ef79fe64a76 to disappear
May 29 17:48:54.572: INFO: Pod pod-secrets-e9f06324-1003-493f-8479-5ef79fe64a76 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:48:54.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9430" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":179,"skipped":2940,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:48:55.010: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:48:59.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2631" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":180,"skipped":2960,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:48:59.294: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
May 29 17:48:59.485: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1b035967-8e69-4d6e-a541-850947c156bb" in namespace "downward-api-2231" to be "Succeeded or Failed"
May 29 17:48:59.496: INFO: Pod "downwardapi-volume-1b035967-8e69-4d6e-a541-850947c156bb": Phase="Pending", Reason="", readiness=false. Elapsed: 11.180472ms
May 29 17:49:01.505: INFO: Pod "downwardapi-volume-1b035967-8e69-4d6e-a541-850947c156bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020322169s
May 29 17:49:03.820: INFO: Pod "downwardapi-volume-1b035967-8e69-4d6e-a541-850947c156bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.335504244s
STEP: Saw pod success
May 29 17:49:03.821: INFO: Pod "downwardapi-volume-1b035967-8e69-4d6e-a541-850947c156bb" satisfied condition "Succeeded or Failed"
May 29 17:49:03.850: INFO: Trying to get logs from node node-cncf-lab-1 pod downwardapi-volume-1b035967-8e69-4d6e-a541-850947c156bb container client-container: <nil>
STEP: delete the pod
May 29 17:49:03.910: INFO: Waiting for pod downwardapi-volume-1b035967-8e69-4d6e-a541-850947c156bb to disappear
May 29 17:49:03.920: INFO: Pod downwardapi-volume-1b035967-8e69-4d6e-a541-850947c156bb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:49:03.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2231" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":277,"completed":181,"skipped":2970,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:49:03.954: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
May 29 17:49:14.192: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7467 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:49:14.192: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 17:49:14.495: INFO: Exec stderr: ""
May 29 17:49:14.496: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7467 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:49:14.496: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 17:49:14.768: INFO: Exec stderr: ""
May 29 17:49:14.768: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7467 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:49:14.768: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 17:49:15.009: INFO: Exec stderr: ""
May 29 17:49:15.009: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7467 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:49:15.009: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 17:49:15.218: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
May 29 17:49:15.218: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7467 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:49:15.218: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 17:49:15.469: INFO: Exec stderr: ""
May 29 17:49:15.469: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7467 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:49:15.469: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 17:49:15.737: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
May 29 17:49:15.737: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7467 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:49:15.737: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 17:49:16.002: INFO: Exec stderr: ""
May 29 17:49:16.003: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7467 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:49:16.003: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 17:49:16.259: INFO: Exec stderr: ""
May 29 17:49:16.259: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7467 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:49:16.259: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 17:49:16.531: INFO: Exec stderr: ""
May 29 17:49:16.531: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7467 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:49:16.531: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 17:49:16.799: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:49:16.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-7467" for this suite.

• [SLOW TEST:12.898 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":182,"skipped":3017,"failed":0}
SSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:49:16.854: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May 29 17:49:22.099: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:49:22.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6916" for this suite.

• [SLOW TEST:5.325 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  blackbox test
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
    on terminated container
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:133
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":277,"completed":183,"skipped":3021,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:49:22.194: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service endpoint-test2 in namespace services-7674
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7674 to expose endpoints map[]
May 29 17:49:22.384: INFO: Get endpoints failed (38.718004ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
May 29 17:49:23.402: INFO: successfully validated that service endpoint-test2 in namespace services-7674 exposes endpoints map[] (1.056244119s elapsed)
STEP: Creating pod pod1 in namespace services-7674
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7674 to expose endpoints map[pod1:[80]]
May 29 17:49:28.755: INFO: successfully validated that service endpoint-test2 in namespace services-7674 exposes endpoints map[pod1:[80]] (4.62400793s elapsed)
STEP: Creating pod pod2 in namespace services-7674
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7674 to expose endpoints map[pod1:[80] pod2:[80]]
May 29 17:49:33.015: INFO: successfully validated that service endpoint-test2 in namespace services-7674 exposes endpoints map[pod1:[80] pod2:[80]] (4.214523331s elapsed)
STEP: Deleting pod pod1 in namespace services-7674
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7674 to expose endpoints map[pod2:[80]]
May 29 17:49:33.079: INFO: successfully validated that service endpoint-test2 in namespace services-7674 exposes endpoints map[pod2:[80]] (23.537316ms elapsed)
STEP: Deleting pod pod2 in namespace services-7674
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7674 to expose endpoints map[]
May 29 17:49:33.126: INFO: successfully validated that service endpoint-test2 in namespace services-7674 exposes endpoints map[] (21.39056ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:49:33.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7674" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:11.074 seconds]
[sig-network] Services
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":277,"completed":184,"skipped":3059,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:49:33.269: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
May 29 17:49:33.438: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6a7fae83-69be-4b26-8e9b-a64ddc5d9908" in namespace "projected-6285" to be "Succeeded or Failed"
May 29 17:49:33.450: INFO: Pod "downwardapi-volume-6a7fae83-69be-4b26-8e9b-a64ddc5d9908": Phase="Pending", Reason="", readiness=false. Elapsed: 11.828404ms
May 29 17:49:35.464: INFO: Pod "downwardapi-volume-6a7fae83-69be-4b26-8e9b-a64ddc5d9908": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025928301s
May 29 17:49:37.476: INFO: Pod "downwardapi-volume-6a7fae83-69be-4b26-8e9b-a64ddc5d9908": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037693184s
STEP: Saw pod success
May 29 17:49:37.477: INFO: Pod "downwardapi-volume-6a7fae83-69be-4b26-8e9b-a64ddc5d9908" satisfied condition "Succeeded or Failed"
May 29 17:49:37.486: INFO: Trying to get logs from node node-cncf-lab-4 pod downwardapi-volume-6a7fae83-69be-4b26-8e9b-a64ddc5d9908 container client-container: <nil>
STEP: delete the pod
May 29 17:49:37.781: INFO: Waiting for pod downwardapi-volume-6a7fae83-69be-4b26-8e9b-a64ddc5d9908 to disappear
May 29 17:49:37.792: INFO: Pod downwardapi-volume-6a7fae83-69be-4b26-8e9b-a64ddc5d9908 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:49:37.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6285" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":185,"skipped":3072,"failed":0}
S
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:49:37.834: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
May 29 17:49:37.977: INFO: Waiting up to 5m0s for pod "downward-api-783b5e08-54d2-4361-9f5d-f07e4f6024cc" in namespace "downward-api-6051" to be "Succeeded or Failed"
May 29 17:49:37.996: INFO: Pod "downward-api-783b5e08-54d2-4361-9f5d-f07e4f6024cc": Phase="Pending", Reason="", readiness=false. Elapsed: 18.989273ms
May 29 17:49:40.007: INFO: Pod "downward-api-783b5e08-54d2-4361-9f5d-f07e4f6024cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029746837s
May 29 17:49:42.019: INFO: Pod "downward-api-783b5e08-54d2-4361-9f5d-f07e4f6024cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04151419s
STEP: Saw pod success
May 29 17:49:42.019: INFO: Pod "downward-api-783b5e08-54d2-4361-9f5d-f07e4f6024cc" satisfied condition "Succeeded or Failed"
May 29 17:49:42.031: INFO: Trying to get logs from node node-cncf-lab-3 pod downward-api-783b5e08-54d2-4361-9f5d-f07e4f6024cc container dapi-container: <nil>
STEP: delete the pod
May 29 17:49:43.707: INFO: Waiting for pod downward-api-783b5e08-54d2-4361-9f5d-f07e4f6024cc to disappear
May 29 17:49:44.240: INFO: Pod downward-api-783b5e08-54d2-4361-9f5d-f07e4f6024cc no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:49:44.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6051" for this suite.

• [SLOW TEST:6.442 seconds]
[sig-node] Downward API
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:34
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":277,"completed":186,"skipped":3073,"failed":0}
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:49:44.276: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:49:45.614: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
May 29 17:49:45.659: INFO: Number of nodes with available pods: 0
May 29 17:49:45.659: INFO: Node node-cncf-lab-1 is running more than one daemon pod
May 29 17:49:48.061: INFO: Number of nodes with available pods: 0
May 29 17:49:48.061: INFO: Node node-cncf-lab-1 is running more than one daemon pod
May 29 17:49:48.727: INFO: Number of nodes with available pods: 0
May 29 17:49:48.728: INFO: Node node-cncf-lab-1 is running more than one daemon pod
May 29 17:49:49.689: INFO: Number of nodes with available pods: 0
May 29 17:49:49.689: INFO: Node node-cncf-lab-1 is running more than one daemon pod
May 29 17:49:50.684: INFO: Number of nodes with available pods: 4
May 29 17:49:50.684: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
May 29 17:49:50.878: INFO: Wrong image for pod: daemon-set-4zk4h. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:50.878: INFO: Wrong image for pod: daemon-set-5w2jk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:50.878: INFO: Wrong image for pod: daemon-set-h77sf. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:50.878: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:51.905: INFO: Wrong image for pod: daemon-set-4zk4h. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:51.906: INFO: Wrong image for pod: daemon-set-5w2jk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:51.906: INFO: Wrong image for pod: daemon-set-h77sf. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:51.906: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:52.911: INFO: Wrong image for pod: daemon-set-4zk4h. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:52.911: INFO: Wrong image for pod: daemon-set-5w2jk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:52.911: INFO: Wrong image for pod: daemon-set-h77sf. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:52.912: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:53.904: INFO: Wrong image for pod: daemon-set-4zk4h. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:53.904: INFO: Wrong image for pod: daemon-set-5w2jk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:53.904: INFO: Wrong image for pod: daemon-set-h77sf. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:53.904: INFO: Pod daemon-set-h77sf is not available
May 29 17:49:53.904: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:54.909: INFO: Wrong image for pod: daemon-set-4zk4h. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:54.909: INFO: Wrong image for pod: daemon-set-5w2jk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:54.909: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:54.909: INFO: Pod daemon-set-szpm4 is not available
May 29 17:49:55.906: INFO: Wrong image for pod: daemon-set-4zk4h. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:55.907: INFO: Wrong image for pod: daemon-set-5w2jk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:55.907: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:55.907: INFO: Pod daemon-set-szpm4 is not available
May 29 17:49:57.377: INFO: Wrong image for pod: daemon-set-4zk4h. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:57.377: INFO: Wrong image for pod: daemon-set-5w2jk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:57.377: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:57.377: INFO: Pod daemon-set-szpm4 is not available
May 29 17:49:57.909: INFO: Wrong image for pod: daemon-set-4zk4h. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:57.909: INFO: Wrong image for pod: daemon-set-5w2jk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:57.910: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:57.910: INFO: Pod daemon-set-szpm4 is not available
May 29 17:49:58.903: INFO: Wrong image for pod: daemon-set-4zk4h. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:58.904: INFO: Wrong image for pod: daemon-set-5w2jk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:58.904: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:59.904: INFO: Wrong image for pod: daemon-set-4zk4h. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:59.905: INFO: Wrong image for pod: daemon-set-5w2jk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:49:59.906: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:00.902: INFO: Wrong image for pod: daemon-set-4zk4h. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:00.902: INFO: Wrong image for pod: daemon-set-5w2jk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:00.902: INFO: Pod daemon-set-5w2jk is not available
May 29 17:50:00.902: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:01.906: INFO: Wrong image for pod: daemon-set-4zk4h. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:01.906: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:01.906: INFO: Pod daemon-set-xrkbh is not available
May 29 17:50:03.140: INFO: Wrong image for pod: daemon-set-4zk4h. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:03.140: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:03.140: INFO: Pod daemon-set-xrkbh is not available
May 29 17:50:03.906: INFO: Wrong image for pod: daemon-set-4zk4h. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:03.906: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:03.906: INFO: Pod daemon-set-xrkbh is not available
May 29 17:50:04.953: INFO: Wrong image for pod: daemon-set-4zk4h. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:04.953: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:06.072: INFO: Wrong image for pod: daemon-set-4zk4h. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:06.072: INFO: Pod daemon-set-4zk4h is not available
May 29 17:50:06.072: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:06.913: INFO: Wrong image for pod: daemon-set-4zk4h. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:06.913: INFO: Pod daemon-set-4zk4h is not available
May 29 17:50:06.913: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:07.914: INFO: Wrong image for pod: daemon-set-4zk4h. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:07.914: INFO: Pod daemon-set-4zk4h is not available
May 29 17:50:07.914: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:08.913: INFO: Wrong image for pod: daemon-set-4zk4h. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:08.914: INFO: Pod daemon-set-4zk4h is not available
May 29 17:50:08.915: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:10.418: INFO: Wrong image for pod: daemon-set-4zk4h. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:10.418: INFO: Pod daemon-set-4zk4h is not available
May 29 17:50:10.419: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:10.912: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:10.912: INFO: Pod daemon-set-ltwqv is not available
May 29 17:50:11.911: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:11.911: INFO: Pod daemon-set-ltwqv is not available
May 29 17:50:12.910: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:12.925: INFO: Pod daemon-set-ltwqv is not available
May 29 17:50:13.907: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:14.908: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:14.908: INFO: Pod daemon-set-jlh8t is not available
May 29 17:50:15.909: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:15.909: INFO: Pod daemon-set-jlh8t is not available
May 29 17:50:18.083: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:18.084: INFO: Pod daemon-set-jlh8t is not available
May 29 17:50:18.907: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:18.907: INFO: Pod daemon-set-jlh8t is not available
May 29 17:50:19.906: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:19.906: INFO: Pod daemon-set-jlh8t is not available
May 29 17:50:20.907: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:20.907: INFO: Pod daemon-set-jlh8t is not available
May 29 17:50:21.911: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:21.911: INFO: Pod daemon-set-jlh8t is not available
May 29 17:50:25.122: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:25.122: INFO: Pod daemon-set-jlh8t is not available
May 29 17:50:25.918: INFO: Wrong image for pod: daemon-set-jlh8t. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
May 29 17:50:25.918: INFO: Pod daemon-set-jlh8t is not available
May 29 17:50:26.914: INFO: Pod daemon-set-djgkt is not available
STEP: Check that daemon pods are still running on every node of the cluster.
May 29 17:50:26.998: INFO: Number of nodes with available pods: 3
May 29 17:50:26.998: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:50:28.045: INFO: Number of nodes with available pods: 3
May 29 17:50:28.045: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:50:29.033: INFO: Number of nodes with available pods: 3
May 29 17:50:29.033: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:50:30.030: INFO: Number of nodes with available pods: 3
May 29 17:50:30.030: INFO: Node node-cncf-lab-2 is running more than one daemon pod
May 29 17:50:31.197: INFO: Number of nodes with available pods: 4
May 29 17:50:31.197: INFO: Number of running nodes: 4, number of available pods: 4
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8857, will wait for the garbage collector to delete the pods
May 29 17:50:31.367: INFO: Deleting DaemonSet.extensions daemon-set took: 21.526997ms
May 29 17:50:31.967: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.232503ms
May 29 17:50:44.282: INFO: Number of nodes with available pods: 0
May 29 17:50:44.282: INFO: Number of running nodes: 0, number of available pods: 0
May 29 17:50:44.308: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8857/daemonsets","resourceVersion":"12710496829"},"items":null}

May 29 17:50:44.332: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8857/pods","resourceVersion":"12710496842"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:50:44.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8857" for this suite.

• [SLOW TEST:60.308 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":277,"completed":187,"skipped":3079,"failed":0}
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:50:44.584: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:50:44.864: INFO: The status of Pod test-webserver-390bde81-0916-4d53-8c54-947d79a5b48c is Pending, waiting for it to be Running (with Ready = true)
May 29 17:50:47.070: INFO: The status of Pod test-webserver-390bde81-0916-4d53-8c54-947d79a5b48c is Pending, waiting for it to be Running (with Ready = true)
May 29 17:50:48.880: INFO: The status of Pod test-webserver-390bde81-0916-4d53-8c54-947d79a5b48c is Running (Ready = false)
May 29 17:50:50.877: INFO: The status of Pod test-webserver-390bde81-0916-4d53-8c54-947d79a5b48c is Running (Ready = false)
May 29 17:50:52.901: INFO: The status of Pod test-webserver-390bde81-0916-4d53-8c54-947d79a5b48c is Running (Ready = false)
May 29 17:50:54.876: INFO: The status of Pod test-webserver-390bde81-0916-4d53-8c54-947d79a5b48c is Running (Ready = false)
May 29 17:50:56.887: INFO: The status of Pod test-webserver-390bde81-0916-4d53-8c54-947d79a5b48c is Running (Ready = false)
May 29 17:50:59.407: INFO: The status of Pod test-webserver-390bde81-0916-4d53-8c54-947d79a5b48c is Running (Ready = false)
May 29 17:51:00.874: INFO: The status of Pod test-webserver-390bde81-0916-4d53-8c54-947d79a5b48c is Running (Ready = false)
May 29 17:51:03.941: INFO: The status of Pod test-webserver-390bde81-0916-4d53-8c54-947d79a5b48c is Running (Ready = false)
May 29 17:51:04.879: INFO: The status of Pod test-webserver-390bde81-0916-4d53-8c54-947d79a5b48c is Running (Ready = false)
May 29 17:51:06.874: INFO: The status of Pod test-webserver-390bde81-0916-4d53-8c54-947d79a5b48c is Running (Ready = false)
May 29 17:51:08.882: INFO: The status of Pod test-webserver-390bde81-0916-4d53-8c54-947d79a5b48c is Running (Ready = false)
May 29 17:51:11.498: INFO: The status of Pod test-webserver-390bde81-0916-4d53-8c54-947d79a5b48c is Running (Ready = false)
May 29 17:51:12.875: INFO: The status of Pod test-webserver-390bde81-0916-4d53-8c54-947d79a5b48c is Running (Ready = true)
May 29 17:51:12.886: INFO: Container started at 2020-05-29 17:50:47 +0000 UTC, pod became ready at 2020-05-29 17:51:11 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:51:12.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-721" for this suite.

• [SLOW TEST:28.346 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":277,"completed":188,"skipped":3079,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:51:12.935: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:51:13.124: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:51:13.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1083" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":277,"completed":189,"skipped":3101,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:51:13.824: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
May 29 17:51:18.598: INFO: Successfully updated pod "labelsupdateb4affa05-2eae-4e8e-b601-5ae4668e602f"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:51:20.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1688" for this suite.

• [SLOW TEST:6.890 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":277,"completed":190,"skipped":3168,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:51:20.714: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-01432bdb-8b31-4a99-9395-8196dc4be721
STEP: Creating a pod to test consume secrets
May 29 17:51:22.031: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e0c62593-bdd2-4f99-b0ad-0c4857975719" in namespace "projected-2305" to be "Succeeded or Failed"
May 29 17:51:22.056: INFO: Pod "pod-projected-secrets-e0c62593-bdd2-4f99-b0ad-0c4857975719": Phase="Pending", Reason="", readiness=false. Elapsed: 24.694186ms
May 29 17:51:24.070: INFO: Pod "pod-projected-secrets-e0c62593-bdd2-4f99-b0ad-0c4857975719": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038685307s
May 29 17:51:26.084: INFO: Pod "pod-projected-secrets-e0c62593-bdd2-4f99-b0ad-0c4857975719": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052743038s
STEP: Saw pod success
May 29 17:51:26.085: INFO: Pod "pod-projected-secrets-e0c62593-bdd2-4f99-b0ad-0c4857975719" satisfied condition "Succeeded or Failed"
May 29 17:51:26.438: INFO: Trying to get logs from node node-cncf-lab-3 pod pod-projected-secrets-e0c62593-bdd2-4f99-b0ad-0c4857975719 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 29 17:51:26.607: INFO: Waiting for pod pod-projected-secrets-e0c62593-bdd2-4f99-b0ad-0c4857975719 to disappear
May 29 17:51:26.616: INFO: Pod pod-projected-secrets-e0c62593-bdd2-4f99-b0ad-0c4857975719 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:51:26.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2305" for this suite.

• [SLOW TEST:5.940 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":191,"skipped":3183,"failed":0}
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:51:26.661: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-dbbe19b4-34e2-48a6-9ab8-a3446df3aabe
STEP: Creating a pod to test consume configMaps
May 29 17:51:26.904: INFO: Waiting up to 5m0s for pod "pod-configmaps-5127e579-5c8f-40d9-8b9a-51231ec53014" in namespace "configmap-1298" to be "Succeeded or Failed"
May 29 17:51:26.914: INFO: Pod "pod-configmaps-5127e579-5c8f-40d9-8b9a-51231ec53014": Phase="Pending", Reason="", readiness=false. Elapsed: 10.440124ms
May 29 17:51:29.454: INFO: Pod "pod-configmaps-5127e579-5c8f-40d9-8b9a-51231ec53014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.549779653s
May 29 17:51:31.471: INFO: Pod "pod-configmaps-5127e579-5c8f-40d9-8b9a-51231ec53014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.567664885s
STEP: Saw pod success
May 29 17:51:31.472: INFO: Pod "pod-configmaps-5127e579-5c8f-40d9-8b9a-51231ec53014" satisfied condition "Succeeded or Failed"
May 29 17:51:31.486: INFO: Trying to get logs from node node-cncf-lab-3 pod pod-configmaps-5127e579-5c8f-40d9-8b9a-51231ec53014 container configmap-volume-test: <nil>
STEP: delete the pod
May 29 17:51:31.910: INFO: Waiting for pod pod-configmaps-5127e579-5c8f-40d9-8b9a-51231ec53014 to disappear
May 29 17:51:31.921: INFO: Pod pod-configmaps-5127e579-5c8f-40d9-8b9a-51231ec53014 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:51:31.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1298" for this suite.

• [SLOW TEST:5.310 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":192,"skipped":3190,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:51:31.971: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
May 29 17:51:32.082: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 29 17:51:32.128: INFO: Waiting for terminating namespaces to be deleted...
May 29 17:51:32.191: INFO: 
Logging pods the kubelet thinks is on node node-cncf-lab-1 before test
May 29 17:51:32.231: INFO: wormhole-b4h5r from kube-system started at 2020-05-29 12:57:00 +0000 UTC (1 container statuses recorded)
May 29 17:51:32.231: INFO: 	Container wormhole ready: true, restart count 0
May 29 17:51:32.231: INFO: canal-6vpdg from kube-system started at 2020-05-29 12:57:00 +0000 UTC (2 container statuses recorded)
May 29 17:51:32.231: INFO: 	Container calico-node ready: true, restart count 0
May 29 17:51:32.231: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:51:32.231: INFO: sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-dngk9 from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:51:32.231: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:51:32.231: INFO: 	Container systemd-logs ready: true, restart count 0
May 29 17:51:32.231: INFO: kube-proxy-24chw from kube-system started at 2020-05-29 12:57:00 +0000 UTC (1 container statuses recorded)
May 29 17:51:32.231: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:51:32.231: INFO: 
Logging pods the kubelet thinks is on node node-cncf-lab-2 before test
May 29 17:51:32.310: INFO: kube-proxy-88gmf from kube-system started at 2020-05-29 12:52:43 +0000 UTC (1 container statuses recorded)
May 29 17:51:32.310: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:51:32.310: INFO: metrics-server-79cfd68c87-l6wn9 from kube-system started at 2020-05-29 12:53:03 +0000 UTC (1 container statuses recorded)
May 29 17:51:32.310: INFO: 	Container metrics-server ready: true, restart count 0
May 29 17:51:32.310: INFO: sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-pvwlk from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:51:32.310: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:51:32.310: INFO: 	Container systemd-logs ready: true, restart count 0
May 29 17:51:32.310: INFO: canal-xdv24 from kube-system started at 2020-05-29 12:52:43 +0000 UTC (2 container statuses recorded)
May 29 17:51:32.310: INFO: 	Container calico-node ready: true, restart count 0
May 29 17:51:32.310: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:51:32.310: INFO: kube-dns-autoscaler-579dbcdc47-vzwfl from kube-system started at 2020-05-29 12:53:14 +0000 UTC (1 container statuses recorded)
May 29 17:51:32.310: INFO: 	Container autoscaler ready: true, restart count 0
May 29 17:51:32.310: INFO: coredns-78ff568f7c-8tdx9 from kube-system started at 2020-05-29 12:54:56 +0000 UTC (1 container statuses recorded)
May 29 17:51:32.310: INFO: 	Container coredns ready: true, restart count 0
May 29 17:51:32.310: INFO: wormhole-rbswg from kube-system started at 2020-05-29 12:52:43 +0000 UTC (1 container statuses recorded)
May 29 17:51:32.310: INFO: 	Container wormhole ready: true, restart count 0
May 29 17:51:32.310: INFO: coredns-78ff568f7c-d8dj2 from kube-system started at 2020-05-29 12:53:14 +0000 UTC (1 container statuses recorded)
May 29 17:51:32.310: INFO: 	Container coredns ready: true, restart count 0
May 29 17:51:32.310: INFO: 
Logging pods the kubelet thinks is on node node-cncf-lab-3 before test
May 29 17:51:32.336: INFO: wormhole-8llxp from kube-system started at 2020-05-29 12:59:04 +0000 UTC (1 container statuses recorded)
May 29 17:51:32.337: INFO: 	Container wormhole ready: true, restart count 0
May 29 17:51:32.337: INFO: sonobuoy from sonobuoy started at 2020-05-29 16:59:22 +0000 UTC (1 container statuses recorded)
May 29 17:51:32.337: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 29 17:51:32.338: INFO: sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-kp7d8 from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:51:32.338: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:51:32.338: INFO: 	Container systemd-logs ready: true, restart count 0
May 29 17:51:32.339: INFO: canal-lh9kw from kube-system started at 2020-05-29 12:59:04 +0000 UTC (2 container statuses recorded)
May 29 17:51:32.339: INFO: 	Container calico-node ready: true, restart count 0
May 29 17:51:32.339: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:51:32.339: INFO: kube-proxy-7bqtd from kube-system started at 2020-05-29 12:59:04 +0000 UTC (1 container statuses recorded)
May 29 17:51:32.340: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:51:32.340: INFO: 
Logging pods the kubelet thinks is on node node-cncf-lab-4 before test
May 29 17:51:32.430: INFO: wormhole-n2mpq from kube-system started at 2020-05-29 12:54:56 +0000 UTC (1 container statuses recorded)
May 29 17:51:32.430: INFO: 	Container wormhole ready: true, restart count 0
May 29 17:51:32.430: INFO: kube-proxy-rkjk6 from kube-system started at 2020-05-29 12:54:56 +0000 UTC (1 container statuses recorded)
May 29 17:51:32.430: INFO: 	Container kube-proxy ready: true, restart count 0
May 29 17:51:32.430: INFO: sonobuoy-e2e-job-1012d486abe04715 from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:51:32.430: INFO: 	Container e2e ready: true, restart count 0
May 29 17:51:32.430: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:51:32.430: INFO: canal-7v9cn from kube-system started at 2020-05-29 12:54:56 +0000 UTC (2 container statuses recorded)
May 29 17:51:32.430: INFO: 	Container calico-node ready: true, restart count 0
May 29 17:51:32.431: INFO: 	Container kube-flannel ready: true, restart count 0
May 29 17:51:32.431: INFO: sonobuoy-systemd-logs-daemon-set-16f197a70e3944b0-7449p from sonobuoy started at 2020-05-29 16:59:25 +0000 UTC (2 container statuses recorded)
May 29 17:51:32.431: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 29 17:51:32.431: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-b3ff1498-1639-45e5-8601-6e56c36d2363 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-b3ff1498-1639-45e5-8601-6e56c36d2363 off the node node-cncf-lab-1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-b3ff1498-1639-45e5-8601-6e56c36d2363
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:56:41.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7087" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:309.849 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":277,"completed":193,"skipped":3207,"failed":0}
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:56:41.822: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
May 29 17:56:41.971: INFO: Waiting up to 5m0s for pod "downwardapi-volume-128d1e92-0844-4890-a997-d92d6e972774" in namespace "projected-7647" to be "Succeeded or Failed"
May 29 17:56:41.982: INFO: Pod "downwardapi-volume-128d1e92-0844-4890-a997-d92d6e972774": Phase="Pending", Reason="", readiness=false. Elapsed: 10.434674ms
May 29 17:56:43.996: INFO: Pod "downwardapi-volume-128d1e92-0844-4890-a997-d92d6e972774": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024358119s
May 29 17:56:46.011: INFO: Pod "downwardapi-volume-128d1e92-0844-4890-a997-d92d6e972774": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039875882s
STEP: Saw pod success
May 29 17:56:46.012: INFO: Pod "downwardapi-volume-128d1e92-0844-4890-a997-d92d6e972774" satisfied condition "Succeeded or Failed"
May 29 17:56:46.023: INFO: Trying to get logs from node node-cncf-lab-3 pod downwardapi-volume-128d1e92-0844-4890-a997-d92d6e972774 container client-container: <nil>
STEP: delete the pod
May 29 17:56:46.126: INFO: Waiting for pod downwardapi-volume-128d1e92-0844-4890-a997-d92d6e972774 to disappear
May 29 17:56:46.134: INFO: Pod downwardapi-volume-128d1e92-0844-4890-a997-d92d6e972774 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:56:46.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7647" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":277,"completed":194,"skipped":3211,"failed":0}

------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:56:46.172: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
May 29 17:56:46.348: INFO: Pod name pod-release: Found 0 pods out of 1
May 29 17:56:51.369: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:56:52.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5130" for this suite.

• [SLOW TEST:6.291 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":277,"completed":195,"skipped":3211,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:56:52.468: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:56:57.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1171" for this suite.

• [SLOW TEST:5.241 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":277,"completed":196,"skipped":3233,"failed":0}
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:56:57.709: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's command
May 29 17:56:57.877: INFO: Waiting up to 5m0s for pod "var-expansion-99082e4f-b128-47db-abb2-2c0a37810113" in namespace "var-expansion-6188" to be "Succeeded or Failed"
May 29 17:56:57.889: INFO: Pod "var-expansion-99082e4f-b128-47db-abb2-2c0a37810113": Phase="Pending", Reason="", readiness=false. Elapsed: 12.403652ms
May 29 17:56:59.902: INFO: Pod "var-expansion-99082e4f-b128-47db-abb2-2c0a37810113": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025632595s
May 29 17:57:01.914: INFO: Pod "var-expansion-99082e4f-b128-47db-abb2-2c0a37810113": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037296715s
STEP: Saw pod success
May 29 17:57:01.914: INFO: Pod "var-expansion-99082e4f-b128-47db-abb2-2c0a37810113" satisfied condition "Succeeded or Failed"
May 29 17:57:01.925: INFO: Trying to get logs from node node-cncf-lab-1 pod var-expansion-99082e4f-b128-47db-abb2-2c0a37810113 container dapi-container: <nil>
STEP: delete the pod
May 29 17:57:02.086: INFO: Waiting for pod var-expansion-99082e4f-b128-47db-abb2-2c0a37810113 to disappear
May 29 17:57:02.098: INFO: Pod var-expansion-99082e4f-b128-47db-abb2-2c0a37810113 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:57:02.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6188" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":277,"completed":197,"skipped":3233,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:57:02.142: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:57:02.248: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
May 29 17:57:05.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 --namespace=crd-publish-openapi-7093 create -f -'
May 29 17:57:06.538: INFO: stderr: ""
May 29 17:57:06.538: INFO: stdout: "e2e-test-crd-publish-openapi-1011-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
May 29 17:57:06.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 --namespace=crd-publish-openapi-7093 delete e2e-test-crd-publish-openapi-1011-crds test-cr'
May 29 17:57:06.700: INFO: stderr: ""
May 29 17:57:06.700: INFO: stdout: "e2e-test-crd-publish-openapi-1011-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
May 29 17:57:06.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 --namespace=crd-publish-openapi-7093 apply -f -'
May 29 17:57:06.992: INFO: stderr: ""
May 29 17:57:06.992: INFO: stdout: "e2e-test-crd-publish-openapi-1011-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
May 29 17:57:06.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 --namespace=crd-publish-openapi-7093 delete e2e-test-crd-publish-openapi-1011-crds test-cr'
May 29 17:57:07.171: INFO: stderr: ""
May 29 17:57:07.171: INFO: stdout: "e2e-test-crd-publish-openapi-1011-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
May 29 17:57:07.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 explain e2e-test-crd-publish-openapi-1011-crds'
May 29 17:57:07.421: INFO: stderr: ""
May 29 17:57:07.421: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1011-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:57:11.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7093" for this suite.

• [SLOW TEST:9.083 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":277,"completed":198,"skipped":3263,"failed":0}
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:57:11.226: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 17:57:11.426: INFO: (0) /api/v1/nodes/node-cncf-lab-3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 23.30251ms)
May 29 17:57:11.440: INFO: (1) /api/v1/nodes/node-cncf-lab-3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.890595ms)
May 29 17:57:11.457: INFO: (2) /api/v1/nodes/node-cncf-lab-3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 16.390504ms)
May 29 17:57:11.518: INFO: (3) /api/v1/nodes/node-cncf-lab-3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 60.18714ms)
May 29 17:57:11.537: INFO: (4) /api/v1/nodes/node-cncf-lab-3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 19.11101ms)
May 29 17:57:11.558: INFO: (5) /api/v1/nodes/node-cncf-lab-3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 20.468085ms)
May 29 17:57:11.793: INFO: (6) /api/v1/nodes/node-cncf-lab-3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 234.86336ms)
May 29 17:57:11.815: INFO: (7) /api/v1/nodes/node-cncf-lab-3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 20.397492ms)
May 29 17:57:11.832: INFO: (8) /api/v1/nodes/node-cncf-lab-3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 16.970064ms)
May 29 17:57:11.846: INFO: (9) /api/v1/nodes/node-cncf-lab-3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.551495ms)
May 29 17:57:11.860: INFO: (10) /api/v1/nodes/node-cncf-lab-3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.724951ms)
May 29 17:57:11.874: INFO: (11) /api/v1/nodes/node-cncf-lab-3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.44548ms)
May 29 17:57:11.890: INFO: (12) /api/v1/nodes/node-cncf-lab-3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 16.429637ms)
May 29 17:57:11.908: INFO: (13) /api/v1/nodes/node-cncf-lab-3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 17.461246ms)
May 29 17:57:11.921: INFO: (14) /api/v1/nodes/node-cncf-lab-3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.19628ms)
May 29 17:57:11.935: INFO: (15) /api/v1/nodes/node-cncf-lab-3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.785656ms)
May 29 17:57:11.949: INFO: (16) /api/v1/nodes/node-cncf-lab-3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.780318ms)
May 29 17:57:11.964: INFO: (17) /api/v1/nodes/node-cncf-lab-3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.465817ms)
May 29 17:57:11.980: INFO: (18) /api/v1/nodes/node-cncf-lab-3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 15.667884ms)
May 29 17:57:11.998: INFO: (19) /api/v1/nodes/node-cncf-lab-3/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 17.976331ms)
[AfterEach] version v1
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:57:11.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1109" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node using proxy subresource  [Conformance]","total":277,"completed":199,"skipped":3264,"failed":0}
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:57:12.034: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
May 29 17:57:12.171: INFO: Waiting up to 5m0s for pod "downwardapi-volume-19aad461-fba3-4aae-b17d-d25edf269fa8" in namespace "downward-api-7771" to be "Succeeded or Failed"
May 29 17:57:12.186: INFO: Pod "downwardapi-volume-19aad461-fba3-4aae-b17d-d25edf269fa8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.689093ms
May 29 17:57:14.197: INFO: Pod "downwardapi-volume-19aad461-fba3-4aae-b17d-d25edf269fa8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025555324s
May 29 17:57:16.210: INFO: Pod "downwardapi-volume-19aad461-fba3-4aae-b17d-d25edf269fa8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039169627s
STEP: Saw pod success
May 29 17:57:16.211: INFO: Pod "downwardapi-volume-19aad461-fba3-4aae-b17d-d25edf269fa8" satisfied condition "Succeeded or Failed"
May 29 17:57:16.227: INFO: Trying to get logs from node node-cncf-lab-1 pod downwardapi-volume-19aad461-fba3-4aae-b17d-d25edf269fa8 container client-container: <nil>
STEP: delete the pod
May 29 17:57:16.341: INFO: Waiting for pod downwardapi-volume-19aad461-fba3-4aae-b17d-d25edf269fa8 to disappear
May 29 17:57:16.350: INFO: Pod downwardapi-volume-19aad461-fba3-4aae-b17d-d25edf269fa8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 17:57:16.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7771" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":277,"completed":200,"skipped":3267,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 17:57:16.432: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-6927
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
May 29 17:57:16.696: INFO: Found 0 stateful pods, waiting for 3
May 29 17:57:26.718: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 29 17:57:26.718: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 29 17:57:26.718: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
May 29 17:57:36.709: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 29 17:57:36.709: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 29 17:57:36.709: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May 29 17:57:36.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-6927 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 29 17:57:37.215: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 29 17:57:37.215: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 29 17:57:37.215: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
May 29 17:57:47.594: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
May 29 17:57:58.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-6927 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 17:57:58.663: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May 29 17:57:58.663: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 29 17:57:58.663: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 29 17:58:28.729: INFO: Waiting for StatefulSet statefulset-6927/ss2 to complete update
May 29 17:58:28.730: INFO: Waiting for Pod statefulset-6927/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
May 29 17:58:38.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-6927 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 29 17:58:39.208: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 29 17:58:39.208: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 29 17:58:39.208: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 29 17:58:49.379: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
May 29 17:58:59.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-6927 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 17:58:59.886: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May 29 17:58:59.886: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 29 17:58:59.886: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 29 17:59:09.989: INFO: Waiting for StatefulSet statefulset-6927/ss2 to complete update
May 29 17:59:09.989: INFO: Waiting for Pod statefulset-6927/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
May 29 17:59:09.989: INFO: Waiting for Pod statefulset-6927/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
May 29 17:59:09.989: INFO: Waiting for Pod statefulset-6927/ss2-2 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
May 29 17:59:20.061: INFO: Waiting for StatefulSet statefulset-6927/ss2 to complete update
May 29 17:59:20.061: INFO: Waiting for Pod statefulset-6927/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
May 29 17:59:30.016: INFO: Waiting for StatefulSet statefulset-6927/ss2 to complete update
May 29 17:59:30.017: INFO: Waiting for Pod statefulset-6927/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
May 29 17:59:40.015: INFO: Deleting all statefulset in ns statefulset-6927
May 29 17:59:40.028: INFO: Scaling statefulset ss2 to 0
May 29 18:00:20.192: INFO: Waiting for statefulset status.replicas updated to 0
May 29 18:00:20.212: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:00:20.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6927" for this suite.

• [SLOW TEST:183.867 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":277,"completed":201,"skipped":3317,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:00:20.299: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
May 29 18:00:21.085: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
May 29 18:00:23.324: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372021, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372021, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372021, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372021, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 29 18:00:26.367: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 18:00:26.382: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:00:29.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-9305" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:9.427 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":277,"completed":202,"skipped":3334,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:00:29.727: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 29 18:00:30.072: INFO: Number of nodes with available pods: 0
May 29 18:00:30.072: INFO: Node node-cncf-lab-1 is running more than one daemon pod
May 29 18:00:31.103: INFO: Number of nodes with available pods: 0
May 29 18:00:31.103: INFO: Node node-cncf-lab-1 is running more than one daemon pod
May 29 18:00:32.100: INFO: Number of nodes with available pods: 0
May 29 18:00:32.100: INFO: Node node-cncf-lab-1 is running more than one daemon pod
May 29 18:00:33.098: INFO: Number of nodes with available pods: 0
May 29 18:00:33.098: INFO: Node node-cncf-lab-1 is running more than one daemon pod
May 29 18:00:34.099: INFO: Number of nodes with available pods: 4
May 29 18:00:34.099: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
May 29 18:00:34.166: INFO: Number of nodes with available pods: 3
May 29 18:00:34.167: INFO: Node node-cncf-lab-3 is running more than one daemon pod
May 29 18:00:35.205: INFO: Number of nodes with available pods: 3
May 29 18:00:35.205: INFO: Node node-cncf-lab-3 is running more than one daemon pod
May 29 18:00:36.195: INFO: Number of nodes with available pods: 3
May 29 18:00:36.196: INFO: Node node-cncf-lab-3 is running more than one daemon pod
May 29 18:00:37.196: INFO: Number of nodes with available pods: 3
May 29 18:00:37.196: INFO: Node node-cncf-lab-3 is running more than one daemon pod
May 29 18:00:38.196: INFO: Number of nodes with available pods: 3
May 29 18:00:38.196: INFO: Node node-cncf-lab-3 is running more than one daemon pod
May 29 18:00:39.195: INFO: Number of nodes with available pods: 3
May 29 18:00:39.195: INFO: Node node-cncf-lab-3 is running more than one daemon pod
May 29 18:00:40.191: INFO: Number of nodes with available pods: 3
May 29 18:00:40.192: INFO: Node node-cncf-lab-3 is running more than one daemon pod
May 29 18:00:41.401: INFO: Number of nodes with available pods: 4
May 29 18:00:41.401: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9461, will wait for the garbage collector to delete the pods
May 29 18:00:41.551: INFO: Deleting DaemonSet.extensions daemon-set took: 47.837252ms
May 29 18:00:42.152: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.431322ms
May 29 18:00:53.161: INFO: Number of nodes with available pods: 0
May 29 18:00:53.161: INFO: Number of running nodes: 0, number of available pods: 0
May 29 18:00:53.185: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9461/daemonsets","resourceVersion":"12710725272"},"items":null}

May 29 18:00:53.197: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9461/pods","resourceVersion":"12710725297"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:00:53.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9461" for this suite.

• [SLOW TEST:24.165 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":277,"completed":203,"skipped":3345,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:00:53.896: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
May 29 18:00:54.035: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 18:00:57.756: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:01:12.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6195" for this suite.

• [SLOW TEST:18.404 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":277,"completed":204,"skipped":3357,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:01:12.303: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 18:01:12.422: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
May 29 18:01:16.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 --namespace=crd-publish-openapi-8876 create -f -'
May 29 18:01:16.762: INFO: stderr: ""
May 29 18:01:16.762: INFO: stdout: "e2e-test-crd-publish-openapi-4298-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
May 29 18:01:16.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 --namespace=crd-publish-openapi-8876 delete e2e-test-crd-publish-openapi-4298-crds test-cr'
May 29 18:01:16.956: INFO: stderr: ""
May 29 18:01:16.956: INFO: stdout: "e2e-test-crd-publish-openapi-4298-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
May 29 18:01:16.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 --namespace=crd-publish-openapi-8876 apply -f -'
May 29 18:01:17.278: INFO: stderr: ""
May 29 18:01:17.278: INFO: stdout: "e2e-test-crd-publish-openapi-4298-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
May 29 18:01:17.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 --namespace=crd-publish-openapi-8876 delete e2e-test-crd-publish-openapi-4298-crds test-cr'
May 29 18:01:17.454: INFO: stderr: ""
May 29 18:01:17.454: INFO: stdout: "e2e-test-crd-publish-openapi-4298-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
May 29 18:01:17.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 explain e2e-test-crd-publish-openapi-4298-crds'
May 29 18:01:17.692: INFO: stderr: ""
May 29 18:01:17.692: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4298-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:01:21.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8876" for this suite.

• [SLOW TEST:9.098 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":277,"completed":205,"skipped":3385,"failed":0}
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:01:21.404: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0529 18:01:31.811154      20 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 29 18:01:31.811: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:01:31.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8405" for this suite.

• [SLOW TEST:10.444 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":277,"completed":206,"skipped":3388,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:01:31.848: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:01:31.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-7400" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":277,"completed":207,"skipped":3396,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:01:32.007: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-5908
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-5908
I0529 18:01:32.218202      20 runners.go:190] Created replication controller with name: externalname-service, namespace: services-5908, replica count: 2
I0529 18:01:35.268926      20 runners.go:190] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 29 18:01:38.269: INFO: Creating new exec pod
I0529 18:01:38.269192      20 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 29 18:01:43.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=services-5908 execpodgkkg2 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
May 29 18:01:43.757: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
May 29 18:01:43.757: INFO: stdout: ""
May 29 18:01:43.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=services-5908 execpodgkkg2 -- /bin/sh -x -c nc -zv -t -w 2 10.3.240.74 80'
May 29 18:01:44.222: INFO: stderr: "+ nc -zv -t -w 2 10.3.240.74 80\nConnection to 10.3.240.74 80 port [tcp/http] succeeded!\n"
May 29 18:01:44.222: INFO: stdout: ""
May 29 18:01:44.222: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:01:44.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5908" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:12.370 seconds]
[sig-network] Services
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":277,"completed":208,"skipped":3413,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:01:44.377: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
May 29 18:01:44.531: INFO: Waiting up to 5m0s for pod "downward-api-a654b936-3f23-4909-9cf8-72d219164e4e" in namespace "downward-api-4985" to be "Succeeded or Failed"
May 29 18:01:44.545: INFO: Pod "downward-api-a654b936-3f23-4909-9cf8-72d219164e4e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.895134ms
May 29 18:01:46.630: INFO: Pod "downward-api-a654b936-3f23-4909-9cf8-72d219164e4e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.098247157s
May 29 18:01:48.646: INFO: Pod "downward-api-a654b936-3f23-4909-9cf8-72d219164e4e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.11410752s
STEP: Saw pod success
May 29 18:01:48.646: INFO: Pod "downward-api-a654b936-3f23-4909-9cf8-72d219164e4e" satisfied condition "Succeeded or Failed"
May 29 18:01:48.680: INFO: Trying to get logs from node node-cncf-lab-1 pod downward-api-a654b936-3f23-4909-9cf8-72d219164e4e container dapi-container: <nil>
STEP: delete the pod
May 29 18:01:49.668: INFO: Waiting for pod downward-api-a654b936-3f23-4909-9cf8-72d219164e4e to disappear
May 29 18:01:49.679: INFO: Pod downward-api-a654b936-3f23-4909-9cf8-72d219164e4e no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:01:49.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4985" for this suite.

• [SLOW TEST:5.378 seconds]
[sig-node] Downward API
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:34
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":277,"completed":209,"skipped":3435,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:01:49.756: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-07b1734c-2250-4857-bdba-c22b875ee801
STEP: Creating a pod to test consume secrets
May 29 18:01:50.138: INFO: Waiting up to 5m0s for pod "pod-secrets-4da2f661-95a3-465a-9eec-c01dd0a0a176" in namespace "secrets-3530" to be "Succeeded or Failed"
May 29 18:01:50.162: INFO: Pod "pod-secrets-4da2f661-95a3-465a-9eec-c01dd0a0a176": Phase="Pending", Reason="", readiness=false. Elapsed: 24.298667ms
May 29 18:01:52.249: INFO: Pod "pod-secrets-4da2f661-95a3-465a-9eec-c01dd0a0a176": Phase="Pending", Reason="", readiness=false. Elapsed: 2.111374411s
May 29 18:01:54.268: INFO: Pod "pod-secrets-4da2f661-95a3-465a-9eec-c01dd0a0a176": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.130032113s
STEP: Saw pod success
May 29 18:01:54.268: INFO: Pod "pod-secrets-4da2f661-95a3-465a-9eec-c01dd0a0a176" satisfied condition "Succeeded or Failed"
May 29 18:01:54.278: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-secrets-4da2f661-95a3-465a-9eec-c01dd0a0a176 container secret-volume-test: <nil>
STEP: delete the pod
May 29 18:01:54.817: INFO: Waiting for pod pod-secrets-4da2f661-95a3-465a-9eec-c01dd0a0a176 to disappear
May 29 18:01:54.877: INFO: Pod pod-secrets-4da2f661-95a3-465a-9eec-c01dd0a0a176 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:01:54.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3530" for this suite.
STEP: Destroying namespace "secret-namespace-439" for this suite.

• [SLOW TEST:5.217 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":277,"completed":210,"skipped":3448,"failed":0}
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:01:54.973: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
May 29 18:01:55.125: INFO: Waiting up to 5m0s for pod "pod-918697ea-acf9-4078-9b7f-d928efffcaa2" in namespace "emptydir-9075" to be "Succeeded or Failed"
May 29 18:01:55.150: INFO: Pod "pod-918697ea-acf9-4078-9b7f-d928efffcaa2": Phase="Pending", Reason="", readiness=false. Elapsed: 24.930691ms
May 29 18:01:57.166: INFO: Pod "pod-918697ea-acf9-4078-9b7f-d928efffcaa2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040407701s
May 29 18:01:59.179: INFO: Pod "pod-918697ea-acf9-4078-9b7f-d928efffcaa2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.053372283s
May 29 18:02:01.195: INFO: Pod "pod-918697ea-acf9-4078-9b7f-d928efffcaa2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.06901285s
STEP: Saw pod success
May 29 18:02:01.195: INFO: Pod "pod-918697ea-acf9-4078-9b7f-d928efffcaa2" satisfied condition "Succeeded or Failed"
May 29 18:02:01.204: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-918697ea-acf9-4078-9b7f-d928efffcaa2 container test-container: <nil>
STEP: delete the pod
May 29 18:02:01.347: INFO: Waiting for pod pod-918697ea-acf9-4078-9b7f-d928efffcaa2 to disappear
May 29 18:02:01.356: INFO: Pod pod-918697ea-acf9-4078-9b7f-d928efffcaa2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:02:01.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9075" for this suite.

• [SLOW TEST:6.415 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":211,"skipped":3451,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:02:01.391: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-4332
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating stateful set ss in namespace statefulset-4332
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4332
May 29 18:02:01.557: INFO: Found 0 stateful pods, waiting for 1
May 29 18:02:11.572: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
May 29 18:02:11.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-4332 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 29 18:02:12.034: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 29 18:02:12.034: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 29 18:02:12.034: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 29 18:02:12.048: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 29 18:02:22.088: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 29 18:02:22.088: INFO: Waiting for statefulset status.replicas updated to 0
May 29 18:02:22.141: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
May 29 18:02:22.141: INFO: ss-0  node-cncf-lab-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:12 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:12 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:01 +0000 UTC  }]
May 29 18:02:22.141: INFO: 
May 29 18:02:22.141: INFO: StatefulSet ss has not reached scale 3, at 1
May 29 18:02:23.154: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.985716174s
May 29 18:02:24.169: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.972793392s
May 29 18:02:25.183: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.957923002s
May 29 18:02:26.196: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.943691602s
May 29 18:02:27.209: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.930909487s
May 29 18:02:28.224: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.917729681s
May 29 18:02:29.240: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.902332032s
May 29 18:02:30.255: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.886917705s
May 29 18:02:31.268: INFO: Verifying statefulset ss doesn't scale past 3 for another 871.828359ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4332
May 29 18:02:32.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-4332 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:02:32.702: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May 29 18:02:32.702: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 29 18:02:32.702: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 29 18:02:32.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-4332 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:02:33.148: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May 29 18:02:33.148: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 29 18:02:33.148: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 29 18:02:33.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-4332 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:02:33.572: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May 29 18:02:33.573: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 29 18:02:33.573: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 29 18:02:33.583: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 29 18:02:33.583: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 29 18:02:33.583: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
May 29 18:02:33.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-4332 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 29 18:02:33.947: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 29 18:02:33.947: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 29 18:02:33.947: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 29 18:02:33.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-4332 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 29 18:02:34.408: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 29 18:02:34.410: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 29 18:02:34.410: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 29 18:02:34.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-4332 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 29 18:02:35.413: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 29 18:02:35.414: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 29 18:02:35.414: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 29 18:02:35.414: INFO: Waiting for statefulset status.replicas updated to 0
May 29 18:02:35.429: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
May 29 18:02:45.455: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 29 18:02:45.455: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 29 18:02:45.456: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 29 18:02:45.667: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
May 29 18:02:45.667: INFO: ss-0  node-cncf-lab-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:01 +0000 UTC  }]
May 29 18:02:45.668: INFO: ss-1  node-cncf-lab-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  }]
May 29 18:02:45.668: INFO: ss-2  node-cncf-lab-4  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  }]
May 29 18:02:45.668: INFO: 
May 29 18:02:45.668: INFO: StatefulSet ss has not reached scale 0, at 3
May 29 18:02:46.682: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
May 29 18:02:46.682: INFO: ss-0  node-cncf-lab-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:01 +0000 UTC  }]
May 29 18:02:46.682: INFO: ss-1  node-cncf-lab-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  }]
May 29 18:02:46.682: INFO: ss-2  node-cncf-lab-4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  }]
May 29 18:02:46.682: INFO: 
May 29 18:02:46.682: INFO: StatefulSet ss has not reached scale 0, at 3
May 29 18:02:47.695: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
May 29 18:02:47.695: INFO: ss-0  node-cncf-lab-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:01 +0000 UTC  }]
May 29 18:02:47.695: INFO: ss-1  node-cncf-lab-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  }]
May 29 18:02:47.695: INFO: ss-2  node-cncf-lab-4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  }]
May 29 18:02:47.695: INFO: 
May 29 18:02:47.695: INFO: StatefulSet ss has not reached scale 0, at 3
May 29 18:02:48.714: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
May 29 18:02:48.714: INFO: ss-0  node-cncf-lab-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:01 +0000 UTC  }]
May 29 18:02:48.718: INFO: ss-1  node-cncf-lab-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  }]
May 29 18:02:48.718: INFO: 
May 29 18:02:48.718: INFO: StatefulSet ss has not reached scale 0, at 2
May 29 18:02:49.745: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
May 29 18:02:49.745: INFO: ss-0  node-cncf-lab-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:01 +0000 UTC  }]
May 29 18:02:49.745: INFO: ss-1  node-cncf-lab-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  }]
May 29 18:02:49.745: INFO: 
May 29 18:02:49.745: INFO: StatefulSet ss has not reached scale 0, at 2
May 29 18:02:50.761: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
May 29 18:02:50.761: INFO: ss-1  node-cncf-lab-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  }]
May 29 18:02:50.761: INFO: 
May 29 18:02:50.761: INFO: StatefulSet ss has not reached scale 0, at 1
May 29 18:02:52.164: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
May 29 18:02:52.164: INFO: ss-1  node-cncf-lab-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  }]
May 29 18:02:52.164: INFO: 
May 29 18:02:52.164: INFO: StatefulSet ss has not reached scale 0, at 1
May 29 18:02:53.180: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
May 29 18:02:53.180: INFO: ss-1  node-cncf-lab-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  }]
May 29 18:02:53.181: INFO: 
May 29 18:02:53.181: INFO: StatefulSet ss has not reached scale 0, at 1
May 29 18:02:54.228: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
May 29 18:02:54.228: INFO: ss-1  node-cncf-lab-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  }]
May 29 18:02:54.228: INFO: 
May 29 18:02:54.228: INFO: StatefulSet ss has not reached scale 0, at 1
May 29 18:02:55.247: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
May 29 18:02:55.247: INFO: ss-1  node-cncf-lab-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-29 18:02:22 +0000 UTC  }]
May 29 18:02:55.247: INFO: 
May 29 18:02:55.247: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4332
May 29 18:02:56.257: INFO: Scaling statefulset ss to 0
May 29 18:02:56.306: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
May 29 18:02:56.315: INFO: Deleting all statefulset in ns statefulset-4332
May 29 18:02:56.907: INFO: Scaling statefulset ss to 0
May 29 18:02:56.979: INFO: Waiting for statefulset status.replicas updated to 0
May 29 18:02:56.991: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:02:57.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4332" for this suite.

• [SLOW TEST:55.918 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":277,"completed":212,"skipped":3491,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:02:57.313: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
May 29 18:02:57.952: INFO: namespace kubectl-7664
May 29 18:02:57.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 create -f - --namespace=kubectl-7664'
May 29 18:02:58.345: INFO: stderr: ""
May 29 18:02:58.345: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
May 29 18:02:59.359: INFO: Selector matched 1 pods for map[app:agnhost]
May 29 18:02:59.359: INFO: Found 0 / 1
May 29 18:03:00.650: INFO: Selector matched 1 pods for map[app:agnhost]
May 29 18:03:00.650: INFO: Found 0 / 1
May 29 18:03:01.377: INFO: Selector matched 1 pods for map[app:agnhost]
May 29 18:03:01.377: INFO: Found 0 / 1
May 29 18:03:02.363: INFO: Selector matched 1 pods for map[app:agnhost]
May 29 18:03:02.363: INFO: Found 0 / 1
May 29 18:03:03.394: INFO: Selector matched 1 pods for map[app:agnhost]
May 29 18:03:03.394: INFO: Found 1 / 1
May 29 18:03:03.394: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 29 18:03:03.415: INFO: Selector matched 1 pods for map[app:agnhost]
May 29 18:03:03.415: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 29 18:03:03.415: INFO: wait on agnhost-master startup in kubectl-7664 
May 29 18:03:03.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 logs agnhost-master-8lf7r agnhost-master --namespace=kubectl-7664'
May 29 18:03:03.736: INFO: stderr: ""
May 29 18:03:03.736: INFO: stdout: "Paused\n"
STEP: exposing RC
May 29 18:03:03.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 expose rc agnhost-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-7664'
May 29 18:03:03.943: INFO: stderr: ""
May 29 18:03:03.943: INFO: stdout: "service/rm2 exposed\n"
May 29 18:03:03.973: INFO: Service rm2 in namespace kubectl-7664 found.
STEP: exposing service
May 29 18:03:05.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-7664'
May 29 18:03:06.197: INFO: stderr: ""
May 29 18:03:06.197: INFO: stdout: "service/rm3 exposed\n"
May 29 18:03:06.213: INFO: Service rm3 in namespace kubectl-7664 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:03:08.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7664" for this suite.

• [SLOW TEST:11.593 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1119
    should create services for rc  [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":277,"completed":213,"skipped":3515,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:03:08.907: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 29 18:03:09.897: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 29 18:03:11.930: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372189, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372189, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372189, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372189, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 29 18:03:15.201: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:03:15.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3239" for this suite.
STEP: Destroying namespace "webhook-3239-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.698 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":277,"completed":214,"skipped":3546,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:03:15.605: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 29 18:03:16.323: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 29 18:03:18.443: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372196, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372196, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372196, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372196, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 18:03:20.454: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372196, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372196, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372196, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372196, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 29 18:03:23.513: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:03:24.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8501" for this suite.
STEP: Destroying namespace "webhook-8501-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:9.358 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":277,"completed":215,"skipped":3555,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:03:24.965: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2085.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2085.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2085.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2085.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 29 18:03:31.468: INFO: DNS probes using dns-test-e5eac397-796b-4e4a-b7ea-a828da4fe608 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2085.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2085.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2085.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2085.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 29 18:03:37.918: INFO: File wheezy_udp@dns-test-service-3.dns-2085.svc.cluster.local from pod  dns-2085/dns-test-3bf22238-c9aa-44c7-af3c-94310d49d9ac contains 'foo.example.com.
' instead of 'bar.example.com.'
May 29 18:03:37.933: INFO: File jessie_udp@dns-test-service-3.dns-2085.svc.cluster.local from pod  dns-2085/dns-test-3bf22238-c9aa-44c7-af3c-94310d49d9ac contains 'foo.example.com.
' instead of 'bar.example.com.'
May 29 18:03:37.933: INFO: Lookups using dns-2085/dns-test-3bf22238-c9aa-44c7-af3c-94310d49d9ac failed for: [wheezy_udp@dns-test-service-3.dns-2085.svc.cluster.local jessie_udp@dns-test-service-3.dns-2085.svc.cluster.local]

May 29 18:03:42.957: INFO: File wheezy_udp@dns-test-service-3.dns-2085.svc.cluster.local from pod  dns-2085/dns-test-3bf22238-c9aa-44c7-af3c-94310d49d9ac contains 'foo.example.com.
' instead of 'bar.example.com.'
May 29 18:03:42.971: INFO: File jessie_udp@dns-test-service-3.dns-2085.svc.cluster.local from pod  dns-2085/dns-test-3bf22238-c9aa-44c7-af3c-94310d49d9ac contains 'foo.example.com.
' instead of 'bar.example.com.'
May 29 18:03:42.971: INFO: Lookups using dns-2085/dns-test-3bf22238-c9aa-44c7-af3c-94310d49d9ac failed for: [wheezy_udp@dns-test-service-3.dns-2085.svc.cluster.local jessie_udp@dns-test-service-3.dns-2085.svc.cluster.local]

May 29 18:03:47.952: INFO: File wheezy_udp@dns-test-service-3.dns-2085.svc.cluster.local from pod  dns-2085/dns-test-3bf22238-c9aa-44c7-af3c-94310d49d9ac contains 'foo.example.com.
' instead of 'bar.example.com.'
May 29 18:03:47.968: INFO: File jessie_udp@dns-test-service-3.dns-2085.svc.cluster.local from pod  dns-2085/dns-test-3bf22238-c9aa-44c7-af3c-94310d49d9ac contains 'foo.example.com.
' instead of 'bar.example.com.'
May 29 18:03:47.968: INFO: Lookups using dns-2085/dns-test-3bf22238-c9aa-44c7-af3c-94310d49d9ac failed for: [wheezy_udp@dns-test-service-3.dns-2085.svc.cluster.local jessie_udp@dns-test-service-3.dns-2085.svc.cluster.local]

May 29 18:03:53.054: INFO: File wheezy_udp@dns-test-service-3.dns-2085.svc.cluster.local from pod  dns-2085/dns-test-3bf22238-c9aa-44c7-af3c-94310d49d9ac contains 'foo.example.com.
' instead of 'bar.example.com.'
May 29 18:03:53.070: INFO: File jessie_udp@dns-test-service-3.dns-2085.svc.cluster.local from pod  dns-2085/dns-test-3bf22238-c9aa-44c7-af3c-94310d49d9ac contains 'foo.example.com.
' instead of 'bar.example.com.'
May 29 18:03:53.070: INFO: Lookups using dns-2085/dns-test-3bf22238-c9aa-44c7-af3c-94310d49d9ac failed for: [wheezy_udp@dns-test-service-3.dns-2085.svc.cluster.local jessie_udp@dns-test-service-3.dns-2085.svc.cluster.local]

May 29 18:03:57.947: INFO: File wheezy_udp@dns-test-service-3.dns-2085.svc.cluster.local from pod  dns-2085/dns-test-3bf22238-c9aa-44c7-af3c-94310d49d9ac contains 'foo.example.com.
' instead of 'bar.example.com.'
May 29 18:03:57.959: INFO: File jessie_udp@dns-test-service-3.dns-2085.svc.cluster.local from pod  dns-2085/dns-test-3bf22238-c9aa-44c7-af3c-94310d49d9ac contains 'foo.example.com.
' instead of 'bar.example.com.'
May 29 18:03:57.959: INFO: Lookups using dns-2085/dns-test-3bf22238-c9aa-44c7-af3c-94310d49d9ac failed for: [wheezy_udp@dns-test-service-3.dns-2085.svc.cluster.local jessie_udp@dns-test-service-3.dns-2085.svc.cluster.local]

May 29 18:04:02.963: INFO: DNS probes using dns-test-3bf22238-c9aa-44c7-af3c-94310d49d9ac succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2085.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-2085.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2085.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-2085.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 29 18:04:09.168: INFO: DNS probes using dns-test-80a50cdb-550e-44f7-a879-f990377014bd succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:04:09.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2085" for this suite.

• [SLOW TEST:44.326 seconds]
[sig-network] DNS
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":277,"completed":216,"skipped":3568,"failed":0}
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:04:09.292: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-5336
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 29 18:04:09.418: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
May 29 18:04:09.521: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May 29 18:04:11.532: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May 29 18:04:13.535: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 18:04:15.533: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 18:04:17.530: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 18:04:19.535: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 18:04:21.533: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 18:04:23.535: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 18:04:25.532: INFO: The status of Pod netserver-0 is Running (Ready = true)
May 29 18:04:25.559: INFO: The status of Pod netserver-1 is Running (Ready = false)
May 29 18:04:27.569: INFO: The status of Pod netserver-1 is Running (Ready = false)
May 29 18:04:29.571: INFO: The status of Pod netserver-1 is Running (Ready = true)
May 29 18:04:29.594: INFO: The status of Pod netserver-2 is Running (Ready = true)
May 29 18:04:29.615: INFO: The status of Pod netserver-3 is Running (Ready = true)
STEP: Creating test pods
May 29 18:04:33.716: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.2.40:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5336 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 18:04:33.716: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 18:04:33.972: INFO: Found all expected endpoints: [netserver-0]
May 29 18:04:33.992: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.0.49:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5336 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 18:04:33.992: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 18:04:34.251: INFO: Found all expected endpoints: [netserver-1]
May 29 18:04:34.262: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.3.92:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5336 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 18:04:34.263: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 18:04:34.581: INFO: Found all expected endpoints: [netserver-2]
May 29 18:04:34.597: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.1.98:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5336 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 18:04:34.597: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 18:04:35.026: INFO: Found all expected endpoints: [netserver-3]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:04:35.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5336" for this suite.

• [SLOW TEST:26.147 seconds]
[sig-network] Networking
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":217,"skipped":3571,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:04:35.450: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3411.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3411.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3411.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3411.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3411.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3411.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 29 18:04:42.587: INFO: DNS probes using dns-3411/dns-test-6a6a6749-4f78-4dde-9335-0e5e357a26e2 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:04:42.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3411" for this suite.

• [SLOW TEST:7.271 seconds]
[sig-network] DNS
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":277,"completed":218,"skipped":3667,"failed":0}
SS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:04:42.722: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-57c6ff1b-7f84-4af5-a2b6-118d13e8d440
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:04:49.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9976" for this suite.

• [SLOW TEST:6.800 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":219,"skipped":3669,"failed":0}
SS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:04:49.531: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-projected-all-test-volume-07913b4e-e102-4340-bbf7-9eb87ae8e208
STEP: Creating secret with name secret-projected-all-test-volume-5afa4770-c1fa-47dc-aaf9-e7095a4781bb
STEP: Creating a pod to test Check all projections for projected volume plugin
May 29 18:04:49.702: INFO: Waiting up to 5m0s for pod "projected-volume-bdac09d2-9c05-4500-9409-5792199bfb38" in namespace "projected-7142" to be "Succeeded or Failed"
May 29 18:04:49.712: INFO: Pod "projected-volume-bdac09d2-9c05-4500-9409-5792199bfb38": Phase="Pending", Reason="", readiness=false. Elapsed: 10.294601ms
May 29 18:04:51.727: INFO: Pod "projected-volume-bdac09d2-9c05-4500-9409-5792199bfb38": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024692855s
May 29 18:04:53.752: INFO: Pod "projected-volume-bdac09d2-9c05-4500-9409-5792199bfb38": Phase="Pending", Reason="", readiness=false. Elapsed: 4.049988759s
May 29 18:04:55.765: INFO: Pod "projected-volume-bdac09d2-9c05-4500-9409-5792199bfb38": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.062548896s
STEP: Saw pod success
May 29 18:04:55.765: INFO: Pod "projected-volume-bdac09d2-9c05-4500-9409-5792199bfb38" satisfied condition "Succeeded or Failed"
May 29 18:04:55.778: INFO: Trying to get logs from node node-cncf-lab-3 pod projected-volume-bdac09d2-9c05-4500-9409-5792199bfb38 container projected-all-volume-test: <nil>
STEP: delete the pod
May 29 18:04:55.934: INFO: Waiting for pod projected-volume-bdac09d2-9c05-4500-9409-5792199bfb38 to disappear
May 29 18:04:55.943: INFO: Pod projected-volume-bdac09d2-9c05-4500-9409-5792199bfb38 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:04:55.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7142" for this suite.

• [SLOW TEST:6.453 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":277,"completed":220,"skipped":3671,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:04:55.989: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with configMap that has name projected-configmap-test-upd-c1484e83-4a70-406d-9d33-edefa59dc97a
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-c1484e83-4a70-406d-9d33-edefa59dc97a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:06:06.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7818" for this suite.

• [SLOW TEST:70.663 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":221,"skipped":3695,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:06:06.654: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-3b638b8c-b356-4fb5-918c-fb5700afa77e in namespace container-probe-1828
May 29 18:06:10.931: INFO: Started pod liveness-3b638b8c-b356-4fb5-918c-fb5700afa77e in namespace container-probe-1828
STEP: checking the pod's current state and verifying that restartCount is present
May 29 18:06:10.960: INFO: Initial restart count of pod liveness-3b638b8c-b356-4fb5-918c-fb5700afa77e is 0
May 29 18:06:31.231: INFO: Restart count of pod container-probe-1828/liveness-3b638b8c-b356-4fb5-918c-fb5700afa77e is now 1 (20.271312617s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:06:31.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1828" for this suite.

• [SLOW TEST:24.744 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":277,"completed":222,"skipped":3710,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:06:31.399: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:06:48.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3216" for this suite.

• [SLOW TEST:17.146 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":277,"completed":223,"skipped":3718,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:06:48.556: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 18:06:48.721: INFO: Creating deployment "test-recreate-deployment"
May 29 18:06:48.737: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
May 29 18:06:48.767: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
May 29 18:06:51.086: INFO: Waiting deployment "test-recreate-deployment" to complete
May 29 18:06:51.107: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372408, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372408, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372408, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372408, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 18:06:53.699: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372408, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372408, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372408, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372408, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 18:06:55.119: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
May 29 18:06:55.160: INFO: Updating deployment test-recreate-deployment
May 29 18:06:55.160: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
May 29 18:06:55.330: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-3189 /apis/apps/v1/namespaces/deployment-3189/deployments/test-recreate-deployment fc2fc7ff-3b40-44fc-962e-e71ff8284e21 12710865599 2 2020-05-29 18:06:48 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-05-29 18:06:55 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-05-29 18:06:55 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005ca2778 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-05-29 18:06:55 +0000 UTC,LastTransitionTime:2020-05-29 18:06:55 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-d5667d9c7" is progressing.,LastUpdateTime:2020-05-29 18:06:55 +0000 UTC,LastTransitionTime:2020-05-29 18:06:48 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

May 29 18:06:55.341: INFO: New ReplicaSet "test-recreate-deployment-d5667d9c7" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-d5667d9c7  deployment-3189 /apis/apps/v1/namespaces/deployment-3189/replicasets/test-recreate-deployment-d5667d9c7 e18a9f72-8174-41aa-8a7c-8eae56feb704 12710865596 1 2020-05-29 18:06:55 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment fc2fc7ff-3b40-44fc-962e-e71ff8284e21 0xc005ca2ce0 0xc005ca2ce1}] []  [{kube-controller-manager Update apps/v1 2020-05-29 18:06:55 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 99 50 102 99 55 102 102 45 51 98 52 48 45 52 52 102 99 45 57 54 50 101 45 101 55 49 102 102 56 50 56 52 101 50 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: d5667d9c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005ca2d58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May 29 18:06:55.341: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
May 29 18:06:55.342: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-74d98b5f7c  deployment-3189 /apis/apps/v1/namespaces/deployment-3189/replicasets/test-recreate-deployment-74d98b5f7c 48644f63-66c2-499a-ad04-33e34472e801 12710865577 2 2020-05-29 18:06:48 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment fc2fc7ff-3b40-44fc-962e-e71ff8284e21 0xc005ca2be7 0xc005ca2be8}] []  [{kube-controller-manager Update apps/v1 2020-05-29 18:06:55 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 99 50 102 99 55 102 102 45 51 98 52 48 45 52 52 102 99 45 57 54 50 101 45 101 55 49 102 102 56 50 56 52 101 50 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 74d98b5f7c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005ca2c78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May 29 18:06:55.359: INFO: Pod "test-recreate-deployment-d5667d9c7-4hp9b" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-d5667d9c7-4hp9b test-recreate-deployment-d5667d9c7- deployment-3189 /api/v1/namespaces/deployment-3189/pods/test-recreate-deployment-d5667d9c7-4hp9b 8414c32e-bbfc-439e-a4aa-b13a8a56f0d7 12710865605 0 2020-05-29 18:06:55 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[] [{apps/v1 ReplicaSet test-recreate-deployment-d5667d9c7 e18a9f72-8174-41aa-8a7c-8eae56feb704 0xc005ca3260 0xc005ca3261}] []  [{kube-controller-manager Update v1 2020-05-29 18:06:55 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 49 56 97 57 102 55 50 45 56 49 55 52 45 52 49 97 97 45 56 97 55 99 45 56 101 97 101 53 54 102 101 98 55 48 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-05-29 18:06:55 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nxstj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nxstj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nxstj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-cncf-lab-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 18:06:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 18:06:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 18:06:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-29 18:06:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:51.83.108.252,PodIP:,StartTime:2020-05-29 18:06:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:06:55.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3189" for this suite.

• [SLOW TEST:6.844 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":277,"completed":224,"skipped":3728,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:06:55.401: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override arguments
May 29 18:06:55.604: INFO: Waiting up to 5m0s for pod "client-containers-68c34138-11e3-4259-8a8f-361e97c5b987" in namespace "containers-4901" to be "Succeeded or Failed"
May 29 18:06:55.611: INFO: Pod "client-containers-68c34138-11e3-4259-8a8f-361e97c5b987": Phase="Pending", Reason="", readiness=false. Elapsed: 7.870103ms
May 29 18:06:57.624: INFO: Pod "client-containers-68c34138-11e3-4259-8a8f-361e97c5b987": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019942792s
May 29 18:06:59.636: INFO: Pod "client-containers-68c34138-11e3-4259-8a8f-361e97c5b987": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032391925s
STEP: Saw pod success
May 29 18:06:59.636: INFO: Pod "client-containers-68c34138-11e3-4259-8a8f-361e97c5b987" satisfied condition "Succeeded or Failed"
May 29 18:06:59.646: INFO: Trying to get logs from node node-cncf-lab-1 pod client-containers-68c34138-11e3-4259-8a8f-361e97c5b987 container test-container: <nil>
STEP: delete the pod
May 29 18:06:59.807: INFO: Waiting for pod client-containers-68c34138-11e3-4259-8a8f-361e97c5b987 to disappear
May 29 18:06:59.819: INFO: Pod client-containers-68c34138-11e3-4259-8a8f-361e97c5b987 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:06:59.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4901" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":277,"completed":225,"skipped":3744,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:06:59.877: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
May 29 18:07:00.078: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4040 /api/v1/namespaces/watch-4040/configmaps/e2e-watch-test-configmap-a e2bd0eb1-71de-4233-a046-4b34be1601fd 12710867224 0 2020-05-29 18:07:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-05-29 18:07:00 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
May 29 18:07:00.079: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4040 /api/v1/namespaces/watch-4040/configmaps/e2e-watch-test-configmap-a e2bd0eb1-71de-4233-a046-4b34be1601fd 12710867224 0 2020-05-29 18:07:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-05-29 18:07:00 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
May 29 18:07:10.131: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4040 /api/v1/namespaces/watch-4040/configmaps/e2e-watch-test-configmap-a e2bd0eb1-71de-4233-a046-4b34be1601fd 12710870543 0 2020-05-29 18:07:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-05-29 18:07:10 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
May 29 18:07:10.132: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4040 /api/v1/namespaces/watch-4040/configmaps/e2e-watch-test-configmap-a e2bd0eb1-71de-4233-a046-4b34be1601fd 12710870543 0 2020-05-29 18:07:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-05-29 18:07:10 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
May 29 18:07:20.843: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4040 /api/v1/namespaces/watch-4040/configmaps/e2e-watch-test-configmap-a e2bd0eb1-71de-4233-a046-4b34be1601fd 12710873842 0 2020-05-29 18:07:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-05-29 18:07:20 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
May 29 18:07:20.843: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4040 /api/v1/namespaces/watch-4040/configmaps/e2e-watch-test-configmap-a e2bd0eb1-71de-4233-a046-4b34be1601fd 12710873842 0 2020-05-29 18:07:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-05-29 18:07:20 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
May 29 18:07:30.880: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4040 /api/v1/namespaces/watch-4040/configmaps/e2e-watch-test-configmap-a e2bd0eb1-71de-4233-a046-4b34be1601fd 12710877488 0 2020-05-29 18:07:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-05-29 18:07:20 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
May 29 18:07:30.880: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4040 /api/v1/namespaces/watch-4040/configmaps/e2e-watch-test-configmap-a e2bd0eb1-71de-4233-a046-4b34be1601fd 12710877488 0 2020-05-29 18:07:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-05-29 18:07:20 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
May 29 18:07:41.314: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4040 /api/v1/namespaces/watch-4040/configmaps/e2e-watch-test-configmap-b 8eb34075-e284-4b5f-870c-883d1436a3c1 12710880958 0 2020-05-29 18:07:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-05-29 18:07:40 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
May 29 18:07:41.315: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4040 /api/v1/namespaces/watch-4040/configmaps/e2e-watch-test-configmap-b 8eb34075-e284-4b5f-870c-883d1436a3c1 12710880958 0 2020-05-29 18:07:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-05-29 18:07:40 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
May 29 18:07:51.361: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4040 /api/v1/namespaces/watch-4040/configmaps/e2e-watch-test-configmap-b 8eb34075-e284-4b5f-870c-883d1436a3c1 12710884201 0 2020-05-29 18:07:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-05-29 18:07:40 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
May 29 18:07:51.361: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4040 /api/v1/namespaces/watch-4040/configmaps/e2e-watch-test-configmap-b 8eb34075-e284-4b5f-870c-883d1436a3c1 12710884201 0 2020-05-29 18:07:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-05-29 18:07:40 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:08:01.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4040" for this suite.

• [SLOW TEST:61.550 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":277,"completed":226,"skipped":3761,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:08:01.427: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service nodeport-test with type=NodePort in namespace services-2304
STEP: creating replication controller nodeport-test in namespace services-2304
I0529 18:08:01.569970      20 runners.go:190] Created replication controller with name: nodeport-test, namespace: services-2304, replica count: 2
I0529 18:08:04.621060      20 runners.go:190] nodeport-test Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 18:08:07.621791      20 runners.go:190] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 29 18:08:07.622: INFO: Creating new exec pod
May 29 18:08:12.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=services-2304 execpod6mbhs -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
May 29 18:08:13.445: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
May 29 18:08:13.445: INFO: stdout: ""
May 29 18:08:13.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=services-2304 execpod6mbhs -- /bin/sh -x -c nc -zv -t -w 2 10.3.189.117 80'
May 29 18:08:13.883: INFO: stderr: "+ nc -zv -t -w 2 10.3.189.117 80\nConnection to 10.3.189.117 80 port [tcp/http] succeeded!\n"
May 29 18:08:13.883: INFO: stdout: ""
May 29 18:08:13.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=services-2304 execpod6mbhs -- /bin/sh -x -c nc -zv -t -w 2 51.178.95.196 30999'
May 29 18:08:14.298: INFO: stderr: "+ nc -zv -t -w 2 51.178.95.196 30999\nConnection to 51.178.95.196 30999 port [tcp/30999] succeeded!\n"
May 29 18:08:14.298: INFO: stdout: ""
May 29 18:08:14.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=services-2304 execpod6mbhs -- /bin/sh -x -c nc -zv -t -w 2 51.75.198.105 30999'
May 29 18:08:14.777: INFO: stderr: "+ nc -zv -t -w 2 51.75.198.105 30999\nConnection to 51.75.198.105 30999 port [tcp/30999] succeeded!\n"
May 29 18:08:14.777: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:08:14.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2304" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:13.384 seconds]
[sig-network] Services
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":277,"completed":227,"skipped":3784,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:08:14.813: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 29 18:08:15.497: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 29 18:08:17.524: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372495, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372495, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372495, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372495, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 18:08:19.543: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372495, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372495, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372495, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726372495, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 29 18:08:22.581: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:08:22.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2941" for this suite.
STEP: Destroying namespace "webhook-2941-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:8.061 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":277,"completed":228,"skipped":3792,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Lease 
  lease API should be available [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Lease
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:08:22.879: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename lease-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Lease
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:08:23.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-8671" for this suite.
•{"msg":"PASSED [k8s.io] Lease lease API should be available [Conformance]","total":277,"completed":229,"skipped":3808,"failed":0}
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:08:23.254: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-3877
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 29 18:08:23.387: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
May 29 18:08:23.487: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May 29 18:08:25.504: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May 29 18:08:27.497: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 18:08:29.508: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 18:08:31.502: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 18:08:33.509: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 18:08:35.499: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 18:08:37.502: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 29 18:08:39.501: INFO: The status of Pod netserver-0 is Running (Ready = true)
May 29 18:08:39.521: INFO: The status of Pod netserver-1 is Running (Ready = true)
May 29 18:08:39.541: INFO: The status of Pod netserver-2 is Running (Ready = true)
May 29 18:08:39.565: INFO: The status of Pod netserver-3 is Running (Ready = false)
May 29 18:08:41.581: INFO: The status of Pod netserver-3 is Running (Ready = false)
May 29 18:08:43.578: INFO: The status of Pod netserver-3 is Running (Ready = true)
STEP: Creating test pods
May 29 18:08:49.662: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.2.53:8080/dial?request=hostname&protocol=udp&host=10.2.2.52&port=8081&tries=1'] Namespace:pod-network-test-3877 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 18:08:49.662: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 18:08:49.946: INFO: Waiting for responses: map[]
May 29 18:08:49.957: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.2.53:8080/dial?request=hostname&protocol=udp&host=10.2.0.50&port=8081&tries=1'] Namespace:pod-network-test-3877 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 18:08:49.957: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 18:08:50.237: INFO: Waiting for responses: map[]
May 29 18:08:50.249: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.2.53:8080/dial?request=hostname&protocol=udp&host=10.2.3.97&port=8081&tries=1'] Namespace:pod-network-test-3877 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 18:08:50.249: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 18:08:50.498: INFO: Waiting for responses: map[]
May 29 18:08:50.509: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.2.53:8080/dial?request=hostname&protocol=udp&host=10.2.1.99&port=8081&tries=1'] Namespace:pod-network-test-3877 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 18:08:50.509: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
May 29 18:08:50.803: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:08:50.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3877" for this suite.

• [SLOW TEST:27.590 seconds]
[sig-network] Networking
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":277,"completed":230,"skipped":3815,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:08:50.846: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 29 18:08:50.996: INFO: Waiting up to 5m0s for pod "pod-5a081db7-2040-49bf-8448-358110da5ddb" in namespace "emptydir-8501" to be "Succeeded or Failed"
May 29 18:08:51.006: INFO: Pod "pod-5a081db7-2040-49bf-8448-358110da5ddb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.173242ms
May 29 18:08:53.018: INFO: Pod "pod-5a081db7-2040-49bf-8448-358110da5ddb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021539668s
May 29 18:08:55.030: INFO: Pod "pod-5a081db7-2040-49bf-8448-358110da5ddb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033971882s
STEP: Saw pod success
May 29 18:08:55.031: INFO: Pod "pod-5a081db7-2040-49bf-8448-358110da5ddb" satisfied condition "Succeeded or Failed"
May 29 18:08:55.042: INFO: Trying to get logs from node node-cncf-lab-3 pod pod-5a081db7-2040-49bf-8448-358110da5ddb container test-container: <nil>
STEP: delete the pod
May 29 18:08:55.145: INFO: Waiting for pod pod-5a081db7-2040-49bf-8448-358110da5ddb to disappear
May 29 18:08:55.153: INFO: Pod pod-5a081db7-2040-49bf-8448-358110da5ddb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:08:55.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8501" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":231,"skipped":3816,"failed":0}
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:08:55.184: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 29 18:08:55.621: INFO: Waiting up to 5m0s for pod "pod-0382f18a-3107-47ee-a311-864e29d46ddc" in namespace "emptydir-8387" to be "Succeeded or Failed"
May 29 18:08:55.634: INFO: Pod "pod-0382f18a-3107-47ee-a311-864e29d46ddc": Phase="Pending", Reason="", readiness=false. Elapsed: 13.089591ms
May 29 18:08:57.654: INFO: Pod "pod-0382f18a-3107-47ee-a311-864e29d46ddc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032989028s
May 29 18:08:59.668: INFO: Pod "pod-0382f18a-3107-47ee-a311-864e29d46ddc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046389061s
STEP: Saw pod success
May 29 18:08:59.668: INFO: Pod "pod-0382f18a-3107-47ee-a311-864e29d46ddc" satisfied condition "Succeeded or Failed"
May 29 18:08:59.680: INFO: Trying to get logs from node node-cncf-lab-3 pod pod-0382f18a-3107-47ee-a311-864e29d46ddc container test-container: <nil>
STEP: delete the pod
May 29 18:08:59.884: INFO: Waiting for pod pod-0382f18a-3107-47ee-a311-864e29d46ddc to disappear
May 29 18:08:59.908: INFO: Pod pod-0382f18a-3107-47ee-a311-864e29d46ddc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:08:59.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8387" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":232,"skipped":3823,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:08:59.991: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:09:12.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3037" for this suite.

• [SLOW TEST:12.182 seconds]
[sig-apps] Job
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":277,"completed":233,"skipped":3835,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:09:12.176: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
May 29 18:09:12.340: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f87224b6-66c4-45d2-9c5a-f9ee5b92e8f7" in namespace "downward-api-5761" to be "Succeeded or Failed"
May 29 18:09:12.352: INFO: Pod "downwardapi-volume-f87224b6-66c4-45d2-9c5a-f9ee5b92e8f7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.146723ms
May 29 18:09:14.369: INFO: Pod "downwardapi-volume-f87224b6-66c4-45d2-9c5a-f9ee5b92e8f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029112209s
May 29 18:09:16.406: INFO: Pod "downwardapi-volume-f87224b6-66c4-45d2-9c5a-f9ee5b92e8f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.065697043s
STEP: Saw pod success
May 29 18:09:16.406: INFO: Pod "downwardapi-volume-f87224b6-66c4-45d2-9c5a-f9ee5b92e8f7" satisfied condition "Succeeded or Failed"
May 29 18:09:16.415: INFO: Trying to get logs from node node-cncf-lab-1 pod downwardapi-volume-f87224b6-66c4-45d2-9c5a-f9ee5b92e8f7 container client-container: <nil>
STEP: delete the pod
May 29 18:09:16.566: INFO: Waiting for pod downwardapi-volume-f87224b6-66c4-45d2-9c5a-f9ee5b92e8f7 to disappear
May 29 18:09:16.578: INFO: Pod downwardapi-volume-f87224b6-66c4-45d2-9c5a-f9ee5b92e8f7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:09:16.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5761" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":277,"completed":234,"skipped":3848,"failed":0}
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:09:16.615: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on tmpfs
May 29 18:09:16.986: INFO: Waiting up to 5m0s for pod "pod-9357d0b1-9234-471b-a021-3eb9525e4768" in namespace "emptydir-6609" to be "Succeeded or Failed"
May 29 18:09:17.007: INFO: Pod "pod-9357d0b1-9234-471b-a021-3eb9525e4768": Phase="Pending", Reason="", readiness=false. Elapsed: 20.350616ms
May 29 18:09:19.027: INFO: Pod "pod-9357d0b1-9234-471b-a021-3eb9525e4768": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041038586s
May 29 18:09:21.038: INFO: Pod "pod-9357d0b1-9234-471b-a021-3eb9525e4768": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051886878s
STEP: Saw pod success
May 29 18:09:21.039: INFO: Pod "pod-9357d0b1-9234-471b-a021-3eb9525e4768" satisfied condition "Succeeded or Failed"
May 29 18:09:22.601: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-9357d0b1-9234-471b-a021-3eb9525e4768 container test-container: <nil>
STEP: delete the pod
May 29 18:09:22.844: INFO: Waiting for pod pod-9357d0b1-9234-471b-a021-3eb9525e4768 to disappear
May 29 18:09:23.088: INFO: Pod pod-9357d0b1-9234-471b-a021-3eb9525e4768 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:09:23.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6609" for this suite.

• [SLOW TEST:6.548 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":235,"skipped":3855,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:09:23.171: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
May 29 18:09:23.315: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ddd50f4d-0a60-4f73-b2e1-d605e8cfde23" in namespace "downward-api-4967" to be "Succeeded or Failed"
May 29 18:09:23.758: INFO: Pod "downwardapi-volume-ddd50f4d-0a60-4f73-b2e1-d605e8cfde23": Phase="Pending", Reason="", readiness=false. Elapsed: 442.335111ms
May 29 18:09:25.949: INFO: Pod "downwardapi-volume-ddd50f4d-0a60-4f73-b2e1-d605e8cfde23": Phase="Pending", Reason="", readiness=false. Elapsed: 2.634192216s
May 29 18:09:27.971: INFO: Pod "downwardapi-volume-ddd50f4d-0a60-4f73-b2e1-d605e8cfde23": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.655535808s
STEP: Saw pod success
May 29 18:09:27.971: INFO: Pod "downwardapi-volume-ddd50f4d-0a60-4f73-b2e1-d605e8cfde23" satisfied condition "Succeeded or Failed"
May 29 18:09:27.989: INFO: Trying to get logs from node node-cncf-lab-1 pod downwardapi-volume-ddd50f4d-0a60-4f73-b2e1-d605e8cfde23 container client-container: <nil>
STEP: delete the pod
May 29 18:09:28.680: INFO: Waiting for pod downwardapi-volume-ddd50f4d-0a60-4f73-b2e1-d605e8cfde23 to disappear
May 29 18:09:28.687: INFO: Pod downwardapi-volume-ddd50f4d-0a60-4f73-b2e1-d605e8cfde23 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:09:28.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4967" for this suite.

• [SLOW TEST:5.553 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":236,"skipped":3898,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:09:28.725: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-6673/configmap-test-de1f629f-8007-4dc2-94b8-3288aabfdfd6
STEP: Creating a pod to test consume configMaps
May 29 18:09:28.958: INFO: Waiting up to 5m0s for pod "pod-configmaps-6f91fb30-6154-4e34-aad7-e246f0c13aa8" in namespace "configmap-6673" to be "Succeeded or Failed"
May 29 18:09:28.977: INFO: Pod "pod-configmaps-6f91fb30-6154-4e34-aad7-e246f0c13aa8": Phase="Pending", Reason="", readiness=false. Elapsed: 18.850766ms
May 29 18:09:31.131: INFO: Pod "pod-configmaps-6f91fb30-6154-4e34-aad7-e246f0c13aa8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.173147951s
May 29 18:09:33.144: INFO: Pod "pod-configmaps-6f91fb30-6154-4e34-aad7-e246f0c13aa8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.186041853s
STEP: Saw pod success
May 29 18:09:33.144: INFO: Pod "pod-configmaps-6f91fb30-6154-4e34-aad7-e246f0c13aa8" satisfied condition "Succeeded or Failed"
May 29 18:09:33.154: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-configmaps-6f91fb30-6154-4e34-aad7-e246f0c13aa8 container env-test: <nil>
STEP: delete the pod
May 29 18:09:33.221: INFO: Waiting for pod pod-configmaps-6f91fb30-6154-4e34-aad7-e246f0c13aa8 to disappear
May 29 18:09:33.230: INFO: Pod pod-configmaps-6f91fb30-6154-4e34-aad7-e246f0c13aa8 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:09:33.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6673" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":277,"completed":237,"skipped":3931,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:09:33.258: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
May 29 18:09:33.425: INFO: Waiting up to 5m0s for pod "pod-a26f32c8-41c8-4571-a649-8b2ad231e826" in namespace "emptydir-2892" to be "Succeeded or Failed"
May 29 18:09:33.473: INFO: Pod "pod-a26f32c8-41c8-4571-a649-8b2ad231e826": Phase="Pending", Reason="", readiness=false. Elapsed: 47.627717ms
May 29 18:09:35.484: INFO: Pod "pod-a26f32c8-41c8-4571-a649-8b2ad231e826": Phase="Pending", Reason="", readiness=false. Elapsed: 2.058309564s
May 29 18:09:37.496: INFO: Pod "pod-a26f32c8-41c8-4571-a649-8b2ad231e826": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.07019099s
STEP: Saw pod success
May 29 18:09:37.496: INFO: Pod "pod-a26f32c8-41c8-4571-a649-8b2ad231e826" satisfied condition "Succeeded or Failed"
May 29 18:09:37.507: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-a26f32c8-41c8-4571-a649-8b2ad231e826 container test-container: <nil>
STEP: delete the pod
May 29 18:09:37.607: INFO: Waiting for pod pod-a26f32c8-41c8-4571-a649-8b2ad231e826 to disappear
May 29 18:09:37.620: INFO: Pod pod-a26f32c8-41c8-4571-a649-8b2ad231e826 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:09:37.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2892" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":238,"skipped":3939,"failed":0}
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:09:37.675: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-864
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-864
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-864
May 29 18:09:37.997: INFO: Found 0 stateful pods, waiting for 1
May 29 18:09:48.009: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
May 29 18:09:48.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 29 18:09:48.431: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 29 18:09:48.431: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 29 18:09:48.431: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 29 18:09:48.444: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 29 18:09:58.457: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 29 18:09:58.457: INFO: Waiting for statefulset status.replicas updated to 0
May 29 18:09:58.652: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999875s
May 29 18:09:59.664: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.984522152s
May 29 18:10:00.675: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.972979217s
May 29 18:10:01.688: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.961884317s
May 29 18:10:02.728: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.94846527s
May 29 18:10:03.745: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.909560303s
May 29 18:10:04.759: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.892270911s
May 29 18:10:05.772: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.878217995s
May 29 18:10:06.785: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.864702089s
May 29 18:10:07.797: INFO: Verifying statefulset ss doesn't scale past 1 for another 851.261227ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-864
May 29 18:10:08.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:10:09.256: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May 29 18:10:09.256: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 29 18:10:09.256: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 29 18:10:09.267: INFO: Found 1 stateful pods, waiting for 3
May 29 18:10:19.283: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 29 18:10:19.283: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 29 18:10:19.284: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
May 29 18:10:19.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 29 18:10:19.735: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 29 18:10:19.735: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 29 18:10:19.735: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 29 18:10:19.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 29 18:10:20.191: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 29 18:10:20.192: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 29 18:10:20.192: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 29 18:10:20.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 29 18:10:20.579: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 29 18:10:20.579: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 29 18:10:20.579: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 29 18:10:20.579: INFO: Waiting for statefulset status.replicas updated to 0
May 29 18:10:20.586: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
May 29 18:10:30.611: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 29 18:10:30.611: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 29 18:10:30.611: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 29 18:10:30.658: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998937s
May 29 18:10:32.328: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.986706586s
May 29 18:10:33.342: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.317008975s
May 29 18:10:34.369: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.302294079s
May 29 18:10:35.382: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.275500446s
May 29 18:10:37.024: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.26268045s
May 29 18:10:38.773: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.621192303s
May 29 18:10:39.788: INFO: Verifying statefulset ss doesn't scale past 3 for another 871.910065ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-864
May 29 18:10:40.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:10:41.270: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May 29 18:10:41.270: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 29 18:10:41.270: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 29 18:10:41.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:10:41.676: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May 29 18:10:41.676: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 29 18:10:41.676: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 29 18:10:41.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:10:42.070: INFO: rc: 126
May 29 18:10:42.070: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:
OCI runtime exec failed: exec failed: container_linux.go:348: starting container process caused "process_linux.go:86: executing setns process caused \"exit status 21\"": unknown

stderr:
command terminated with exit code 126

error:
exit status 126
May 29 18:10:52.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:10:52.348: INFO: rc: 1
May 29 18:10:52.348: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
May 29 18:11:02.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:11:03.729: INFO: rc: 1
May 29 18:11:03.730: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:11:13.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:11:13.885: INFO: rc: 1
May 29 18:11:13.885: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:11:23.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:11:24.227: INFO: rc: 1
May 29 18:11:24.227: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:11:34.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:11:36.125: INFO: rc: 1
May 29 18:11:36.126: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:11:46.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:11:46.286: INFO: rc: 1
May 29 18:11:46.287: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:11:56.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:11:56.502: INFO: rc: 1
May 29 18:11:56.502: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:12:06.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:12:06.659: INFO: rc: 1
May 29 18:12:06.659: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:12:16.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:12:16.847: INFO: rc: 1
May 29 18:12:16.847: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:12:26.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:12:27.016: INFO: rc: 1
May 29 18:12:27.016: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:12:37.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:12:37.178: INFO: rc: 1
May 29 18:12:37.178: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:12:47.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:12:47.354: INFO: rc: 1
May 29 18:12:47.354: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:12:57.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:12:57.521: INFO: rc: 1
May 29 18:12:57.521: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:13:07.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:13:07.666: INFO: rc: 1
May 29 18:13:07.666: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:13:17.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:13:17.815: INFO: rc: 1
May 29 18:13:17.815: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:13:27.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:13:28.829: INFO: rc: 1
May 29 18:13:28.829: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:13:38.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:13:38.997: INFO: rc: 1
May 29 18:13:38.997: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:13:48.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:13:49.189: INFO: rc: 1
May 29 18:13:49.189: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:13:59.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:13:59.374: INFO: rc: 1
May 29 18:13:59.374: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:14:09.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:14:09.775: INFO: rc: 1
May 29 18:14:09.775: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:14:19.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:14:19.957: INFO: rc: 1
May 29 18:14:19.957: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:14:29.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:14:30.461: INFO: rc: 1
May 29 18:14:30.462: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:14:40.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:14:40.877: INFO: rc: 1
May 29 18:14:40.878: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:14:50.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:14:51.044: INFO: rc: 1
May 29 18:14:51.044: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:15:01.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:15:01.210: INFO: rc: 1
May 29 18:15:01.210: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:15:11.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:15:11.381: INFO: rc: 1
May 29 18:15:11.381: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:15:21.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:15:21.528: INFO: rc: 1
May 29 18:15:21.528: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:15:31.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:15:31.683: INFO: rc: 1
May 29 18:15:31.683: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 29 18:15:41.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 exec --namespace=statefulset-864 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 29 18:15:41.881: INFO: rc: 1
May 29 18:15:41.882: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
May 29 18:15:41.882: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
May 29 18:15:41.919: INFO: Deleting all statefulset in ns statefulset-864
May 29 18:15:41.928: INFO: Scaling statefulset ss to 0
May 29 18:15:41.968: INFO: Waiting for statefulset status.replicas updated to 0
May 29 18:15:41.980: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:15:42.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-864" for this suite.

• [SLOW TEST:364.423 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":277,"completed":239,"skipped":3943,"failed":0}
SSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:15:42.103: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:15:48.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2332" for this suite.

• [SLOW TEST:6.376 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when scheduling a read only busybox container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:188
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":240,"skipped":3946,"failed":0}
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:15:48.487: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override command
May 29 18:15:48.692: INFO: Waiting up to 5m0s for pod "client-containers-7c733ca0-a801-4105-985e-4b0608cf9e19" in namespace "containers-4255" to be "Succeeded or Failed"
May 29 18:15:48.701: INFO: Pod "client-containers-7c733ca0-a801-4105-985e-4b0608cf9e19": Phase="Pending", Reason="", readiness=false. Elapsed: 9.899755ms
May 29 18:15:50.715: INFO: Pod "client-containers-7c733ca0-a801-4105-985e-4b0608cf9e19": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023357869s
May 29 18:15:52.725: INFO: Pod "client-containers-7c733ca0-a801-4105-985e-4b0608cf9e19": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033567288s
STEP: Saw pod success
May 29 18:15:52.725: INFO: Pod "client-containers-7c733ca0-a801-4105-985e-4b0608cf9e19" satisfied condition "Succeeded or Failed"
May 29 18:15:52.735: INFO: Trying to get logs from node node-cncf-lab-1 pod client-containers-7c733ca0-a801-4105-985e-4b0608cf9e19 container test-container: <nil>
STEP: delete the pod
May 29 18:15:52.811: INFO: Waiting for pod client-containers-7c733ca0-a801-4105-985e-4b0608cf9e19 to disappear
May 29 18:15:52.821: INFO: Pod client-containers-7c733ca0-a801-4105-985e-4b0608cf9e19 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:15:52.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4255" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":277,"completed":241,"skipped":3949,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:15:52.861: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
May 29 18:15:52.996: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:16:00.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8870" for this suite.

• [SLOW TEST:7.441 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":277,"completed":242,"skipped":3998,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:16:00.313: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 29 18:16:05.026: INFO: Successfully updated pod "pod-update-activedeadlineseconds-7b4029ca-3044-44cd-aa7a-403f315999cd"
May 29 18:16:05.026: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-7b4029ca-3044-44cd-aa7a-403f315999cd" in namespace "pods-5465" to be "terminated due to deadline exceeded"
May 29 18:16:05.035: INFO: Pod "pod-update-activedeadlineseconds-7b4029ca-3044-44cd-aa7a-403f315999cd": Phase="Running", Reason="", readiness=true. Elapsed: 8.726812ms
May 29 18:16:07.048: INFO: Pod "pod-update-activedeadlineseconds-7b4029ca-3044-44cd-aa7a-403f315999cd": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.021607942s
May 29 18:16:07.048: INFO: Pod "pod-update-activedeadlineseconds-7b4029ca-3044-44cd-aa7a-403f315999cd" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:16:07.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5465" for this suite.

• [SLOW TEST:6.770 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":277,"completed":243,"skipped":4015,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:16:07.085: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-5008
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-5008
STEP: Creating statefulset with conflicting port in namespace statefulset-5008
STEP: Waiting until pod test-pod will start running in namespace statefulset-5008
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-5008
May 29 18:16:13.312: INFO: Observed stateful pod in namespace: statefulset-5008, name: ss-0, uid: 9317053e-83fd-4500-9295-2897c80a4ccd, status phase: Pending. Waiting for statefulset controller to delete.
May 29 18:16:13.893: INFO: Observed stateful pod in namespace: statefulset-5008, name: ss-0, uid: 9317053e-83fd-4500-9295-2897c80a4ccd, status phase: Failed. Waiting for statefulset controller to delete.
May 29 18:16:13.912: INFO: Observed stateful pod in namespace: statefulset-5008, name: ss-0, uid: 9317053e-83fd-4500-9295-2897c80a4ccd, status phase: Failed. Waiting for statefulset controller to delete.
May 29 18:16:13.922: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-5008
STEP: Removing pod with conflicting port in namespace statefulset-5008
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-5008 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
May 29 18:16:22.011: INFO: Deleting all statefulset in ns statefulset-5008
May 29 18:16:22.021: INFO: Scaling statefulset ss to 0
May 29 18:16:42.066: INFO: Waiting for statefulset status.replicas updated to 0
May 29 18:16:42.076: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:16:42.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5008" for this suite.

• [SLOW TEST:35.101 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":277,"completed":244,"skipped":4027,"failed":0}
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:16:42.187: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
May 29 18:16:42.396: INFO: Waiting up to 5m0s for pod "downwardapi-volume-11fd2b65-5229-42a2-85d3-04e623afe766" in namespace "downward-api-8473" to be "Succeeded or Failed"
May 29 18:16:42.408: INFO: Pod "downwardapi-volume-11fd2b65-5229-42a2-85d3-04e623afe766": Phase="Pending", Reason="", readiness=false. Elapsed: 12.112714ms
May 29 18:16:44.421: INFO: Pod "downwardapi-volume-11fd2b65-5229-42a2-85d3-04e623afe766": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025426819s
May 29 18:16:46.459: INFO: Pod "downwardapi-volume-11fd2b65-5229-42a2-85d3-04e623afe766": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.06345577s
STEP: Saw pod success
May 29 18:16:46.460: INFO: Pod "downwardapi-volume-11fd2b65-5229-42a2-85d3-04e623afe766" satisfied condition "Succeeded or Failed"
May 29 18:16:46.475: INFO: Trying to get logs from node node-cncf-lab-1 pod downwardapi-volume-11fd2b65-5229-42a2-85d3-04e623afe766 container client-container: <nil>
STEP: delete the pod
May 29 18:16:46.838: INFO: Waiting for pod downwardapi-volume-11fd2b65-5229-42a2-85d3-04e623afe766 to disappear
May 29 18:16:46.845: INFO: Pod downwardapi-volume-11fd2b65-5229-42a2-85d3-04e623afe766 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:16:46.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8473" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":245,"skipped":4027,"failed":0}
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:16:46.877: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 29 18:16:55.169: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 18:16:55.178: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 18:16:57.179: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 18:16:57.191: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 18:16:59.178: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 18:16:59.206: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 18:17:01.178: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 18:17:01.194: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 18:17:03.178: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 18:17:03.194: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 18:17:05.178: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 18:17:05.193: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 18:17:07.178: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 18:17:07.192: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 18:17:09.178: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 18:17:09.191: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 18:17:11.178: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 18:17:11.193: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:17:11.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4409" for this suite.

• [SLOW TEST:24.346 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":277,"completed":246,"skipped":4033,"failed":0}
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:17:11.229: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's args
May 29 18:17:11.388: INFO: Waiting up to 5m0s for pod "var-expansion-5e220c98-9174-4ca3-aa13-e07acb85e814" in namespace "var-expansion-9254" to be "Succeeded or Failed"
May 29 18:17:11.399: INFO: Pod "var-expansion-5e220c98-9174-4ca3-aa13-e07acb85e814": Phase="Pending", Reason="", readiness=false. Elapsed: 11.027585ms
May 29 18:17:13.414: INFO: Pod "var-expansion-5e220c98-9174-4ca3-aa13-e07acb85e814": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02538537s
May 29 18:17:15.425: INFO: Pod "var-expansion-5e220c98-9174-4ca3-aa13-e07acb85e814": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037017853s
May 29 18:17:17.441: INFO: Pod "var-expansion-5e220c98-9174-4ca3-aa13-e07acb85e814": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.052311014s
STEP: Saw pod success
May 29 18:17:17.441: INFO: Pod "var-expansion-5e220c98-9174-4ca3-aa13-e07acb85e814" satisfied condition "Succeeded or Failed"
May 29 18:17:17.499: INFO: Trying to get logs from node node-cncf-lab-3 pod var-expansion-5e220c98-9174-4ca3-aa13-e07acb85e814 container dapi-container: <nil>
STEP: delete the pod
May 29 18:17:17.691: INFO: Waiting for pod var-expansion-5e220c98-9174-4ca3-aa13-e07acb85e814 to disappear
May 29 18:17:17.700: INFO: Pod var-expansion-5e220c98-9174-4ca3-aa13-e07acb85e814 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:17:17.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9254" for this suite.

• [SLOW TEST:6.510 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":277,"completed":247,"skipped":4035,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:17:17.742: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 29 18:17:17.897: INFO: Waiting up to 5m0s for pod "pod-200f5490-0162-453c-9bd4-847fd325c456" in namespace "emptydir-9629" to be "Succeeded or Failed"
May 29 18:17:17.911: INFO: Pod "pod-200f5490-0162-453c-9bd4-847fd325c456": Phase="Pending", Reason="", readiness=false. Elapsed: 13.575392ms
May 29 18:17:19.925: INFO: Pod "pod-200f5490-0162-453c-9bd4-847fd325c456": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027382627s
May 29 18:17:21.936: INFO: Pod "pod-200f5490-0162-453c-9bd4-847fd325c456": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03865552s
STEP: Saw pod success
May 29 18:17:21.936: INFO: Pod "pod-200f5490-0162-453c-9bd4-847fd325c456" satisfied condition "Succeeded or Failed"
May 29 18:17:21.944: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-200f5490-0162-453c-9bd4-847fd325c456 container test-container: <nil>
STEP: delete the pod
May 29 18:17:22.009: INFO: Waiting for pod pod-200f5490-0162-453c-9bd4-847fd325c456 to disappear
May 29 18:17:22.018: INFO: Pod pod-200f5490-0162-453c-9bd4-847fd325c456 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:17:22.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9629" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":248,"skipped":4056,"failed":0}

------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:17:22.059: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 29 18:17:22.899: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
May 29 18:17:25.125: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726373042, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726373042, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726373042, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726373042, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 29 18:17:28.699: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:17:41.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-574" for this suite.
STEP: Destroying namespace "webhook-574-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:19.510 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":277,"completed":249,"skipped":4056,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:17:41.574: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 18:17:41.763: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"ed349945-d51c-41ee-a918-00ead3aa027d", Controller:(*bool)(0xc0059fdb86), BlockOwnerDeletion:(*bool)(0xc0059fdb87)}}
May 29 18:17:41.775: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"f674b9cb-1fdd-48b0-bc83-574d0634fe07", Controller:(*bool)(0xc005c5b846), BlockOwnerDeletion:(*bool)(0xc005c5b847)}}
May 29 18:17:41.791: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"a6c57a24-83fb-48e6-80c1-1ec4c5e54972", Controller:(*bool)(0xc005c5ba32), BlockOwnerDeletion:(*bool)(0xc005c5ba33)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:17:46.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8034" for this suite.

• [SLOW TEST:5.281 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":277,"completed":250,"skipped":4064,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:17:46.857: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-3a439bd6-f7bf-4607-979b-758732e4f1d5
STEP: Creating a pod to test consume secrets
May 29 18:17:47.018: INFO: Waiting up to 5m0s for pod "pod-secrets-8b73f196-6c6e-4d41-9c1d-6d2052b7eb47" in namespace "secrets-9125" to be "Succeeded or Failed"
May 29 18:17:47.034: INFO: Pod "pod-secrets-8b73f196-6c6e-4d41-9c1d-6d2052b7eb47": Phase="Pending", Reason="", readiness=false. Elapsed: 16.081679ms
May 29 18:17:49.044: INFO: Pod "pod-secrets-8b73f196-6c6e-4d41-9c1d-6d2052b7eb47": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026131374s
May 29 18:17:51.054: INFO: Pod "pod-secrets-8b73f196-6c6e-4d41-9c1d-6d2052b7eb47": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035348577s
STEP: Saw pod success
May 29 18:17:51.054: INFO: Pod "pod-secrets-8b73f196-6c6e-4d41-9c1d-6d2052b7eb47" satisfied condition "Succeeded or Failed"
May 29 18:17:51.067: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-secrets-8b73f196-6c6e-4d41-9c1d-6d2052b7eb47 container secret-volume-test: <nil>
STEP: delete the pod
May 29 18:17:51.130: INFO: Waiting for pod pod-secrets-8b73f196-6c6e-4d41-9c1d-6d2052b7eb47 to disappear
May 29 18:17:51.138: INFO: Pod pod-secrets-8b73f196-6c6e-4d41-9c1d-6d2052b7eb47 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:17:51.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9125" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":277,"completed":251,"skipped":4084,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:17:51.178: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
May 29 18:17:51.318: INFO: Waiting up to 5m0s for pod "downward-api-b0044bfb-1731-45e4-8e8e-ab0db053c3d0" in namespace "downward-api-7853" to be "Succeeded or Failed"
May 29 18:17:51.326: INFO: Pod "downward-api-b0044bfb-1731-45e4-8e8e-ab0db053c3d0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.466742ms
May 29 18:17:53.341: INFO: Pod "downward-api-b0044bfb-1731-45e4-8e8e-ab0db053c3d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022875238s
May 29 18:17:55.358: INFO: Pod "downward-api-b0044bfb-1731-45e4-8e8e-ab0db053c3d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039890631s
STEP: Saw pod success
May 29 18:17:55.358: INFO: Pod "downward-api-b0044bfb-1731-45e4-8e8e-ab0db053c3d0" satisfied condition "Succeeded or Failed"
May 29 18:17:55.370: INFO: Trying to get logs from node node-cncf-lab-1 pod downward-api-b0044bfb-1731-45e4-8e8e-ab0db053c3d0 container dapi-container: <nil>
STEP: delete the pod
May 29 18:17:55.511: INFO: Waiting for pod downward-api-b0044bfb-1731-45e4-8e8e-ab0db053c3d0 to disappear
May 29 18:17:55.519: INFO: Pod downward-api-b0044bfb-1731-45e4-8e8e-ab0db053c3d0 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:17:55.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7853" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":277,"completed":252,"skipped":4100,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:17:55.571: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name secret-emptykey-test-fd7b7bdf-3c01-4f9d-a2cd-f87094213df7
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:17:55.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9881" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should fail to create secret due to empty secret key [Conformance]","total":277,"completed":253,"skipped":4113,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:17:55.746: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:18:03.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-704" for this suite.

• [SLOW TEST:8.230 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:79
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":277,"completed":254,"skipped":4140,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:18:03.981: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-d9ba307b-09dc-40a2-aa6b-b880773f131a
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-d9ba307b-09dc-40a2-aa6b-b880773f131a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:19:32.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4250" for this suite.

• [SLOW TEST:89.151 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":255,"skipped":4160,"failed":0}
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:19:33.132: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod test-webserver-e3c9e9b2-2392-4c21-85a9-4f1077b7c21d in namespace container-probe-4468
May 29 18:19:37.635: INFO: Started pod test-webserver-e3c9e9b2-2392-4c21-85a9-4f1077b7c21d in namespace container-probe-4468
STEP: checking the pod's current state and verifying that restartCount is present
May 29 18:19:37.651: INFO: Initial restart count of pod test-webserver-e3c9e9b2-2392-4c21-85a9-4f1077b7c21d is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:23:37.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4468" for this suite.

• [SLOW TEST:244.858 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":277,"completed":256,"skipped":4160,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:23:37.995: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
May 29 18:23:38.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 create -f - --namespace=kubectl-897'
May 29 18:23:38.606: INFO: stderr: ""
May 29 18:23:38.606: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
May 29 18:23:39.616: INFO: Selector matched 1 pods for map[app:agnhost]
May 29 18:23:39.616: INFO: Found 0 / 1
May 29 18:23:40.619: INFO: Selector matched 1 pods for map[app:agnhost]
May 29 18:23:40.619: INFO: Found 0 / 1
May 29 18:23:41.616: INFO: Selector matched 1 pods for map[app:agnhost]
May 29 18:23:41.616: INFO: Found 1 / 1
May 29 18:23:41.616: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
May 29 18:23:41.627: INFO: Selector matched 1 pods for map[app:agnhost]
May 29 18:23:41.627: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 29 18:23:41.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 patch pod agnhost-master-8qt5n --namespace=kubectl-897 -p {"metadata":{"annotations":{"x":"y"}}}'
May 29 18:23:41.815: INFO: stderr: ""
May 29 18:23:41.815: INFO: stdout: "pod/agnhost-master-8qt5n patched\n"
STEP: checking annotations
May 29 18:23:41.824: INFO: Selector matched 1 pods for map[app:agnhost]
May 29 18:23:41.824: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:23:41.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-897" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":277,"completed":257,"skipped":4182,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:23:41.855: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
May 29 18:23:42.664: INFO: created pod pod-service-account-defaultsa
May 29 18:23:42.665: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May 29 18:23:42.682: INFO: created pod pod-service-account-mountsa
May 29 18:23:42.682: INFO: pod pod-service-account-mountsa service account token volume mount: true
May 29 18:23:42.697: INFO: created pod pod-service-account-nomountsa
May 29 18:23:42.697: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May 29 18:23:42.709: INFO: created pod pod-service-account-defaultsa-mountspec
May 29 18:23:42.709: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May 29 18:23:42.720: INFO: created pod pod-service-account-mountsa-mountspec
May 29 18:23:42.720: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May 29 18:23:42.736: INFO: created pod pod-service-account-nomountsa-mountspec
May 29 18:23:42.736: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May 29 18:23:42.753: INFO: created pod pod-service-account-defaultsa-nomountspec
May 29 18:23:42.753: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May 29 18:23:42.767: INFO: created pod pod-service-account-mountsa-nomountspec
May 29 18:23:42.767: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May 29 18:23:42.796: INFO: created pod pod-service-account-nomountsa-nomountspec
May 29 18:23:42.796: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:23:42.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6062" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":277,"completed":258,"skipped":4255,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:23:42.825: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:23:43.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8375" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":277,"completed":259,"skipped":4266,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:23:43.109: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 29 18:23:44.385: INFO: Waiting up to 5m0s for pod "pod-4b64a9b5-aa7d-49bd-9805-586a2fbfad75" in namespace "emptydir-891" to be "Succeeded or Failed"
May 29 18:23:44.420: INFO: Pod "pod-4b64a9b5-aa7d-49bd-9805-586a2fbfad75": Phase="Pending", Reason="", readiness=false. Elapsed: 35.640431ms
May 29 18:23:46.434: INFO: Pod "pod-4b64a9b5-aa7d-49bd-9805-586a2fbfad75": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049224891s
May 29 18:23:48.453: INFO: Pod "pod-4b64a9b5-aa7d-49bd-9805-586a2fbfad75": Phase="Pending", Reason="", readiness=false. Elapsed: 4.068785512s
May 29 18:23:50.489: INFO: Pod "pod-4b64a9b5-aa7d-49bd-9805-586a2fbfad75": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.104812882s
STEP: Saw pod success
May 29 18:23:50.490: INFO: Pod "pod-4b64a9b5-aa7d-49bd-9805-586a2fbfad75" satisfied condition "Succeeded or Failed"
May 29 18:23:50.587: INFO: Trying to get logs from node node-cncf-lab-3 pod pod-4b64a9b5-aa7d-49bd-9805-586a2fbfad75 container test-container: <nil>
STEP: delete the pod
May 29 18:23:50.783: INFO: Waiting for pod pod-4b64a9b5-aa7d-49bd-9805-586a2fbfad75 to disappear
May 29 18:23:50.792: INFO: Pod pod-4b64a9b5-aa7d-49bd-9805-586a2fbfad75 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:23:50.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-891" for this suite.

• [SLOW TEST:7.740 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":260,"skipped":4284,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:23:50.865: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-56nkm in namespace proxy-5566
I0529 18:23:51.201444      20 runners.go:190] Created replication controller with name: proxy-service-56nkm, namespace: proxy-5566, replica count: 1
I0529 18:23:52.256745      20 runners.go:190] proxy-service-56nkm Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 18:23:53.257139      20 runners.go:190] proxy-service-56nkm Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 18:23:54.257572      20 runners.go:190] proxy-service-56nkm Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 18:23:55.258034      20 runners.go:190] proxy-service-56nkm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0529 18:23:56.258486      20 runners.go:190] proxy-service-56nkm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0529 18:23:57.258906      20 runners.go:190] proxy-service-56nkm Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 29 18:23:57.271: INFO: setup took 6.244580852s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
May 29 18:23:57.297: INFO: (0) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:162/proxy/: bar (200; 24.424158ms)
May 29 18:23:57.308: INFO: (0) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/rewriteme">... (200; 35.751986ms)
May 29 18:23:57.313: INFO: (0) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname1/proxy/: foo (200; 41.231433ms)
May 29 18:23:57.314: INFO: (0) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:160/proxy/: foo (200; 41.881892ms)
May 29 18:23:57.314: INFO: (0) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname2/proxy/: tls qux (200; 43.161525ms)
May 29 18:23:57.316: INFO: (0) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname1/proxy/: tls baz (200; 44.201753ms)
May 29 18:23:57.316: INFO: (0) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:460/proxy/: tls baz (200; 44.65234ms)
May 29 18:23:57.319: INFO: (0) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/tlsrewritem... (200; 46.882863ms)
May 29 18:23:57.319: INFO: (0) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:462/proxy/: tls qux (200; 47.138779ms)
May 29 18:23:58.624: INFO: (0) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname2/proxy/: bar (200; 1.35162672s)
May 29 18:23:58.629: INFO: (0) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname1/proxy/: foo (200; 1.35713217s)
May 29 18:23:58.631: INFO: (0) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:162/proxy/: bar (200; 1.359231209s)
May 29 18:23:58.705: INFO: (0) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:160/proxy/: foo (200; 1.432753453s)
May 29 18:23:58.705: INFO: (0) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/rewriteme">test<... (200; 1.433246802s)
May 29 18:23:58.708: INFO: (0) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/rewriteme">test</a> (200; 1.435970637s)
May 29 18:23:59.523: INFO: (0) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname2/proxy/: bar (200; 2.251173241s)
May 29 18:23:59.542: INFO: (1) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:460/proxy/: tls baz (200; 16.827476ms)
May 29 18:23:59.542: INFO: (1) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:160/proxy/: foo (200; 16.840484ms)
May 29 18:23:59.543: INFO: (1) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:160/proxy/: foo (200; 18.02097ms)
May 29 18:23:59.543: INFO: (1) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/rewriteme">... (200; 18.147282ms)
May 29 18:23:59.549: INFO: (1) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/tlsrewritem... (200; 25.048315ms)
May 29 18:23:59.549: INFO: (1) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:162/proxy/: bar (200; 25.247409ms)
May 29 18:23:59.549: INFO: (1) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:462/proxy/: tls qux (200; 23.307259ms)
May 29 18:23:59.559: INFO: (1) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname1/proxy/: foo (200; 34.150821ms)
May 29 18:23:59.571: INFO: (1) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname2/proxy/: bar (200; 47.204761ms)
May 29 18:23:59.575: INFO: (1) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname2/proxy/: bar (200; 50.754994ms)
May 29 18:23:59.618: INFO: (1) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/rewriteme">test</a> (200; 93.340191ms)
May 29 18:23:59.618: INFO: (1) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:162/proxy/: bar (200; 94.105615ms)
May 29 18:23:59.618: INFO: (1) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname2/proxy/: tls qux (200; 92.645656ms)
May 29 18:23:59.620: INFO: (1) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/rewriteme">test<... (200; 95.378201ms)
May 29 18:23:59.620: INFO: (1) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname1/proxy/: tls baz (200; 94.697654ms)
May 29 18:23:59.645: INFO: (1) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname1/proxy/: foo (200; 120.379815ms)
May 29 18:23:59.660: INFO: (2) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/rewriteme">test</a> (200; 14.500985ms)
May 29 18:23:59.661: INFO: (2) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/rewriteme">... (200; 15.168314ms)
May 29 18:23:59.664: INFO: (2) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:160/proxy/: foo (200; 18.248872ms)
May 29 18:23:59.665: INFO: (2) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/rewriteme">test<... (200; 19.37708ms)
May 29 18:23:59.665: INFO: (2) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:162/proxy/: bar (200; 17.793544ms)
May 29 18:23:59.668: INFO: (2) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:462/proxy/: tls qux (200; 21.207594ms)
May 29 18:23:59.673: INFO: (2) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname2/proxy/: tls qux (200; 26.783717ms)
May 29 18:23:59.673: INFO: (2) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:162/proxy/: bar (200; 25.806419ms)
May 29 18:23:59.674: INFO: (2) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/tlsrewritem... (200; 28.977397ms)
May 29 18:23:59.675: INFO: (2) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:460/proxy/: tls baz (200; 29.1776ms)
May 29 18:23:59.676: INFO: (2) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:160/proxy/: foo (200; 28.945917ms)
May 29 18:23:59.678: INFO: (2) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname1/proxy/: tls baz (200; 31.40585ms)
May 29 18:23:59.680: INFO: (2) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname1/proxy/: foo (200; 33.659639ms)
May 29 18:23:59.680: INFO: (2) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname2/proxy/: bar (200; 34.808823ms)
May 29 18:23:59.681: INFO: (2) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname2/proxy/: bar (200; 34.82256ms)
May 29 18:23:59.681: INFO: (2) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname1/proxy/: foo (200; 36.065847ms)
May 29 18:23:59.699: INFO: (3) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:462/proxy/: tls qux (200; 16.717329ms)
May 29 18:23:59.701: INFO: (3) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/rewriteme">test</a> (200; 18.163123ms)
May 29 18:23:59.706: INFO: (3) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:160/proxy/: foo (200; 23.54336ms)
May 29 18:23:59.706: INFO: (3) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:460/proxy/: tls baz (200; 23.728394ms)
May 29 18:23:59.706: INFO: (3) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/rewriteme">test<... (200; 23.331421ms)
May 29 18:23:59.707: INFO: (3) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:160/proxy/: foo (200; 24.165697ms)
May 29 18:23:59.707: INFO: (3) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:162/proxy/: bar (200; 24.419836ms)
May 29 18:23:59.708: INFO: (3) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:162/proxy/: bar (200; 25.57221ms)
May 29 18:23:59.708: INFO: (3) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/tlsrewritem... (200; 25.509522ms)
May 29 18:23:59.710: INFO: (3) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/rewriteme">... (200; 28.650241ms)
May 29 18:23:59.714: INFO: (3) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname1/proxy/: foo (200; 32.133911ms)
May 29 18:23:59.716: INFO: (3) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname2/proxy/: bar (200; 33.494067ms)
May 29 18:23:59.716: INFO: (3) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname1/proxy/: foo (200; 33.868551ms)
May 29 18:23:59.717: INFO: (3) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname2/proxy/: tls qux (200; 34.085422ms)
May 29 18:23:59.724: INFO: (3) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname1/proxy/: tls baz (200; 41.746693ms)
May 29 18:23:59.724: INFO: (3) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname2/proxy/: bar (200; 41.282492ms)
May 29 18:23:59.741: INFO: (4) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:160/proxy/: foo (200; 15.279757ms)
May 29 18:23:59.741: INFO: (4) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:162/proxy/: bar (200; 15.292998ms)
May 29 18:23:59.741: INFO: (4) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:162/proxy/: bar (200; 16.428951ms)
May 29 18:23:59.749: INFO: (4) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname2/proxy/: tls qux (200; 23.96494ms)
May 29 18:23:59.750: INFO: (4) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:460/proxy/: tls baz (200; 24.00468ms)
May 29 18:23:59.750: INFO: (4) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/tlsrewritem... (200; 24.279676ms)
May 29 18:23:59.751: INFO: (4) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname1/proxy/: tls baz (200; 25.889105ms)
May 29 18:23:59.751: INFO: (4) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname1/proxy/: foo (200; 25.354127ms)
May 29 18:23:59.752: INFO: (4) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname2/proxy/: bar (200; 26.991492ms)
May 29 18:24:00.451: INFO: (4) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:462/proxy/: tls qux (200; 725.297478ms)
May 29 18:24:00.452: INFO: (4) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/rewriteme">... (200; 726.147586ms)
May 29 18:24:00.453: INFO: (4) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname2/proxy/: bar (200; 727.545004ms)
May 29 18:24:00.462: INFO: (4) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/rewriteme">test</a> (200; 737.100786ms)
May 29 18:24:00.464: INFO: (4) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/rewriteme">test<... (200; 738.709143ms)
May 29 18:24:00.464: INFO: (4) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname1/proxy/: foo (200; 738.746371ms)
May 29 18:24:00.464: INFO: (4) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:160/proxy/: foo (200; 738.870943ms)
May 29 18:24:00.490: INFO: (5) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:160/proxy/: foo (200; 24.619643ms)
May 29 18:24:00.491: INFO: (5) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/rewriteme">... (200; 24.793826ms)
May 29 18:24:00.494: INFO: (5) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:162/proxy/: bar (200; 28.758961ms)
May 29 18:24:00.494: INFO: (5) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:160/proxy/: foo (200; 29.26806ms)
May 29 18:24:00.495: INFO: (5) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:462/proxy/: tls qux (200; 30.131067ms)
May 29 18:24:00.505: INFO: (5) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/rewriteme">test<... (200; 39.616629ms)
May 29 18:24:00.505: INFO: (5) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname1/proxy/: foo (200; 40.189707ms)
May 29 18:24:00.505: INFO: (5) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname1/proxy/: foo (200; 40.674363ms)
May 29 18:24:00.506: INFO: (5) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname1/proxy/: tls baz (200; 40.884226ms)
May 29 18:24:00.506: INFO: (5) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:162/proxy/: bar (200; 40.776848ms)
May 29 18:24:00.506: INFO: (5) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:460/proxy/: tls baz (200; 41.636113ms)
May 29 18:24:00.506: INFO: (5) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname2/proxy/: bar (200; 40.70139ms)
May 29 18:24:00.506: INFO: (5) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/tlsrewritem... (200; 41.684925ms)
May 29 18:24:00.505: INFO: (5) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/rewriteme">test</a> (200; 40.051572ms)
May 29 18:24:00.519: INFO: (5) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname2/proxy/: bar (200; 53.656699ms)
May 29 18:24:00.520: INFO: (5) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname2/proxy/: tls qux (200; 55.196052ms)
May 29 18:24:00.559: INFO: (6) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:162/proxy/: bar (200; 37.189585ms)
May 29 18:24:00.559: INFO: (6) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/rewriteme">... (200; 36.856991ms)
May 29 18:24:00.559: INFO: (6) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:162/proxy/: bar (200; 37.368515ms)
May 29 18:24:00.576: INFO: (6) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname2/proxy/: tls qux (200; 55.255425ms)
May 29 18:24:00.577: INFO: (6) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:462/proxy/: tls qux (200; 55.07802ms)
May 29 18:24:00.577: INFO: (6) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname2/proxy/: bar (200; 54.085576ms)
May 29 18:24:00.577: INFO: (6) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/rewriteme">test<... (200; 54.205705ms)
May 29 18:24:00.577: INFO: (6) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:160/proxy/: foo (200; 55.267458ms)
May 29 18:24:00.581: INFO: (6) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname1/proxy/: foo (200; 59.146519ms)
May 29 18:24:00.581: INFO: (6) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname2/proxy/: bar (200; 59.156819ms)
May 29 18:24:00.581: INFO: (6) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/rewriteme">test</a> (200; 59.547329ms)
May 29 18:24:00.582: INFO: (6) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname1/proxy/: foo (200; 60.67266ms)
May 29 18:24:00.582: INFO: (6) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:460/proxy/: tls baz (200; 60.934707ms)
May 29 18:24:00.582: INFO: (6) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname1/proxy/: tls baz (200; 60.510768ms)
May 29 18:24:00.582: INFO: (6) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:160/proxy/: foo (200; 59.012547ms)
May 29 18:24:00.582: INFO: (6) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/tlsrewritem... (200; 59.462085ms)
May 29 18:24:00.608: INFO: (7) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/rewriteme">test</a> (200; 24.923018ms)
May 29 18:24:00.608: INFO: (7) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:162/proxy/: bar (200; 25.228361ms)
May 29 18:24:00.608: INFO: (7) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:462/proxy/: tls qux (200; 25.364857ms)
May 29 18:24:00.610: INFO: (7) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:162/proxy/: bar (200; 27.103497ms)
May 29 18:24:00.610: INFO: (7) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:460/proxy/: tls baz (200; 26.913891ms)
May 29 18:24:00.610: INFO: (7) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/rewriteme">... (200; 27.063887ms)
May 29 18:24:00.611: INFO: (7) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/rewriteme">test<... (200; 28.8346ms)
May 29 18:24:00.611: INFO: (7) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:160/proxy/: foo (200; 28.255693ms)
May 29 18:24:00.611: INFO: (7) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:160/proxy/: foo (200; 28.212907ms)
May 29 18:24:00.618: INFO: (7) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname2/proxy/: tls qux (200; 35.80443ms)
May 29 18:24:00.619: INFO: (7) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname1/proxy/: foo (200; 35.412618ms)
May 29 18:24:00.619: INFO: (7) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname2/proxy/: bar (200; 35.752111ms)
May 29 18:24:00.620: INFO: (7) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/tlsrewritem... (200; 36.562549ms)
May 29 18:24:00.620: INFO: (7) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname1/proxy/: tls baz (200; 36.498615ms)
May 29 18:24:00.621: INFO: (7) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname1/proxy/: foo (200; 37.253238ms)
May 29 18:24:00.635: INFO: (7) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname2/proxy/: bar (200; 51.743068ms)
May 29 18:24:00.655: INFO: (8) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/rewriteme">... (200; 18.422874ms)
May 29 18:24:00.658: INFO: (8) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:462/proxy/: tls qux (200; 20.604231ms)
May 29 18:24:00.658: INFO: (8) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:460/proxy/: tls baz (200; 21.001321ms)
May 29 18:24:00.659: INFO: (8) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/tlsrewritem... (200; 21.520302ms)
May 29 18:24:00.670: INFO: (8) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/rewriteme">test<... (200; 33.642321ms)
May 29 18:24:00.690: INFO: (8) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname1/proxy/: foo (200; 51.956472ms)
May 29 18:24:00.691: INFO: (8) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:160/proxy/: foo (200; 53.759751ms)
May 29 18:24:00.691: INFO: (8) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname1/proxy/: tls baz (200; 53.688283ms)
May 29 18:24:00.691: INFO: (8) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname1/proxy/: foo (200; 53.805986ms)
May 29 18:24:00.696: INFO: (8) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:162/proxy/: bar (200; 58.714573ms)
May 29 18:24:00.696: INFO: (8) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/rewriteme">test</a> (200; 57.72691ms)
May 29 18:24:00.696: INFO: (8) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname2/proxy/: tls qux (200; 60.862987ms)
May 29 18:24:00.697: INFO: (8) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:162/proxy/: bar (200; 59.064915ms)
May 29 18:24:00.697: INFO: (8) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:160/proxy/: foo (200; 59.429664ms)
May 29 18:24:00.697: INFO: (8) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname2/proxy/: bar (200; 60.534832ms)
May 29 18:24:00.698: INFO: (8) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname2/proxy/: bar (200; 62.339772ms)
May 29 18:24:00.720: INFO: (9) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:462/proxy/: tls qux (200; 20.717413ms)
May 29 18:24:00.720: INFO: (9) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:162/proxy/: bar (200; 20.946408ms)
May 29 18:24:00.720: INFO: (9) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/tlsrewritem... (200; 21.040561ms)
May 29 18:24:00.721: INFO: (9) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/rewriteme">test</a> (200; 21.201674ms)
May 29 18:24:00.721: INFO: (9) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/rewriteme">test<... (200; 22.453289ms)
May 29 18:24:00.721: INFO: (9) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/rewriteme">... (200; 22.590173ms)
May 29 18:24:00.727: INFO: (9) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname1/proxy/: tls baz (200; 27.548181ms)
May 29 18:24:00.727: INFO: (9) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname2/proxy/: bar (200; 28.309001ms)
May 29 18:24:00.727: INFO: (9) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname2/proxy/: tls qux (200; 27.966452ms)
May 29 18:24:00.727: INFO: (9) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:162/proxy/: bar (200; 28.120707ms)
May 29 18:24:00.730: INFO: (9) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:460/proxy/: tls baz (200; 30.729048ms)
May 29 18:24:00.730: INFO: (9) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:160/proxy/: foo (200; 31.14389ms)
May 29 18:24:00.760: INFO: (9) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname1/proxy/: foo (200; 60.884559ms)
May 29 18:24:00.761: INFO: (9) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:160/proxy/: foo (200; 61.88946ms)
May 29 18:24:00.765: INFO: (9) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname2/proxy/: bar (200; 66.08543ms)
May 29 18:24:00.786: INFO: (9) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname1/proxy/: foo (200; 86.757496ms)
May 29 18:24:00.805: INFO: (10) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:162/proxy/: bar (200; 17.43992ms)
May 29 18:24:00.808: INFO: (10) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/rewriteme">... (200; 21.029121ms)
May 29 18:24:00.808: INFO: (10) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:460/proxy/: tls baz (200; 20.948062ms)
May 29 18:24:00.809: INFO: (10) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/rewriteme">test</a> (200; 20.930051ms)
May 29 18:24:00.809: INFO: (10) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:162/proxy/: bar (200; 21.441147ms)
May 29 18:24:00.812: INFO: (10) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:462/proxy/: tls qux (200; 25.632459ms)
May 29 18:24:00.813: INFO: (10) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname2/proxy/: tls qux (200; 25.378848ms)
May 29 18:24:00.823: INFO: (10) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/rewriteme">test<... (200; 34.678631ms)
May 29 18:24:00.824: INFO: (10) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname2/proxy/: bar (200; 36.303044ms)
May 29 18:24:01.054: INFO: (10) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:160/proxy/: foo (200; 267.156005ms)
May 29 18:24:01.060: INFO: (10) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname1/proxy/: foo (200; 272.798282ms)
May 29 18:24:01.060: INFO: (10) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:160/proxy/: foo (200; 273.315693ms)
May 29 18:24:01.061: INFO: (10) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/tlsrewritem... (200; 273.719847ms)
May 29 18:24:01.062: INFO: (10) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname1/proxy/: foo (200; 275.095026ms)
May 29 18:24:01.063: INFO: (10) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname1/proxy/: tls baz (200; 276.221624ms)
May 29 18:24:02.019: INFO: (10) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname2/proxy/: bar (200; 1.232675993s)
May 29 18:24:02.052: INFO: (11) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:462/proxy/: tls qux (200; 31.20437ms)
May 29 18:24:02.055: INFO: (11) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:160/proxy/: foo (200; 34.040301ms)
May 29 18:24:02.057: INFO: (11) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/tlsrewritem... (200; 36.863691ms)
May 29 18:24:02.062: INFO: (11) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:162/proxy/: bar (200; 41.50695ms)
May 29 18:24:02.062: INFO: (11) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname2/proxy/: bar (200; 41.448651ms)
May 29 18:24:02.064: INFO: (11) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/rewriteme">test<... (200; 43.048294ms)
May 29 18:24:02.066: INFO: (11) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:460/proxy/: tls baz (200; 45.883648ms)
May 29 18:24:02.066: INFO: (11) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:162/proxy/: bar (200; 45.25017ms)
May 29 18:24:02.074: INFO: (11) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname2/proxy/: tls qux (200; 53.631738ms)
May 29 18:24:02.143: INFO: (11) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:160/proxy/: foo (200; 123.112165ms)
May 29 18:24:02.154: INFO: (11) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname1/proxy/: foo (200; 133.872222ms)
May 29 18:24:02.154: INFO: (11) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/rewriteme">... (200; 133.052625ms)
May 29 18:24:02.155: INFO: (11) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/rewriteme">test</a> (200; 133.782432ms)
May 29 18:24:02.157: INFO: (11) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname2/proxy/: bar (200; 135.811591ms)
May 29 18:24:02.161: INFO: (11) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname1/proxy/: foo (200; 140.446673ms)
May 29 18:24:02.161: INFO: (11) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname1/proxy/: tls baz (200; 140.990612ms)
May 29 18:24:02.199: INFO: (12) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:162/proxy/: bar (200; 36.87634ms)
May 29 18:24:02.200: INFO: (12) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/rewriteme">test<... (200; 37.477197ms)
May 29 18:24:02.200: INFO: (12) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/rewriteme">... (200; 38.271961ms)
May 29 18:24:02.200: INFO: (12) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:160/proxy/: foo (200; 37.930583ms)
May 29 18:24:02.200: INFO: (12) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/tlsrewritem... (200; 37.820586ms)
May 29 18:24:02.201: INFO: (12) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:460/proxy/: tls baz (200; 38.441288ms)
May 29 18:24:02.201: INFO: (12) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:160/proxy/: foo (200; 38.879854ms)
May 29 18:24:02.202: INFO: (12) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname1/proxy/: foo (200; 40.143115ms)
May 29 18:24:02.202: INFO: (12) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname1/proxy/: tls baz (200; 40.155114ms)
May 29 18:24:02.215: INFO: (12) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:462/proxy/: tls qux (200; 52.45574ms)
May 29 18:24:02.216: INFO: (12) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:162/proxy/: bar (200; 53.870899ms)
May 29 18:24:02.218: INFO: (12) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/rewriteme">test</a> (200; 54.992015ms)
May 29 18:24:02.227: INFO: (12) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname1/proxy/: foo (200; 65.23235ms)
May 29 18:24:02.227: INFO: (12) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname2/proxy/: tls qux (200; 64.632112ms)
May 29 18:24:02.231: INFO: (12) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname2/proxy/: bar (200; 69.021755ms)
May 29 18:24:02.248: INFO: (12) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname2/proxy/: bar (200; 85.966041ms)
May 29 18:24:02.267: INFO: (13) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:162/proxy/: bar (200; 17.669074ms)
May 29 18:24:02.268: INFO: (13) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:162/proxy/: bar (200; 18.538455ms)
May 29 18:24:02.269: INFO: (13) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:462/proxy/: tls qux (200; 18.578442ms)
May 29 18:24:02.270: INFO: (13) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/rewriteme">test</a> (200; 19.706209ms)
May 29 18:24:02.271: INFO: (13) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/tlsrewritem... (200; 21.484553ms)
May 29 18:24:02.271: INFO: (13) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:160/proxy/: foo (200; 19.958475ms)
May 29 18:24:02.272: INFO: (13) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:160/proxy/: foo (200; 21.607806ms)
May 29 18:24:02.272: INFO: (13) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname2/proxy/: bar (200; 23.679543ms)
May 29 18:24:02.279: INFO: (13) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:460/proxy/: tls baz (200; 28.398584ms)
May 29 18:24:02.279: INFO: (13) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname2/proxy/: tls qux (200; 28.556827ms)
May 29 18:24:02.280: INFO: (13) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/rewriteme">test<... (200; 30.043302ms)
May 29 18:24:02.282: INFO: (13) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname1/proxy/: tls baz (200; 31.208514ms)
May 29 18:24:02.284: INFO: (13) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/rewriteme">... (200; 33.048426ms)
May 29 18:24:02.287: INFO: (13) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname2/proxy/: bar (200; 36.575221ms)
May 29 18:24:02.288: INFO: (13) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname1/proxy/: foo (200; 36.905469ms)
May 29 18:24:02.308: INFO: (13) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname1/proxy/: foo (200; 58.145698ms)
May 29 18:24:02.326: INFO: (14) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/rewriteme">test</a> (200; 17.231796ms)
May 29 18:24:02.327: INFO: (14) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:162/proxy/: bar (200; 17.489391ms)
May 29 18:24:02.351: INFO: (14) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname1/proxy/: foo (200; 42.332224ms)
May 29 18:24:02.351: INFO: (14) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/rewriteme">... (200; 41.648643ms)
May 29 18:24:02.351: INFO: (14) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/tlsrewritem... (200; 42.873747ms)
May 29 18:24:02.351: INFO: (14) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:160/proxy/: foo (200; 41.775933ms)
May 29 18:24:02.351: INFO: (14) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:162/proxy/: bar (200; 42.126017ms)
May 29 18:24:02.351: INFO: (14) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:462/proxy/: tls qux (200; 42.212002ms)
May 29 18:24:02.355: INFO: (14) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:160/proxy/: foo (200; 46.200911ms)
May 29 18:24:02.356: INFO: (14) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname2/proxy/: bar (200; 46.527546ms)
May 29 18:24:02.356: INFO: (14) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/rewriteme">test<... (200; 47.568418ms)
May 29 18:24:02.356: INFO: (14) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname2/proxy/: tls qux (200; 47.408664ms)
May 29 18:24:02.356: INFO: (14) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname1/proxy/: tls baz (200; 47.561481ms)
May 29 18:24:02.356: INFO: (14) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname1/proxy/: foo (200; 47.676198ms)
May 29 18:24:02.357: INFO: (14) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname2/proxy/: bar (200; 47.106853ms)
May 29 18:24:02.357: INFO: (14) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:460/proxy/: tls baz (200; 48.224086ms)
May 29 18:24:02.378: INFO: (15) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/rewriteme">test<... (200; 18.725048ms)
May 29 18:24:02.378: INFO: (15) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:160/proxy/: foo (200; 17.10473ms)
May 29 18:24:02.378: INFO: (15) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:162/proxy/: bar (200; 17.241586ms)
May 29 18:24:02.384: INFO: (15) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:162/proxy/: bar (200; 24.305233ms)
May 29 18:24:02.384: INFO: (15) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:462/proxy/: tls qux (200; 24.495206ms)
May 29 18:24:02.385: INFO: (15) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname2/proxy/: bar (200; 24.822946ms)
May 29 18:24:02.385: INFO: (15) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:460/proxy/: tls baz (200; 24.528823ms)
May 29 18:24:02.385: INFO: (15) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/tlsrewritem... (200; 24.634139ms)
May 29 18:24:02.385: INFO: (15) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname2/proxy/: tls qux (200; 26.321132ms)
May 29 18:24:02.385: INFO: (15) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/rewriteme">... (200; 24.912363ms)
May 29 18:24:02.386: INFO: (15) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/rewriteme">test</a> (200; 24.943197ms)
May 29 18:24:02.387: INFO: (15) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname1/proxy/: foo (200; 26.223064ms)
May 29 18:24:02.387: INFO: (15) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:160/proxy/: foo (200; 27.327372ms)
May 29 18:24:02.390: INFO: (15) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname2/proxy/: bar (200; 30.905999ms)
May 29 18:24:02.393: INFO: (15) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname1/proxy/: foo (200; 32.008469ms)
May 29 18:24:02.393: INFO: (15) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname1/proxy/: tls baz (200; 32.600821ms)
May 29 18:24:02.408: INFO: (16) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:462/proxy/: tls qux (200; 14.321387ms)
May 29 18:24:02.409: INFO: (16) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/tlsrewritem... (200; 14.874797ms)
May 29 18:24:02.413: INFO: (16) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:162/proxy/: bar (200; 18.706477ms)
May 29 18:24:02.413: INFO: (16) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:162/proxy/: bar (200; 18.704901ms)
May 29 18:24:02.414: INFO: (16) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:160/proxy/: foo (200; 17.789738ms)
May 29 18:24:02.414: INFO: (16) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname1/proxy/: foo (200; 19.841248ms)
May 29 18:24:02.414: INFO: (16) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:460/proxy/: tls baz (200; 19.356619ms)
May 29 18:24:02.415: INFO: (16) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/rewriteme">test<... (200; 19.717914ms)
May 29 18:24:02.424: INFO: (16) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname2/proxy/: bar (200; 28.59836ms)
May 29 18:24:02.424: INFO: (16) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname1/proxy/: foo (200; 29.475868ms)
May 29 18:24:02.425: INFO: (16) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname2/proxy/: tls qux (200; 30.347727ms)
May 29 18:24:02.425: INFO: (16) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/rewriteme">... (200; 28.948198ms)
May 29 18:24:02.425: INFO: (16) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/rewriteme">test</a> (200; 29.857068ms)
May 29 18:24:02.427: INFO: (16) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:160/proxy/: foo (200; 32.817919ms)
May 29 18:24:02.428: INFO: (16) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname1/proxy/: tls baz (200; 33.609202ms)
May 29 18:24:02.428: INFO: (16) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname2/proxy/: bar (200; 32.838826ms)
May 29 18:24:02.446: INFO: (17) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/tlsrewritem... (200; 17.506613ms)
May 29 18:24:02.447: INFO: (17) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:460/proxy/: tls baz (200; 18.006016ms)
May 29 18:24:02.456: INFO: (17) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:162/proxy/: bar (200; 26.219225ms)
May 29 18:24:02.456: INFO: (17) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:162/proxy/: bar (200; 26.537421ms)
May 29 18:24:02.456: INFO: (17) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/rewriteme">... (200; 26.262418ms)
May 29 18:24:02.457: INFO: (17) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/rewriteme">test</a> (200; 26.596076ms)
May 29 18:24:02.457: INFO: (17) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/rewriteme">test<... (200; 26.644357ms)
May 29 18:24:02.458: INFO: (17) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:160/proxy/: foo (200; 28.464471ms)
May 29 18:24:02.458: INFO: (17) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:462/proxy/: tls qux (200; 28.475596ms)
May 29 18:24:02.459: INFO: (17) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname1/proxy/: foo (200; 29.889321ms)
May 29 18:24:02.461: INFO: (17) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname2/proxy/: bar (200; 31.26992ms)
May 29 18:24:02.461: INFO: (17) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname1/proxy/: tls baz (200; 31.926282ms)
May 29 18:24:02.461: INFO: (17) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname2/proxy/: bar (200; 30.881428ms)
May 29 18:24:02.463: INFO: (17) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:160/proxy/: foo (200; 32.472479ms)
May 29 18:24:02.463: INFO: (17) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname2/proxy/: tls qux (200; 33.761103ms)
May 29 18:24:02.463: INFO: (17) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname1/proxy/: foo (200; 32.939155ms)
May 29 18:24:02.479: INFO: (18) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/rewriteme">... (200; 15.37106ms)
May 29 18:24:02.479: INFO: (18) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:160/proxy/: foo (200; 15.263765ms)
May 29 18:24:02.481: INFO: (18) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:162/proxy/: bar (200; 16.140222ms)
May 29 18:24:02.481: INFO: (18) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/tlsrewritem... (200; 16.741983ms)
May 29 18:24:02.481: INFO: (18) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:462/proxy/: tls qux (200; 17.060619ms)
May 29 18:24:02.482: INFO: (18) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/rewriteme">test<... (200; 17.323774ms)
May 29 18:24:02.482: INFO: (18) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:460/proxy/: tls baz (200; 17.607931ms)
May 29 18:24:02.483: INFO: (18) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname1/proxy/: foo (200; 19.72755ms)
May 29 18:24:02.483: INFO: (18) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname2/proxy/: tls qux (200; 19.198589ms)
May 29 18:24:02.485: INFO: (18) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname2/proxy/: bar (200; 20.664027ms)
May 29 18:24:02.503: INFO: (18) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname1/proxy/: tls baz (200; 38.814189ms)
May 29 18:24:02.504: INFO: (18) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:160/proxy/: foo (200; 39.830515ms)
May 29 18:24:02.505: INFO: (18) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:162/proxy/: bar (200; 40.177738ms)
May 29 18:24:02.507: INFO: (18) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/rewriteme">test</a> (200; 42.611355ms)
May 29 18:24:02.509: INFO: (18) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname1/proxy/: foo (200; 44.047091ms)
May 29 18:24:02.522: INFO: (18) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname2/proxy/: bar (200; 58.404483ms)
May 29 18:24:02.540: INFO: (19) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:460/proxy/: tls baz (200; 17.617801ms)
May 29 18:24:02.559: INFO: (19) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:160/proxy/: foo (200; 35.021749ms)
May 29 18:24:02.560: INFO: (19) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:162/proxy/: bar (200; 34.685437ms)
May 29 18:24:02.560: INFO: (19) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:160/proxy/: foo (200; 35.81035ms)
May 29 18:24:02.560: INFO: (19) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:443/proxy/tlsrewritem... (200; 35.226454ms)
May 29 18:24:02.560: INFO: (19) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm/proxy/rewriteme">test</a> (200; 36.902716ms)
May 29 18:24:02.560: INFO: (19) /api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/proxy-service-56nkm-k98tm:1080/proxy/rewriteme">test<... (200; 36.819827ms)
May 29 18:24:02.560: INFO: (19) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:162/proxy/: bar (200; 34.572207ms)
May 29 18:24:02.561: INFO: (19) /api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5566/pods/http:proxy-service-56nkm-k98tm:1080/proxy/rewriteme">... (200; 36.453237ms)
May 29 18:24:02.561: INFO: (19) /api/v1/namespaces/proxy-5566/pods/https:proxy-service-56nkm-k98tm:462/proxy/: tls qux (200; 35.14829ms)
May 29 18:24:02.574: INFO: (19) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname2/proxy/: bar (200; 50.108837ms)
May 29 18:24:02.574: INFO: (19) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname1/proxy/: tls baz (200; 49.534058ms)
May 29 18:24:02.574: INFO: (19) /api/v1/namespaces/proxy-5566/services/http:proxy-service-56nkm:portname1/proxy/: foo (200; 49.877681ms)
May 29 18:24:02.574: INFO: (19) /api/v1/namespaces/proxy-5566/services/https:proxy-service-56nkm:tlsportname2/proxy/: tls qux (200; 49.220256ms)
May 29 18:24:02.576: INFO: (19) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname2/proxy/: bar (200; 52.374663ms)
May 29 18:24:02.579: INFO: (19) /api/v1/namespaces/proxy-5566/services/proxy-service-56nkm:portname1/proxy/: foo (200; 56.001551ms)
STEP: deleting ReplicationController proxy-service-56nkm in namespace proxy-5566, will wait for the garbage collector to delete the pods
May 29 18:24:03.505: INFO: Deleting ReplicationController proxy-service-56nkm took: 863.772765ms
May 29 18:24:04.006: INFO: Terminating ReplicationController proxy-service-56nkm pods took: 501.277277ms
[AfterEach] version v1
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:24:11.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5566" for this suite.

• [SLOW TEST:20.673 seconds]
[sig-network] Proxy
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:59
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":277,"completed":261,"skipped":4307,"failed":0}
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:24:11.538: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
May 29 18:24:11.695: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:24:20.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6436" for this suite.

• [SLOW TEST:9.318 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":277,"completed":262,"skipped":4312,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:24:20.876: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
May 29 18:24:23.781: INFO: Pod name wrapped-volume-race-d701151c-536e-42cc-b368-447ca1c97d9e: Found 0 pods out of 5
May 29 18:24:28.806: INFO: Pod name wrapped-volume-race-d701151c-536e-42cc-b368-447ca1c97d9e: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d701151c-536e-42cc-b368-447ca1c97d9e in namespace emptydir-wrapper-1758, will wait for the garbage collector to delete the pods
May 29 18:24:42.278: INFO: Deleting ReplicationController wrapped-volume-race-d701151c-536e-42cc-b368-447ca1c97d9e took: 29.933552ms
May 29 18:24:42.879: INFO: Terminating ReplicationController wrapped-volume-race-d701151c-536e-42cc-b368-447ca1c97d9e pods took: 600.422409ms
STEP: Creating RC which spawns configmap-volume pods
May 29 18:24:56.353: INFO: Pod name wrapped-volume-race-b31a39b3-f8c6-4fff-b388-aada4363ddb6: Found 0 pods out of 5
May 29 18:25:01.387: INFO: Pod name wrapped-volume-race-b31a39b3-f8c6-4fff-b388-aada4363ddb6: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-b31a39b3-f8c6-4fff-b388-aada4363ddb6 in namespace emptydir-wrapper-1758, will wait for the garbage collector to delete the pods
May 29 18:25:13.879: INFO: Deleting ReplicationController wrapped-volume-race-b31a39b3-f8c6-4fff-b388-aada4363ddb6 took: 50.474603ms
May 29 18:25:14.480: INFO: Terminating ReplicationController wrapped-volume-race-b31a39b3-f8c6-4fff-b388-aada4363ddb6 pods took: 600.490327ms
STEP: Creating RC which spawns configmap-volume pods
May 29 18:25:26.547: INFO: Pod name wrapped-volume-race-b5aee8ed-9087-4311-bb5b-c6629d7be8b0: Found 0 pods out of 5
May 29 18:25:31.567: INFO: Pod name wrapped-volume-race-b5aee8ed-9087-4311-bb5b-c6629d7be8b0: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-b5aee8ed-9087-4311-bb5b-c6629d7be8b0 in namespace emptydir-wrapper-1758, will wait for the garbage collector to delete the pods
May 29 18:25:43.790: INFO: Deleting ReplicationController wrapped-volume-race-b5aee8ed-9087-4311-bb5b-c6629d7be8b0 took: 77.38029ms
May 29 18:25:44.390: INFO: Terminating ReplicationController wrapped-volume-race-b5aee8ed-9087-4311-bb5b-c6629d7be8b0 pods took: 600.583497ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:25:56.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1758" for this suite.

• [SLOW TEST:95.447 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":277,"completed":263,"skipped":4390,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:25:56.331: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
May 29 18:25:56.484: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fd0fb086-bd10-4721-a398-64d9132318e9" in namespace "downward-api-417" to be "Succeeded or Failed"
May 29 18:25:56.509: INFO: Pod "downwardapi-volume-fd0fb086-bd10-4721-a398-64d9132318e9": Phase="Pending", Reason="", readiness=false. Elapsed: 25.666823ms
May 29 18:25:58.528: INFO: Pod "downwardapi-volume-fd0fb086-bd10-4721-a398-64d9132318e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043981654s
May 29 18:26:00.674: INFO: Pod "downwardapi-volume-fd0fb086-bd10-4721-a398-64d9132318e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.190150602s
STEP: Saw pod success
May 29 18:26:00.674: INFO: Pod "downwardapi-volume-fd0fb086-bd10-4721-a398-64d9132318e9" satisfied condition "Succeeded or Failed"
May 29 18:26:00.692: INFO: Trying to get logs from node node-cncf-lab-1 pod downwardapi-volume-fd0fb086-bd10-4721-a398-64d9132318e9 container client-container: <nil>
STEP: delete the pod
May 29 18:26:00.825: INFO: Waiting for pod downwardapi-volume-fd0fb086-bd10-4721-a398-64d9132318e9 to disappear
May 29 18:26:00.854: INFO: Pod downwardapi-volume-fd0fb086-bd10-4721-a398-64d9132318e9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:26:00.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-417" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":264,"skipped":4421,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:26:00.924: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 18:26:01.095: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
May 29 18:26:02.233: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:26:02.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9697" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":277,"completed":265,"skipped":4439,"failed":0}

------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:26:02.285: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-fa992dce-3c7d-46ff-800a-ee6bd3a14cfa
STEP: Creating configMap with name cm-test-opt-upd-e9a066e0-7004-45c2-830b-49f05ef3f2b9
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-fa992dce-3c7d-46ff-800a-ee6bd3a14cfa
STEP: Updating configmap cm-test-opt-upd-e9a066e0-7004-45c2-830b-49f05ef3f2b9
STEP: Creating configMap with name cm-test-opt-create-5c88249c-57a3-4b51-8a00-0235bcfc56ef
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:26:12.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2937" for this suite.

• [SLOW TEST:10.686 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":266,"skipped":4439,"failed":0}
SSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:26:12.972: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:164
May 29 18:26:13.134: INFO: Waiting up to 1m0s for all nodes to be ready
May 29 18:27:13.202: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 18:27:13.213: INFO: Starting informer...
STEP: Starting pod...
May 29 18:27:13.722: INFO: Pod is running on node-cncf-lab-1. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
May 29 18:27:13.834: INFO: Pod wasn't evicted. Proceeding
May 29 18:27:13.834: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
May 29 18:28:28.874: INFO: Pod wasn't evicted. Test successful
[AfterEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:28:28.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-4830" for this suite.

• [SLOW TEST:136.196 seconds]
[k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":277,"completed":267,"skipped":4452,"failed":0}
SS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:28:29.169: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap that has name configmap-test-emptyKey-f91232b3-8f69-46f7-b7a5-82ece9518354
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:28:29.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-278" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":277,"completed":268,"skipped":4454,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:28:29.468: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
May 29 18:28:29.771: INFO: Waiting up to 5m0s for pod "pod-b8551df5-f8c6-493c-b5ed-73130524727b" in namespace "emptydir-4350" to be "Succeeded or Failed"
May 29 18:28:29.780: INFO: Pod "pod-b8551df5-f8c6-493c-b5ed-73130524727b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.201843ms
May 29 18:28:31.796: INFO: Pod "pod-b8551df5-f8c6-493c-b5ed-73130524727b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024613443s
May 29 18:28:33.815: INFO: Pod "pod-b8551df5-f8c6-493c-b5ed-73130524727b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0437397s
STEP: Saw pod success
May 29 18:28:33.815: INFO: Pod "pod-b8551df5-f8c6-493c-b5ed-73130524727b" satisfied condition "Succeeded or Failed"
May 29 18:28:33.828: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-b8551df5-f8c6-493c-b5ed-73130524727b container test-container: <nil>
STEP: delete the pod
May 29 18:28:33.964: INFO: Waiting for pod pod-b8551df5-f8c6-493c-b5ed-73130524727b to disappear
May 29 18:28:33.982: INFO: Pod pod-b8551df5-f8c6-493c-b5ed-73130524727b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:28:33.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4350" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":269,"skipped":4504,"failed":0}
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:28:34.012: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-5206/configmap-test-f29117a9-2f91-4fe9-986b-18adb35d3466
STEP: Creating a pod to test consume configMaps
May 29 18:28:34.185: INFO: Waiting up to 5m0s for pod "pod-configmaps-916e1e81-c392-4e96-9d88-fdb0980a97e6" in namespace "configmap-5206" to be "Succeeded or Failed"
May 29 18:28:34.205: INFO: Pod "pod-configmaps-916e1e81-c392-4e96-9d88-fdb0980a97e6": Phase="Pending", Reason="", readiness=false. Elapsed: 19.0506ms
May 29 18:28:36.217: INFO: Pod "pod-configmaps-916e1e81-c392-4e96-9d88-fdb0980a97e6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031916906s
May 29 18:28:38.229: INFO: Pod "pod-configmaps-916e1e81-c392-4e96-9d88-fdb0980a97e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044024421s
STEP: Saw pod success
May 29 18:28:38.230: INFO: Pod "pod-configmaps-916e1e81-c392-4e96-9d88-fdb0980a97e6" satisfied condition "Succeeded or Failed"
May 29 18:28:38.241: INFO: Trying to get logs from node node-cncf-lab-1 pod pod-configmaps-916e1e81-c392-4e96-9d88-fdb0980a97e6 container env-test: <nil>
STEP: delete the pod
May 29 18:28:38.308: INFO: Waiting for pod pod-configmaps-916e1e81-c392-4e96-9d88-fdb0980a97e6 to disappear
May 29 18:28:38.317: INFO: Pod pod-configmaps-916e1e81-c392-4e96-9d88-fdb0980a97e6 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:28:38.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5206" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":277,"completed":270,"skipped":4505,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:28:38.360: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
May 29 18:28:38.503: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f680c2b2-1e41-4f65-88ad-93249eac1c76" in namespace "projected-6055" to be "Succeeded or Failed"
May 29 18:28:38.514: INFO: Pod "downwardapi-volume-f680c2b2-1e41-4f65-88ad-93249eac1c76": Phase="Pending", Reason="", readiness=false. Elapsed: 10.258561ms
May 29 18:28:40.528: INFO: Pod "downwardapi-volume-f680c2b2-1e41-4f65-88ad-93249eac1c76": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024122735s
May 29 18:28:42.538: INFO: Pod "downwardapi-volume-f680c2b2-1e41-4f65-88ad-93249eac1c76": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03418496s
May 29 18:28:44.549: INFO: Pod "downwardapi-volume-f680c2b2-1e41-4f65-88ad-93249eac1c76": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.044838354s
STEP: Saw pod success
May 29 18:28:44.549: INFO: Pod "downwardapi-volume-f680c2b2-1e41-4f65-88ad-93249eac1c76" satisfied condition "Succeeded or Failed"
May 29 18:28:44.559: INFO: Trying to get logs from node node-cncf-lab-1 pod downwardapi-volume-f680c2b2-1e41-4f65-88ad-93249eac1c76 container client-container: <nil>
STEP: delete the pod
May 29 18:28:45.442: INFO: Waiting for pod downwardapi-volume-f680c2b2-1e41-4f65-88ad-93249eac1c76 to disappear
May 29 18:28:45.460: INFO: Pod downwardapi-volume-f680c2b2-1e41-4f65-88ad-93249eac1c76 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:28:45.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6055" for this suite.

• [SLOW TEST:8.396 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":271,"skipped":4537,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:28:46.757: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 18:28:46.875: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
May 29 18:28:50.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 --namespace=crd-publish-openapi-4687 create -f -'
May 29 18:28:52.805: INFO: stderr: ""
May 29 18:28:52.805: INFO: stdout: "e2e-test-crd-publish-openapi-5132-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
May 29 18:28:52.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 --namespace=crd-publish-openapi-4687 delete e2e-test-crd-publish-openapi-5132-crds test-cr'
May 29 18:28:53.094: INFO: stderr: ""
May 29 18:28:53.094: INFO: stdout: "e2e-test-crd-publish-openapi-5132-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
May 29 18:28:53.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 --namespace=crd-publish-openapi-4687 apply -f -'
May 29 18:28:53.385: INFO: stderr: ""
May 29 18:28:53.385: INFO: stdout: "e2e-test-crd-publish-openapi-5132-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
May 29 18:28:53.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 --namespace=crd-publish-openapi-4687 delete e2e-test-crd-publish-openapi-5132-crds test-cr'
May 29 18:28:54.400: INFO: stderr: ""
May 29 18:28:54.401: INFO: stdout: "e2e-test-crd-publish-openapi-5132-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
May 29 18:28:54.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-852825370 explain e2e-test-crd-publish-openapi-5132-crds'
May 29 18:28:54.690: INFO: stderr: ""
May 29 18:28:54.690: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5132-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:28:58.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4687" for this suite.

• [SLOW TEST:11.660 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":277,"completed":272,"skipped":4551,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:28:58.430: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
May 29 18:29:04.905: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:29:06.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4800" for this suite.

• [SLOW TEST:7.715 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":277,"completed":273,"skipped":4611,"failed":0}
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:29:06.146: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:29:12.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3842" for this suite.

• [SLOW TEST:6.388 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when scheduling a busybox command in a pod
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:41
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":277,"completed":274,"skipped":4617,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:29:12.536: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:345
May 29 18:29:12.627: INFO: Waiting up to 1m0s for all nodes to be ready
May 29 18:30:12.696: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 18:30:12.708: INFO: Starting informer...
STEP: Starting pods...
May 29 18:30:12.958: INFO: Pod1 is running on node-cncf-lab-1. Tainting Node
May 29 18:30:17.239: INFO: Pod2 is running on node-cncf-lab-1. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
May 29 18:30:32.525: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
May 29 18:30:44.933: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:30:44.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-9649" for this suite.

• [SLOW TEST:92.472 seconds]
[k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":277,"completed":275,"skipped":4656,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:30:45.009: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 29 18:30:46.290: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
May 29 18:30:49.442: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726373846, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726373846, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726373846, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726373846, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 29 18:30:52.504: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
May 29 18:30:52.565: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9113-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:30:54.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4934" for this suite.
STEP: Destroying namespace "webhook-4934-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:10.106 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":277,"completed":276,"skipped":4661,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
May 29 18:30:55.116: INFO: >>> kubeConfig: /tmp/kubeconfig-852825370
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May 29 18:31:02.117: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
May 29 18:31:02.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8955" for this suite.

• [SLOW TEST:7.787 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  blackbox test
  /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
    on terminated container
    /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:133
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.18.1-beta.0.38+49aac775931dd1/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":277,"skipped":4677,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSMay 29 18:31:02.905: INFO: Running AfterSuite actions on all nodes
May 29 18:31:02.905: INFO: Running AfterSuite actions on node 1
May 29 18:31:02.905: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/results/junit_01.xml
{"msg":"Test Suite completed","total":277,"completed":277,"skipped":4715,"failed":0}

Ran 277 of 4992 Specs in 5491.918 seconds
SUCCESS! -- 277 Passed | 0 Failed | 0 Pending | 4715 Skipped
PASS

Ginkgo ran 1 suite in 1h31m33.855573983s
Test Suite Passed
