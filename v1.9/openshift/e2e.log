May 21 07:05:33.002: INFO: Overriding default scale value of zero to 1
May 21 07:05:33.002: INFO: Overriding default milliseconds value of zero to 5000
I0521 07:05:33.120144   24333 e2e.go:331] Starting e2e run "5a5e5c88-5cc5-11e8-849c-0e182f31d764" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1526886332 - Will randomize all specs
Will run 149 of 843 specs

I0521 07:05:33.145856   24333 e2e.go:56] The --provider flag is not set.  Treating as a conformance test.  Some tests may not be run.
May 21 07:05:33.145: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
May 21 07:05:33.150: INFO: Waiting up to 4h0m0s for all (but 1) nodes to be schedulable
May 21 07:05:33.232: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 21 07:05:33.332: INFO: 0 / 0 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 21 07:05:33.332: INFO: expected 0 pod replicas in namespace 'kube-system', 0 are Running and Ready.
May 21 07:05:33.348: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
May 21 07:05:33.348: INFO: Dumping network health container logs from all nodes to file /data/src/github.com/openshift/origin/_output/scripts/conformance-k8s/artifacts/nethealth.txt
May 21 07:05:33.364: INFO: e2e test version: v1.9.8-beta.0.40+c138b851781560
May 21 07:05:33.378: INFO: kube-apiserver version: v1.9.1+a0ce1bc657
I0521 07:05:33.378508   24333 e2e.go:56] The --provider flag is not set.  Treating as a conformance test.  Some tests may not be run.
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:05:33.378: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
May 21 07:05:33.488: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create a job from an image, then delete the job  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: executing a command with run --rm and attach with stdin
May 21 07:05:33.504: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig --namespace=e2e-tests-kubectl-wjh5g run e2e-test-rm-busybox-job --image=busybox --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
May 21 07:05:48.271: INFO: stderr: "If you don't see a command prompt, try pressing enter.\n"
May 21 07:05:48.271: INFO: stdout: "abcd1234stdin closed\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:05:48.287: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wjh5g" for this suite.
May 21 07:05:54.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:05:55.665: INFO: namespace: e2e-tests-kubectl-wjh5g, resource: bindings, ignored listing per whitelist
May 21 07:05:55.803: INFO: namespace e2e-tests-kubectl-wjh5g deletion completed in 7.499580485s

• [SLOW TEST:22.425 seconds]
[sig-cli] Kubectl client
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should create a job from an image, then delete the job  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:05:55.803: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should set DefaultMode on files  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward API volume plugin
May 21 07:05:55.927: INFO: Waiting up to 5m0s for pod "downwardapi-volume-68119b19-5cc5-11e8-849c-0e182f31d764" in namespace "e2e-tests-downward-api-w9xzx" to be "success or failure"
May 21 07:05:55.942: INFO: Pod "downwardapi-volume-68119b19-5cc5-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 14.744868ms
May 21 07:05:57.958: INFO: Pod "downwardapi-volume-68119b19-5cc5-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03096794s
May 21 07:05:59.975: INFO: Pod "downwardapi-volume-68119b19-5cc5-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047099979s
May 21 07:06:01.991: INFO: Pod "downwardapi-volume-68119b19-5cc5-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 6.063448517s
May 21 07:06:04.007: INFO: Pod "downwardapi-volume-68119b19-5cc5-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.079602043s
STEP: Saw pod success
May 21 07:06:04.007: INFO: Pod "downwardapi-volume-68119b19-5cc5-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:06:04.023: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod downwardapi-volume-68119b19-5cc5-11e8-849c-0e182f31d764 container client-container: <nil>
STEP: delete the pod
May 21 07:06:04.097: INFO: Waiting for pod downwardapi-volume-68119b19-5cc5-11e8-849c-0e182f31d764 to disappear
May 21 07:06:04.112: INFO: Pod downwardapi-volume-68119b19-5cc5-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:06:04.112: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-w9xzx" for this suite.
May 21 07:06:10.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:06:11.246: INFO: namespace: e2e-tests-downward-api-w9xzx, resource: bindings, ignored listing per whitelist
May 21 07:06:11.628: INFO: namespace e2e-tests-downward-api-w9xzx deletion completed in 7.499525449s

• [SLOW TEST:15.826 seconds]
[sig-storage] Downward API volume
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should set DefaultMode on files  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:06:11.629: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward API volume plugin
May 21 07:06:11.757: INFO: Waiting up to 5m0s for pod "downwardapi-volume-718073fa-5cc5-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-s7xft" to be "success or failure"
May 21 07:06:11.772: INFO: Pod "downwardapi-volume-718073fa-5cc5-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 14.957384ms
May 21 07:06:13.789: INFO: Pod "downwardapi-volume-718073fa-5cc5-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03154274s
May 21 07:06:15.805: INFO: Pod "downwardapi-volume-718073fa-5cc5-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047985427s
May 21 07:06:17.821: INFO: Pod "downwardapi-volume-718073fa-5cc5-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.064472927s
STEP: Saw pod success
May 21 07:06:17.822: INFO: Pod "downwardapi-volume-718073fa-5cc5-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:06:17.838: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod downwardapi-volume-718073fa-5cc5-11e8-849c-0e182f31d764 container client-container: <nil>
STEP: delete the pod
May 21 07:06:17.906: INFO: Waiting for pod downwardapi-volume-718073fa-5cc5-11e8-849c-0e182f31d764 to disappear
May 21 07:06:17.922: INFO: Pod downwardapi-volume-718073fa-5cc5-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:06:17.922: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s7xft" for this suite.
May 21 07:06:23.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:06:24.702: INFO: namespace: e2e-tests-projected-s7xft, resource: bindings, ignored listing per whitelist
May 21 07:06:25.461: INFO: namespace e2e-tests-projected-s7xft deletion completed in 7.523272668s

• [SLOW TEST:13.833 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's cpu request [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:06:25.462: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should update labels on modification  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating the pod
May 21 07:06:30.252: INFO: Successfully updated pod "labelsupdate79c3c521-5cc5-11e8-849c-0e182f31d764"
[AfterEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:06:32.297: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2rg8m" for this suite.
May 21 07:06:54.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:06:55.677: INFO: namespace: e2e-tests-downward-api-2rg8m, resource: bindings, ignored listing per whitelist
May 21 07:06:55.818: INFO: namespace e2e-tests-downward-api-2rg8m deletion completed in 23.504673114s

• [SLOW TEST:30.356 seconds]
[sig-storage] Downward API volume
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should update labels on modification  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:06:55.818: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run default
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1116
[It] should create an rc or deployment from an image  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: running the image gcr.io/google-containers/nginx-slim-amd64:0.20
May 21 07:06:55.933: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig run e2e-test-nginx-deployment --image=gcr.io/google-containers/nginx-slim-amd64:0.20 --namespace=e2e-tests-kubectl-h626g'
May 21 07:06:56.183: INFO: stderr: ""
May 21 07:06:56.183: INFO: stdout: "deployment \"e2e-test-nginx-deployment\" created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1122
May 21 07:06:56.209: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-h626g'
May 21 07:06:59.613: INFO: stderr: ""
May 21 07:06:59.613: INFO: stdout: "deployment \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:06:59.613: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-h626g" for this suite.
May 21 07:07:05.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:07:06.578: INFO: namespace: e2e-tests-kubectl-h626g, resource: bindings, ignored listing per whitelist
May 21 07:07:07.131: INFO: namespace e2e-tests-kubectl-h626g deletion completed in 7.501891472s

• [SLOW TEST:11.313 seconds]
[sig-cli] Kubectl client
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should create an rc or deployment from an image  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:07:07.131: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-ssrpq
May 21 07:07:13.332: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-ssrpq
STEP: checking the pod's current state and verifying that restartCount is present
May 21 07:07:13.347: INFO: Initial restart count of pod liveness-exec is 0
May 21 07:07:59.744: INFO: Restart count of pod e2e-tests-container-probe-ssrpq/liveness-exec is now 1 (46.396868305s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:07:59.774: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-ssrpq" for this suite.
May 21 07:08:05.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:08:10.092: INFO: namespace: e2e-tests-container-probe-ssrpq, resource: bindings, ignored listing per whitelist
May 21 07:08:10.379: INFO: namespace e2e-tests-container-probe-ssrpq deletion completed in 10.58752549s

• [SLOW TEST:63.248 seconds]
[k8s.io] Probing container
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  should be restarted with a exec "cat /tmp/health" liveness probe [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:08:10.379: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating projection with secret that has name projected-secret-test-map-b868711d-5cc5-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume secrets
May 21 07:08:10.766: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b86e3103-5cc5-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-mg9qt" to be "success or failure"
May 21 07:08:10.816: INFO: Pod "pod-projected-secrets-b86e3103-5cc5-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 49.573019ms
May 21 07:08:12.832: INFO: Pod "pod-projected-secrets-b86e3103-5cc5-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065834143s
May 21 07:08:14.849: INFO: Pod "pod-projected-secrets-b86e3103-5cc5-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.083350813s
STEP: Saw pod success
May 21 07:08:14.849: INFO: Pod "pod-projected-secrets-b86e3103-5cc5-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:08:14.866: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod pod-projected-secrets-b86e3103-5cc5-11e8-849c-0e182f31d764 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 07:08:14.915: INFO: Waiting for pod pod-projected-secrets-b86e3103-5cc5-11e8-849c-0e182f31d764 to disappear
May 21 07:08:14.931: INFO: Pod pod-projected-secrets-b86e3103-5cc5-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:08:14.931: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mg9qt" for this suite.
May 21 07:08:21.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:08:21.880: INFO: namespace: e2e-tests-projected-mg9qt, resource: bindings, ignored listing per whitelist
May 21 07:08:22.645: INFO: namespace e2e-tests-projected-mg9qt deletion completed in 7.696186263s

• [SLOW TEST:12.266 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:08:22.645: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating projection with secret that has name projected-secret-test-bfafeb2b-5cc5-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume secrets
May 21 07:08:22.972: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bfb3dcbe-5cc5-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-27ml4" to be "success or failure"
May 21 07:08:22.998: INFO: Pod "pod-projected-secrets-bfb3dcbe-5cc5-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 26.720332ms
May 21 07:08:25.014: INFO: Pod "pod-projected-secrets-bfb3dcbe-5cc5-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042909776s
May 21 07:08:27.030: INFO: Pod "pod-projected-secrets-bfb3dcbe-5cc5-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058867023s
STEP: Saw pod success
May 21 07:08:27.030: INFO: Pod "pod-projected-secrets-bfb3dcbe-5cc5-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:08:27.046: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod pod-projected-secrets-bfb3dcbe-5cc5-11e8-849c-0e182f31d764 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 07:08:27.092: INFO: Waiting for pod pod-projected-secrets-bfb3dcbe-5cc5-11e8-849c-0e182f31d764 to disappear
May 21 07:08:27.107: INFO: Pod pod-projected-secrets-bfb3dcbe-5cc5-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:08:27.107: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-27ml4" for this suite.
May 21 07:08:33.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:08:34.201: INFO: namespace: e2e-tests-projected-27ml4, resource: bindings, ignored listing per whitelist
May 21 07:08:34.647: INFO: namespace e2e-tests-projected-27ml4 deletion completed in 7.523739737s

• [SLOW TEST:12.002 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:08:34.647: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test emptydir 0777 on node default medium
May 21 07:08:34.809: INFO: Waiting up to 5m0s for pod "pod-c6c4392d-5cc5-11e8-849c-0e182f31d764" in namespace "e2e-tests-emptydir-2s9cr" to be "success or failure"
May 21 07:08:34.825: INFO: Pod "pod-c6c4392d-5cc5-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 16.613681ms
May 21 07:08:36.841: INFO: Pod "pod-c6c4392d-5cc5-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032740864s
May 21 07:08:38.857: INFO: Pod "pod-c6c4392d-5cc5-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048369238s
STEP: Saw pod success
May 21 07:08:38.857: INFO: Pod "pod-c6c4392d-5cc5-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:08:38.872: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod pod-c6c4392d-5cc5-11e8-849c-0e182f31d764 container test-container: <nil>
STEP: delete the pod
May 21 07:08:38.914: INFO: Waiting for pod pod-c6c4392d-5cc5-11e8-849c-0e182f31d764 to disappear
May 21 07:08:38.929: INFO: Pod pod-c6c4392d-5cc5-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:08:38.929: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2s9cr" for this suite.
May 21 07:08:44.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:08:46.447: INFO: namespace: e2e-tests-emptydir-2s9cr, resource: bindings, ignored listing per whitelist
May 21 07:08:46.448: INFO: namespace e2e-tests-emptydir-2s9cr deletion completed in 7.502834255s

• [SLOW TEST:11.800 seconds]
[sig-storage] EmptyDir volumes
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:08:46.448: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward API volume plugin
May 21 07:08:46.620: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cdceb677-5cc5-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-wmkdb" to be "success or failure"
May 21 07:08:46.637: INFO: Pod "downwardapi-volume-cdceb677-5cc5-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 16.487252ms
May 21 07:08:48.653: INFO: Pod "downwardapi-volume-cdceb677-5cc5-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032696379s
May 21 07:08:50.671: INFO: Pod "downwardapi-volume-cdceb677-5cc5-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050579812s
STEP: Saw pod success
May 21 07:08:50.671: INFO: Pod "downwardapi-volume-cdceb677-5cc5-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:08:50.687: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod downwardapi-volume-cdceb677-5cc5-11e8-849c-0e182f31d764 container client-container: <nil>
STEP: delete the pod
May 21 07:08:50.730: INFO: Waiting for pod downwardapi-volume-cdceb677-5cc5-11e8-849c-0e182f31d764 to disappear
May 21 07:08:50.745: INFO: Pod downwardapi-volume-cdceb677-5cc5-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:08:50.745: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wmkdb" for this suite.
May 21 07:08:56.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:08:58.279: INFO: namespace: e2e-tests-projected-wmkdb, resource: bindings, ignored listing per whitelist
May 21 07:08:58.279: INFO: namespace e2e-tests-projected-wmkdb deletion completed in 7.517638833s

• [SLOW TEST:11.831 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's memory limit [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
S
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] Pods
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:08:58.279: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should allow activeDeadlineSeconds to be updated  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 21 07:09:03.043: INFO: Successfully updated pod "pod-update-activedeadlineseconds-d4db26b5-5cc5-11e8-849c-0e182f31d764"
May 21 07:09:03.043: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-d4db26b5-5cc5-11e8-849c-0e182f31d764" in namespace "e2e-tests-pods-ljbq2" to be "terminated due to deadline exceeded"
May 21 07:09:03.058: INFO: Pod "pod-update-activedeadlineseconds-d4db26b5-5cc5-11e8-849c-0e182f31d764": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 15.249796ms
May 21 07:09:03.058: INFO: Pod "pod-update-activedeadlineseconds-d4db26b5-5cc5-11e8-849c-0e182f31d764" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:09:03.058: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-ljbq2" for this suite.
May 21 07:09:09.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:09:09.976: INFO: namespace: e2e-tests-pods-ljbq2, resource: bindings, ignored listing per whitelist
May 21 07:09:10.573: INFO: namespace e2e-tests-pods-ljbq2 deletion completed in 7.498616983s

• [SLOW TEST:12.293 seconds]
[k8s.io] Pods
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  should allow activeDeadlineSeconds to be updated  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] version v1
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:09:10.573: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] version v1
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:68
[It] should proxy logs on node with explicit kubelet port  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
May 21 07:09:10.764: INFO: (0) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 24.372903ms)
May 21 07:09:10.780: INFO: (1) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.432573ms)
May 21 07:09:10.798: INFO: (2) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.392963ms)
May 21 07:09:10.814: INFO: (3) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.517235ms)
May 21 07:09:10.831: INFO: (4) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.044074ms)
May 21 07:09:10.847: INFO: (5) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.391246ms)
May 21 07:09:10.863: INFO: (6) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.474897ms)
May 21 07:09:10.879: INFO: (7) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.031402ms)
May 21 07:09:10.896: INFO: (8) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.328142ms)
May 21 07:09:10.915: INFO: (9) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 18.923448ms)
May 21 07:09:10.934: INFO: (10) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 18.722111ms)
May 21 07:09:10.950: INFO: (11) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.725532ms)
May 21 07:09:10.966: INFO: (12) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.113369ms)
May 21 07:09:10.983: INFO: (13) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.858432ms)
May 21 07:09:11.000: INFO: (14) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.502456ms)
May 21 07:09:11.016: INFO: (15) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.163349ms)
May 21 07:09:11.033: INFO: (16) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.793659ms)
May 21 07:09:11.050: INFO: (17) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.881447ms)
May 21 07:09:11.067: INFO: (18) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.612855ms)
May 21 07:09:11.084: INFO: (19) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.366907ms)
[AfterEach] version v1
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:09:11.084: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-np9s2" for this suite.
May 21 07:09:17.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:09:18.342: INFO: namespace: e2e-tests-proxy-np9s2, resource: bindings, ignored listing per whitelist
May 21 07:09:18.588: INFO: namespace e2e-tests-proxy-np9s2 deletion completed in 7.48865199s

• [SLOW TEST:8.016 seconds]
[sig-network] Proxy
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:60
    should proxy logs on node with explicit kubelet port  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] Variable Expansion
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:09:18.589: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test substitution in container's command
May 21 07:09:18.862: INFO: Waiting up to 5m0s for pod "var-expansion-e10297e6-5cc5-11e8-849c-0e182f31d764" in namespace "e2e-tests-var-expansion-zwrpl" to be "success or failure"
May 21 07:09:18.879: INFO: Pod "var-expansion-e10297e6-5cc5-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 16.941978ms
May 21 07:09:20.895: INFO: Pod "var-expansion-e10297e6-5cc5-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032832121s
May 21 07:09:22.910: INFO: Pod "var-expansion-e10297e6-5cc5-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04860522s
May 21 07:09:24.926: INFO: Pod "var-expansion-e10297e6-5cc5-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.064364003s
STEP: Saw pod success
May 21 07:09:24.926: INFO: Pod "var-expansion-e10297e6-5cc5-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:09:24.941: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod var-expansion-e10297e6-5cc5-11e8-849c-0e182f31d764 container dapi-container: <nil>
STEP: delete the pod
May 21 07:09:24.985: INFO: Waiting for pod var-expansion-e10297e6-5cc5-11e8-849c-0e182f31d764 to disappear
May 21 07:09:25.000: INFO: Pod var-expansion-e10297e6-5cc5-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:09:25.000: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-zwrpl" for this suite.
May 21 07:09:31.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:09:32.152: INFO: namespace: e2e-tests-var-expansion-zwrpl, resource: bindings, ignored listing per whitelist
May 21 07:09:32.526: INFO: namespace e2e-tests-var-expansion-zwrpl deletion completed in 7.510080684s

• [SLOW TEST:13.938 seconds]
[k8s.io] Variable Expansion
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  should allow substituting values in a container's command  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should update labels on modification [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:09:32.526: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating the pod
May 21 07:09:37.293: INFO: Successfully updated pod "labelsupdatee944a748-5cc5-11e8-849c-0e182f31d764"
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:09:39.335: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w5q77" for this suite.
May 21 07:10:01.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:10:02.568: INFO: namespace: e2e-tests-projected-w5q77, resource: bindings, ignored listing per whitelist
May 21 07:10:02.864: INFO: namespace e2e-tests-projected-w5q77 deletion completed in 23.513120927s

• [SLOW TEST:30.337 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should update labels on modification [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] ConfigMap
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:10:02.864: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating configMap with name configmap-test-volume-fb4fc26d-5cc5-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume configMaps
May 21 07:10:02.982: INFO: Waiting up to 5m0s for pod "pod-configmaps-fb52e83e-5cc5-11e8-849c-0e182f31d764" in namespace "e2e-tests-configmap-98lpq" to be "success or failure"
May 21 07:10:02.997: INFO: Pod "pod-configmaps-fb52e83e-5cc5-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.111479ms
May 21 07:10:05.013: INFO: Pod "pod-configmaps-fb52e83e-5cc5-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031289797s
May 21 07:10:07.029: INFO: Pod "pod-configmaps-fb52e83e-5cc5-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047781688s
STEP: Saw pod success
May 21 07:10:07.030: INFO: Pod "pod-configmaps-fb52e83e-5cc5-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:10:07.045: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod pod-configmaps-fb52e83e-5cc5-11e8-849c-0e182f31d764 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 07:10:07.088: INFO: Waiting for pod pod-configmaps-fb52e83e-5cc5-11e8-849c-0e182f31d764 to disappear
May 21 07:10:07.104: INFO: Pod pod-configmaps-fb52e83e-5cc5-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:10:07.104: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-98lpq" for this suite.
May 21 07:10:13.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:10:15.071: INFO: namespace: e2e-tests-configmap-98lpq, resource: bindings, ignored listing per whitelist
May 21 07:10:15.426: INFO: namespace e2e-tests-configmap-98lpq deletion completed in 8.305704796s

• [SLOW TEST:12.562 seconds]
[sig-storage] ConfigMap
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Secrets
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:10:15.426: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating secret with name secret-test-map-02d80c67-5cc6-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume secrets
May 21 07:10:15.628: INFO: Waiting up to 5m0s for pod "pod-secrets-02db9b17-5cc6-11e8-849c-0e182f31d764" in namespace "e2e-tests-secrets-5thwf" to be "success or failure"
May 21 07:10:15.651: INFO: Pod "pod-secrets-02db9b17-5cc6-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 22.377238ms
May 21 07:10:17.667: INFO: Pod "pod-secrets-02db9b17-5cc6-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038591505s
May 21 07:10:19.683: INFO: Pod "pod-secrets-02db9b17-5cc6-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054880429s
STEP: Saw pod success
May 21 07:10:19.683: INFO: Pod "pod-secrets-02db9b17-5cc6-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:10:19.699: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod pod-secrets-02db9b17-5cc6-11e8-849c-0e182f31d764 container secret-volume-test: <nil>
STEP: delete the pod
May 21 07:10:19.741: INFO: Waiting for pod pod-secrets-02db9b17-5cc6-11e8-849c-0e182f31d764 to disappear
May 21 07:10:19.756: INFO: Pod pod-secrets-02db9b17-5cc6-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Secrets
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:10:19.756: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5thwf" for this suite.
May 21 07:10:25.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:10:27.279: INFO: namespace: e2e-tests-secrets-5thwf, resource: bindings, ignored listing per whitelist
May 21 07:10:27.279: INFO: namespace e2e-tests-secrets-5thwf deletion completed in 7.506471371s

• [SLOW TEST:11.853 seconds]
[sig-storage] Secrets
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:10:27.279: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should add annotations for pods in rc  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: creating Redis RC
May 21 07:10:27.391: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig create -f - --namespace=e2e-tests-kubectl-s6wl7'
May 21 07:10:27.829: INFO: stderr: ""
May 21 07:10:27.829: INFO: stdout: "replicationcontroller \"redis-master\" created\n"
STEP: Waiting for Redis master to start.
May 21 07:10:28.846: INFO: Selector matched 1 pods for map[app:redis]
May 21 07:10:28.846: INFO: Found 0 / 1
May 21 07:10:29.845: INFO: Selector matched 1 pods for map[app:redis]
May 21 07:10:29.846: INFO: Found 0 / 1
May 21 07:10:30.846: INFO: Selector matched 1 pods for map[app:redis]
May 21 07:10:30.846: INFO: Found 0 / 1
May 21 07:10:31.846: INFO: Selector matched 1 pods for map[app:redis]
May 21 07:10:31.846: INFO: Found 0 / 1
May 21 07:10:32.845: INFO: Selector matched 1 pods for map[app:redis]
May 21 07:10:32.845: INFO: Found 0 / 1
May 21 07:10:33.846: INFO: Selector matched 1 pods for map[app:redis]
May 21 07:10:33.846: INFO: Found 1 / 1
May 21 07:10:33.846: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
May 21 07:10:33.865: INFO: Selector matched 1 pods for map[app:redis]
May 21 07:10:33.865: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 21 07:10:33.865: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig patch pod redis-master-6rghk --namespace=e2e-tests-kubectl-s6wl7 -p {"metadata":{"annotations":{"x":"y"}}}'
May 21 07:10:34.064: INFO: stderr: ""
May 21 07:10:34.064: INFO: stdout: "pod \"redis-master-6rghk\" patched\n"
STEP: checking annotations
May 21 07:10:34.080: INFO: Selector matched 1 pods for map[app:redis]
May 21 07:10:34.080: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:10:34.080: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-s6wl7" for this suite.
May 21 07:10:56.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:10:57.308: INFO: namespace: e2e-tests-kubectl-s6wl7, resource: bindings, ignored listing per whitelist
May 21 07:10:57.583: INFO: namespace e2e-tests-kubectl-s6wl7 deletion completed in 23.486171209s

• [SLOW TEST:30.304 seconds]
[sig-cli] Kubectl client
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should add annotations for pods in rc  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:10:57.583: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating configMap with name projected-configmap-test-volume-1bf3016b-5cc6-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume configMaps
May 21 07:10:57.736: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1bf570df-5cc6-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-4cj4b" to be "success or failure"
May 21 07:10:57.752: INFO: Pod "pod-projected-configmaps-1bf570df-5cc6-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.154254ms
May 21 07:10:59.768: INFO: Pod "pod-projected-configmaps-1bf570df-5cc6-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031050506s
May 21 07:11:01.783: INFO: Pod "pod-projected-configmaps-1bf570df-5cc6-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046938545s
STEP: Saw pod success
May 21 07:11:01.783: INFO: Pod "pod-projected-configmaps-1bf570df-5cc6-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:11:01.799: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod pod-projected-configmaps-1bf570df-5cc6-11e8-849c-0e182f31d764 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 07:11:01.843: INFO: Waiting for pod pod-projected-configmaps-1bf570df-5cc6-11e8-849c-0e182f31d764 to disappear
May 21 07:11:01.859: INFO: Pod pod-projected-configmaps-1bf570df-5cc6-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:11:01.859: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4cj4b" for this suite.
May 21 07:11:07.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:11:08.998: INFO: namespace: e2e-tests-projected-4cj4b, resource: bindings, ignored listing per whitelist
May 21 07:11:09.388: INFO: namespace e2e-tests-projected-4cj4b deletion completed in 7.5131791s

• [SLOW TEST:11.805 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with defaultMode set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:11:09.388: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl logs
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1010
STEP: creating an rc
May 21 07:11:09.520: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig create -f - --namespace=e2e-tests-kubectl-wmhbj'
May 21 07:11:09.815: INFO: stderr: ""
May 21 07:11:09.815: INFO: stdout: "replicationcontroller \"redis-master\" created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Waiting for Redis master to start.
May 21 07:11:10.831: INFO: Selector matched 1 pods for map[app:redis]
May 21 07:11:10.831: INFO: Found 0 / 1
May 21 07:11:11.832: INFO: Selector matched 1 pods for map[app:redis]
May 21 07:11:11.832: INFO: Found 0 / 1
May 21 07:11:12.832: INFO: Selector matched 1 pods for map[app:redis]
May 21 07:11:12.832: INFO: Found 1 / 1
May 21 07:11:12.832: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 21 07:11:12.847: INFO: Selector matched 1 pods for map[app:redis]
May 21 07:11:12.847: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
May 21 07:11:12.847: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig logs redis-master-5r88x redis-master --namespace=e2e-tests-kubectl-wmhbj'
May 21 07:11:13.092: INFO: stderr: ""
May 21 07:11:13.092: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.8 (6737a5e6/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 May 07:11:12.429 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 May 07:11:12.429 # Server started, Redis version 3.2.8\n1:M 21 May 07:11:12.429 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 May 07:11:12.429 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
May 21 07:11:13.092: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig log redis-master-5r88x redis-master --namespace=e2e-tests-kubectl-wmhbj --tail=1'
May 21 07:11:13.326: INFO: stderr: ""
May 21 07:11:13.326: INFO: stdout: "1:M 21 May 07:11:12.429 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
May 21 07:11:13.326: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig log redis-master-5r88x redis-master --namespace=e2e-tests-kubectl-wmhbj --limit-bytes=1'
May 21 07:11:13.564: INFO: stderr: ""
May 21 07:11:13.564: INFO: stdout: " "
STEP: exposing timestamps
May 21 07:11:13.564: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig log redis-master-5r88x redis-master --namespace=e2e-tests-kubectl-wmhbj --tail=1 --timestamps'
May 21 07:11:13.801: INFO: stderr: ""
May 21 07:11:13.801: INFO: stdout: "2018-05-21T07:11:12.429642123Z 1:M 21 May 07:11:12.429 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
May 21 07:11:16.301: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig log redis-master-5r88x redis-master --namespace=e2e-tests-kubectl-wmhbj --since=1s'
May 21 07:11:16.535: INFO: stderr: ""
May 21 07:11:16.535: INFO: stdout: ""
May 21 07:11:16.535: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig log redis-master-5r88x redis-master --namespace=e2e-tests-kubectl-wmhbj --since=24h'
May 21 07:11:16.771: INFO: stderr: ""
May 21 07:11:16.771: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.8 (6737a5e6/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 May 07:11:12.429 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 May 07:11:12.429 # Server started, Redis version 3.2.8\n1:M 21 May 07:11:12.429 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 May 07:11:12.429 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1015
STEP: using delete to clean up resources
May 21 07:11:16.771: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wmhbj'
May 21 07:11:17.065: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 07:11:17.065: INFO: stdout: "replicationcontroller \"redis-master\" deleted\n"
May 21 07:11:17.065: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-wmhbj'
May 21 07:11:17.251: INFO: stderr: "No resources found.\n"
May 21 07:11:17.251: INFO: stdout: ""
May 21 07:11:17.252: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods -l name=nginx --namespace=e2e-tests-kubectl-wmhbj -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 21 07:11:17.422: INFO: stderr: ""
May 21 07:11:17.422: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:11:17.422: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wmhbj" for this suite.
May 21 07:11:23.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:11:24.909: INFO: namespace: e2e-tests-kubectl-wmhbj, resource: bindings, ignored listing per whitelist
May 21 07:11:24.956: INFO: namespace e2e-tests-kubectl-wmhbj deletion completed in 7.518327642s

• [SLOW TEST:15.567 seconds]
[sig-cli] Kubectl client
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should be able to retrieve and filter logs  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:11:24.956: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 21 07:11:25.129: INFO: Waiting up to 5m0s for pod "pod-2c490c8f-5cc6-11e8-849c-0e182f31d764" in namespace "e2e-tests-emptydir-zw8hw" to be "success or failure"
May 21 07:11:25.145: INFO: Pod "pod-2c490c8f-5cc6-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 16.082176ms
May 21 07:11:27.162: INFO: Pod "pod-2c490c8f-5cc6-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032357318s
May 21 07:11:29.178: INFO: Pod "pod-2c490c8f-5cc6-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048709528s
STEP: Saw pod success
May 21 07:11:29.178: INFO: Pod "pod-2c490c8f-5cc6-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:11:29.194: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod pod-2c490c8f-5cc6-11e8-849c-0e182f31d764 container test-container: <nil>
STEP: delete the pod
May 21 07:11:29.242: INFO: Waiting for pod pod-2c490c8f-5cc6-11e8-849c-0e182f31d764 to disappear
May 21 07:11:29.257: INFO: Pod pod-2c490c8f-5cc6-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:11:29.258: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zw8hw" for this suite.
May 21 07:11:35.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:11:36.027: INFO: namespace: e2e-tests-emptydir-zw8hw, resource: bindings, ignored listing per whitelist
May 21 07:11:36.789: INFO: namespace e2e-tests-emptydir-zw8hw deletion completed in 7.515180262s

• [SLOW TEST:11.833 seconds]
[sig-storage] EmptyDir volumes
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-storage] Projected 
  should provide container's memory request [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:11:36.789: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward API volume plugin
May 21 07:11:36.933: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3352292d-5cc6-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-nsj8w" to be "success or failure"
May 21 07:11:36.949: INFO: Pod "downwardapi-volume-3352292d-5cc6-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 16.723591ms
May 21 07:11:38.966: INFO: Pod "downwardapi-volume-3352292d-5cc6-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033039332s
May 21 07:11:40.982: INFO: Pod "downwardapi-volume-3352292d-5cc6-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049211756s
STEP: Saw pod success
May 21 07:11:40.982: INFO: Pod "downwardapi-volume-3352292d-5cc6-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:11:40.998: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod downwardapi-volume-3352292d-5cc6-11e8-849c-0e182f31d764 container client-container: <nil>
STEP: delete the pod
May 21 07:11:41.048: INFO: Waiting for pod downwardapi-volume-3352292d-5cc6-11e8-849c-0e182f31d764 to disappear
May 21 07:11:41.064: INFO: Pod downwardapi-volume-3352292d-5cc6-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:11:41.064: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nsj8w" for this suite.
May 21 07:11:47.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:11:47.863: INFO: namespace: e2e-tests-projected-nsj8w, resource: bindings, ignored listing per whitelist
May 21 07:11:48.592: INFO: namespace e2e-tests-projected-nsj8w deletion completed in 7.511894269s

• [SLOW TEST:11.803 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's memory request [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:11:48.593: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should set mode on item file  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward API volume plugin
May 21 07:11:48.743: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3a5c216c-5cc6-11e8-849c-0e182f31d764" in namespace "e2e-tests-downward-api-zvtnx" to be "success or failure"
May 21 07:11:48.760: INFO: Pod "downwardapi-volume-3a5c216c-5cc6-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 17.251672ms
May 21 07:11:50.776: INFO: Pod "downwardapi-volume-3a5c216c-5cc6-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033432526s
May 21 07:11:52.793: INFO: Pod "downwardapi-volume-3a5c216c-5cc6-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050258399s
STEP: Saw pod success
May 21 07:11:52.793: INFO: Pod "downwardapi-volume-3a5c216c-5cc6-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:11:52.809: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod downwardapi-volume-3a5c216c-5cc6-11e8-849c-0e182f31d764 container client-container: <nil>
STEP: delete the pod
May 21 07:11:52.864: INFO: Waiting for pod downwardapi-volume-3a5c216c-5cc6-11e8-849c-0e182f31d764 to disappear
May 21 07:11:52.880: INFO: Pod downwardapi-volume-3a5c216c-5cc6-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:11:52.880: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zvtnx" for this suite.
May 21 07:11:58.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:11:59.922: INFO: namespace: e2e-tests-downward-api-zvtnx, resource: bindings, ignored listing per whitelist
May 21 07:12:00.405: INFO: namespace e2e-tests-downward-api-zvtnx deletion completed in 7.508886271s

• [SLOW TEST:11.812 seconds]
[sig-storage] Downward API volume
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should set mode on item file  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Secrets
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:12:00.405: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating secret with name secret-test-map-4165fe5f-5cc6-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume secrets
May 21 07:12:00.565: INFO: Waiting up to 5m0s for pod "pod-secrets-4168a4c2-5cc6-11e8-849c-0e182f31d764" in namespace "e2e-tests-secrets-6sc4l" to be "success or failure"
May 21 07:12:00.580: INFO: Pod "pod-secrets-4168a4c2-5cc6-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.015284ms
May 21 07:12:02.596: INFO: Pod "pod-secrets-4168a4c2-5cc6-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031295748s
May 21 07:12:04.612: INFO: Pod "pod-secrets-4168a4c2-5cc6-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047492683s
STEP: Saw pod success
May 21 07:12:04.612: INFO: Pod "pod-secrets-4168a4c2-5cc6-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:12:04.628: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod pod-secrets-4168a4c2-5cc6-11e8-849c-0e182f31d764 container secret-volume-test: <nil>
STEP: delete the pod
May 21 07:12:04.670: INFO: Waiting for pod pod-secrets-4168a4c2-5cc6-11e8-849c-0e182f31d764 to disappear
May 21 07:12:04.686: INFO: Pod pod-secrets-4168a4c2-5cc6-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Secrets
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:12:04.686: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6sc4l" for this suite.
May 21 07:12:10.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:12:12.153: INFO: namespace: e2e-tests-secrets-6sc4l, resource: bindings, ignored listing per whitelist
May 21 07:12:12.200: INFO: namespace e2e-tests-secrets-6sc4l deletion completed in 7.497851233s

• [SLOW TEST:11.795 seconds]
[sig-storage] Secrets
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] Pods
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:12:12.200: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should be submitted and removed  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
May 21 07:12:16.433: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-486ad7c4-5cc6-11e8-849c-0e182f31d764", GenerateName:"", Namespace:"e2e-tests-pods-rr9v6", SelfLink:"/api/v1/namespaces/e2e-tests-pods-rr9v6/pods/pod-submit-remove-486ad7c4-5cc6-11e8-849c-0e182f31d764", UID:"4872ce1e-5cc6-11e8-bb49-42010a8e0002", ResourceVersion:"4862", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63662483532, loc:(*time.Location)(0x61ad540)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"304180607"}, Annotations:map[string]string{"openshift.io/scc":"privileged"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-b66j7", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc42177fec0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"gcr.io/google-containers/nginx-slim-amd64:0.20", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-b66j7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc42044c418), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string{"role":"app"}, ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"prtest-7d230a7-103-ig-n-wbpf", HostNetwork:false, HostPID:false, HostIPC:false, SecurityContext:(*v1.PodSecurityContext)(0xc42177ffc0), ImagePullSecrets:[]v1.LocalObjectReference{v1.LocalObjectReference{Name:"default-dockercfg-8pjcm"}}, Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration(nil), HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63662483532, loc:(*time.Location)(0x61ad540)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63662483534, loc:(*time.Location)(0x61ad540)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63662483532, loc:(*time.Location)(0x61ad540)}}, Reason:"", Message:""}}, Message:"", Reason:"", HostIP:"10.142.0.4", PodIP:"172.16.6.12", StartTime:(*v1.Time)(0xc420f41ae0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc420f41b20), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"gcr.io/google-containers/nginx-slim-amd64:0.20", ImageID:"docker-pullable://gcr.io/google-containers/nginx-slim-amd64@sha256:6654db6d4028756062edac466454ee5c9cf9b20ef79e35a81e3c840031eb1e2b", ContainerID:"docker://a21b0cf80b06664ccc690cc75651b9019c60ce1197bca57adc2c8384e2cb825b"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:12:29.059: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-rr9v6" for this suite.
May 21 07:12:35.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:12:35.790: INFO: namespace: e2e-tests-pods-rr9v6, resource: bindings, ignored listing per whitelist
May 21 07:12:36.576: INFO: namespace e2e-tests-pods-rr9v6 deletion completed in 7.50072869s

• [SLOW TEST:24.376 seconds]
[k8s.io] Pods
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  should be submitted and removed  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:12:36.576: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should do a rolling update of a replication controller  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: creating the initial replication controller
May 21 07:12:36.696: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig create -f - --namespace=e2e-tests-kubectl-k4f8w'
May 21 07:12:37.018: INFO: stderr: ""
May 21 07:12:37.018: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 07:12:37.018: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k4f8w'
May 21 07:12:37.193: INFO: stderr: ""
May 21 07:12:37.193: INFO: stdout: "update-demo-nautilus-d5b6t update-demo-nautilus-rpdm5 "
May 21 07:12:37.193: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-nautilus-d5b6t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k4f8w'
May 21 07:12:37.363: INFO: stderr: ""
May 21 07:12:37.363: INFO: stdout: ""
May 21 07:12:37.363: INFO: update-demo-nautilus-d5b6t is created but not running
May 21 07:12:42.363: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k4f8w'
May 21 07:12:42.536: INFO: stderr: ""
May 21 07:12:42.536: INFO: stdout: "update-demo-nautilus-d5b6t update-demo-nautilus-rpdm5 "
May 21 07:12:42.536: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-nautilus-d5b6t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k4f8w'
May 21 07:12:42.709: INFO: stderr: ""
May 21 07:12:42.709: INFO: stdout: "true"
May 21 07:12:42.709: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-nautilus-d5b6t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k4f8w'
May 21 07:12:42.879: INFO: stderr: ""
May 21 07:12:42.879: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 21 07:12:42.879: INFO: validating pod update-demo-nautilus-d5b6t
May 21 07:12:42.899: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 07:12:42.899: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 07:12:42.899: INFO: update-demo-nautilus-d5b6t is verified up and running
May 21 07:12:42.899: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-nautilus-rpdm5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k4f8w'
May 21 07:12:43.070: INFO: stderr: ""
May 21 07:12:43.070: INFO: stdout: "true"
May 21 07:12:43.070: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-nautilus-rpdm5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k4f8w'
May 21 07:12:43.243: INFO: stderr: ""
May 21 07:12:43.243: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 21 07:12:43.243: INFO: validating pod update-demo-nautilus-rpdm5
May 21 07:12:43.263: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 07:12:43.263: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 07:12:43.263: INFO: update-demo-nautilus-rpdm5 is verified up and running
STEP: rolling-update to new replication controller
May 21 07:12:43.263: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-k4f8w'
May 21 07:12:59.509: INFO: stderr: ""
May 21 07:12:59.509: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting update-demo-nautilus\nreplicationcontroller \"update-demo-nautilus\" rolling updated to \"update-demo-kitten\"\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 07:12:59.510: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k4f8w'
May 21 07:12:59.693: INFO: stderr: ""
May 21 07:12:59.693: INFO: stdout: "update-demo-kitten-hzks6 update-demo-kitten-s5zgq update-demo-nautilus-rpdm5 "
STEP: Replicas for name=update-demo: expected=2 actual=3
May 21 07:13:04.693: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k4f8w'
May 21 07:13:04.869: INFO: stderr: ""
May 21 07:13:04.869: INFO: stdout: "update-demo-kitten-hzks6 update-demo-kitten-s5zgq "
May 21 07:13:04.869: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-kitten-hzks6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k4f8w'
May 21 07:13:05.040: INFO: stderr: ""
May 21 07:13:05.040: INFO: stdout: "true"
May 21 07:13:05.040: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-kitten-hzks6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k4f8w'
May 21 07:13:05.212: INFO: stderr: ""
May 21 07:13:05.212: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten-amd64:1.0"
May 21 07:13:05.212: INFO: validating pod update-demo-kitten-hzks6
May 21 07:13:05.231: INFO: got data: {
  "image": "kitten.jpg"
}

May 21 07:13:05.231: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 21 07:13:05.231: INFO: update-demo-kitten-hzks6 is verified up and running
May 21 07:13:05.231: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-kitten-s5zgq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k4f8w'
May 21 07:13:05.404: INFO: stderr: ""
May 21 07:13:05.404: INFO: stdout: "true"
May 21 07:13:05.404: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-kitten-s5zgq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k4f8w'
May 21 07:13:05.573: INFO: stderr: ""
May 21 07:13:05.573: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten-amd64:1.0"
May 21 07:13:05.573: INFO: validating pod update-demo-kitten-s5zgq
May 21 07:13:05.593: INFO: got data: {
  "image": "kitten.jpg"
}

May 21 07:13:05.593: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 21 07:13:05.593: INFO: update-demo-kitten-s5zgq is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:13:05.593: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k4f8w" for this suite.
May 21 07:13:27.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:13:28.914: INFO: namespace: e2e-tests-kubectl-k4f8w, resource: bindings, ignored listing per whitelist
May 21 07:13:29.115: INFO: namespace e2e-tests-kubectl-k4f8w deletion completed in 23.505861761s

• [SLOW TEST:52.539 seconds]
[sig-cli] Kubectl client
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should do a rolling update of a replication controller  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:13:29.115: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should create and stop a replication controller  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: creating a replication controller
May 21 07:13:29.198: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig create -f - --namespace=e2e-tests-kubectl-nkp5d'
May 21 07:13:29.476: INFO: stderr: ""
May 21 07:13:29.476: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 07:13:29.476: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nkp5d'
May 21 07:13:29.670: INFO: stderr: ""
May 21 07:13:29.670: INFO: stdout: "update-demo-nautilus-pnxlz update-demo-nautilus-tn759 "
May 21 07:13:29.670: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-nautilus-pnxlz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nkp5d'
May 21 07:13:29.841: INFO: stderr: ""
May 21 07:13:29.841: INFO: stdout: ""
May 21 07:13:29.841: INFO: update-demo-nautilus-pnxlz is created but not running
May 21 07:13:34.841: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nkp5d'
May 21 07:13:35.013: INFO: stderr: ""
May 21 07:13:35.013: INFO: stdout: "update-demo-nautilus-pnxlz update-demo-nautilus-tn759 "
May 21 07:13:35.013: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-nautilus-pnxlz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nkp5d'
May 21 07:13:35.185: INFO: stderr: ""
May 21 07:13:35.185: INFO: stdout: "true"
May 21 07:13:35.185: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-nautilus-pnxlz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nkp5d'
May 21 07:13:35.357: INFO: stderr: ""
May 21 07:13:35.357: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 21 07:13:35.357: INFO: validating pod update-demo-nautilus-pnxlz
May 21 07:13:35.376: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 07:13:35.376: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 07:13:35.376: INFO: update-demo-nautilus-pnxlz is verified up and running
May 21 07:13:35.376: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-nautilus-tn759 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nkp5d'
May 21 07:13:35.548: INFO: stderr: ""
May 21 07:13:35.548: INFO: stdout: "true"
May 21 07:13:35.548: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-nautilus-tn759 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nkp5d'
May 21 07:13:35.716: INFO: stderr: ""
May 21 07:13:35.716: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 21 07:13:35.716: INFO: validating pod update-demo-nautilus-tn759
May 21 07:13:35.741: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 07:13:35.741: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 07:13:35.741: INFO: update-demo-nautilus-tn759 is verified up and running
STEP: using delete to clean up resources
May 21 07:13:35.741: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-nkp5d'
May 21 07:13:36.060: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 07:13:36.060: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" deleted\n"
May 21 07:13:36.060: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-nkp5d'
May 21 07:13:36.336: INFO: stderr: "No resources found.\n"
May 21 07:13:36.336: INFO: stdout: ""
May 21 07:13:36.336: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods -l name=update-demo --namespace=e2e-tests-kubectl-nkp5d -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 21 07:13:36.507: INFO: stderr: ""
May 21 07:13:36.507: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:13:36.507: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nkp5d" for this suite.
May 21 07:13:58.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:13:59.862: INFO: namespace: e2e-tests-kubectl-nkp5d, resource: bindings, ignored listing per whitelist
May 21 07:14:00.032: INFO: namespace e2e-tests-kubectl-nkp5d deletion completed in 23.509087433s

• [SLOW TEST:30.917 seconds]
[sig-cli] Kubectl client
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should create and stop a replication controller  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:14:00.032: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run job
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1287
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: running the image gcr.io/google-containers/nginx-slim-amd64:0.20
May 21 07:14:00.152: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=gcr.io/google-containers/nginx-slim-amd64:0.20 --namespace=e2e-tests-kubectl-kr79t'
May 21 07:14:00.372: INFO: stderr: ""
May 21 07:14:00.372: INFO: stdout: "job \"e2e-test-nginx-job\" created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1292
May 21 07:14:00.389: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-kr79t'
May 21 07:14:02.735: INFO: stderr: ""
May 21 07:14:02.735: INFO: stdout: "job \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:14:02.735: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kr79t" for this suite.
May 21 07:14:08.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:14:10.100: INFO: namespace: e2e-tests-kubectl-kr79t, resource: bindings, ignored listing per whitelist
May 21 07:14:10.303: INFO: namespace e2e-tests-kubectl-kr79t deletion completed in 7.538915897s

• [SLOW TEST:10.271 seconds]
[sig-cli] Kubectl client
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should create a job from an image when restart is OnFailure  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:14:10.303: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
May 21 07:14:10.475: INFO: Couldn't get node TTL annotation (using default value of 0): No TTL annotation found on the node
STEP: Creating secret with name s-test-opt-del-8eda5fea-5cc6-11e8-849c-0e182f31d764
STEP: Creating secret with name s-test-opt-upd-8eda6050-5cc6-11e8-849c-0e182f31d764
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-8eda5fea-5cc6-11e8-849c-0e182f31d764
STEP: Updating secret s-test-opt-upd-8eda6050-5cc6-11e8-849c-0e182f31d764
STEP: Creating secret with name s-test-opt-create-8eda607e-5cc6-11e8-849c-0e182f31d764
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:15:23.514: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gsccp" for this suite.
May 21 07:15:45.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:15:46.964: INFO: namespace: e2e-tests-projected-gsccp, resource: bindings, ignored listing per whitelist
May 21 07:15:47.008: INFO: namespace e2e-tests-projected-gsccp deletion completed in 23.465192479s

• [SLOW TEST:96.705 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  optional updates should be reflected in volume [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-network] Services
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:15:47.009: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:51
[It] should provide secure master service  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[AfterEach] [sig-network] Services
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:15:47.117: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-fjqjx" for this suite.
May 21 07:15:53.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:15:54.643: INFO: namespace: e2e-tests-services-fjqjx, resource: bindings, ignored listing per whitelist
May 21 07:15:54.643: INFO: namespace e2e-tests-services-fjqjx deletion completed in 7.497517566s
[AfterEach] [sig-network] Services
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:56

• [SLOW TEST:7.635 seconds]
[sig-network] Services
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Secrets
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:15:54.643: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
May 21 07:15:54.774: INFO: Couldn't get node TTL annotation (using default value of 0): No TTL annotation found on the node
STEP: Creating secret with name s-test-opt-del-cd0512ef-5cc6-11e8-849c-0e182f31d764
STEP: Creating secret with name s-test-opt-upd-cd051351-5cc6-11e8-849c-0e182f31d764
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-cd0512ef-5cc6-11e8-849c-0e182f31d764
STEP: Updating secret s-test-opt-upd-cd051351-5cc6-11e8-849c-0e182f31d764
STEP: Creating secret with name s-test-opt-create-cd05137e-5cc6-11e8-849c-0e182f31d764
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:17:03.774: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bwkz4" for this suite.
May 21 07:17:25.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:17:26.832: INFO: namespace: e2e-tests-secrets-bwkz4, resource: bindings, ignored listing per whitelist
May 21 07:17:27.309: INFO: namespace e2e-tests-secrets-bwkz4 deletion completed in 23.50613407s

• [SLOW TEST:92.666 seconds]
[sig-storage] Secrets
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:17:27.309: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
May 21 07:17:47.512: INFO: Container started at 2018-05-21 07:17:29 +0000 UTC, pod became ready at 2018-05-21 07:17:45 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:17:47.512: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4wqr4" for this suite.
May 21 07:18:09.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:18:10.230: INFO: namespace: e2e-tests-container-probe-4wqr4, resource: bindings, ignored listing per whitelist
May 21 07:18:11.048: INFO: namespace e2e-tests-container-probe-4wqr4 deletion completed in 23.50715573s

• [SLOW TEST:43.739 seconds]
[k8s.io] Probing container
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  with readiness probe should not be ready before initial delay and never restart  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:18:11.048: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating projection with secret that has name projected-secret-test-1e5178c4-5cc7-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume secrets
May 21 07:18:11.211: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1e5459ef-5cc7-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-bb28x" to be "success or failure"
May 21 07:18:11.227: INFO: Pod "pod-projected-secrets-1e5459ef-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 16.035475ms
May 21 07:18:13.243: INFO: Pod "pod-projected-secrets-1e5459ef-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03224868s
May 21 07:18:15.259: INFO: Pod "pod-projected-secrets-1e5459ef-5cc7-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048605514s
STEP: Saw pod success
May 21 07:18:15.259: INFO: Pod "pod-projected-secrets-1e5459ef-5cc7-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:18:15.275: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod pod-projected-secrets-1e5459ef-5cc7-11e8-849c-0e182f31d764 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 07:18:15.322: INFO: Waiting for pod pod-projected-secrets-1e5459ef-5cc7-11e8-849c-0e182f31d764 to disappear
May 21 07:18:15.337: INFO: Pod pod-projected-secrets-1e5459ef-5cc7-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:18:15.337: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bb28x" for this suite.
May 21 07:18:21.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:18:22.871: INFO: namespace: e2e-tests-projected-bb28x, resource: bindings, ignored listing per whitelist
May 21 07:18:22.886: INFO: namespace e2e-tests-projected-bb28x deletion completed in 7.519754137s

• [SLOW TEST:11.838 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-api-machinery] Downward API
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:18:22.886: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward api env vars
May 21 07:18:23.031: INFO: Waiting up to 5m0s for pod "downward-api-255b10c1-5cc7-11e8-849c-0e182f31d764" in namespace "e2e-tests-downward-api-9kjr7" to be "success or failure"
May 21 07:18:23.047: INFO: Pod "downward-api-255b10c1-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.36032ms
May 21 07:18:25.063: INFO: Pod "downward-api-255b10c1-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031584995s
May 21 07:18:27.079: INFO: Pod "downward-api-255b10c1-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 4.048318225s
May 21 07:18:29.096: INFO: Pod "downward-api-255b10c1-5cc7-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.064942489s
STEP: Saw pod success
May 21 07:18:29.096: INFO: Pod "downward-api-255b10c1-5cc7-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:18:29.112: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod downward-api-255b10c1-5cc7-11e8-849c-0e182f31d764 container dapi-container: <nil>
STEP: delete the pod
May 21 07:18:29.156: INFO: Waiting for pod downward-api-255b10c1-5cc7-11e8-849c-0e182f31d764 to disappear
May 21 07:18:29.172: INFO: Pod downward-api-255b10c1-5cc7-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:18:29.172: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9kjr7" for this suite.
May 21 07:18:35.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:18:36.031: INFO: namespace: e2e-tests-downward-api-9kjr7, resource: bindings, ignored listing per whitelist
May 21 07:18:36.717: INFO: namespace e2e-tests-downward-api-9kjr7 deletion completed in 7.516531822s

• [SLOW TEST:13.831 seconds]
[sig-api-machinery] Downward API
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide pod name, namespace and IP address as env vars  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] version v1
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:18:36.718: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] version v1
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:68
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
May 21 07:18:36.898: INFO: (0) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 20.108501ms)
May 21 07:18:36.915: INFO: (1) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.53104ms)
May 21 07:18:36.932: INFO: (2) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.277162ms)
May 21 07:18:36.951: INFO: (3) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 18.616231ms)
May 21 07:18:36.968: INFO: (4) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.300138ms)
May 21 07:18:36.986: INFO: (5) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.328295ms)
May 21 07:18:37.003: INFO: (6) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.04553ms)
May 21 07:18:37.020: INFO: (7) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.180102ms)
May 21 07:18:37.038: INFO: (8) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.489378ms)
May 21 07:18:37.055: INFO: (9) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.166207ms)
May 21 07:18:37.073: INFO: (10) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 18.293679ms)
May 21 07:18:37.091: INFO: (11) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.874102ms)
May 21 07:18:37.109: INFO: (12) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.516753ms)
May 21 07:18:37.126: INFO: (13) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.497118ms)
May 21 07:18:37.143: INFO: (14) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.932417ms)
May 21 07:18:37.160: INFO: (15) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.346802ms)
May 21 07:18:37.178: INFO: (16) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 18.080554ms)
May 21 07:18:37.196: INFO: (17) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.323306ms)
May 21 07:18:37.212: INFO: (18) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.534441ms)
May 21 07:18:37.229: INFO: (19) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.795767ms)
[AfterEach] version v1
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:18:37.229: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-hlt5h" for this suite.
May 21 07:18:43.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:18:44.574: INFO: namespace: e2e-tests-proxy-hlt5h, resource: bindings, ignored listing per whitelist
May 21 07:18:44.787: INFO: namespace e2e-tests-proxy-hlt5h deletion completed in 7.541245974s

• [SLOW TEST:8.070 seconds]
[sig-network] Proxy
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:60
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Secrets
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:18:44.787: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating secret with name secret-test-326be1f2-5cc7-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume secrets
May 21 07:18:44.938: INFO: Waiting up to 5m0s for pod "pod-secrets-326ec2ec-5cc7-11e8-849c-0e182f31d764" in namespace "e2e-tests-secrets-nkn4g" to be "success or failure"
May 21 07:18:44.953: INFO: Pod "pod-secrets-326ec2ec-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.3208ms
May 21 07:18:46.970: INFO: Pod "pod-secrets-326ec2ec-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031580244s
May 21 07:18:48.986: INFO: Pod "pod-secrets-326ec2ec-5cc7-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047669375s
STEP: Saw pod success
May 21 07:18:48.986: INFO: Pod "pod-secrets-326ec2ec-5cc7-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:18:49.001: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod pod-secrets-326ec2ec-5cc7-11e8-849c-0e182f31d764 container secret-volume-test: <nil>
STEP: delete the pod
May 21 07:18:49.049: INFO: Waiting for pod pod-secrets-326ec2ec-5cc7-11e8-849c-0e182f31d764 to disappear
May 21 07:18:49.065: INFO: Pod pod-secrets-326ec2ec-5cc7-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Secrets
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:18:49.065: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nkn4g" for this suite.
May 21 07:18:55.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:18:56.378: INFO: namespace: e2e-tests-secrets-nkn4g, resource: bindings, ignored listing per whitelist
May 21 07:18:56.613: INFO: namespace e2e-tests-secrets-nkn4g deletion completed in 7.518735066s

• [SLOW TEST:11.826 seconds]
[sig-storage] Secrets
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:18:56.614: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 21 07:18:56.777: INFO: Waiting up to 5m0s for pod "pod-397d798c-5cc7-11e8-849c-0e182f31d764" in namespace "e2e-tests-emptydir-g4pw8" to be "success or failure"
May 21 07:18:56.793: INFO: Pod "pod-397d798c-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.682681ms
May 21 07:18:58.809: INFO: Pod "pod-397d798c-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031954399s
May 21 07:19:00.826: INFO: Pod "pod-397d798c-5cc7-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04892174s
STEP: Saw pod success
May 21 07:19:00.826: INFO: Pod "pod-397d798c-5cc7-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:19:00.842: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod pod-397d798c-5cc7-11e8-849c-0e182f31d764 container test-container: <nil>
STEP: delete the pod
May 21 07:19:00.888: INFO: Waiting for pod pod-397d798c-5cc7-11e8-849c-0e182f31d764 to disappear
May 21 07:19:00.903: INFO: Pod pod-397d798c-5cc7-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:19:00.903: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-g4pw8" for this suite.
May 21 07:19:06.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:19:07.663: INFO: namespace: e2e-tests-emptydir-g4pw8, resource: bindings, ignored listing per whitelist
May 21 07:19:08.431: INFO: namespace e2e-tests-emptydir-g4pw8 deletion completed in 7.497796455s

• [SLOW TEST:11.817 seconds]
[sig-storage] EmptyDir volumes
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:19:08.431: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl label
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
STEP: creating the pod
May 21 07:19:08.546: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig create -f - --namespace=e2e-tests-kubectl-fbcvh'
May 21 07:19:09.497: INFO: stderr: ""
May 21 07:19:09.497: INFO: stdout: "pod \"pause\" created\n"
May 21 07:19:09.497: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May 21 07:19:09.497: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-fbcvh" to be "running and ready"
May 21 07:19:09.512: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 15.611316ms
May 21 07:19:11.528: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031534197s
May 21 07:19:13.545: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.047834391s
May 21 07:19:13.545: INFO: Pod "pause" satisfied condition "running and ready"
May 21 07:19:13.545: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: adding the label testing-label with value testing-label-value to a pod
May 21 07:19:13.545: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-fbcvh'
May 21 07:19:13.736: INFO: stderr: ""
May 21 07:19:13.736: INFO: stdout: "pod \"pause\" labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
May 21 07:19:13.736: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pod pause -L testing-label --namespace=e2e-tests-kubectl-fbcvh'
May 21 07:19:14.031: INFO: stderr: ""
May 21 07:19:14.031: INFO: stdout: "NAME      READY     STATUS    RESTARTS   AGE       TESTING-LABEL\npause     1/1       Running   0          5s        testing-label-value\n"
STEP: removing the label testing-label of a pod
May 21 07:19:14.031: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig label pods pause testing-label- --namespace=e2e-tests-kubectl-fbcvh'
May 21 07:19:14.225: INFO: stderr: ""
May 21 07:19:14.225: INFO: stdout: "pod \"pause\" labeled\n"
STEP: verifying the pod doesn't have the label testing-label
May 21 07:19:14.225: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pod pause -L testing-label --namespace=e2e-tests-kubectl-fbcvh'
May 21 07:19:14.518: INFO: stderr: ""
May 21 07:19:14.518: INFO: stdout: "NAME      READY     STATUS    RESTARTS   AGE       TESTING-LABEL\npause     1/1       Running   0          5s        \n"
[AfterEach] [k8s.io] Kubectl label
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:980
STEP: using delete to clean up resources
May 21 07:19:14.519: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fbcvh'
May 21 07:19:14.758: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 07:19:14.758: INFO: stdout: "pod \"pause\" deleted\n"
May 21 07:19:14.758: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-fbcvh'
May 21 07:19:14.947: INFO: stderr: "No resources found.\n"
May 21 07:19:14.947: INFO: stdout: ""
May 21 07:19:14.947: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods -l name=pause --namespace=e2e-tests-kubectl-fbcvh -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 21 07:19:15.117: INFO: stderr: ""
May 21 07:19:15.117: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:19:15.117: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fbcvh" for this suite.
May 21 07:19:21.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:19:22.028: INFO: namespace: e2e-tests-kubectl-fbcvh, resource: bindings, ignored listing per whitelist
May 21 07:19:22.634: INFO: namespace e2e-tests-kubectl-fbcvh deletion completed in 7.487815748s

• [SLOW TEST:14.203 seconds]
[sig-cli] Kubectl client
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should update the label on a resource  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:19:22.634: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating projection with secret that has name projected-secret-test-48fcb744-5cc7-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume secrets
May 21 07:19:22.793: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-48ff5d83-5cc7-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-4fhnp" to be "success or failure"
May 21 07:19:22.809: INFO: Pod "pod-projected-secrets-48ff5d83-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.71807ms
May 21 07:19:24.825: INFO: Pod "pod-projected-secrets-48ff5d83-5cc7-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031992606s
STEP: Saw pod success
May 21 07:19:24.825: INFO: Pod "pod-projected-secrets-48ff5d83-5cc7-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:19:24.841: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod pod-projected-secrets-48ff5d83-5cc7-11e8-849c-0e182f31d764 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 07:19:24.886: INFO: Waiting for pod pod-projected-secrets-48ff5d83-5cc7-11e8-849c-0e182f31d764 to disappear
May 21 07:19:24.901: INFO: Pod pod-projected-secrets-48ff5d83-5cc7-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:19:24.902: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4fhnp" for this suite.
May 21 07:19:30.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:19:31.622: INFO: namespace: e2e-tests-projected-4fhnp, resource: bindings, ignored listing per whitelist
May 21 07:19:32.436: INFO: namespace e2e-tests-projected-4fhnp deletion completed in 7.50501896s

• [SLOW TEST:9.802 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with defaultMode set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection] [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:19:32.436: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection] [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating configMap with name configmap-projected-all-test-volume-4edae668-5cc7-11e8-849c-0e182f31d764
STEP: Creating secret with name secret-projected-all-test-volume-4edae64a-5cc7-11e8-849c-0e182f31d764
STEP: Creating a pod to test Check all projections for projected volume plugin
May 21 07:19:32.664: INFO: Waiting up to 5m0s for pod "projected-volume-4edae60f-5cc7-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-rlsh2" to be "success or failure"
May 21 07:19:32.681: INFO: Pod "projected-volume-4edae60f-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 17.361324ms
May 21 07:19:34.697: INFO: Pod "projected-volume-4edae60f-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033429997s
May 21 07:19:36.714: INFO: Pod "projected-volume-4edae60f-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 4.049805433s
May 21 07:19:38.730: INFO: Pod "projected-volume-4edae60f-5cc7-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.065963193s
STEP: Saw pod success
May 21 07:19:38.730: INFO: Pod "projected-volume-4edae60f-5cc7-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:19:38.746: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod projected-volume-4edae60f-5cc7-11e8-849c-0e182f31d764 container projected-all-volume-test: <nil>
STEP: delete the pod
May 21 07:19:38.789: INFO: Waiting for pod projected-volume-4edae60f-5cc7-11e8-849c-0e182f31d764 to disappear
May 21 07:19:38.804: INFO: Pod projected-volume-4edae60f-5cc7-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:19:38.804: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rlsh2" for this suite.
May 21 07:19:44.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:19:45.536: INFO: namespace: e2e-tests-projected-rlsh2, resource: bindings, ignored listing per whitelist
May 21 07:19:46.335: INFO: namespace e2e-tests-projected-rlsh2 deletion completed in 7.501975413s

• [SLOW TEST:13.899 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should project all components that make up the projection API [Projection] [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default commmand (docker entrypoint)  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] Docker Containers
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:19:46.336: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default commmand (docker entrypoint)  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test override command
May 21 07:19:46.489: INFO: Waiting up to 5m0s for pod "client-containers-571ec415-5cc7-11e8-849c-0e182f31d764" in namespace "e2e-tests-containers-zqm72" to be "success or failure"
May 21 07:19:46.505: INFO: Pod "client-containers-571ec415-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.131009ms
May 21 07:19:48.521: INFO: Pod "client-containers-571ec415-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03124608s
May 21 07:19:50.537: INFO: Pod "client-containers-571ec415-5cc7-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047249336s
STEP: Saw pod success
May 21 07:19:50.537: INFO: Pod "client-containers-571ec415-5cc7-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:19:50.553: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod client-containers-571ec415-5cc7-11e8-849c-0e182f31d764 container test-container: <nil>
STEP: delete the pod
May 21 07:19:50.598: INFO: Waiting for pod client-containers-571ec415-5cc7-11e8-849c-0e182f31d764 to disappear
May 21 07:19:50.614: INFO: Pod client-containers-571ec415-5cc7-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:19:50.614: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-zqm72" for this suite.
May 21 07:19:56.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:19:57.678: INFO: namespace: e2e-tests-containers-zqm72, resource: bindings, ignored listing per whitelist
May 21 07:19:58.139: INFO: namespace e2e-tests-containers-zqm72 deletion completed in 7.495255716s

• [SLOW TEST:11.803 seconds]
[k8s.io] Docker Containers
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  should be able to override the image's default commmand (docker entrypoint)  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:19:58.139: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test emptydir volume type on tmpfs
May 21 07:19:58.280: INFO: Waiting up to 5m0s for pod "pod-5e268993-5cc7-11e8-849c-0e182f31d764" in namespace "e2e-tests-emptydir-cplcf" to be "success or failure"
May 21 07:19:58.295: INFO: Pod "pod-5e268993-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 14.927679ms
May 21 07:20:00.311: INFO: Pod "pod-5e268993-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030888601s
May 21 07:20:02.327: INFO: Pod "pod-5e268993-5cc7-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047003089s
STEP: Saw pod success
May 21 07:20:02.327: INFO: Pod "pod-5e268993-5cc7-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:20:02.343: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod pod-5e268993-5cc7-11e8-849c-0e182f31d764 container test-container: <nil>
STEP: delete the pod
May 21 07:20:02.389: INFO: Waiting for pod pod-5e268993-5cc7-11e8-849c-0e182f31d764 to disappear
May 21 07:20:02.405: INFO: Pod pod-5e268993-5cc7-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:20:02.405: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cplcf" for this suite.
May 21 07:20:08.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:20:09.570: INFO: namespace: e2e-tests-emptydir-cplcf, resource: bindings, ignored listing per whitelist
May 21 07:20:09.938: INFO: namespace e2e-tests-emptydir-cplcf deletion completed in 7.503616792s

• [SLOW TEST:11.799 seconds]
[sig-storage] EmptyDir volumes
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:20:09.938: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create services for rc  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: creating Redis RC
May 21 07:20:10.041: INFO: namespace e2e-tests-kubectl-q5nrd
May 21 07:20:10.041: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig create -f - --namespace=e2e-tests-kubectl-q5nrd'
May 21 07:20:10.354: INFO: stderr: ""
May 21 07:20:10.354: INFO: stdout: "replicationcontroller \"redis-master\" created\n"
STEP: Waiting for Redis master to start.
May 21 07:20:11.370: INFO: Selector matched 1 pods for map[app:redis]
May 21 07:20:11.370: INFO: Found 0 / 1
May 21 07:20:12.370: INFO: Selector matched 1 pods for map[app:redis]
May 21 07:20:12.370: INFO: Found 0 / 1
May 21 07:20:13.371: INFO: Selector matched 1 pods for map[app:redis]
May 21 07:20:13.371: INFO: Found 1 / 1
May 21 07:20:13.371: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 21 07:20:13.386: INFO: Selector matched 1 pods for map[app:redis]
May 21 07:20:13.386: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 21 07:20:13.386: INFO: wait on redis-master startup in e2e-tests-kubectl-q5nrd 
May 21 07:20:13.386: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig logs redis-master-l6vk8 redis-master --namespace=e2e-tests-kubectl-q5nrd'
May 21 07:20:13.627: INFO: stderr: ""
May 21 07:20:13.627: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.8 (6737a5e6/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 May 07:20:12.148 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 May 07:20:12.148 # Server started, Redis version 3.2.8\n1:M 21 May 07:20:12.148 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 May 07:20:12.148 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
May 21 07:20:13.627: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-q5nrd'
May 21 07:20:13.880: INFO: stderr: ""
May 21 07:20:13.880: INFO: stdout: "service \"rm2\" exposed\n"
May 21 07:20:13.913: INFO: Service rm2 in namespace e2e-tests-kubectl-q5nrd found.
STEP: exposing service
May 21 07:20:15.945: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-q5nrd'
May 21 07:20:16.156: INFO: stderr: ""
May 21 07:20:16.156: INFO: stdout: "service \"rm3\" exposed\n"
May 21 07:20:16.172: INFO: Service rm3 in namespace e2e-tests-kubectl-q5nrd found.
[AfterEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:20:18.203: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-q5nrd" for this suite.
May 21 07:20:40.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:20:41.472: INFO: namespace: e2e-tests-kubectl-q5nrd, resource: bindings, ignored listing per whitelist
May 21 07:20:41.735: INFO: namespace e2e-tests-kubectl-q5nrd deletion completed in 23.502605741s

• [SLOW TEST:31.797 seconds]
[sig-cli] Kubectl client
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should create services for rc  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:20:41.735: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward API volume plugin
May 21 07:20:41.861: INFO: Waiting up to 5m0s for pod "downwardapi-volume-78200490-5cc7-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-lc6qk" to be "success or failure"
May 21 07:20:41.877: INFO: Pod "downwardapi-volume-78200490-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.32426ms
May 21 07:20:43.893: INFO: Pod "downwardapi-volume-78200490-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032063953s
May 21 07:20:45.909: INFO: Pod "downwardapi-volume-78200490-5cc7-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04823835s
STEP: Saw pod success
May 21 07:20:45.909: INFO: Pod "downwardapi-volume-78200490-5cc7-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:20:45.925: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod downwardapi-volume-78200490-5cc7-11e8-849c-0e182f31d764 container client-container: <nil>
STEP: delete the pod
May 21 07:20:45.968: INFO: Waiting for pod downwardapi-volume-78200490-5cc7-11e8-849c-0e182f31d764 to disappear
May 21 07:20:45.983: INFO: Pod downwardapi-volume-78200490-5cc7-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:20:45.983: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lc6qk" for this suite.
May 21 07:20:52.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:20:52.932: INFO: namespace: e2e-tests-projected-lc6qk, resource: bindings, ignored listing per whitelist
May 21 07:20:53.514: INFO: namespace e2e-tests-projected-lc6qk deletion completed in 7.501717456s

• [SLOW TEST:11.780 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:20:53.515: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward API volume plugin
May 21 07:20:53.641: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7f25d87c-5cc7-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-22z99" to be "success or failure"
May 21 07:20:53.656: INFO: Pod "downwardapi-volume-7f25d87c-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 14.923051ms
May 21 07:20:55.672: INFO: Pod "downwardapi-volume-7f25d87c-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031064016s
May 21 07:20:57.689: INFO: Pod "downwardapi-volume-7f25d87c-5cc7-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047662446s
STEP: Saw pod success
May 21 07:20:57.689: INFO: Pod "downwardapi-volume-7f25d87c-5cc7-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:20:57.705: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod downwardapi-volume-7f25d87c-5cc7-11e8-849c-0e182f31d764 container client-container: <nil>
STEP: delete the pod
May 21 07:20:57.749: INFO: Waiting for pod downwardapi-volume-7f25d87c-5cc7-11e8-849c-0e182f31d764 to disappear
May 21 07:20:57.765: INFO: Pod downwardapi-volume-7f25d87c-5cc7-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:20:57.765: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-22z99" for this suite.
May 21 07:21:03.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:21:05.158: INFO: namespace: e2e-tests-projected-22z99, resource: bindings, ignored listing per whitelist
May 21 07:21:05.328: INFO: namespace e2e-tests-projected-22z99 deletion completed in 7.53347529s

• [SLOW TEST:11.813 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide podname only [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:21:05.328: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide node allocatable (memory) as default memory limit if the limit is not set  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward API volume plugin
May 21 07:21:05.470: INFO: Waiting up to 5m0s for pod "downwardapi-volume-86325ac5-5cc7-11e8-849c-0e182f31d764" in namespace "e2e-tests-downward-api-f6q9h" to be "success or failure"
May 21 07:21:05.485: INFO: Pod "downwardapi-volume-86325ac5-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.504705ms
May 21 07:21:07.501: INFO: Pod "downwardapi-volume-86325ac5-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0314479s
May 21 07:21:09.517: INFO: Pod "downwardapi-volume-86325ac5-5cc7-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047589539s
STEP: Saw pod success
May 21 07:21:09.517: INFO: Pod "downwardapi-volume-86325ac5-5cc7-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:21:09.533: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod downwardapi-volume-86325ac5-5cc7-11e8-849c-0e182f31d764 container client-container: <nil>
STEP: delete the pod
May 21 07:21:09.580: INFO: Waiting for pod downwardapi-volume-86325ac5-5cc7-11e8-849c-0e182f31d764 to disappear
May 21 07:21:09.596: INFO: Pod downwardapi-volume-86325ac5-5cc7-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:21:09.596: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f6q9h" for this suite.
May 21 07:21:15.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:21:17.060: INFO: namespace: e2e-tests-downward-api-f6q9h, resource: bindings, ignored listing per whitelist
May 21 07:21:17.135: INFO: namespace e2e-tests-downward-api-f6q9h deletion completed in 7.510199819s

• [SLOW TEST:11.807 seconds]
[sig-storage] Downward API volume
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:21:17.135: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 21 07:21:17.297: INFO: Waiting up to 5m0s for pod "pod-8d3f704b-5cc7-11e8-849c-0e182f31d764" in namespace "e2e-tests-emptydir-tcz7w" to be "success or failure"
May 21 07:21:17.313: INFO: Pod "pod-8d3f704b-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.910895ms
May 21 07:21:19.329: INFO: Pod "pod-8d3f704b-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032080199s
May 21 07:21:21.346: INFO: Pod "pod-8d3f704b-5cc7-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049293133s
STEP: Saw pod success
May 21 07:21:21.346: INFO: Pod "pod-8d3f704b-5cc7-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:21:21.362: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod pod-8d3f704b-5cc7-11e8-849c-0e182f31d764 container test-container: <nil>
STEP: delete the pod
May 21 07:21:21.408: INFO: Waiting for pod pod-8d3f704b-5cc7-11e8-849c-0e182f31d764 to disappear
May 21 07:21:21.423: INFO: Pod pod-8d3f704b-5cc7-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:21:21.423: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tcz7w" for this suite.
May 21 07:21:27.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:21:28.479: INFO: namespace: e2e-tests-emptydir-tcz7w, resource: bindings, ignored listing per whitelist
May 21 07:21:28.956: INFO: namespace e2e-tests-emptydir-tcz7w deletion completed in 7.502898658s

• [SLOW TEST:11.821 seconds]
[sig-storage] EmptyDir volumes
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-network] Services
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:21:28.956: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:51
[It] should serve multiport endpoints from pods  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-54xch
STEP: waiting up to 1m0s for service multi-endpoint-test in namespace e2e-tests-services-54xch to expose endpoints map[]
May 21 07:21:29.121: INFO: Get endpoints failed (15.569094ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
May 21 07:21:30.137: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-54xch exposes endpoints map[] (1.031711909s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-54xch
STEP: waiting up to 1m0s for service multi-endpoint-test in namespace e2e-tests-services-54xch to expose endpoints map[pod1:[100]]
May 21 07:21:33.299: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-54xch exposes endpoints map[pod1:[100]] (3.125734809s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-54xch
STEP: waiting up to 1m0s for service multi-endpoint-test in namespace e2e-tests-services-54xch to expose endpoints map[pod1:[100] pod2:[101]]
May 21 07:21:36.518: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-54xch exposes endpoints map[pod1:[100] pod2:[101]] (3.187594207s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-54xch
STEP: waiting up to 1m0s for service multi-endpoint-test in namespace e2e-tests-services-54xch to expose endpoints map[pod2:[101]]
May 21 07:21:36.567: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-54xch exposes endpoints map[pod2:[101]] (31.283138ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-54xch
STEP: waiting up to 1m0s for service multi-endpoint-test in namespace e2e-tests-services-54xch to expose endpoints map[]
May 21 07:21:36.601: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-54xch exposes endpoints map[] (16.815601ms elapsed)
[AfterEach] [sig-network] Services
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:21:36.630: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-54xch" for this suite.
May 21 07:21:42.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:21:44.088: INFO: namespace: e2e-tests-services-54xch, resource: bindings, ignored listing per whitelist
May 21 07:21:44.163: INFO: namespace e2e-tests-services-54xch deletion completed in 7.502886953s
[AfterEach] [sig-network] Services
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:56

• [SLOW TEST:15.207 seconds]
[sig-network] Services
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:21:44.163: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating configMap with name projected-configmap-test-volume-map-9d5ced46-5cc7-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume configMaps
May 21 07:21:44.359: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9d5f6c0c-5cc7-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-sv825" to be "success or failure"
May 21 07:21:44.375: INFO: Pod "pod-projected-configmaps-9d5f6c0c-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.74546ms
May 21 07:21:46.391: INFO: Pod "pod-projected-configmaps-9d5f6c0c-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031679655s
May 21 07:21:48.407: INFO: Pod "pod-projected-configmaps-9d5f6c0c-5cc7-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047522604s
STEP: Saw pod success
May 21 07:21:48.407: INFO: Pod "pod-projected-configmaps-9d5f6c0c-5cc7-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:21:48.422: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod pod-projected-configmaps-9d5f6c0c-5cc7-11e8-849c-0e182f31d764 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 07:21:48.475: INFO: Waiting for pod pod-projected-configmaps-9d5f6c0c-5cc7-11e8-849c-0e182f31d764 to disappear
May 21 07:21:48.490: INFO: Pod pod-projected-configmaps-9d5f6c0c-5cc7-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:21:48.490: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sv825" for this suite.
May 21 07:21:54.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:21:55.969: INFO: namespace: e2e-tests-projected-sv825, resource: bindings, ignored listing per whitelist
May 21 07:21:56.014: INFO: namespace e2e-tests-projected-sv825 deletion completed in 7.494418291s

• [SLOW TEST:11.851 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings and Item mode set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
S
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:21:56.014: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward API volume plugin
May 21 07:21:56.155: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a46888e1-5cc7-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-x5m9f" to be "success or failure"
May 21 07:21:56.170: INFO: Pod "downwardapi-volume-a46888e1-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 14.918628ms
May 21 07:21:58.187: INFO: Pod "downwardapi-volume-a46888e1-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031060968s
May 21 07:22:00.202: INFO: Pod "downwardapi-volume-a46888e1-5cc7-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046816973s
STEP: Saw pod success
May 21 07:22:00.202: INFO: Pod "downwardapi-volume-a46888e1-5cc7-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:22:00.218: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod downwardapi-volume-a46888e1-5cc7-11e8-849c-0e182f31d764 container client-container: <nil>
STEP: delete the pod
May 21 07:22:00.260: INFO: Waiting for pod downwardapi-volume-a46888e1-5cc7-11e8-849c-0e182f31d764 to disappear
May 21 07:22:00.275: INFO: Pod downwardapi-volume-a46888e1-5cc7-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:22:00.275: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x5m9f" for this suite.
May 21 07:22:06.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:22:07.057: INFO: namespace: e2e-tests-projected-x5m9f, resource: bindings, ignored listing per whitelist
May 21 07:22:07.812: INFO: namespace e2e-tests-projected-x5m9f deletion completed in 7.507301894s

• [SLOW TEST:11.798 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Secrets
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:22:07.812: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating secret with name secret-test-ab71e5b3-5cc7-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume secrets
May 21 07:22:07.977: INFO: Waiting up to 5m0s for pod "pod-secrets-ab746dc7-5cc7-11e8-849c-0e182f31d764" in namespace "e2e-tests-secrets-b7dbp" to be "success or failure"
May 21 07:22:07.995: INFO: Pod "pod-secrets-ab746dc7-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 18.738375ms
May 21 07:22:10.012: INFO: Pod "pod-secrets-ab746dc7-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035022444s
May 21 07:22:12.028: INFO: Pod "pod-secrets-ab746dc7-5cc7-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051552806s
STEP: Saw pod success
May 21 07:22:12.028: INFO: Pod "pod-secrets-ab746dc7-5cc7-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:22:12.044: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod pod-secrets-ab746dc7-5cc7-11e8-849c-0e182f31d764 container secret-volume-test: <nil>
STEP: delete the pod
May 21 07:22:12.087: INFO: Waiting for pod pod-secrets-ab746dc7-5cc7-11e8-849c-0e182f31d764 to disappear
May 21 07:22:12.103: INFO: Pod pod-secrets-ab746dc7-5cc7-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Secrets
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:22:12.103: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-b7dbp" for this suite.
May 21 07:22:18.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:22:19.480: INFO: namespace: e2e-tests-secrets-b7dbp, resource: bindings, ignored listing per whitelist
May 21 07:22:19.616: INFO: namespace e2e-tests-secrets-b7dbp deletion completed in 7.48363072s

• [SLOW TEST:11.804 seconds]
[sig-storage] Secrets
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:22:19.616: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's cpu request  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward API volume plugin
May 21 07:22:19.842: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b2869cec-5cc7-11e8-849c-0e182f31d764" in namespace "e2e-tests-downward-api-5mg5m" to be "success or failure"
May 21 07:22:19.859: INFO: Pod "downwardapi-volume-b2869cec-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 16.45263ms
May 21 07:22:21.876: INFO: Pod "downwardapi-volume-b2869cec-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03366631s
May 21 07:22:23.892: INFO: Pod "downwardapi-volume-b2869cec-5cc7-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049285693s
STEP: Saw pod success
May 21 07:22:23.892: INFO: Pod "downwardapi-volume-b2869cec-5cc7-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:22:23.907: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod downwardapi-volume-b2869cec-5cc7-11e8-849c-0e182f31d764 container client-container: <nil>
STEP: delete the pod
May 21 07:22:23.958: INFO: Waiting for pod downwardapi-volume-b2869cec-5cc7-11e8-849c-0e182f31d764 to disappear
May 21 07:22:23.977: INFO: Pod downwardapi-volume-b2869cec-5cc7-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:22:23.977: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5mg5m" for this suite.
May 21 07:22:30.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:22:30.886: INFO: namespace: e2e-tests-downward-api-5mg5m, resource: bindings, ignored listing per whitelist
May 21 07:22:31.496: INFO: namespace e2e-tests-downward-api-5mg5m deletion completed in 7.489988802s

• [SLOW TEST:11.880 seconds]
[sig-storage] Downward API volume
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's cpu request  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] ConfigMap
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:22:31.496: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating configMap with name configmap-test-volume-map-b98fa74e-5cc7-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume configMaps
May 21 07:22:31.662: INFO: Waiting up to 5m0s for pod "pod-configmaps-b9924fdf-5cc7-11e8-849c-0e182f31d764" in namespace "e2e-tests-configmap-t62gd" to be "success or failure"
May 21 07:22:31.679: INFO: Pod "pod-configmaps-b9924fdf-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 16.1335ms
May 21 07:22:33.695: INFO: Pod "pod-configmaps-b9924fdf-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032312653s
May 21 07:22:35.711: INFO: Pod "pod-configmaps-b9924fdf-5cc7-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048540434s
STEP: Saw pod success
May 21 07:22:35.711: INFO: Pod "pod-configmaps-b9924fdf-5cc7-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:22:35.727: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod pod-configmaps-b9924fdf-5cc7-11e8-849c-0e182f31d764 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 07:22:35.775: INFO: Waiting for pod pod-configmaps-b9924fdf-5cc7-11e8-849c-0e182f31d764 to disappear
May 21 07:22:35.790: INFO: Pod pod-configmaps-b9924fdf-5cc7-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:22:35.790: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-t62gd" for this suite.
May 21 07:22:41.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:22:43.024: INFO: namespace: e2e-tests-configmap-t62gd, resource: bindings, ignored listing per whitelist
May 21 07:22:43.329: INFO: namespace e2e-tests-configmap-t62gd deletion completed in 7.509474723s

• [SLOW TEST:11.832 seconds]
[sig-storage] ConfigMap
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:22:43.329: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: validating cluster-info
May 21 07:22:43.462: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig cluster-info'
May 21 07:22:43.744: INFO: stderr: ""
May 21 07:22:43.744: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://internal-api.prtest-7d230a7-103.origin-ci-int-gce.dev.rhcloud.com:8443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:22:43.744: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xtrnv" for this suite.
May 21 07:22:49.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:22:51.076: INFO: namespace: e2e-tests-kubectl-xtrnv, resource: bindings, ignored listing per whitelist
May 21 07:22:51.279: INFO: namespace e2e-tests-kubectl-xtrnv deletion completed in 7.505396677s

• [SLOW TEST:7.950 seconds]
[sig-cli] Kubectl client
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:22:51.279: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run rc
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1147
[It] should create an rc from an image  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: running the image gcr.io/google-containers/nginx-slim-amd64:0.20
May 21 07:22:51.428: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig run e2e-test-nginx-rc --image=gcr.io/google-containers/nginx-slim-amd64:0.20 --generator=run/v1 --namespace=e2e-tests-kubectl-l9wrx'
May 21 07:22:51.653: INFO: stderr: ""
May 21 07:22:51.653: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
May 21 07:22:51.684: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-7dps4]
May 21 07:22:51.684: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-7dps4" in namespace "e2e-tests-kubectl-l9wrx" to be "running and ready"
May 21 07:22:51.700: INFO: Pod "e2e-test-nginx-rc-7dps4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.728901ms
May 21 07:22:53.716: INFO: Pod "e2e-test-nginx-rc-7dps4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031735132s
May 21 07:22:55.732: INFO: Pod "e2e-test-nginx-rc-7dps4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047720992s
May 21 07:22:57.748: INFO: Pod "e2e-test-nginx-rc-7dps4": Phase="Running", Reason="", readiness=true. Elapsed: 6.063720098s
May 21 07:22:57.748: INFO: Pod "e2e-test-nginx-rc-7dps4" satisfied condition "running and ready"
May 21 07:22:57.748: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-7dps4]
May 21 07:22:57.748: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-l9wrx'
May 21 07:22:58.014: INFO: stderr: ""
[AfterEach] [k8s.io] Kubectl run rc
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1152
May 21 07:22:58.015: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-l9wrx'
May 21 07:22:58.314: INFO: stderr: ""
May 21 07:22:58.314: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:22:58.314: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l9wrx" for this suite.
May 21 07:23:20.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:23:21.356: INFO: namespace: e2e-tests-kubectl-l9wrx, resource: bindings, ignored listing per whitelist
May 21 07:23:21.829: INFO: namespace e2e-tests-kubectl-l9wrx deletion completed in 23.485728952s

• [SLOW TEST:30.551 seconds]
[sig-cli] Kubectl client
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should create an rc from an image  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-api-machinery] Downward API
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:23:21.830: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward api env vars
May 21 07:23:21.972: INFO: Waiting up to 5m0s for pod "downward-api-d78e5cf5-5cc7-11e8-849c-0e182f31d764" in namespace "e2e-tests-downward-api-4gdb5" to be "success or failure"
May 21 07:23:21.988: INFO: Pod "downward-api-d78e5cf5-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.340487ms
May 21 07:23:24.004: INFO: Pod "downward-api-d78e5cf5-5cc7-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031273591s
May 21 07:23:26.020: INFO: Pod "downward-api-d78e5cf5-5cc7-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047488977s
STEP: Saw pod success
May 21 07:23:26.020: INFO: Pod "downward-api-d78e5cf5-5cc7-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:23:26.036: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod downward-api-d78e5cf5-5cc7-11e8-849c-0e182f31d764 container dapi-container: <nil>
STEP: delete the pod
May 21 07:23:26.084: INFO: Waiting for pod downward-api-d78e5cf5-5cc7-11e8-849c-0e182f31d764 to disappear
May 21 07:23:26.099: INFO: Pod downward-api-d78e5cf5-5cc7-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:23:26.099: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4gdb5" for this suite.
May 21 07:23:32.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:23:33.329: INFO: namespace: e2e-tests-downward-api-4gdb5, resource: bindings, ignored listing per whitelist
May 21 07:23:33.622: INFO: namespace e2e-tests-downward-api-4gdb5 deletion completed in 7.493440585s

• [SLOW TEST:11.793 seconds]
[sig-api-machinery] Downward API
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide default limits.cpu/memory from node allocatable  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:23:33.623: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating the pod
May 21 07:23:38.391: INFO: Successfully updated pod "annotationupdatede968b7c-5cc7-11e8-849c-0e182f31d764"
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:23:42.457: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kspfx" for this suite.
May 21 07:24:04.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:24:05.578: INFO: namespace: e2e-tests-projected-kspfx, resource: bindings, ignored listing per whitelist
May 21 07:24:06.000: INFO: namespace e2e-tests-projected-kspfx deletion completed in 23.513138931s

• [SLOW TEST:32.377 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should update annotations on modification [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:24:06.000: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should update annotations on modification  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating the pod
May 21 07:24:08.803: INFO: Successfully updated pod "annotationupdatef1e80dc0-5cc7-11e8-849c-0e182f31d764"
[AfterEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:24:10.846: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xz2w8" for this suite.
May 21 07:24:32.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:24:34.333: INFO: namespace: e2e-tests-downward-api-xz2w8, resource: bindings, ignored listing per whitelist
May 21 07:24:34.396: INFO: namespace e2e-tests-downward-api-xz2w8 deletion completed in 23.520648715s

• [SLOW TEST:28.396 seconds]
[sig-storage] Downward API volume
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should update annotations on modification  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-api-machinery] Downward API
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:24:34.397: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward api env vars
May 21 07:24:34.546: INFO: Waiting up to 5m0s for pod "downward-api-02d00cf4-5cc8-11e8-849c-0e182f31d764" in namespace "e2e-tests-downward-api-7k2nf" to be "success or failure"
May 21 07:24:34.561: INFO: Pod "downward-api-02d00cf4-5cc8-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.167299ms
May 21 07:24:36.577: INFO: Pod "downward-api-02d00cf4-5cc8-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031196166s
May 21 07:24:38.593: INFO: Pod "downward-api-02d00cf4-5cc8-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047212317s
May 21 07:24:40.609: INFO: Pod "downward-api-02d00cf4-5cc8-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.063143691s
STEP: Saw pod success
May 21 07:24:40.609: INFO: Pod "downward-api-02d00cf4-5cc8-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:24:40.626: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod downward-api-02d00cf4-5cc8-11e8-849c-0e182f31d764 container dapi-container: <nil>
STEP: delete the pod
May 21 07:24:40.671: INFO: Waiting for pod downward-api-02d00cf4-5cc8-11e8-849c-0e182f31d764 to disappear
May 21 07:24:40.687: INFO: Pod downward-api-02d00cf4-5cc8-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:24:40.687: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7k2nf" for this suite.
May 21 07:24:46.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:24:48.067: INFO: namespace: e2e-tests-downward-api-7k2nf, resource: bindings, ignored listing per whitelist
May 21 07:24:48.202: INFO: namespace e2e-tests-downward-api-7k2nf deletion completed in 7.486450623s

• [SLOW TEST:13.806 seconds]
[sig-api-machinery] Downward API
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:24:48.203: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 21 07:24:48.285: INFO: Waiting up to 1m0s for all nodes to be ready
May 21 07:25:48.411: INFO: Waiting for terminating namespaces to be deleted...
May 21 07:25:48.444: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 21 07:25:48.490: INFO: 0 / 0 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 21 07:25:48.490: INFO: expected 0 pod replicas in namespace 'kube-system', 0 are Running and Ready.
May 21 07:25:48.506: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
May 21 07:25:48.506: INFO: 
Logging pods the kubelet thinks is on node prtest-7d230a7-103-ig-n-3zcc before test
May 21 07:25:48.528: INFO: 
Logging pods the kubelet thinks is on node prtest-7d230a7-103-ig-n-hmsw before test
May 21 07:25:48.554: INFO: registry-console-1-w8zl4 from default started at 2018-05-21 06:56:59 +0000 UTC (1 container statuses recorded)
May 21 07:25:48.554: INFO: 	Container registry-console ready: true, restart count 0
May 21 07:25:48.554: INFO: 
Logging pods the kubelet thinks is on node prtest-7d230a7-103-ig-n-wbpf before test
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: verifying the node has the label node prtest-7d230a7-103-ig-n-3zcc
STEP: verifying the node has the label node prtest-7d230a7-103-ig-n-hmsw
STEP: verifying the node has the label node prtest-7d230a7-103-ig-n-wbpf
May 21 07:25:48.708: INFO: Pod registry-console-1-w8zl4 requesting resource cpu=0m on Node prtest-7d230a7-103-ig-n-hmsw
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f084b0d-5cc8-11e8-849c-0e182f31d764.15309822c2b6a282], Reason = [Scheduled], Message = [Successfully assigned filler-pod-2f084b0d-5cc8-11e8-849c-0e182f31d764 to prtest-7d230a7-103-ig-n-wbpf]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f084b0d-5cc8-11e8-849c-0e182f31d764.15309822d311395b], Reason = [SuccessfulMountVolume], Message = [MountVolume.SetUp succeeded for volume "default-token-cwwn8" ]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f084b0d-5cc8-11e8-849c-0e182f31d764.1530982343130e49], Reason = [Pulled], Message = [Container image "gcr.io/google_containers/pause-amd64:3.0" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f084b0d-5cc8-11e8-849c-0e182f31d764.1530982344d20ccb], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f084b0d-5cc8-11e8-849c-0e182f31d764.153098234bd67490], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f0dba29-5cc8-11e8-849c-0e182f31d764.15309822c4a13351], Reason = [Scheduled], Message = [Successfully assigned filler-pod-2f0dba29-5cc8-11e8-849c-0e182f31d764 to prtest-7d230a7-103-ig-n-3zcc]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f0dba29-5cc8-11e8-849c-0e182f31d764.15309822d1519289], Reason = [SuccessfulMountVolume], Message = [MountVolume.SetUp succeeded for volume "default-token-cwwn8" ]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f0dba29-5cc8-11e8-849c-0e182f31d764.1530982340571bff], Reason = [Pulling], Message = [pulling image "gcr.io/google_containers/pause-amd64:3.0"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f0dba29-5cc8-11e8-849c-0e182f31d764.15309823505b2f0b], Reason = [Pulled], Message = [Successfully pulled image "gcr.io/google_containers/pause-amd64:3.0"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f0dba29-5cc8-11e8-849c-0e182f31d764.15309823525a59f9], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f0dba29-5cc8-11e8-849c-0e182f31d764.15309823581d1c68], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f1302c2-5cc8-11e8-849c-0e182f31d764.15309822c6d0060f], Reason = [Scheduled], Message = [Successfully assigned filler-pod-2f1302c2-5cc8-11e8-849c-0e182f31d764 to prtest-7d230a7-103-ig-n-hmsw]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f1302c2-5cc8-11e8-849c-0e182f31d764.15309822d97284d2], Reason = [SuccessfulMountVolume], Message = [MountVolume.SetUp succeeded for volume "default-token-cwwn8" ]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f1302c2-5cc8-11e8-849c-0e182f31d764.15309823518f1bd7], Reason = [Pulled], Message = [Container image "gcr.io/google_containers/pause-amd64:3.0" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f1302c2-5cc8-11e8-849c-0e182f31d764.153098235325bc25], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f1302c2-5cc8-11e8-849c-0e182f31d764.15309823592c860e], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15309823bc907322], Reason = [FailedScheduling], Message = [0/4 nodes are available: 1 MatchNodeSelector, 1 NodeUnschedulable, 3 Insufficient cpu.]
STEP: removing the label node off the node prtest-7d230a7-103-ig-n-3zcc
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node prtest-7d230a7-103-ig-n-hmsw
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node prtest-7d230a7-103-ig-n-wbpf
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:25:54.122: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-4njdg" for this suite.
May 21 07:26:16.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:26:17.621: INFO: namespace: e2e-tests-sched-pred-4njdg, resource: bindings, ignored listing per whitelist
May 21 07:26:17.637: INFO: namespace e2e-tests-sched-pred-4njdg deletion completed in 23.498740414s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:89.434 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:26:17.637: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward API volume plugin
May 21 07:26:17.775: INFO: Waiting up to 5m0s for pod "downwardapi-volume-40582e14-5cc8-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-75rqw" to be "success or failure"
May 21 07:26:17.791: INFO: Pod "downwardapi-volume-40582e14-5cc8-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.793494ms
May 21 07:26:19.807: INFO: Pod "downwardapi-volume-40582e14-5cc8-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031984954s
May 21 07:26:21.823: INFO: Pod "downwardapi-volume-40582e14-5cc8-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048166933s
STEP: Saw pod success
May 21 07:26:21.824: INFO: Pod "downwardapi-volume-40582e14-5cc8-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:26:21.839: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod downwardapi-volume-40582e14-5cc8-11e8-849c-0e182f31d764 container client-container: <nil>
STEP: delete the pod
May 21 07:26:21.882: INFO: Waiting for pod downwardapi-volume-40582e14-5cc8-11e8-849c-0e182f31d764 to disappear
May 21 07:26:21.898: INFO: Pod downwardapi-volume-40582e14-5cc8-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:26:21.898: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-75rqw" for this suite.
May 21 07:26:27.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:26:29.362: INFO: namespace: e2e-tests-projected-75rqw, resource: bindings, ignored listing per whitelist
May 21 07:26:29.455: INFO: namespace e2e-tests-projected-75rqw deletion completed in 7.526350288s

• [SLOW TEST:11.818 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should set DefaultMode on files [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-apps] ReplicationController
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:26:29.455: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating replication controller my-hostname-basic-4763b910-5cc8-11e8-849c-0e182f31d764
May 21 07:26:29.607: INFO: Pod name my-hostname-basic-4763b910-5cc8-11e8-849c-0e182f31d764: Found 1 pods out of 1
May 21 07:26:29.607: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-4763b910-5cc8-11e8-849c-0e182f31d764" are running
May 21 07:26:33.645: INFO: Pod "my-hostname-basic-4763b910-5cc8-11e8-849c-0e182f31d764-mgkmr" is running (conditions: [])
May 21 07:26:33.645: INFO: Trying to dial the pod
May 21 07:26:38.697: INFO: Controller my-hostname-basic-4763b910-5cc8-11e8-849c-0e182f31d764: Got expected result from replica 1 [my-hostname-basic-4763b910-5cc8-11e8-849c-0e182f31d764-mgkmr]: "my-hostname-basic-4763b910-5cc8-11e8-849c-0e182f31d764-mgkmr", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:26:38.697: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-xgcwp" for this suite.
May 21 07:26:44.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:26:45.927: INFO: namespace: e2e-tests-replication-controller-xgcwp, resource: bindings, ignored listing per whitelist
May 21 07:26:46.254: INFO: namespace e2e-tests-replication-controller-xgcwp deletion completed in 7.52643533s

• [SLOW TEST:16.799 seconds]
[sig-apps] ReplicationController
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:26:46.254: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating configMap with name projected-configmap-test-volume-map-5168ba85-5cc8-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume configMaps
May 21 07:26:46.421: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-516b3b61-5cc8-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-mmh89" to be "success or failure"
May 21 07:26:46.438: INFO: Pod "pod-projected-configmaps-516b3b61-5cc8-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 17.173524ms
May 21 07:26:48.455: INFO: Pod "pod-projected-configmaps-516b3b61-5cc8-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033948921s
May 21 07:26:50.471: INFO: Pod "pod-projected-configmaps-516b3b61-5cc8-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050126029s
STEP: Saw pod success
May 21 07:26:50.471: INFO: Pod "pod-projected-configmaps-516b3b61-5cc8-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:26:50.487: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod pod-projected-configmaps-516b3b61-5cc8-11e8-849c-0e182f31d764 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 07:26:50.533: INFO: Waiting for pod pod-projected-configmaps-516b3b61-5cc8-11e8-849c-0e182f31d764 to disappear
May 21 07:26:50.549: INFO: Pod pod-projected-configmaps-516b3b61-5cc8-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:26:50.549: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mmh89" for this suite.
May 21 07:26:56.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:26:57.297: INFO: namespace: e2e-tests-projected-mmh89, resource: bindings, ignored listing per whitelist
May 21 07:26:58.081: INFO: namespace e2e-tests-projected-mmh89 deletion completed in 7.502781775s

• [SLOW TEST:11.828 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings as non-root [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[k8s.io] Pods 
  should get a host IP  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] Pods
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:26:58.081: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should get a host IP  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: creating pod
May 21 07:27:02.277: INFO: Pod pod-hostip-587115ed-5cc8-11e8-849c-0e182f31d764 has hostIP: 10.142.0.3
[AfterEach] [k8s.io] Pods
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:27:02.277: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-p7cjt" for this suite.
May 21 07:27:24.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:27:25.191: INFO: namespace: e2e-tests-pods-p7cjt, resource: bindings, ignored listing per whitelist
May 21 07:27:25.827: INFO: namespace e2e-tests-pods-p7cjt deletion completed in 23.52029878s

• [SLOW TEST:27.746 seconds]
[k8s.io] Pods
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  should get a host IP  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] version v1
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:27:25.827: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] version v1
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:68
[It] should proxy logs on node  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
May 21 07:27:25.977: INFO: (0) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 19.868145ms)
May 21 07:27:25.995: INFO: (1) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.453846ms)
May 21 07:27:26.012: INFO: (2) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.938241ms)
May 21 07:27:26.030: INFO: (3) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.096268ms)
May 21 07:27:26.047: INFO: (4) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.888101ms)
May 21 07:27:26.064: INFO: (5) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.168679ms)
May 21 07:27:26.081: INFO: (6) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.106678ms)
May 21 07:27:26.098: INFO: (7) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.817699ms)
May 21 07:27:26.115: INFO: (8) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.929327ms)
May 21 07:27:26.132: INFO: (9) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.837697ms)
May 21 07:27:26.149: INFO: (10) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.020885ms)
May 21 07:27:26.166: INFO: (11) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.052152ms)
May 21 07:27:26.183: INFO: (12) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.878466ms)
May 21 07:27:26.199: INFO: (13) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.666379ms)
May 21 07:27:26.216: INFO: (14) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.943509ms)
May 21 07:27:26.235: INFO: (15) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 18.480206ms)
May 21 07:27:26.252: INFO: (16) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.811155ms)
May 21 07:27:26.268: INFO: (17) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.933485ms)
May 21 07:27:26.285: INFO: (18) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.771583ms)
May 21 07:27:26.302: INFO: (19) /api/v1/proxy/nodes/prtest-7d230a7-103-ig-n-3zcc/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.944951ms)
[AfterEach] version v1
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:27:26.302: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-hgq7r" for this suite.
May 21 07:27:32.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:27:33.013: INFO: namespace: e2e-tests-proxy-hgq7r, resource: bindings, ignored listing per whitelist
May 21 07:27:33.840: INFO: namespace e2e-tests-proxy-hgq7r deletion completed in 7.521950754s

• [SLOW TEST:8.013 seconds]
[sig-network] Proxy
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:60
    should proxy logs on node  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] Docker Containers
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:27:33.841: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test use defaults
May 21 07:27:34.066: INFO: Waiting up to 5m0s for pod "client-containers-6dd1f892-5cc8-11e8-849c-0e182f31d764" in namespace "e2e-tests-containers-n548h" to be "success or failure"
May 21 07:27:34.082: INFO: Pod "client-containers-6dd1f892-5cc8-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 16.193459ms
May 21 07:27:36.098: INFO: Pod "client-containers-6dd1f892-5cc8-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032437403s
May 21 07:27:38.114: INFO: Pod "client-containers-6dd1f892-5cc8-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048589605s
STEP: Saw pod success
May 21 07:27:38.114: INFO: Pod "client-containers-6dd1f892-5cc8-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:27:38.130: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod client-containers-6dd1f892-5cc8-11e8-849c-0e182f31d764 container test-container: <nil>
STEP: delete the pod
May 21 07:27:38.173: INFO: Waiting for pod client-containers-6dd1f892-5cc8-11e8-849c-0e182f31d764 to disappear
May 21 07:27:38.189: INFO: Pod client-containers-6dd1f892-5cc8-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:27:38.189: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-n548h" for this suite.
May 21 07:27:44.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:27:45.102: INFO: namespace: e2e-tests-containers-n548h, resource: bindings, ignored listing per whitelist
May 21 07:27:45.721: INFO: namespace e2e-tests-containers-n548h deletion completed in 7.502920889s

• [SLOW TEST:11.880 seconds]
[k8s.io] Docker Containers
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  should use the image defaults if command and args are blank  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:27:45.721: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward API volume plugin
May 21 07:27:45.872: INFO: Waiting up to 5m0s for pod "downwardapi-volume-74db1ed2-5cc8-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-xpxrd" to be "success or failure"
May 21 07:27:45.887: INFO: Pod "downwardapi-volume-74db1ed2-5cc8-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 14.927595ms
May 21 07:27:47.903: INFO: Pod "downwardapi-volume-74db1ed2-5cc8-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030997703s
May 21 07:27:49.919: INFO: Pod "downwardapi-volume-74db1ed2-5cc8-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047218034s
STEP: Saw pod success
May 21 07:27:49.919: INFO: Pod "downwardapi-volume-74db1ed2-5cc8-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:27:49.935: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod downwardapi-volume-74db1ed2-5cc8-11e8-849c-0e182f31d764 container client-container: <nil>
STEP: delete the pod
May 21 07:27:49.979: INFO: Waiting for pod downwardapi-volume-74db1ed2-5cc8-11e8-849c-0e182f31d764 to disappear
May 21 07:27:49.994: INFO: Pod downwardapi-volume-74db1ed2-5cc8-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:27:49.994: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xpxrd" for this suite.
May 21 07:27:56.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:27:56.709: INFO: namespace: e2e-tests-projected-xpxrd, resource: bindings, ignored listing per whitelist
May 21 07:27:57.532: INFO: namespace e2e-tests-projected-xpxrd deletion completed in 7.507799729s

• [SLOW TEST:11.812 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's cpu limit [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:27:57.533: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-9xr6s
May 21 07:28:01.706: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-9xr6s
STEP: checking the pod's current state and verifying that restartCount is present
May 21 07:28:01.723: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:30:02.707: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-9xr6s" for this suite.
May 21 07:30:08.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:30:10.167: INFO: namespace: e2e-tests-container-probe-9xr6s, resource: bindings, ignored listing per whitelist
May 21 07:30:10.227: INFO: namespace e2e-tests-container-probe-9xr6s deletion completed in 7.491223628s

• [SLOW TEST:132.695 seconds]
[k8s.io] Probing container
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:30:10.227: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support proxy with --port 0  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: starting the proxy server
May 21 07:30:10.345: INFO: Asynchronously running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:30:10.561: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k8xxm" for this suite.
May 21 07:30:16.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:30:17.838: INFO: namespace: e2e-tests-kubectl-k8xxm, resource: bindings, ignored listing per whitelist
May 21 07:30:18.084: INFO: namespace e2e-tests-kubectl-k8xxm deletion completed in 7.493480886s

• [SLOW TEST:7.857 seconds]
[sig-cli] Kubectl client
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should support proxy with --port 0  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] ConfigMap
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:30:18.084: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating configMap with name configmap-test-volume-map-cfa48627-5cc8-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume configMaps
May 21 07:30:18.215: INFO: Waiting up to 5m0s for pod "pod-configmaps-cfa75b40-5cc8-11e8-849c-0e182f31d764" in namespace "e2e-tests-configmap-z65ht" to be "success or failure"
May 21 07:30:18.231: INFO: Pod "pod-configmaps-cfa75b40-5cc8-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.781797ms
May 21 07:30:20.247: INFO: Pod "pod-configmaps-cfa75b40-5cc8-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031553887s
May 21 07:30:22.263: INFO: Pod "pod-configmaps-cfa75b40-5cc8-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047542586s
STEP: Saw pod success
May 21 07:30:22.263: INFO: Pod "pod-configmaps-cfa75b40-5cc8-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:30:22.279: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod pod-configmaps-cfa75b40-5cc8-11e8-849c-0e182f31d764 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 07:30:22.324: INFO: Waiting for pod pod-configmaps-cfa75b40-5cc8-11e8-849c-0e182f31d764 to disappear
May 21 07:30:22.340: INFO: Pod pod-configmaps-cfa75b40-5cc8-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:30:22.340: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-z65ht" for this suite.
May 21 07:30:28.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:30:29.674: INFO: namespace: e2e-tests-configmap-z65ht, resource: bindings, ignored listing per whitelist
May 21 07:30:29.877: INFO: namespace e2e-tests-configmap-z65ht deletion completed in 7.507916489s

• [SLOW TEST:11.793 seconds]
[sig-storage] ConfigMap
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:30:29.877: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl rolling-update
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1202
[It] should support rolling-update to same image  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: running the image gcr.io/google-containers/nginx-slim-amd64:0.20
May 21 07:30:30.018: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig run e2e-test-nginx-rc --image=gcr.io/google-containers/nginx-slim-amd64:0.20 --generator=run/v1 --namespace=e2e-tests-kubectl-lggrc'
May 21 07:30:30.818: INFO: stderr: ""
May 21 07:30:30.818: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
May 21 07:30:30.849: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig rolling-update e2e-test-nginx-rc --update-period=1s --image=gcr.io/google-containers/nginx-slim-amd64:0.20 --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-lggrc'
May 21 07:30:42.654: INFO: stderr: ""
May 21 07:30:42.654: INFO: stdout: "Created e2e-test-nginx-rc-f64824ff55743ed7d8b0ce378d50e16c\nScaling up e2e-test-nginx-rc-f64824ff55743ed7d8b0ce378d50e16c from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-f64824ff55743ed7d8b0ce378d50e16c up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-f64824ff55743ed7d8b0ce378d50e16c to e2e-test-nginx-rc\nreplicationcontroller \"e2e-test-nginx-rc\" rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
May 21 07:30:42.654: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-lggrc'
May 21 07:30:42.824: INFO: stderr: ""
May 21 07:30:42.824: INFO: stdout: "e2e-test-nginx-rc-f64824ff55743ed7d8b0ce378d50e16c-jgpbj "
May 21 07:30:42.824: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods e2e-test-nginx-rc-f64824ff55743ed7d8b0ce378d50e16c-jgpbj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lggrc'
May 21 07:30:42.993: INFO: stderr: ""
May 21 07:30:42.994: INFO: stdout: "true"
May 21 07:30:42.994: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods e2e-test-nginx-rc-f64824ff55743ed7d8b0ce378d50e16c-jgpbj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lggrc'
May 21 07:30:43.165: INFO: stderr: ""
May 21 07:30:43.165: INFO: stdout: "gcr.io/google-containers/nginx-slim-amd64:0.20"
May 21 07:30:43.165: INFO: e2e-test-nginx-rc-f64824ff55743ed7d8b0ce378d50e16c-jgpbj is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1208
May 21 07:30:43.165: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-lggrc'
May 21 07:30:43.485: INFO: stderr: ""
May 21 07:30:43.485: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:30:43.485: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lggrc" for this suite.
May 21 07:30:49.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:30:50.821: INFO: namespace: e2e-tests-kubectl-lggrc, resource: bindings, ignored listing per whitelist
May 21 07:30:51.022: INFO: namespace e2e-tests-kubectl-lggrc deletion completed in 7.507753948s

• [SLOW TEST:21.145 seconds]
[sig-cli] Kubectl client
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should support rolling-update to same image  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:30:51.023: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run deployment
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1237
[It] should create a deployment from an image  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: running the image gcr.io/google-containers/nginx-slim-amd64:0.20
May 21 07:30:51.148: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig run e2e-test-nginx-deployment --image=gcr.io/google-containers/nginx-slim-amd64:0.20 --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-b92rr'
May 21 07:30:51.368: INFO: stderr: ""
May 21 07:30:51.368: INFO: stdout: "deployment \"e2e-test-nginx-deployment\" created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1242
May 21 07:30:53.400: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-b92rr'
May 21 07:30:56.806: INFO: stderr: ""
[AfterEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:30:56.806: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b92rr" for this suite.
May 21 07:31:02.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:31:03.916: INFO: namespace: e2e-tests-kubectl-b92rr, resource: bindings, ignored listing per whitelist
May 21 07:31:04.351: INFO: namespace e2e-tests-kubectl-b92rr deletion completed in 7.51483503s

• [SLOW TEST:13.329 seconds]
[sig-cli] Kubectl client
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should create a deployment from an image  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:31:04.351: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-gdf92
May 21 07:31:08.525: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-gdf92
STEP: checking the pod's current state and verifying that restartCount is present
May 21 07:31:08.541: INFO: Initial restart count of pod liveness-http is 0
May 21 07:31:32.751: INFO: Restart count of pod e2e-tests-container-probe-gdf92/liveness-http is now 1 (24.210071384s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:31:32.771: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-gdf92" for this suite.
May 21 07:31:38.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:31:40.252: INFO: namespace: e2e-tests-container-probe-gdf92, resource: bindings, ignored listing per whitelist
May 21 07:31:40.298: INFO: namespace e2e-tests-container-probe-gdf92 deletion completed in 7.495889583s

• [SLOW TEST:35.947 seconds]
[k8s.io] Probing container
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  should be restarted with a /healthz http liveness probe  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-api-machinery] Secrets
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:31:40.298: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: creating secret e2e-tests-secrets-g22wj/secret-test-00ac434d-5cc9-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume secrets
May 21 07:31:40.478: INFO: Waiting up to 5m0s for pod "pod-configmaps-00aef1c6-5cc9-11e8-849c-0e182f31d764" in namespace "e2e-tests-secrets-g22wj" to be "success or failure"
May 21 07:31:40.494: INFO: Pod "pod-configmaps-00aef1c6-5cc9-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.947231ms
May 21 07:31:42.510: INFO: Pod "pod-configmaps-00aef1c6-5cc9-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03200638s
May 21 07:31:44.527: INFO: Pod "pod-configmaps-00aef1c6-5cc9-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048281996s
STEP: Saw pod success
May 21 07:31:44.527: INFO: Pod "pod-configmaps-00aef1c6-5cc9-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:31:44.542: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod pod-configmaps-00aef1c6-5cc9-11e8-849c-0e182f31d764 container env-test: <nil>
STEP: delete the pod
May 21 07:31:44.590: INFO: Waiting for pod pod-configmaps-00aef1c6-5cc9-11e8-849c-0e182f31d764 to disappear
May 21 07:31:44.606: INFO: Pod pod-configmaps-00aef1c6-5cc9-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:31:44.606: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-g22wj" for this suite.
May 21 07:31:50.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:31:51.980: INFO: namespace: e2e-tests-secrets-g22wj, resource: bindings, ignored listing per whitelist
May 21 07:31:52.154: INFO: namespace e2e-tests-secrets-g22wj deletion completed in 7.518443797s

• [SLOW TEST:11.855 seconds]
[sig-api-machinery] Secrets
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:30
  should be consumable via the environment  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:31:52.154: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 21 07:31:52.301: INFO: Waiting up to 5m0s for pod "pod-07bc8f05-5cc9-11e8-849c-0e182f31d764" in namespace "e2e-tests-emptydir-g5mm8" to be "success or failure"
May 21 07:31:52.316: INFO: Pod "pod-07bc8f05-5cc9-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 14.89288ms
May 21 07:31:54.333: INFO: Pod "pod-07bc8f05-5cc9-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031341207s
May 21 07:31:56.349: INFO: Pod "pod-07bc8f05-5cc9-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047505041s
STEP: Saw pod success
May 21 07:31:56.349: INFO: Pod "pod-07bc8f05-5cc9-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:31:56.364: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod pod-07bc8f05-5cc9-11e8-849c-0e182f31d764 container test-container: <nil>
STEP: delete the pod
May 21 07:31:56.408: INFO: Waiting for pod pod-07bc8f05-5cc9-11e8-849c-0e182f31d764 to disappear
May 21 07:31:56.423: INFO: Pod pod-07bc8f05-5cc9-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:31:56.423: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-g5mm8" for this suite.
May 21 07:32:02.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:32:03.619: INFO: namespace: e2e-tests-emptydir-g5mm8, resource: bindings, ignored listing per whitelist
May 21 07:32:03.960: INFO: namespace e2e-tests-emptydir-g5mm8 deletion completed in 7.507559331s

• [SLOW TEST:11.806 seconds]
[sig-storage] EmptyDir volumes
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:32:03.960: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create and stop a working application  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: creating all guestbook components
May 21 07:32:04.280: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

May 21 07:32:04.280: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig create -f - --namespace=e2e-tests-kubectl-v55n8'
May 21 07:32:04.635: INFO: stderr: ""
May 21 07:32:04.635: INFO: stdout: "service \"redis-slave\" created\n"
May 21 07:32:04.635: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

May 21 07:32:04.635: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig create -f - --namespace=e2e-tests-kubectl-v55n8'
May 21 07:32:04.929: INFO: stderr: ""
May 21 07:32:04.929: INFO: stdout: "service \"redis-master\" created\n"
May 21 07:32:04.929: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May 21 07:32:04.929: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig create -f - --namespace=e2e-tests-kubectl-v55n8'
May 21 07:32:05.212: INFO: stderr: ""
May 21 07:32:05.212: INFO: stdout: "service \"frontend\" created\n"
May 21 07:32:05.212: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend-amd64:v5
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

May 21 07:32:05.212: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig create -f - --namespace=e2e-tests-kubectl-v55n8'
May 21 07:32:05.499: INFO: stderr: ""
May 21 07:32:05.499: INFO: stdout: "deployment \"frontend\" created\n"
May 21 07:32:05.499: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May 21 07:32:05.499: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig create -f - --namespace=e2e-tests-kubectl-v55n8'
May 21 07:32:05.777: INFO: stderr: ""
May 21 07:32:05.777: INFO: stdout: "deployment \"redis-master\" created\n"
May 21 07:32:05.778: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave-amd64:v2
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

May 21 07:32:05.778: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig create -f - --namespace=e2e-tests-kubectl-v55n8'
May 21 07:32:06.058: INFO: stderr: ""
May 21 07:32:06.058: INFO: stdout: "deployment \"redis-slave\" created\n"
STEP: validating guestbook app
May 21 07:32:06.058: INFO: Waiting for all frontend pods to be Running.
May 21 07:32:26.109: INFO: Waiting for frontend to serve content.
May 21 07:32:26.138: INFO: Trying to add a new entry to the guestbook.
May 21 07:32:26.160: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
May 21 07:32:26.189: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-v55n8'
May 21 07:32:26.370: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 07:32:26.370: INFO: stdout: "service \"redis-slave\" deleted\n"
STEP: using delete to clean up resources
May 21 07:32:26.370: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-v55n8'
May 21 07:32:26.550: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 07:32:26.550: INFO: stdout: "service \"redis-master\" deleted\n"
STEP: using delete to clean up resources
May 21 07:32:26.550: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-v55n8'
May 21 07:32:26.731: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 07:32:26.731: INFO: stdout: "service \"frontend\" deleted\n"
STEP: using delete to clean up resources
May 21 07:32:26.731: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-v55n8'
May 21 07:32:30.132: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 07:32:30.132: INFO: stdout: "deployment \"frontend\" deleted\n"
STEP: using delete to clean up resources
May 21 07:32:30.133: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-v55n8'
May 21 07:32:33.532: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 07:32:33.532: INFO: stdout: "deployment \"redis-master\" deleted\n"
STEP: using delete to clean up resources
May 21 07:32:33.532: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-v55n8'
May 21 07:32:36.948: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 07:32:36.948: INFO: stdout: "deployment \"redis-slave\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:32:36.948: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-v55n8" for this suite.
May 21 07:33:17.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:33:18.384: INFO: namespace: e2e-tests-kubectl-v55n8, resource: bindings, ignored listing per whitelist
May 21 07:33:18.476: INFO: namespace e2e-tests-kubectl-v55n8 deletion completed in 41.497672102s

• [SLOW TEST:74.516 seconds]
[sig-cli] Kubectl client
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should create and stop a working application  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:33:18.476: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 21 07:33:18.635: INFO: Waiting up to 5m0s for pod "pod-3b325ba2-5cc9-11e8-849c-0e182f31d764" in namespace "e2e-tests-emptydir-ggp2l" to be "success or failure"
May 21 07:33:18.651: INFO: Pod "pod-3b325ba2-5cc9-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.313308ms
May 21 07:33:20.667: INFO: Pod "pod-3b325ba2-5cc9-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031435842s
May 21 07:33:22.683: INFO: Pod "pod-3b325ba2-5cc9-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047821355s
STEP: Saw pod success
May 21 07:33:22.683: INFO: Pod "pod-3b325ba2-5cc9-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:33:22.699: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod pod-3b325ba2-5cc9-11e8-849c-0e182f31d764 container test-container: <nil>
STEP: delete the pod
May 21 07:33:22.745: INFO: Waiting for pod pod-3b325ba2-5cc9-11e8-849c-0e182f31d764 to disappear
May 21 07:33:22.760: INFO: Pod pod-3b325ba2-5cc9-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:33:22.760: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ggp2l" for this suite.
May 21 07:33:28.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:33:30.277: INFO: namespace: e2e-tests-emptydir-ggp2l, resource: bindings, ignored listing per whitelist
May 21 07:33:30.293: INFO: namespace e2e-tests-emptydir-ggp2l deletion completed in 7.50363251s

• [SLOW TEST:11.817 seconds]
[sig-storage] EmptyDir volumes
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:33:30.293: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test emptydir 0777 on node default medium
May 21 07:33:30.445: INFO: Waiting up to 5m0s for pod "pod-423c69f9-5cc9-11e8-849c-0e182f31d764" in namespace "e2e-tests-emptydir-hdqn2" to be "success or failure"
May 21 07:33:30.460: INFO: Pod "pod-423c69f9-5cc9-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.07788ms
May 21 07:33:32.476: INFO: Pod "pod-423c69f9-5cc9-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031180012s
May 21 07:33:34.492: INFO: Pod "pod-423c69f9-5cc9-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047512129s
STEP: Saw pod success
May 21 07:33:34.492: INFO: Pod "pod-423c69f9-5cc9-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:33:34.508: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod pod-423c69f9-5cc9-11e8-849c-0e182f31d764 container test-container: <nil>
STEP: delete the pod
May 21 07:33:34.553: INFO: Waiting for pod pod-423c69f9-5cc9-11e8-849c-0e182f31d764 to disappear
May 21 07:33:34.568: INFO: Pod pod-423c69f9-5cc9-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:33:34.569: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hdqn2" for this suite.
May 21 07:33:40.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:33:42.066: INFO: namespace: e2e-tests-emptydir-hdqn2, resource: bindings, ignored listing per whitelist
May 21 07:33:42.112: INFO: namespace e2e-tests-emptydir-hdqn2 deletion completed in 7.514609459s

• [SLOW TEST:11.819 seconds]
[sig-storage] EmptyDir volumes
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] ConfigMap
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:33:42.112: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating configMap with name configmap-test-volume-49491325-5cc9-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume configMaps
May 21 07:33:42.288: INFO: Waiting up to 5m0s for pod "pod-configmaps-494b9aef-5cc9-11e8-849c-0e182f31d764" in namespace "e2e-tests-configmap-87pz2" to be "success or failure"
May 21 07:33:42.303: INFO: Pod "pod-configmaps-494b9aef-5cc9-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 14.996501ms
May 21 07:33:44.321: INFO: Pod "pod-configmaps-494b9aef-5cc9-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032840513s
May 21 07:33:46.337: INFO: Pod "pod-configmaps-494b9aef-5cc9-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048834173s
STEP: Saw pod success
May 21 07:33:46.337: INFO: Pod "pod-configmaps-494b9aef-5cc9-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:33:46.359: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod pod-configmaps-494b9aef-5cc9-11e8-849c-0e182f31d764 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 07:33:46.402: INFO: Waiting for pod pod-configmaps-494b9aef-5cc9-11e8-849c-0e182f31d764 to disappear
May 21 07:33:46.417: INFO: Pod pod-configmaps-494b9aef-5cc9-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:33:46.417: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-87pz2" for this suite.
May 21 07:33:52.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:33:53.284: INFO: namespace: e2e-tests-configmap-87pz2, resource: bindings, ignored listing per whitelist
May 21 07:33:53.969: INFO: namespace e2e-tests-configmap-87pz2 deletion completed in 7.522730283s

• [SLOW TEST:11.857 seconds]
[sig-storage] ConfigMap
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-api-machinery] Downward API
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:33:53.969: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward api env vars
May 21 07:33:54.158: INFO: Waiting up to 5m0s for pod "downward-api-505d6a1f-5cc9-11e8-849c-0e182f31d764" in namespace "e2e-tests-downward-api-pcll2" to be "success or failure"
May 21 07:33:54.174: INFO: Pod "downward-api-505d6a1f-5cc9-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.088829ms
May 21 07:33:56.190: INFO: Pod "downward-api-505d6a1f-5cc9-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031063095s
May 21 07:33:58.206: INFO: Pod "downward-api-505d6a1f-5cc9-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047214032s
May 21 07:34:00.222: INFO: Pod "downward-api-505d6a1f-5cc9-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.063187228s
STEP: Saw pod success
May 21 07:34:00.222: INFO: Pod "downward-api-505d6a1f-5cc9-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:34:00.237: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod downward-api-505d6a1f-5cc9-11e8-849c-0e182f31d764 container dapi-container: <nil>
STEP: delete the pod
May 21 07:34:00.292: INFO: Waiting for pod downward-api-505d6a1f-5cc9-11e8-849c-0e182f31d764 to disappear
May 21 07:34:00.307: INFO: Pod downward-api-505d6a1f-5cc9-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:34:00.307: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pcll2" for this suite.
May 21 07:34:06.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:34:07.567: INFO: namespace: e2e-tests-downward-api-pcll2, resource: bindings, ignored listing per whitelist
May 21 07:34:07.830: INFO: namespace e2e-tests-downward-api-pcll2 deletion completed in 7.493854875s

• [SLOW TEST:13.860 seconds]
[sig-api-machinery] Downward API
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide pod UID as env vars  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Secrets
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:34:07.830: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating secret with name secret-test-5899fd08-5cc9-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume secrets
May 21 07:34:07.983: INFO: Waiting up to 5m0s for pod "pod-secrets-589cbd5c-5cc9-11e8-849c-0e182f31d764" in namespace "e2e-tests-secrets-rjr24" to be "success or failure"
May 21 07:34:07.998: INFO: Pod "pod-secrets-589cbd5c-5cc9-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 14.853928ms
May 21 07:34:10.014: INFO: Pod "pod-secrets-589cbd5c-5cc9-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031111898s
May 21 07:34:12.030: INFO: Pod "pod-secrets-589cbd5c-5cc9-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046878518s
STEP: Saw pod success
May 21 07:34:12.030: INFO: Pod "pod-secrets-589cbd5c-5cc9-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:34:12.046: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod pod-secrets-589cbd5c-5cc9-11e8-849c-0e182f31d764 container secret-volume-test: <nil>
STEP: delete the pod
May 21 07:34:12.088: INFO: Waiting for pod pod-secrets-589cbd5c-5cc9-11e8-849c-0e182f31d764 to disappear
May 21 07:34:12.104: INFO: Pod pod-secrets-589cbd5c-5cc9-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Secrets
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:34:12.104: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-rjr24" for this suite.
May 21 07:34:18.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:34:19.590: INFO: namespace: e2e-tests-secrets-rjr24, resource: bindings, ignored listing per whitelist
May 21 07:34:19.635: INFO: namespace e2e-tests-secrets-rjr24 deletion completed in 7.501989663s

• [SLOW TEST:11.805 seconds]
[sig-storage] Secrets
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:34:19.635: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating configMap with name projected-configmap-test-volume-5fa41834-5cc9-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume configMaps
May 21 07:34:19.795: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5fa6b025-5cc9-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-qmd6j" to be "success or failure"
May 21 07:34:19.810: INFO: Pod "pod-projected-configmaps-5fa6b025-5cc9-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.564793ms
May 21 07:34:21.827: INFO: Pod "pod-projected-configmaps-5fa6b025-5cc9-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031916551s
May 21 07:34:23.843: INFO: Pod "pod-projected-configmaps-5fa6b025-5cc9-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047991752s
STEP: Saw pod success
May 21 07:34:23.843: INFO: Pod "pod-projected-configmaps-5fa6b025-5cc9-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:34:23.859: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod pod-projected-configmaps-5fa6b025-5cc9-11e8-849c-0e182f31d764 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 07:34:23.930: INFO: Waiting for pod pod-projected-configmaps-5fa6b025-5cc9-11e8-849c-0e182f31d764 to disappear
May 21 07:34:23.946: INFO: Pod pod-projected-configmaps-5fa6b025-5cc9-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:34:23.946: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qmd6j" for this suite.
May 21 07:34:30.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:34:31.467: INFO: namespace: e2e-tests-projected-qmd6j, resource: bindings, ignored listing per whitelist
May 21 07:34:31.467: INFO: namespace e2e-tests-projected-qmd6j deletion completed in 7.491424673s

• [SLOW TEST:11.832 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:34:31.468: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
May 21 07:34:31.608: INFO: Couldn't get node TTL annotation (using default value of 0): No TTL annotation found on the node
STEP: Creating projection with configMap that has name projected-configmap-test-upd-66b474c7-5cc9-11e8-849c-0e182f31d764
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-66b474c7-5cc9-11e8-849c-0e182f31d764
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:35:52.627: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j7xg4" for this suite.
May 21 07:36:14.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:36:15.714: INFO: namespace: e2e-tests-projected-j7xg4, resource: bindings, ignored listing per whitelist
May 21 07:36:16.169: INFO: namespace e2e-tests-projected-j7xg4 deletion completed in 23.512208021s

• [SLOW TEST:104.701 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  updates should be reflected in volume [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a docker exec liveness probe with timeout  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:36:16.169: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a docker exec liveness probe with timeout  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
May 21 07:36:16.251: INFO: The default exec handler, dockertools.NativeExecHandler, does not support timeouts due to a limitation in the Docker Remote API
[AfterEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:36:16.252: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-llhtv" for this suite.
May 21 07:36:22.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:36:23.151: INFO: namespace: e2e-tests-container-probe-llhtv, resource: bindings, ignored listing per whitelist
May 21 07:36:23.826: INFO: namespace e2e-tests-container-probe-llhtv deletion completed in 7.541956215s

S [SKIPPING] [7.657 seconds]
[k8s.io] Probing container
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  should be restarted with a docker exec liveness probe with timeout  [Conformance] [It]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648

  May 21 07:36:16.251: The default exec handler, dockertools.NativeExecHandler, does not support timeouts due to a limitation in the Docker Remote API

  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:290
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count  [Slow] [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:36:23.827: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count  [Slow] [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-pgbvl
May 21 07:36:28.100: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-pgbvl
STEP: checking the pod's current state and verifying that restartCount is present
May 21 07:36:28.115: INFO: Initial restart count of pod liveness-http is 0
May 21 07:36:44.257: INFO: Restart count of pod e2e-tests-container-probe-pgbvl/liveness-http is now 1 (16.141925387s elapsed)
May 21 07:37:02.401: INFO: Restart count of pod e2e-tests-container-probe-pgbvl/liveness-http is now 2 (34.285531282s elapsed)
May 21 07:37:22.564: INFO: Restart count of pod e2e-tests-container-probe-pgbvl/liveness-http is now 3 (54.448935341s elapsed)
May 21 07:37:42.733: INFO: Restart count of pod e2e-tests-container-probe-pgbvl/liveness-http is now 4 (1m14.618090416s elapsed)
May 21 07:38:59.345: INFO: Restart count of pod e2e-tests-container-probe-pgbvl/liveness-http is now 5 (2m31.230097156s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:38:59.366: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-pgbvl" for this suite.
May 21 07:39:05.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:39:06.418: INFO: namespace: e2e-tests-container-probe-pgbvl, resource: bindings, ignored listing per whitelist
May 21 07:39:06.891: INFO: namespace e2e-tests-container-probe-pgbvl deletion completed in 7.495801377s

• [SLOW TEST:163.064 seconds]
[k8s.io] Probing container
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  should have monotonically increasing restart count  [Slow] [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:39:06.891: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's memory request  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward API volume plugin
May 21 07:39:07.028: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0adb626f-5cca-11e8-849c-0e182f31d764" in namespace "e2e-tests-downward-api-sds5m" to be "success or failure"
May 21 07:39:07.043: INFO: Pod "downwardapi-volume-0adb626f-5cca-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.064487ms
May 21 07:39:09.060: INFO: Pod "downwardapi-volume-0adb626f-5cca-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031238616s
May 21 07:39:11.076: INFO: Pod "downwardapi-volume-0adb626f-5cca-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047212335s
STEP: Saw pod success
May 21 07:39:11.076: INFO: Pod "downwardapi-volume-0adb626f-5cca-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:39:11.091: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod downwardapi-volume-0adb626f-5cca-11e8-849c-0e182f31d764 container client-container: <nil>
STEP: delete the pod
May 21 07:39:11.138: INFO: Waiting for pod downwardapi-volume-0adb626f-5cca-11e8-849c-0e182f31d764 to disappear
May 21 07:39:11.153: INFO: Pod downwardapi-volume-0adb626f-5cca-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:39:11.153: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sds5m" for this suite.
May 21 07:39:17.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:39:18.219: INFO: namespace: e2e-tests-downward-api-sds5m, resource: bindings, ignored listing per whitelist
May 21 07:39:18.684: INFO: namespace e2e-tests-downward-api-sds5m deletion completed in 7.500837934s

• [SLOW TEST:11.793 seconds]
[sig-storage] Downward API volume
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's memory request  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:39:18.684: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check is all data is printed  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
May 21 07:39:18.830: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig version'
May 21 07:39:19.029: INFO: stderr: ""
May 21 07:39:19.029: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"9+\", GitVersion:\"v1.9.8-beta.0.40+c138b851781560\", GitCommit:\"c138b85178156011dc934c2c9f4837476876fb07\", GitTreeState:\"clean\", BuildDate:\"2018-05-21T07:00:21Z\", GoVersion:\"go1.9.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"9\", GitVersion:\"v1.9.1+a0ce1bc657\", GitCommit:\"a0ce1bc\", GitTreeState:\"clean\", BuildDate:\"2018-05-17T01:22:38Z\", GoVersion:\"go1.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:39:19.029: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-t6bxt" for this suite.
May 21 07:39:25.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:39:25.804: INFO: namespace: e2e-tests-kubectl-t6bxt, resource: bindings, ignored listing per whitelist
May 21 07:39:26.557: INFO: namespace e2e-tests-kubectl-t6bxt deletion completed in 7.498717564s

• [SLOW TEST:7.873 seconds]
[sig-cli] Kubectl client
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should check is all data is printed  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:39:26.557: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if v1 is in available api versions  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: validating api versions
May 21 07:39:26.669: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig api-versions'
May 21 07:39:26.841: INFO: stderr: ""
May 21 07:39:26.841: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1beta1\napps.openshift.io/v1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nauthorization.openshift.io/v1\nautoscaling/v1\nautoscaling/v2beta1\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\nbuild.openshift.io/v1\ncertificates.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nimage.openshift.io/v1\nnetwork.openshift.io/v1\nnetworking.k8s.io/v1\noauth.openshift.io/v1\npolicy/v1beta1\nproject.openshift.io/v1\nquota.openshift.io/v1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nroute.openshift.io/v1\nsecurity.openshift.io/v1\nsettings.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\ntemplate.openshift.io/v1\nuser.openshift.io/v1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:39:26.842: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-h2ls2" for this suite.
May 21 07:39:32.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:39:34.347: INFO: namespace: e2e-tests-kubectl-h2ls2, resource: bindings, ignored listing per whitelist
May 21 07:39:34.391: INFO: namespace e2e-tests-kubectl-h2ls2 deletion completed in 7.520313031s

• [SLOW TEST:7.834 seconds]
[sig-cli] Kubectl client
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should check if v1 is in available api versions  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:39:34.391: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
May 21 07:39:34.503: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig version --client'
May 21 07:39:34.595: INFO: stderr: ""
May 21 07:39:34.595: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"9+\", GitVersion:\"v1.9.8-beta.0.40+c138b851781560\", GitCommit:\"c138b85178156011dc934c2c9f4837476876fb07\", GitTreeState:\"clean\", BuildDate:\"2018-05-21T07:00:21Z\", GoVersion:\"go1.9.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
May 21 07:39:34.610: INFO: Not supported for server versions before "1.9.8-beta.0.40+c138b851781560"
[AfterEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:39:34.611: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kw5bd" for this suite.
May 21 07:39:40.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:39:41.512: INFO: namespace: e2e-tests-kubectl-kw5bd, resource: bindings, ignored listing per whitelist
May 21 07:39:42.140: INFO: namespace e2e-tests-kubectl-kw5bd deletion completed in 7.499371324s

S [SKIPPING] [7.749 seconds]
[sig-cli] Kubectl client
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should check if kubectl describe prints relevant information for rc and pods  [Conformance] [It]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648

    May 21 07:39:34.610: Not supported for server versions before "1.9.8-beta.0.40+c138b851781560"

    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:290
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] Docker Containers
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:39:42.140: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test override all
May 21 07:39:42.261: INFO: Waiting up to 5m0s for pod "client-containers-1fdb7480-5cca-11e8-849c-0e182f31d764" in namespace "e2e-tests-containers-57dwp" to be "success or failure"
May 21 07:39:42.276: INFO: Pod "client-containers-1fdb7480-5cca-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.208171ms
May 21 07:39:44.292: INFO: Pod "client-containers-1fdb7480-5cca-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031304488s
May 21 07:39:46.309: INFO: Pod "client-containers-1fdb7480-5cca-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04740934s
STEP: Saw pod success
May 21 07:39:46.309: INFO: Pod "client-containers-1fdb7480-5cca-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:39:46.324: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod client-containers-1fdb7480-5cca-11e8-849c-0e182f31d764 container test-container: <nil>
STEP: delete the pod
May 21 07:39:46.369: INFO: Waiting for pod client-containers-1fdb7480-5cca-11e8-849c-0e182f31d764 to disappear
May 21 07:39:46.385: INFO: Pod client-containers-1fdb7480-5cca-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:39:46.385: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-57dwp" for this suite.
May 21 07:39:52.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:39:53.944: INFO: namespace: e2e-tests-containers-57dwp, resource: bindings, ignored listing per whitelist
May 21 07:39:53.944: INFO: namespace e2e-tests-containers-57dwp deletion completed in 7.529368891s

• [SLOW TEST:11.803 seconds]
[k8s.io] Docker Containers
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  should be able to override the image's default command and arguments  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:39:53.944: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's cpu limit  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward API volume plugin
May 21 07:39:55.162: INFO: Waiting up to 5m0s for pod "downwardapi-volume-26ef4770-5cca-11e8-849c-0e182f31d764" in namespace "e2e-tests-downward-api-hh5dj" to be "success or failure"
May 21 07:39:55.177: INFO: Pod "downwardapi-volume-26ef4770-5cca-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.659998ms
May 21 07:39:57.194: INFO: Pod "downwardapi-volume-26ef4770-5cca-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032011952s
May 21 07:39:59.210: INFO: Pod "downwardapi-volume-26ef4770-5cca-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047973806s
STEP: Saw pod success
May 21 07:39:59.210: INFO: Pod "downwardapi-volume-26ef4770-5cca-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:39:59.225: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod downwardapi-volume-26ef4770-5cca-11e8-849c-0e182f31d764 container client-container: <nil>
STEP: delete the pod
May 21 07:39:59.273: INFO: Waiting for pod downwardapi-volume-26ef4770-5cca-11e8-849c-0e182f31d764 to disappear
May 21 07:39:59.287: INFO: Pod downwardapi-volume-26ef4770-5cca-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:39:59.287: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hh5dj" for this suite.
May 21 07:40:05.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:40:06.769: INFO: namespace: e2e-tests-downward-api-hh5dj, resource: bindings, ignored listing per whitelist
May 21 07:40:06.815: INFO: namespace e2e-tests-downward-api-hh5dj deletion completed in 7.498429049s

• [SLOW TEST:12.871 seconds]
[sig-storage] Downward API volume
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's cpu limit  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:40:06.815: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl replace
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1386
[It] should update a single-container pod's image  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: running the image gcr.io/google-containers/nginx-slim-amd64:0.20
May 21 07:40:06.904: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig run e2e-test-nginx-pod --generator=run-pod/v1 --image=gcr.io/google-containers/nginx-slim-amd64:0.20 --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-r72jg'
May 21 07:40:07.131: INFO: stderr: ""
May 21 07:40:07.131: INFO: stdout: "pod \"e2e-test-nginx-pod\" created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
May 21 07:40:12.182: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-r72jg -o json'
May 21 07:40:12.353: INFO: stderr: ""
May 21 07:40:12.353: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"openshift.io/scc\": \"privileged\"\n        },\n        \"creationTimestamp\": \"2018-05-21T07:40:07Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-r72jg\",\n        \"resourceVersion\": \"12609\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-r72jg/pods/e2e-test-nginx-pod\",\n        \"uid\": \"2ea74089-5cca-11e8-bb49-42010a8e0002\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"gcr.io/google-containers/nginx-slim-amd64:0.20\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-l2bx8\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"imagePullSecrets\": [\n            {\n                \"name\": \"default-dockercfg-pp9cd\"\n            }\n        ],\n        \"nodeName\": \"prtest-7d230a7-103-ig-n-3zcc\",\n        \"nodeSelector\": {\n            \"role\": \"app\"\n        },\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"volumes\": [\n            {\n                \"name\": \"default-token-l2bx8\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-l2bx8\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-05-21T07:40:07Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-05-21T07:40:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-05-21T07:40:07Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://a8b94a114c15c2184d47f672bfae8d2c203a75fef9e24f3829a28a00d94dca19\",\n                \"image\": \"gcr.io/google-containers/nginx-slim-amd64:0.20\",\n                \"imageID\": \"docker-pullable://gcr.io/google-containers/nginx-slim-amd64@sha256:6654db6d4028756062edac466454ee5c9cf9b20ef79e35a81e3c840031eb1e2b\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-05-21T07:40:09Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.142.0.5\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.16.4.41\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-05-21T07:40:07Z\"\n    }\n}\n"
STEP: replace the image in the pod
May 21 07:40:12.353: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig replace -f - --namespace=e2e-tests-kubectl-r72jg'
May 21 07:40:12.645: INFO: stderr: ""
May 21 07:40:12.645: INFO: stdout: "pod \"e2e-test-nginx-pod\" replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image busybox
[AfterEach] [k8s.io] Kubectl replace
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1391
May 21 07:40:12.660: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-r72jg'
May 21 07:40:12.896: INFO: stderr: ""
May 21 07:40:12.896: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:40:12.896: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-r72jg" for this suite.
May 21 07:40:34.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:40:36.046: INFO: namespace: e2e-tests-kubectl-r72jg, resource: bindings, ignored listing per whitelist
May 21 07:40:36.391: INFO: namespace e2e-tests-kubectl-r72jg deletion completed in 23.466558537s

• [SLOW TEST:29.576 seconds]
[sig-cli] Kubectl client
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should update a single-container pod's image  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:40:36.391: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should scale a replication controller  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: creating a replication controller
May 21 07:40:36.498: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig create -f - --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:40:37.417: INFO: stderr: ""
May 21 07:40:37.417: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 07:40:37.417: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:40:37.590: INFO: stderr: ""
May 21 07:40:37.590: INFO: stdout: "update-demo-nautilus-q5wkq update-demo-nautilus-s4srm "
May 21 07:40:37.590: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-nautilus-q5wkq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:40:37.759: INFO: stderr: ""
May 21 07:40:37.759: INFO: stdout: ""
May 21 07:40:37.759: INFO: update-demo-nautilus-q5wkq is created but not running
May 21 07:40:42.759: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:40:42.929: INFO: stderr: ""
May 21 07:40:42.929: INFO: stdout: "update-demo-nautilus-q5wkq update-demo-nautilus-s4srm "
May 21 07:40:42.929: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-nautilus-q5wkq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:40:43.096: INFO: stderr: ""
May 21 07:40:43.096: INFO: stdout: "true"
May 21 07:40:43.096: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-nautilus-q5wkq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:40:43.263: INFO: stderr: ""
May 21 07:40:43.263: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 21 07:40:43.263: INFO: validating pod update-demo-nautilus-q5wkq
May 21 07:40:43.283: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 07:40:43.283: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 07:40:43.283: INFO: update-demo-nautilus-q5wkq is verified up and running
May 21 07:40:43.283: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-nautilus-s4srm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:40:43.453: INFO: stderr: ""
May 21 07:40:43.453: INFO: stdout: "true"
May 21 07:40:43.453: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-nautilus-s4srm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:40:43.623: INFO: stderr: ""
May 21 07:40:43.623: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 21 07:40:43.623: INFO: validating pod update-demo-nautilus-s4srm
May 21 07:40:43.642: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 07:40:43.642: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 07:40:43.642: INFO: update-demo-nautilus-s4srm is verified up and running
STEP: scaling down the replication controller
May 21 07:40:43.642: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:40:43.933: INFO: stderr: ""
May 21 07:40:43.933: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 07:40:43.933: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:40:44.102: INFO: stderr: ""
May 21 07:40:44.102: INFO: stdout: "update-demo-nautilus-q5wkq update-demo-nautilus-s4srm "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 21 07:40:49.103: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:40:49.274: INFO: stderr: ""
May 21 07:40:49.274: INFO: stdout: "update-demo-nautilus-q5wkq update-demo-nautilus-s4srm "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 21 07:40:54.274: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:40:54.445: INFO: stderr: ""
May 21 07:40:54.445: INFO: stdout: "update-demo-nautilus-q5wkq "
May 21 07:40:54.445: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-nautilus-q5wkq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:40:54.624: INFO: stderr: ""
May 21 07:40:54.624: INFO: stdout: "true"
May 21 07:40:54.624: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-nautilus-q5wkq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:40:54.792: INFO: stderr: ""
May 21 07:40:54.792: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 21 07:40:54.792: INFO: validating pod update-demo-nautilus-q5wkq
May 21 07:40:54.811: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 07:40:54.811: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 07:40:54.811: INFO: update-demo-nautilus-q5wkq is verified up and running
STEP: scaling up the replication controller
May 21 07:40:54.811: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:40:55.101: INFO: stderr: ""
May 21 07:40:55.101: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 07:40:55.101: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:40:55.272: INFO: stderr: ""
May 21 07:40:55.272: INFO: stdout: "update-demo-nautilus-dwkw2 update-demo-nautilus-q5wkq "
May 21 07:40:55.272: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-nautilus-dwkw2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:40:55.443: INFO: stderr: ""
May 21 07:40:55.444: INFO: stdout: ""
May 21 07:40:55.444: INFO: update-demo-nautilus-dwkw2 is created but not running
May 21 07:41:00.444: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:41:00.615: INFO: stderr: ""
May 21 07:41:00.615: INFO: stdout: "update-demo-nautilus-dwkw2 update-demo-nautilus-q5wkq "
May 21 07:41:00.615: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-nautilus-dwkw2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:41:00.785: INFO: stderr: ""
May 21 07:41:00.785: INFO: stdout: "true"
May 21 07:41:00.785: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-nautilus-dwkw2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:41:00.955: INFO: stderr: ""
May 21 07:41:00.955: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 21 07:41:00.955: INFO: validating pod update-demo-nautilus-dwkw2
May 21 07:41:00.975: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 07:41:00.975: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 07:41:00.975: INFO: update-demo-nautilus-dwkw2 is verified up and running
May 21 07:41:00.975: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-nautilus-q5wkq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:41:01.150: INFO: stderr: ""
May 21 07:41:01.150: INFO: stdout: "true"
May 21 07:41:01.150: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods update-demo-nautilus-q5wkq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:41:01.320: INFO: stderr: ""
May 21 07:41:01.320: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 21 07:41:01.320: INFO: validating pod update-demo-nautilus-q5wkq
May 21 07:41:01.337: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 07:41:01.337: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 07:41:01.337: INFO: update-demo-nautilus-q5wkq is verified up and running
STEP: using delete to clean up resources
May 21 07:41:01.337: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:41:01.654: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 07:41:01.654: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" deleted\n"
May 21 07:41:01.654: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-d6vkc'
May 21 07:41:01.843: INFO: stderr: "No resources found.\n"
May 21 07:41:01.843: INFO: stdout: ""
May 21 07:41:01.843: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig get pods -l name=update-demo --namespace=e2e-tests-kubectl-d6vkc -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 21 07:41:02.019: INFO: stderr: ""
May 21 07:41:02.019: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:41:02.019: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d6vkc" for this suite.
May 21 07:41:24.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:41:24.677: INFO: namespace: e2e-tests-kubectl-d6vkc, resource: bindings, ignored listing per whitelist
May 21 07:41:25.551: INFO: namespace e2e-tests-kubectl-d6vkc deletion completed in 23.499328678s

• [SLOW TEST:49.160 seconds]
[sig-cli] Kubectl client
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should scale a replication controller  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-storage] Downward API volume 
  should provide podname only  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:41:25.551: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide podname only  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward API volume plugin
May 21 07:41:25.688: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5d80f41b-5cca-11e8-849c-0e182f31d764" in namespace "e2e-tests-downward-api-pdrp6" to be "success or failure"
May 21 07:41:25.704: INFO: Pod "downwardapi-volume-5d80f41b-5cca-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.779506ms
May 21 07:41:27.720: INFO: Pod "downwardapi-volume-5d80f41b-5cca-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031683834s
May 21 07:41:29.736: INFO: Pod "downwardapi-volume-5d80f41b-5cca-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047741937s
STEP: Saw pod success
May 21 07:41:29.736: INFO: Pod "downwardapi-volume-5d80f41b-5cca-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:41:29.752: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod downwardapi-volume-5d80f41b-5cca-11e8-849c-0e182f31d764 container client-container: <nil>
STEP: delete the pod
May 21 07:41:29.796: INFO: Waiting for pod downwardapi-volume-5d80f41b-5cca-11e8-849c-0e182f31d764 to disappear
May 21 07:41:29.811: INFO: Pod downwardapi-volume-5d80f41b-5cca-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:41:29.811: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pdrp6" for this suite.
May 21 07:41:35.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:41:37.121: INFO: namespace: e2e-tests-downward-api-pdrp6, resource: bindings, ignored listing per whitelist
May 21 07:41:37.336: INFO: namespace e2e-tests-downward-api-pdrp6 deletion completed in 7.495951872s

• [SLOW TEST:11.785 seconds]
[sig-storage] Downward API volume
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide podname only  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd)  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] Docker Containers
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:41:37.336: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd)  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test override arguments
May 21 07:41:37.471: INFO: Waiting up to 5m0s for pod "client-containers-6487347d-5cca-11e8-849c-0e182f31d764" in namespace "e2e-tests-containers-tk86h" to be "success or failure"
May 21 07:41:37.486: INFO: Pod "client-containers-6487347d-5cca-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 14.818418ms
May 21 07:41:39.503: INFO: Pod "client-containers-6487347d-5cca-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031103113s
May 21 07:41:41.518: INFO: Pod "client-containers-6487347d-5cca-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04665141s
STEP: Saw pod success
May 21 07:41:41.518: INFO: Pod "client-containers-6487347d-5cca-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:41:41.533: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod client-containers-6487347d-5cca-11e8-849c-0e182f31d764 container test-container: <nil>
STEP: delete the pod
May 21 07:41:41.577: INFO: Waiting for pod client-containers-6487347d-5cca-11e8-849c-0e182f31d764 to disappear
May 21 07:41:41.592: INFO: Pod client-containers-6487347d-5cca-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:41:41.592: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-tk86h" for this suite.
May 21 07:41:47.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:41:48.378: INFO: namespace: e2e-tests-containers-tk86h, resource: bindings, ignored listing per whitelist
May 21 07:41:49.131: INFO: namespace e2e-tests-containers-tk86h deletion completed in 7.509281132s

• [SLOW TEST:11.795 seconds]
[k8s.io] Docker Containers
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  should be able to override the image's default arguments (docker cmd)  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-network] Networking
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:41:49.131: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-wq9c8
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 21 07:41:49.206: INFO: Waiting up to 10m0s for all (but 1) nodes to be schedulable
STEP: Creating test pods
May 21 07:42:11.551: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.16.6.47:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-wq9c8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:42:11.551: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
May 21 07:42:11.869: INFO: Found all expected endpoints: [netserver-0]
May 21 07:42:11.885: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.16.2.42:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-wq9c8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:42:11.885: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
May 21 07:42:12.076: INFO: Found all expected endpoints: [netserver-1]
May 21 07:42:12.092: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.16.4.43:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-wq9c8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:42:12.092: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
May 21 07:42:12.284: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:42:12.284: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-wq9c8" for this suite.
May 21 07:42:34.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:42:35.631: INFO: namespace: e2e-tests-pod-network-test-wq9c8, resource: bindings, ignored listing per whitelist
May 21 07:42:35.834: INFO: namespace e2e-tests-pod-network-test-wq9c8 deletion completed in 23.520716192s

• [SLOW TEST:46.703 seconds]
[sig-network] Networking
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:42:35.834: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test emptydir volume type on node default medium
May 21 07:42:36.256: INFO: Waiting up to 5m0s for pod "pod-8788fe97-5cca-11e8-849c-0e182f31d764" in namespace "e2e-tests-emptydir-2xnbk" to be "success or failure"
May 21 07:42:36.278: INFO: Pod "pod-8788fe97-5cca-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 22.261942ms
May 21 07:42:38.295: INFO: Pod "pod-8788fe97-5cca-11e8-849c-0e182f31d764": Phase="Running", Reason="", readiness=true. Elapsed: 2.038878173s
May 21 07:42:40.311: INFO: Pod "pod-8788fe97-5cca-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05531497s
STEP: Saw pod success
May 21 07:42:40.312: INFO: Pod "pod-8788fe97-5cca-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:42:40.328: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod pod-8788fe97-5cca-11e8-849c-0e182f31d764 container test-container: <nil>
STEP: delete the pod
May 21 07:42:40.378: INFO: Waiting for pod pod-8788fe97-5cca-11e8-849c-0e182f31d764 to disappear
May 21 07:42:40.393: INFO: Pod pod-8788fe97-5cca-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:42:40.393: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2xnbk" for this suite.
May 21 07:42:46.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:42:47.727: INFO: namespace: e2e-tests-emptydir-2xnbk, resource: bindings, ignored listing per whitelist
May 21 07:42:47.945: INFO: namespace e2e-tests-emptydir-2xnbk deletion completed in 7.521724342s

• [SLOW TEST:12.111 seconds]
[sig-storage] EmptyDir volumes
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] ConfigMap
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:42:47.945: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating configMap with name configmap-test-volume-map-8ea3287d-5cca-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume configMaps
May 21 07:42:48.139: INFO: Waiting up to 5m0s for pod "pod-configmaps-8ea5c31e-5cca-11e8-849c-0e182f31d764" in namespace "e2e-tests-configmap-vp5q2" to be "success or failure"
May 21 07:42:48.156: INFO: Pod "pod-configmaps-8ea5c31e-5cca-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 17.364519ms
May 21 07:42:50.173: INFO: Pod "pod-configmaps-8ea5c31e-5cca-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033691031s
May 21 07:42:52.189: INFO: Pod "pod-configmaps-8ea5c31e-5cca-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049877719s
STEP: Saw pod success
May 21 07:42:52.189: INFO: Pod "pod-configmaps-8ea5c31e-5cca-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:42:52.205: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod pod-configmaps-8ea5c31e-5cca-11e8-849c-0e182f31d764 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 07:42:52.251: INFO: Waiting for pod pod-configmaps-8ea5c31e-5cca-11e8-849c-0e182f31d764 to disappear
May 21 07:42:52.267: INFO: Pod pod-configmaps-8ea5c31e-5cca-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:42:52.267: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vp5q2" for this suite.
May 21 07:42:58.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:42:58.950: INFO: namespace: e2e-tests-configmap-vp5q2, resource: bindings, ignored listing per whitelist
May 21 07:42:59.784: INFO: namespace e2e-tests-configmap-vp5q2 deletion completed in 7.487509628s

• [SLOW TEST:11.839 seconds]
[sig-storage] ConfigMap
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] HostPath
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:42:59.785: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test hostPath mode
May 21 07:42:59.939: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-ms9b6" to be "success or failure"
May 21 07:42:59.954: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 15.092991ms
May 21 07:43:01.970: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031035323s
May 21 07:43:03.986: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047436842s
STEP: Saw pod success
May 21 07:43:03.987: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
May 21 07:43:04.002: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
May 21 07:43:04.048: INFO: Waiting for pod pod-host-path-test to disappear
May 21 07:43:04.064: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:43:04.064: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-ms9b6" for this suite.
May 21 07:43:10.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:43:11.150: INFO: namespace: e2e-tests-hostpath-ms9b6, resource: bindings, ignored listing per whitelist
May 21 07:43:11.603: INFO: namespace e2e-tests-hostpath-ms9b6 deletion completed in 7.510219594s

• [SLOW TEST:11.819 seconds]
[sig-storage] HostPath
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] ConfigMap
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:43:11.604: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
May 21 07:43:11.790: INFO: Couldn't get node TTL annotation (using default value of 0): No TTL annotation found on the node
STEP: Creating configMap with name configmap-test-upd-9cc1f69c-5cca-11e8-849c-0e182f31d764
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-9cc1f69c-5cca-11e8-849c-0e182f31d764
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:44:34.820: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-44sx5" for this suite.
May 21 07:44:56.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:44:57.880: INFO: namespace: e2e-tests-configmap-44sx5, resource: bindings, ignored listing per whitelist
May 21 07:44:58.363: INFO: namespace e2e-tests-configmap-44sx5 deletion completed in 23.514067857s

• [SLOW TEST:106.760 seconds]
[sig-storage] ConfigMap
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] version v1
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:44:58.363: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] version v1
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:68
[It] should proxy through a service and a pod  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-6br87 in namespace e2e-tests-proxy-wq6n8
I0521 07:44:58.544903   24333 runners.go:178] Created replication controller with name: proxy-service-6br87, namespace: e2e-tests-proxy-wq6n8, replica count: 1
I0521 07:44:59.595413   24333 runners.go:178] proxy-service-6br87 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0521 07:45:00.595686   24333 runners.go:178] proxy-service-6br87 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0521 07:45:01.595943   24333 runners.go:178] proxy-service-6br87 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 07:45:02.596204   24333 runners.go:178] proxy-service-6br87 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 07:45:03.596487   24333 runners.go:178] proxy-service-6br87 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 07:45:04.596752   24333 runners.go:178] proxy-service-6br87 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 07:45:05.597018   24333 runners.go:178] proxy-service-6br87 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 07:45:06.597259   24333 runners.go:178] proxy-service-6br87 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 21 07:45:06.612: INFO: setup took 8.152510358s, starting test cases
STEP: running 34 cases, 20 attempts per case, 680 total attempts
May 21 07:45:06.634: INFO: (0) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/: bar (200; 21.694396ms)
May 21 07:45:06.635: INFO: (0) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:80/: foo (200; 21.890299ms)
May 21 07:45:06.635: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/proxy/: foo (200; 22.238544ms)
May 21 07:45:06.635: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/proxy/: bar (200; 22.477335ms)
May 21 07:45:06.636: INFO: (0) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/: bar (200; 22.96095ms)
May 21 07:45:06.648: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/rewri... (200; 35.253127ms)
May 21 07:45:06.648: INFO: (0) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/: foo (200; 34.971762ms)
May 21 07:45:06.648: INFO: (0) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/: foo (200; 35.111264ms)
May 21 07:45:06.648: INFO: (0) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/rewri... (200; 35.053296ms)
May 21 07:45:06.651: INFO: (0) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:443/: tls baz (200; 38.81712ms)
May 21 07:45:06.670: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/proxy/: tls baz (200; 56.797218ms)
May 21 07:45:06.671: INFO: (0) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/: tls baz (200; 58.035375ms)
May 21 07:45:06.671: INFO: (0) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/: foo (200; 57.864687ms)
May 21 07:45:06.671: INFO: (0) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/: bar (200; 58.336541ms)
May 21 07:45:06.674: INFO: (0) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/... (200; 61.1285ms)
May 21 07:45:06.675: INFO: (0) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/: bar (200; 62.559915ms)
May 21 07:45:06.676: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/... (200; 63.29465ms)
May 21 07:45:06.676: INFO: (0) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/: foo (200; 63.512125ms)
May 21 07:45:06.679: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/proxy/: bar (200; 66.515046ms)
May 21 07:45:06.683: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:460/proxy/: tls baz (200; 70.313517ms)
May 21 07:45:06.683: INFO: (0) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:81/: bar (200; 70.086113ms)
May 21 07:45:06.683: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/rewriteme"... (200; 70.133825ms)
May 21 07:45:06.683: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/proxy/: foo (200; 70.076295ms)
May 21 07:45:06.683: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/proxy/: foo (200; 70.104197ms)
May 21 07:45:06.683: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/proxy/: foo (200; 70.344048ms)
May 21 07:45:06.683: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/proxy/: bar (200; 70.081063ms)
May 21 07:45:06.683: INFO: (0) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:80/: foo (200; 70.316086ms)
May 21 07:45:06.683: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/proxy/: bar (200; 70.093642ms)
May 21 07:45:06.683: INFO: (0) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:81/: bar (200; 70.319296ms)
May 21 07:45:06.684: INFO: (0) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/: tls qux (200; 71.327196ms)
May 21 07:45:06.684: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:462/proxy/: tls qux (200; 71.215171ms)
May 21 07:45:06.684: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/proxy/: tls qux (200; 71.531952ms)
May 21 07:45:06.685: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/... (200; 72.164553ms)
May 21 07:45:06.688: INFO: (0) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:444/: tls qux (200; 74.877565ms)
May 21 07:45:06.708: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/proxy/: foo (200; 20.346061ms)
May 21 07:45:06.709: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/proxy/: tls qux (200; 20.250919ms)
May 21 07:45:06.716: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/proxy/: foo (200; 27.999878ms)
May 21 07:45:06.717: INFO: (1) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/... (200; 28.440199ms)
May 21 07:45:06.717: INFO: (1) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:80/: foo (200; 28.597189ms)
May 21 07:45:06.717: INFO: (1) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:81/: bar (200; 28.608003ms)
May 21 07:45:06.717: INFO: (1) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/: bar (200; 29.113724ms)
May 21 07:45:06.717: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/proxy/: foo (200; 29.083048ms)
May 21 07:45:06.717: INFO: (1) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/: tls qux (200; 28.850281ms)
May 21 07:45:06.718: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:460/proxy/: tls baz (200; 29.596197ms)
May 21 07:45:06.718: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/proxy/: bar (200; 29.284434ms)
May 21 07:45:06.718: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/... (200; 29.722953ms)
May 21 07:45:06.718: INFO: (1) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:444/: tls qux (200; 29.863497ms)
May 21 07:45:06.718: INFO: (1) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/: bar (200; 29.996622ms)
May 21 07:45:06.718: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/proxy/: bar (200; 29.909917ms)
May 21 07:45:06.718: INFO: (1) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/: foo (200; 30.270113ms)
May 21 07:45:06.722: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/proxy/: foo (200; 34.173755ms)
May 21 07:45:06.722: INFO: (1) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/: foo (200; 33.653832ms)
May 21 07:45:06.724: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:462/proxy/: tls qux (200; 35.690578ms)
May 21 07:45:06.726: INFO: (1) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/: foo (200; 38.138292ms)
May 21 07:45:06.729: INFO: (1) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/: bar (200; 41.064811ms)
May 21 07:45:06.729: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/rewriteme"... (200; 41.386325ms)
May 21 07:45:06.729: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/proxy/: bar (200; 41.055911ms)
May 21 07:45:06.730: INFO: (1) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/: foo (200; 40.937065ms)
May 21 07:45:06.730: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/proxy/: tls baz (200; 41.311796ms)
May 21 07:45:06.730: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/proxy/: bar (200; 41.060704ms)
May 21 07:45:06.730: INFO: (1) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/rewri... (200; 40.972597ms)
May 21 07:45:06.730: INFO: (1) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/: bar (200; 41.001113ms)
May 21 07:45:06.730: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/... (200; 41.230551ms)
May 21 07:45:06.730: INFO: (1) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:81/: bar (200; 41.016819ms)
May 21 07:45:06.730: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/rewri... (200; 41.375682ms)
May 21 07:45:06.731: INFO: (1) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/: tls baz (200; 42.465087ms)
May 21 07:45:06.731: INFO: (1) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:80/: foo (200; 42.532652ms)
May 21 07:45:06.731: INFO: (1) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:443/: tls baz (200; 43.023792ms)
May 21 07:45:06.751: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:462/proxy/: tls qux (200; 20.001806ms)
May 21 07:45:06.752: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/rewri... (200; 20.380778ms)
May 21 07:45:06.758: INFO: (2) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/: bar (200; 26.949834ms)
May 21 07:45:06.758: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/proxy/: bar (200; 26.98134ms)
May 21 07:45:06.759: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/... (200; 27.281798ms)
May 21 07:45:06.759: INFO: (2) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/: foo (200; 27.140052ms)
May 21 07:45:06.763: INFO: (2) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/: tls baz (200; 32.310845ms)
May 21 07:45:06.763: INFO: (2) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:444/: tls qux (200; 31.721951ms)
May 21 07:45:06.763: INFO: (2) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:80/: foo (200; 32.102124ms)
May 21 07:45:06.763: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/proxy/: foo (200; 32.205321ms)
May 21 07:45:06.764: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/proxy/: tls qux (200; 32.351177ms)
May 21 07:45:06.764: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/proxy/: bar (200; 32.238653ms)
May 21 07:45:06.764: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/proxy/: bar (200; 32.440795ms)
May 21 07:45:06.764: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/... (200; 32.045652ms)
May 21 07:45:06.764: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:460/proxy/: tls baz (200; 32.17686ms)
May 21 07:45:06.764: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/rewriteme"... (200; 32.295288ms)
May 21 07:45:06.764: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/proxy/: foo (200; 32.484857ms)
May 21 07:45:06.764: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/proxy/: tls baz (200; 32.327727ms)
May 21 07:45:06.764: INFO: (2) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/: tls qux (200; 32.629522ms)
May 21 07:45:06.764: INFO: (2) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:443/: tls baz (200; 32.729967ms)
May 21 07:45:06.768: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/proxy/: foo (200; 36.558834ms)
May 21 07:45:06.768: INFO: (2) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/rewri... (200; 36.68261ms)
May 21 07:45:06.768: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/proxy/: bar (200; 36.774643ms)
May 21 07:45:06.769: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/proxy/: foo (200; 37.161134ms)
May 21 07:45:06.769: INFO: (2) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/: foo (200; 37.415282ms)
May 21 07:45:06.769: INFO: (2) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:80/: foo (200; 37.57844ms)
May 21 07:45:06.770: INFO: (2) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/: bar (200; 38.070559ms)
May 21 07:45:06.770: INFO: (2) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/: foo (200; 38.109975ms)
May 21 07:45:06.770: INFO: (2) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:81/: bar (200; 38.730249ms)
May 21 07:45:06.771: INFO: (2) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/... (200; 39.619235ms)
May 21 07:45:06.771: INFO: (2) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:81/: bar (200; 40.005503ms)
May 21 07:45:06.771: INFO: (2) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/: foo (200; 39.616831ms)
May 21 07:45:06.772: INFO: (2) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/: bar (200; 40.072364ms)
May 21 07:45:06.772: INFO: (2) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/: bar (200; 40.374973ms)
May 21 07:45:06.799: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/rewriteme"... (200; 26.798086ms)
May 21 07:45:06.804: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/proxy/: foo (200; 31.499722ms)
May 21 07:45:06.804: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/proxy/: bar (200; 31.588715ms)
May 21 07:45:06.804: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:462/proxy/: tls qux (200; 31.793587ms)
May 21 07:45:06.804: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/... (200; 31.52098ms)
May 21 07:45:06.804: INFO: (3) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:444/: tls qux (200; 31.883689ms)
May 21 07:45:06.804: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/proxy/: bar (200; 31.721896ms)
May 21 07:45:06.804: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:460/proxy/: tls baz (200; 32.317361ms)
May 21 07:45:06.804: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/proxy/: tls qux (200; 31.961504ms)
May 21 07:45:06.804: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/proxy/: tls baz (200; 32.24404ms)
May 21 07:45:06.804: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/proxy/: foo (200; 32.346459ms)
May 21 07:45:06.808: INFO: (3) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/: foo (200; 36.380893ms)
May 21 07:45:06.809: INFO: (3) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/rewri... (200; 36.819041ms)
May 21 07:45:06.810: INFO: (3) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/: foo (200; 38.539908ms)
May 21 07:45:06.811: INFO: (3) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/: bar (200; 38.427537ms)
May 21 07:45:06.811: INFO: (3) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:81/: bar (200; 38.73849ms)
May 21 07:45:06.812: INFO: (3) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/: bar (200; 39.34696ms)
May 21 07:45:06.812: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/proxy/: foo (200; 39.749919ms)
May 21 07:45:06.812: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/proxy/: bar (200; 39.912629ms)
May 21 07:45:06.812: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/proxy/: bar (200; 40.083114ms)
May 21 07:45:06.812: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/proxy/: foo (200; 40.295076ms)
May 21 07:45:06.812: INFO: (3) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/: tls baz (200; 39.684014ms)
May 21 07:45:06.812: INFO: (3) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/: foo (200; 40.188254ms)
May 21 07:45:06.812: INFO: (3) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/: bar (200; 40.00427ms)
May 21 07:45:06.813: INFO: (3) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/: tls qux (200; 40.046503ms)
May 21 07:45:06.813: INFO: (3) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/: bar (200; 40.265749ms)
May 21 07:45:06.813: INFO: (3) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:81/: bar (200; 40.49085ms)
May 21 07:45:06.813: INFO: (3) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:80/: foo (200; 40.658914ms)
May 21 07:45:06.814: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/rewri... (200; 41.045897ms)
May 21 07:45:06.814: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/... (200; 41.286317ms)
May 21 07:45:06.815: INFO: (3) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/... (200; 42.389721ms)
May 21 07:45:06.815: INFO: (3) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/: foo (200; 42.786957ms)
May 21 07:45:06.816: INFO: (3) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:443/: tls baz (200; 43.50887ms)
May 21 07:45:06.816: INFO: (3) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:80/: foo (200; 43.542319ms)
May 21 07:45:06.843: INFO: (4) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/... (200; 26.432591ms)
May 21 07:45:06.845: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/rewriteme"... (200; 27.97971ms)
May 21 07:45:06.845: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:462/proxy/: tls qux (200; 29.168402ms)
May 21 07:45:06.846: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:460/proxy/: tls baz (200; 29.257861ms)
May 21 07:45:06.846: INFO: (4) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/: tls baz (200; 30.231821ms)
May 21 07:45:06.846: INFO: (4) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/: bar (200; 29.7138ms)
May 21 07:45:06.846: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/proxy/: bar (200; 30.110749ms)
May 21 07:45:06.847: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/proxy/: foo (200; 29.898278ms)
May 21 07:45:06.849: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/proxy/: tls baz (200; 32.458464ms)
May 21 07:45:06.850: INFO: (4) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:444/: tls qux (200; 32.993125ms)
May 21 07:45:06.850: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/proxy/: foo (200; 33.154647ms)
May 21 07:45:06.851: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/proxy/: tls qux (200; 34.461901ms)
May 21 07:45:06.851: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/proxy/: foo (200; 34.540703ms)
May 21 07:45:06.852: INFO: (4) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/: tls qux (200; 35.38701ms)
May 21 07:45:06.853: INFO: (4) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/: foo (200; 36.474689ms)
May 21 07:45:06.853: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/proxy/: bar (200; 36.572704ms)
May 21 07:45:06.855: INFO: (4) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/: foo (200; 38.352645ms)
May 21 07:45:06.855: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/rewri... (200; 38.2587ms)
May 21 07:45:06.855: INFO: (4) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/: bar (200; 38.670344ms)
May 21 07:45:06.855: INFO: (4) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/: foo (200; 38.532865ms)
May 21 07:45:06.860: INFO: (4) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:80/: foo (200; 43.908558ms)
May 21 07:45:06.860: INFO: (4) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/: bar (200; 44.174704ms)
May 21 07:45:06.860: INFO: (4) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:443/: tls baz (200; 44.280827ms)
May 21 07:45:06.860: INFO: (4) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/: foo (200; 43.927159ms)
May 21 07:45:06.860: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/... (200; 44.01268ms)
May 21 07:45:06.861: INFO: (4) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/rewri... (200; 44.052131ms)
May 21 07:45:06.861: INFO: (4) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:81/: bar (200; 43.901958ms)
May 21 07:45:06.861: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/... (200; 44.102297ms)
May 21 07:45:06.861: INFO: (4) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:80/: foo (200; 43.958697ms)
May 21 07:45:06.861: INFO: (4) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:81/: bar (200; 44.331083ms)
May 21 07:45:06.861: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/proxy/: foo (200; 44.265242ms)
May 21 07:45:06.861: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/proxy/: bar (200; 44.247688ms)
May 21 07:45:06.861: INFO: (4) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/: bar (200; 44.138898ms)
May 21 07:45:06.861: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/proxy/: bar (200; 44.198644ms)
May 21 07:45:06.886: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/... (200; 24.85328ms)
May 21 07:45:06.886: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:462/proxy/: tls qux (200; 24.977158ms)
May 21 07:45:06.886: INFO: (5) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:443/: tls baz (200; 25.683164ms)
May 21 07:45:06.887: INFO: (5) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/: foo (200; 26.176796ms)
May 21 07:45:06.887: INFO: (5) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/: tls baz (200; 26.491103ms)
May 21 07:45:06.887: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:460/proxy/: tls baz (200; 26.427661ms)
May 21 07:45:06.887: INFO: (5) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:81/: bar (200; 26.374784ms)
May 21 07:45:06.889: INFO: (5) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/... (200; 28.323041ms)
May 21 07:45:06.889: INFO: (5) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/: foo (200; 28.321292ms)
May 21 07:45:06.889: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/rewriteme"... (200; 28.601117ms)
May 21 07:45:06.890: INFO: (5) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/: foo (200; 28.989791ms)
May 21 07:45:06.891: INFO: (5) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/rewri... (200; 29.695512ms)
May 21 07:45:06.891: INFO: (5) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:80/: foo (200; 30.169939ms)
May 21 07:45:06.891: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/proxy/: bar (200; 30.133058ms)
May 21 07:45:06.891: INFO: (5) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/: bar (200; 30.101764ms)
May 21 07:45:06.891: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/proxy/: foo (200; 30.838645ms)
May 21 07:45:06.892: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/proxy/: tls qux (200; 31.360783ms)
May 21 07:45:06.893: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/proxy/: tls baz (200; 31.630786ms)
May 21 07:45:06.893: INFO: (5) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:444/: tls qux (200; 32.087024ms)
May 21 07:45:06.894: INFO: (5) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:81/: bar (200; 32.530167ms)
May 21 07:45:06.897: INFO: (5) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/: bar (200; 36.484418ms)
May 21 07:45:06.899: INFO: (5) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/: bar (200; 37.958284ms)
May 21 07:45:06.899: INFO: (5) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/: foo (200; 37.957987ms)
May 21 07:45:06.899: INFO: (5) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/: bar (200; 38.047077ms)
May 21 07:45:06.901: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/proxy/: bar (200; 40.064306ms)
May 21 07:45:06.901: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/proxy/: bar (200; 39.945109ms)
May 21 07:45:06.902: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/proxy/: foo (200; 40.643371ms)
May 21 07:45:06.902: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/rewri... (200; 41.454445ms)
May 21 07:45:06.902: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/... (200; 41.299409ms)
May 21 07:45:06.903: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/proxy/: foo (200; 41.488632ms)
May 21 07:45:06.903: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/proxy/: foo (200; 41.882816ms)
May 21 07:45:06.903: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/proxy/: bar (200; 42.692013ms)
May 21 07:45:06.904: INFO: (5) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:80/: foo (200; 42.635138ms)
May 21 07:45:06.906: INFO: (5) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/: tls qux (200; 44.407608ms)
May 21 07:45:06.932: INFO: (6) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/rewri... (200; 25.911498ms)
May 21 07:45:06.934: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/rewri... (200; 28.512394ms)
May 21 07:45:06.934: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/proxy/: bar (200; 28.833781ms)
May 21 07:45:06.934: INFO: (6) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/: tls baz (200; 28.684616ms)
May 21 07:45:06.935: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/proxy/: tls baz (200; 28.720727ms)
May 21 07:45:06.936: INFO: (6) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/: bar (200; 30.193404ms)
May 21 07:45:06.936: INFO: (6) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/: foo (200; 30.476771ms)
May 21 07:45:06.937: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/... (200; 31.104407ms)
May 21 07:45:06.940: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/... (200; 34.323125ms)
May 21 07:45:06.941: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:462/proxy/: tls qux (200; 34.537191ms)
May 21 07:45:06.941: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:460/proxy/: tls baz (200; 34.974631ms)
May 21 07:45:06.941: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/proxy/: bar (200; 35.231646ms)
May 21 07:45:06.941: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/rewriteme"... (200; 35.810221ms)
May 21 07:45:06.941: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/proxy/: foo (200; 35.679305ms)
May 21 07:45:06.941: INFO: (6) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/: bar (200; 35.441635ms)
May 21 07:45:06.942: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/proxy/: foo (200; 35.572296ms)
May 21 07:45:06.942: INFO: (6) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/: foo (200; 35.728979ms)
May 21 07:45:06.944: INFO: (6) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/: bar (200; 38.304292ms)
May 21 07:45:06.944: INFO: (6) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:80/: foo (200; 38.323897ms)
May 21 07:45:06.944: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/proxy/: bar (200; 38.258573ms)
May 21 07:45:06.945: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/proxy/: foo (200; 38.695393ms)
May 21 07:45:06.946: INFO: (6) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:80/: foo (200; 40.063756ms)
May 21 07:45:06.946: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/proxy/: foo (200; 39.802895ms)
May 21 07:45:06.946: INFO: (6) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/: tls qux (200; 40.039979ms)
May 21 07:45:06.946: INFO: (6) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:81/: bar (200; 39.928329ms)
May 21 07:45:06.946: INFO: (6) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:444/: tls qux (200; 40.266466ms)
May 21 07:45:06.946: INFO: (6) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/: bar (200; 40.178765ms)
May 21 07:45:06.946: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/proxy/: tls qux (200; 40.013027ms)
May 21 07:45:06.946: INFO: (6) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/... (200; 40.192907ms)
May 21 07:45:06.946: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/proxy/: bar (200; 40.162185ms)
May 21 07:45:06.947: INFO: (6) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/: foo (200; 40.872733ms)
May 21 07:45:06.947: INFO: (6) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:81/: bar (200; 40.999971ms)
May 21 07:45:06.947: INFO: (6) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:443/: tls baz (200; 41.533281ms)
May 21 07:45:06.948: INFO: (6) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/: foo (200; 41.970695ms)
May 21 07:45:06.978: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:460/proxy/: tls baz (200; 30.272185ms)
May 21 07:45:06.979: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/proxy/: tls baz (200; 30.532768ms)
May 21 07:45:06.979: INFO: (7) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/: foo (200; 30.584587ms)
May 21 07:45:06.979: INFO: (7) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/: bar (200; 30.7062ms)
May 21 07:45:06.979: INFO: (7) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/: foo (200; 30.858983ms)
May 21 07:45:06.981: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:462/proxy/: tls qux (200; 32.091191ms)
May 21 07:45:06.982: INFO: (7) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/: bar (200; 33.624661ms)
May 21 07:45:06.982: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/proxy/: tls qux (200; 33.551709ms)
May 21 07:45:06.985: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/... (200; 36.568322ms)
May 21 07:45:06.986: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/rewriteme"... (200; 37.141093ms)
May 21 07:45:06.986: INFO: (7) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/: foo (200; 37.74639ms)
May 21 07:45:06.986: INFO: (7) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:81/: bar (200; 37.875851ms)
May 21 07:45:06.986: INFO: (7) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:81/: bar (200; 37.399939ms)
May 21 07:45:06.986: INFO: (7) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/: foo (200; 37.738261ms)
May 21 07:45:06.986: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/proxy/: foo (200; 37.938062ms)
May 21 07:45:06.988: INFO: (7) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:444/: tls qux (200; 40.402935ms)
May 21 07:45:06.989: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/proxy/: bar (200; 40.509378ms)
May 21 07:45:06.989: INFO: (7) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/: tls qux (200; 40.599118ms)
May 21 07:45:06.989: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/proxy/: foo (200; 40.997668ms)
May 21 07:45:06.989: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/proxy/: foo (200; 41.057986ms)
May 21 07:45:06.989: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/proxy/: foo (200; 41.121217ms)
May 21 07:45:06.990: INFO: (7) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:80/: foo (200; 41.756662ms)
May 21 07:45:06.990: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/proxy/: bar (200; 41.252209ms)
May 21 07:45:06.991: INFO: (7) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/rewri... (200; 42.463736ms)
May 21 07:45:06.993: INFO: (7) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/: tls baz (200; 44.609214ms)
May 21 07:45:06.993: INFO: (7) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:443/: tls baz (200; 45.3099ms)
May 21 07:45:06.994: INFO: (7) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:80/: foo (200; 45.325823ms)
May 21 07:45:06.994: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/proxy/: bar (200; 45.755281ms)
May 21 07:45:06.994: INFO: (7) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/: bar (200; 45.751583ms)
May 21 07:45:06.994: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/... (200; 45.300525ms)
May 21 07:45:06.994: INFO: (7) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/... (200; 45.773921ms)
May 21 07:45:06.994: INFO: (7) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/: bar (200; 45.88403ms)
May 21 07:45:06.994: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/proxy/: bar (200; 45.588073ms)
May 21 07:45:06.994: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/rewri... (200; 45.421743ms)
May 21 07:45:07.023: INFO: (8) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/: tls qux (200; 29.149001ms)
May 21 07:45:07.024: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/proxy/: tls baz (200; 29.421414ms)
May 21 07:45:07.025: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/proxy/: tls qux (200; 30.646059ms)
May 21 07:45:07.025: INFO: (8) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/: tls baz (200; 30.815417ms)
May 21 07:45:07.025: INFO: (8) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/: bar (200; 31.088149ms)
May 21 07:45:07.025: INFO: (8) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/: bar (200; 31.287332ms)
May 21 07:45:07.026: INFO: (8) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/rewri... (200; 31.731621ms)
May 21 07:45:07.027: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/rewri... (200; 32.241005ms)
May 21 07:45:07.027: INFO: (8) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/: foo (200; 33.119105ms)
May 21 07:45:07.027: INFO: (8) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/: foo (200; 32.933173ms)
May 21 07:45:07.027: INFO: (8) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/: bar (200; 32.96394ms)
May 21 07:45:07.027: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/proxy/: foo (200; 33.1835ms)
May 21 07:45:07.029: INFO: (8) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/: foo (200; 34.530654ms)
May 21 07:45:07.029: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/proxy/: foo (200; 34.845197ms)
May 21 07:45:07.031: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/proxy/: bar (200; 36.598806ms)
May 21 07:45:07.031: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/proxy/: bar (200; 36.69122ms)
May 21 07:45:07.031: INFO: (8) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:81/: bar (200; 37.011457ms)
May 21 07:45:07.031: INFO: (8) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:80/: foo (200; 36.866719ms)
May 21 07:45:07.031: INFO: (8) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:80/: foo (200; 37.107144ms)
May 21 07:45:07.031: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/proxy/: foo (200; 37.005156ms)
May 21 07:45:07.033: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/... (200; 39.247189ms)
May 21 07:45:07.034: INFO: (8) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/... (200; 39.275247ms)
May 21 07:45:07.034: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/... (200; 39.525898ms)
May 21 07:45:07.035: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/proxy/: bar (200; 40.570884ms)
May 21 07:45:07.036: INFO: (8) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/: bar (200; 41.707662ms)
May 21 07:45:07.036: INFO: (8) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:443/: tls baz (200; 41.84984ms)
May 21 07:45:07.036: INFO: (8) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/: foo (200; 41.807126ms)
May 21 07:45:07.036: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:460/proxy/: tls baz (200; 41.817742ms)
May 21 07:45:07.036: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/rewriteme"... (200; 41.761705ms)
May 21 07:45:07.036: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/proxy/: foo (200; 41.984421ms)
May 21 07:45:07.036: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:462/proxy/: tls qux (200; 41.830607ms)
May 21 07:45:07.036: INFO: (8) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:444/: tls qux (200; 41.899479ms)
May 21 07:45:07.038: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/proxy/: bar (200; 43.706263ms)
May 21 07:45:07.038: INFO: (8) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:81/: bar (200; 43.747133ms)
May 21 07:45:07.068: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/rewri... (200; 28.813204ms)
May 21 07:45:07.068: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:460/proxy/: tls baz (200; 29.223604ms)
May 21 07:45:07.068: INFO: (9) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/: foo (200; 29.197945ms)
May 21 07:45:07.068: INFO: (9) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/: tls baz (200; 29.20896ms)
May 21 07:45:07.068: INFO: (9) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/: bar (200; 29.310357ms)
May 21 07:45:07.068: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/proxy/: foo (200; 29.77987ms)
May 21 07:45:07.069: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/rewriteme"... (200; 29.743424ms)
May 21 07:45:07.069: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/proxy/: tls qux (200; 30.147936ms)
May 21 07:45:07.069: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/proxy/: bar (200; 29.964847ms)
May 21 07:45:07.071: INFO: (9) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/: tls qux (200; 31.828171ms)
May 21 07:45:07.072: INFO: (9) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/... (200; 33.193825ms)
May 21 07:45:07.074: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/proxy/: bar (200; 34.928704ms)
May 21 07:45:07.074: INFO: (9) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/: foo (200; 35.152963ms)
May 21 07:45:07.076: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/proxy/: tls baz (200; 37.233589ms)
May 21 07:45:07.076: INFO: (9) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:443/: tls baz (200; 37.50479ms)
May 21 07:45:07.076: INFO: (9) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/: foo (200; 37.299301ms)
May 21 07:45:07.076: INFO: (9) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/: bar (200; 37.468469ms)
May 21 07:45:07.077: INFO: (9) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:80/: foo (200; 38.005378ms)
May 21 07:45:07.078: INFO: (9) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/rewri... (200; 39.064234ms)
May 21 07:45:07.085: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/proxy/: bar (200; 46.414387ms)
May 21 07:45:07.085: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/proxy/: foo (200; 46.485429ms)
May 21 07:45:07.085: INFO: (9) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:81/: bar (200; 46.480787ms)
May 21 07:45:07.085: INFO: (9) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/: bar (200; 46.446705ms)
May 21 07:45:07.085: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/... (200; 46.274448ms)
May 21 07:45:07.085: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/proxy/: foo (200; 46.271038ms)
May 21 07:45:07.085: INFO: (9) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:81/: bar (200; 46.189972ms)
May 21 07:45:07.085: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:462/proxy/: tls qux (200; 46.151436ms)
May 21 07:45:07.085: INFO: (9) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/: bar (200; 46.433769ms)
May 21 07:45:07.085: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/... (200; 46.155016ms)
May 21 07:45:07.085: INFO: (9) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/: foo (200; 46.53105ms)
May 21 07:45:07.085: INFO: (9) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:444/: tls qux (200; 46.416748ms)
May 21 07:45:07.085: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/proxy/: bar (200; 46.620236ms)
May 21 07:45:07.085: INFO: (9) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:80/: foo (200; 47.125655ms)
May 21 07:45:07.086: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/proxy/: foo (200; 46.942842ms)
May 21 07:45:07.104: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/... (200; 18.560282ms)
May 21 07:45:07.105: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/proxy/: foo (200; 18.790176ms)
May 21 07:45:07.105: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/proxy/: foo (200; 18.934275ms)
May 21 07:45:07.106: INFO: (10) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/: tls qux (200; 19.846746ms)
May 21 07:45:07.106: INFO: (10) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/: tls baz (200; 19.906867ms)
May 21 07:45:07.106: INFO: (10) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:80/: foo (200; 20.14414ms)
May 21 07:45:07.113: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/proxy/: bar (200; 25.967955ms)
May 21 07:45:07.113: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/proxy/: tls baz (200; 26.477175ms)
May 21 07:45:07.113: INFO: (10) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/: foo (200; 26.748884ms)
May 21 07:45:07.113: INFO: (10) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/: bar (200; 26.631466ms)
May 21 07:45:07.115: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/... (200; 28.699975ms)
May 21 07:45:07.116: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/rewri... (200; 29.496381ms)
May 21 07:45:07.116: INFO: (10) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/... (200; 29.380921ms)
May 21 07:45:07.116: INFO: (10) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/: foo (200; 29.130557ms)
May 21 07:45:07.116: INFO: (10) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/: bar (200; 29.626254ms)
May 21 07:45:07.116: INFO: (10) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/: bar (200; 29.468768ms)
May 21 07:45:07.116: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/proxy/: bar (200; 29.783398ms)
May 21 07:45:07.117: INFO: (10) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/rewri... (200; 30.319864ms)
May 21 07:45:07.117: INFO: (10) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/: bar (200; 30.737149ms)
May 21 07:45:07.117: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/proxy/: bar (200; 30.305427ms)
May 21 07:45:07.124: INFO: (10) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:81/: bar (200; 37.258139ms)
May 21 07:45:07.124: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:462/proxy/: tls qux (200; 37.42857ms)
May 21 07:45:07.124: INFO: (10) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:80/: foo (200; 38.126272ms)
May 21 07:45:07.124: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/rewriteme"... (200; 37.741937ms)
May 21 07:45:07.125: INFO: (10) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/: foo (200; 38.339386ms)
May 21 07:45:07.125: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/proxy/: foo (200; 38.935785ms)
May 21 07:45:07.126: INFO: (10) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:443/: tls baz (200; 39.337971ms)
May 21 07:45:07.126: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:460/proxy/: tls baz (200; 40.06762ms)
May 21 07:45:07.126: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/proxy/: bar (200; 39.723252ms)
May 21 07:45:07.127: INFO: (10) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:81/: bar (200; 40.341935ms)
May 21 07:45:07.127: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/proxy/: foo (200; 40.6287ms)
May 21 07:45:07.127: INFO: (10) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/: foo (200; 40.892891ms)
May 21 07:45:07.128: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/proxy/: tls qux (200; 41.159306ms)
May 21 07:45:07.128: INFO: (10) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:444/: tls qux (200; 41.698564ms)
May 21 07:45:07.147: INFO: (11) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/: tls baz (200; 18.272455ms)
May 21 07:45:07.157: INFO: (11) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/: foo (200; 28.626545ms)
May 21 07:45:07.163: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/proxy/: bar (200; 34.336021ms)
May 21 07:45:07.163: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/... (200; 34.173968ms)
May 21 07:45:07.165: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/... (200; 36.583284ms)
May 21 07:45:07.165: INFO: (11) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/: foo (200; 36.946674ms)
May 21 07:45:07.165: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/proxy/: foo (200; 36.909087ms)
May 21 07:45:07.165: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/rewriteme"... (200; 36.867391ms)
May 21 07:45:07.165: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/proxy/: bar (200; 36.977796ms)
May 21 07:45:07.165: INFO: (11) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/... (200; 37.121449ms)
May 21 07:45:07.166: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:460/proxy/: tls baz (200; 38.031275ms)
May 21 07:45:07.167: INFO: (11) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:443/: tls baz (200; 38.513897ms)
May 21 07:45:07.175: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/proxy/: foo (200; 46.528749ms)
May 21 07:45:07.175: INFO: (11) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/rewri... (200; 47.181252ms)
May 21 07:45:07.177: INFO: (11) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/: bar (200; 48.343632ms)
May 21 07:45:07.179: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:462/proxy/: tls qux (200; 50.403397ms)
May 21 07:45:07.179: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/proxy/: tls qux (200; 50.503436ms)
May 21 07:45:07.180: INFO: (11) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/: foo (200; 51.002032ms)
May 21 07:45:07.180: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/rewri... (200; 51.725386ms)
May 21 07:45:07.181: INFO: (11) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:80/: foo (200; 52.374444ms)
May 21 07:45:07.181: INFO: (11) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/: tls qux (200; 52.850113ms)
May 21 07:45:07.182: INFO: (11) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/: bar (200; 53.318503ms)
May 21 07:45:07.182: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/proxy/: bar (200; 52.916358ms)
May 21 07:45:07.182: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/proxy/: tls baz (200; 52.922482ms)
May 21 07:45:07.182: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/proxy/: foo (200; 53.186354ms)
May 21 07:45:07.182: INFO: (11) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/: foo (200; 53.357648ms)
May 21 07:45:07.182: INFO: (11) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:80/: foo (200; 53.654599ms)
May 21 07:45:07.182: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/proxy/: bar (200; 53.584128ms)
May 21 07:45:07.182: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/proxy/: foo (200; 53.855634ms)
May 21 07:45:07.182: INFO: (11) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/: bar (200; 54.00089ms)
May 21 07:45:07.182: INFO: (11) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/: bar (200; 54.152243ms)
May 21 07:45:07.182: INFO: (11) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:81/: bar (200; 53.873518ms)
May 21 07:45:07.183: INFO: (11) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:444/: tls qux (200; 54.257878ms)
May 21 07:45:07.184: INFO: (11) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:81/: bar (200; 55.653453ms)
May 21 07:45:07.213: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/rewriteme"... (200; 28.144697ms)
May 21 07:45:07.214: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/proxy/: bar (200; 29.80923ms)
May 21 07:45:07.215: INFO: (12) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/: foo (200; 30.00882ms)
May 21 07:45:07.215: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/... (200; 29.844988ms)
May 21 07:45:07.216: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:460/proxy/: tls baz (200; 30.573028ms)
May 21 07:45:07.216: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/proxy/: tls baz (200; 31.588912ms)
May 21 07:45:07.216: INFO: (12) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:444/: tls qux (200; 31.468557ms)
May 21 07:45:07.216: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:462/proxy/: tls qux (200; 31.648379ms)
May 21 07:45:07.216: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/proxy/: tls qux (200; 31.456079ms)
May 21 07:45:07.217: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/proxy/: bar (200; 32.944757ms)
May 21 07:45:07.219: INFO: (12) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/rewri... (200; 34.066714ms)
May 21 07:45:07.219: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/proxy/: bar (200; 34.242432ms)
May 21 07:45:07.219: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/proxy/: foo (200; 34.440659ms)
May 21 07:45:07.219: INFO: (12) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/: bar (200; 33.88539ms)
May 21 07:45:07.219: INFO: (12) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/: tls qux (200; 34.251929ms)
May 21 07:45:07.220: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/rewri... (200; 34.872394ms)
May 21 07:45:07.220: INFO: (12) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/: bar (200; 35.232128ms)
May 21 07:45:07.220: INFO: (12) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/: bar (200; 35.263077ms)
May 21 07:45:07.220: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/proxy/: foo (200; 35.147128ms)
May 21 07:45:07.221: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/... (200; 35.471926ms)
May 21 07:45:07.221: INFO: (12) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:81/: bar (200; 36.042359ms)
May 21 07:45:07.221: INFO: (12) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/: tls baz (200; 35.618493ms)
May 21 07:45:07.222: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/proxy/: foo (200; 36.974711ms)
May 21 07:45:07.222: INFO: (12) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/... (200; 37.010303ms)
May 21 07:45:07.222: INFO: (12) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:80/: foo (200; 37.204954ms)
May 21 07:45:07.222: INFO: (12) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:443/: tls baz (200; 37.364584ms)
May 21 07:45:07.223: INFO: (12) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:81/: bar (200; 37.643242ms)
May 21 07:45:07.223: INFO: (12) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:80/: foo (200; 37.855235ms)
May 21 07:45:07.223: INFO: (12) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/: foo (200; 38.519649ms)
May 21 07:45:07.223: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/proxy/: bar (200; 38.082666ms)
May 21 07:45:07.223: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/proxy/: foo (200; 38.532253ms)
May 21 07:45:07.223: INFO: (12) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/: foo (200; 38.301605ms)
May 21 07:45:07.223: INFO: (12) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/: foo (200; 38.449271ms)
May 21 07:45:07.224: INFO: (12) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/: bar (200; 38.820224ms)
May 21 07:45:07.255: INFO: (13) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/: bar (200; 31.147376ms)
May 21 07:45:07.256: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/proxy/: bar (200; 32.023904ms)
May 21 07:45:07.256: INFO: (13) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/: foo (200; 32.572614ms)
May 21 07:45:07.264: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/proxy/: foo (200; 39.740035ms)
May 21 07:45:07.264: INFO: (13) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:443/: tls baz (200; 39.30846ms)
May 21 07:45:07.264: INFO: (13) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/: tls baz (200; 39.308314ms)
May 21 07:45:07.264: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/rewri... (200; 39.301798ms)
May 21 07:45:07.264: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/proxy/: bar (200; 39.380601ms)
May 21 07:45:07.264: INFO: (13) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/: tls qux (200; 39.479819ms)
May 21 07:45:07.264: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/proxy/: bar (200; 39.802345ms)
May 21 07:45:07.264: INFO: (13) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/: bar (200; 39.430686ms)
May 21 07:45:07.264: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:460/proxy/: tls baz (200; 39.475556ms)
May 21 07:45:07.264: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/proxy/: foo (200; 39.745362ms)
May 21 07:45:07.264: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/proxy/: tls baz (200; 39.864783ms)
May 21 07:45:07.264: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:462/proxy/: tls qux (200; 39.950762ms)
May 21 07:45:07.264: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/proxy/: tls qux (200; 40.303158ms)
May 21 07:45:07.265: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/proxy/: bar (200; 40.998443ms)
May 21 07:45:07.265: INFO: (13) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/rewri... (200; 40.936407ms)
May 21 07:45:07.265: INFO: (13) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:81/: bar (200; 41.378881ms)
May 21 07:45:07.265: INFO: (13) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:80/: foo (200; 41.137996ms)
May 21 07:45:07.265: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/proxy/: foo (200; 41.307001ms)
May 21 07:45:07.265: INFO: (13) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/: foo (200; 41.664878ms)
May 21 07:45:07.266: INFO: (13) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/: bar (200; 41.874097ms)
May 21 07:45:07.266: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/proxy/: foo (200; 41.802401ms)
May 21 07:45:07.266: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/rewriteme"... (200; 41.775348ms)
May 21 07:45:07.266: INFO: (13) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:444/: tls qux (200; 42.0249ms)
May 21 07:45:07.266: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/... (200; 41.64644ms)
May 21 07:45:07.266: INFO: (13) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/... (200; 41.732749ms)
May 21 07:45:07.266: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/... (200; 41.623569ms)
May 21 07:45:07.266: INFO: (13) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/: foo (200; 42.331234ms)
May 21 07:45:07.266: INFO: (13) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/: foo (200; 42.444113ms)
May 21 07:45:07.266: INFO: (13) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:80/: foo (200; 42.253214ms)
May 21 07:45:07.266: INFO: (13) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:81/: bar (200; 42.66015ms)
May 21 07:45:07.266: INFO: (13) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/: bar (200; 42.199292ms)
May 21 07:45:07.296: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:460/proxy/: tls baz (200; 29.611011ms)
May 21 07:45:07.297: INFO: (14) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/: foo (200; 29.373854ms)
May 21 07:45:07.297: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/proxy/: foo (200; 29.549674ms)
May 21 07:45:07.301: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/rewri... (200; 34.87876ms)
May 21 07:45:07.302: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/proxy/: foo (200; 35.181946ms)
May 21 07:45:07.303: INFO: (14) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:81/: bar (200; 35.874595ms)
May 21 07:45:07.306: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/rewriteme"... (200; 37.888743ms)
May 21 07:45:07.306: INFO: (14) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:80/: foo (200; 39.173484ms)
May 21 07:45:07.313: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:462/proxy/: tls qux (200; 45.59981ms)
May 21 07:45:07.315: INFO: (14) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/: foo (200; 47.20317ms)
May 21 07:45:07.316: INFO: (14) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/: bar (200; 48.960215ms)
May 21 07:45:07.316: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/proxy/: foo (200; 47.631942ms)
May 21 07:45:07.316: INFO: (14) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/: bar (200; 47.146749ms)
May 21 07:45:07.319: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/proxy/: bar (200; 50.46969ms)
May 21 07:45:07.320: INFO: (14) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:443/: tls baz (200; 52.003918ms)
May 21 07:45:07.321: INFO: (14) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:444/: tls qux (200; 53.559117ms)
May 21 07:45:07.322: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/proxy/: tls qux (200; 52.603808ms)
May 21 07:45:07.322: INFO: (14) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/: tls qux (200; 53.10435ms)
May 21 07:45:07.323: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/... (200; 54.524758ms)
May 21 07:45:07.324: INFO: (14) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/: bar (200; 55.149837ms)
May 21 07:45:07.324: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/proxy/: foo (200; 55.639694ms)
May 21 07:45:07.324: INFO: (14) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/: bar (200; 55.215123ms)
May 21 07:45:07.324: INFO: (14) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/... (200; 57.194127ms)
May 21 07:45:07.325: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/proxy/: tls baz (200; 56.356693ms)
May 21 07:45:07.325: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/proxy/: bar (200; 56.262156ms)
May 21 07:45:07.325: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/proxy/: bar (200; 55.698699ms)
May 21 07:45:07.326: INFO: (14) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/: tls baz (200; 57.028184ms)
May 21 07:45:07.326: INFO: (14) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/: foo (200; 56.845968ms)
May 21 07:45:07.326: INFO: (14) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/rewri... (200; 56.919673ms)
May 21 07:45:07.326: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/proxy/: bar (200; 57.341322ms)
May 21 07:45:07.326: INFO: (14) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/: foo (200; 56.984645ms)
May 21 07:45:07.326: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/... (200; 57.741456ms)
May 21 07:45:07.326: INFO: (14) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:81/: bar (200; 57.497427ms)
May 21 07:45:07.326: INFO: (14) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:80/: foo (200; 57.844423ms)
May 21 07:45:07.350: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/proxy/: foo (200; 24.097655ms)
May 21 07:45:07.356: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:462/proxy/: tls qux (200; 28.975148ms)
May 21 07:45:07.356: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/proxy/: foo (200; 29.802011ms)
May 21 07:45:07.356: INFO: (15) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/: bar (200; 29.905092ms)
May 21 07:45:07.357: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/rewriteme"... (200; 30.144693ms)
May 21 07:45:07.359: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/... (200; 32.570403ms)
May 21 07:45:07.360: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/... (200; 32.877838ms)
May 21 07:45:07.360: INFO: (15) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/: foo (200; 33.134446ms)
May 21 07:45:07.360: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:460/proxy/: tls baz (200; 33.386237ms)
May 21 07:45:07.360: INFO: (15) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/: bar (200; 33.615855ms)
May 21 07:45:07.360: INFO: (15) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/: foo (200; 33.632632ms)
May 21 07:45:07.360: INFO: (15) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/: tls qux (200; 33.397597ms)
May 21 07:45:07.361: INFO: (15) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/... (200; 34.060222ms)
May 21 07:45:07.361: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/proxy/: bar (200; 33.794642ms)
May 21 07:45:07.365: INFO: (15) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:80/: foo (200; 38.604853ms)
May 21 07:45:07.365: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/proxy/: bar (200; 38.082159ms)
May 21 07:45:07.365: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/proxy/: tls baz (200; 38.25139ms)
May 21 07:45:07.365: INFO: (15) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:444/: tls qux (200; 38.346552ms)
May 21 07:45:07.365: INFO: (15) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/: tls baz (200; 38.341765ms)
May 21 07:45:07.365: INFO: (15) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/rewri... (200; 38.518546ms)
May 21 07:45:07.365: INFO: (15) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:443/: tls baz (200; 38.445902ms)
May 21 07:45:07.365: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/proxy/: tls qux (200; 38.756091ms)
May 21 07:45:07.365: INFO: (15) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/: foo (200; 38.474827ms)
May 21 07:45:07.365: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/proxy/: bar (200; 38.619819ms)
May 21 07:45:07.365: INFO: (15) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/: bar (200; 38.762303ms)
May 21 07:45:07.366: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/proxy/: bar (200; 38.733449ms)
May 21 07:45:07.366: INFO: (15) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:81/: bar (200; 38.709255ms)
May 21 07:45:07.366: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/proxy/: foo (200; 39.27793ms)
May 21 07:45:07.366: INFO: (15) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/: bar (200; 39.194521ms)
May 21 07:45:07.366: INFO: (15) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:80/: foo (200; 39.043484ms)
May 21 07:45:07.366: INFO: (15) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:81/: bar (200; 39.526078ms)
May 21 07:45:07.366: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/proxy/: foo (200; 39.270642ms)
May 21 07:45:07.366: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/rewri... (200; 39.369919ms)
May 21 07:45:07.366: INFO: (15) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/: foo (200; 39.689782ms)
May 21 07:45:07.395: INFO: (16) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/: foo (200; 28.327917ms)
May 21 07:45:07.395: INFO: (16) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:81/: bar (200; 28.354747ms)
May 21 07:45:07.395: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/proxy/: bar (200; 28.376993ms)
May 21 07:45:07.396: INFO: (16) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:80/: foo (200; 29.044726ms)
May 21 07:45:07.396: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/proxy/: bar (200; 29.344284ms)
May 21 07:45:07.396: INFO: (16) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:80/: foo (200; 28.976263ms)
May 21 07:45:07.396: INFO: (16) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:81/: bar (200; 29.409407ms)
May 21 07:45:07.399: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/rewri... (200; 31.452079ms)
May 21 07:45:07.399: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/rewriteme"... (200; 32.099305ms)
May 21 07:45:07.399: INFO: (16) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/: bar (200; 31.808824ms)
May 21 07:45:07.401: INFO: (16) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/: tls qux (200; 34.309097ms)
May 21 07:45:07.401: INFO: (16) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/rewri... (200; 33.896817ms)
May 21 07:45:07.401: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/... (200; 34.375065ms)
May 21 07:45:07.402: INFO: (16) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/: foo (200; 35.005212ms)
May 21 07:45:07.402: INFO: (16) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/: bar (200; 34.760456ms)
May 21 07:45:07.402: INFO: (16) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/: bar (200; 35.246008ms)
May 21 07:45:07.402: INFO: (16) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/: foo (200; 34.841066ms)
May 21 07:45:07.402: INFO: (16) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:444/: tls qux (200; 35.526523ms)
May 21 07:45:07.402: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:462/proxy/: tls qux (200; 35.581896ms)
May 21 07:45:07.402: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/proxy/: tls qux (200; 35.518563ms)
May 21 07:45:07.403: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/proxy/: foo (200; 35.505926ms)
May 21 07:45:07.403: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/proxy/: foo (200; 35.982566ms)
May 21 07:45:07.403: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/proxy/: foo (200; 35.823633ms)
May 21 07:45:07.403: INFO: (16) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/: bar (200; 35.77104ms)
May 21 07:45:07.403: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/proxy/: bar (200; 36.118285ms)
May 21 07:45:07.403: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/... (200; 36.714275ms)
May 21 07:45:07.404: INFO: (16) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/: tls baz (200; 36.867849ms)
May 21 07:45:07.404: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/proxy/: tls baz (200; 37.211169ms)
May 21 07:45:07.404: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:460/proxy/: tls baz (200; 37.172804ms)
May 21 07:45:07.404: INFO: (16) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:443/: tls baz (200; 37.002323ms)
May 21 07:45:07.404: INFO: (16) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/... (200; 37.637675ms)
May 21 07:45:07.404: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/proxy/: bar (200; 37.330242ms)
May 21 07:45:07.404: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/proxy/: foo (200; 37.400814ms)
May 21 07:45:07.404: INFO: (16) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/: foo (200; 37.191568ms)
May 21 07:45:07.430: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/proxy/: bar (200; 25.405627ms)
May 21 07:45:07.431: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/proxy/: bar (200; 26.669642ms)
May 21 07:45:07.431: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:462/proxy/: tls qux (200; 26.436228ms)
May 21 07:45:07.431: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/... (200; 26.431375ms)
May 21 07:45:07.431: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/proxy/: foo (200; 26.437039ms)
May 21 07:45:07.434: INFO: (17) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/: tls baz (200; 29.260065ms)
May 21 07:45:07.434: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/... (200; 29.431454ms)
May 21 07:45:07.434: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:460/proxy/: tls baz (200; 29.410629ms)
May 21 07:45:07.434: INFO: (17) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/: foo (200; 29.77972ms)
May 21 07:45:07.435: INFO: (17) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/rewri... (200; 30.268282ms)
May 21 07:45:07.440: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/proxy/: foo (200; 35.551008ms)
May 21 07:45:07.440: INFO: (17) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/: foo (200; 35.635392ms)
May 21 07:45:07.440: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/proxy/: bar (200; 35.740259ms)
May 21 07:45:07.440: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/proxy/: bar (200; 35.524414ms)
May 21 07:45:07.440: INFO: (17) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/: bar (200; 35.631895ms)
May 21 07:45:07.440: INFO: (17) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:81/: bar (200; 35.461902ms)
May 21 07:45:07.440: INFO: (17) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/: foo (200; 35.547586ms)
May 21 07:45:07.440: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/rewriteme"... (200; 35.6656ms)
May 21 07:45:07.440: INFO: (17) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:444/: tls qux (200; 35.600335ms)
May 21 07:45:07.440: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/proxy/: foo (200; 35.639277ms)
May 21 07:45:07.440: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/proxy/: tls qux (200; 35.512644ms)
May 21 07:45:07.440: INFO: (17) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/: bar (200; 35.727939ms)
May 21 07:45:07.441: INFO: (17) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:443/: tls baz (200; 36.365828ms)
May 21 07:45:07.441: INFO: (17) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:80/: foo (200; 36.316983ms)
May 21 07:45:07.441: INFO: (17) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:81/: bar (200; 36.618862ms)
May 21 07:45:07.442: INFO: (17) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/: tls qux (200; 36.899022ms)
May 21 07:45:07.442: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/proxy/: tls baz (200; 36.906946ms)
May 21 07:45:07.445: INFO: (17) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/: foo (200; 40.079349ms)
May 21 07:45:07.446: INFO: (17) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/... (200; 40.771155ms)
May 21 07:45:07.446: INFO: (17) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/: bar (200; 41.27049ms)
May 21 07:45:07.447: INFO: (17) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:80/: foo (200; 41.504134ms)
May 21 07:45:07.447: INFO: (17) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/: bar (200; 41.696957ms)
May 21 07:45:07.447: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/rewri... (200; 42.558561ms)
May 21 07:45:07.448: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/proxy/: foo (200; 43.153878ms)
May 21 07:45:07.472: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/proxy/: tls baz (200; 24.130942ms)
May 21 07:45:07.476: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/proxy/: bar (200; 27.503523ms)
May 21 07:45:07.480: INFO: (18) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/: bar (200; 31.386068ms)
May 21 07:45:07.480: INFO: (18) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/: bar (200; 31.479251ms)
May 21 07:45:07.480: INFO: (18) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/: tls qux (200; 32.002836ms)
May 21 07:45:07.480: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/proxy/: tls qux (200; 31.609988ms)
May 21 07:45:07.482: INFO: (18) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/: foo (200; 33.760408ms)
May 21 07:45:07.482: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/proxy/: foo (200; 33.356559ms)
May 21 07:45:07.483: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/proxy/: bar (200; 34.214124ms)
May 21 07:45:07.484: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/proxy/: bar (200; 35.656971ms)
May 21 07:45:07.484: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/proxy/: foo (200; 35.455884ms)
May 21 07:45:07.485: INFO: (18) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/: foo (200; 36.234037ms)
May 21 07:45:07.485: INFO: (18) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/: foo (200; 36.767651ms)
May 21 07:45:07.485: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:462/proxy/: tls qux (200; 36.894231ms)
May 21 07:45:07.485: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/proxy/: foo (200; 36.906119ms)
May 21 07:45:07.485: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/rewriteme"... (200; 37.400631ms)
May 21 07:45:07.485: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/rewri... (200; 37.524264ms)
May 21 07:45:07.486: INFO: (18) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/: bar (200; 37.81615ms)
May 21 07:45:07.486: INFO: (18) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:444/: tls qux (200; 37.595893ms)
May 21 07:45:07.486: INFO: (18) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/rewri... (200; 37.872352ms)
May 21 07:45:07.486: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:460/proxy/: tls baz (200; 37.820214ms)
May 21 07:45:07.486: INFO: (18) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/: foo (200; 37.572054ms)
May 21 07:45:07.486: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/... (200; 37.655454ms)
May 21 07:45:07.486: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/... (200; 38.263346ms)
May 21 07:45:07.486: INFO: (18) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/: tls baz (200; 38.23284ms)
May 21 07:45:07.486: INFO: (18) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/... (200; 38.138496ms)
May 21 07:45:07.486: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/proxy/: foo (200; 38.449415ms)
May 21 07:45:07.486: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/proxy/: bar (200; 38.09188ms)
May 21 07:45:07.487: INFO: (18) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:80/: foo (200; 38.520146ms)
May 21 07:45:07.487: INFO: (18) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/: bar (200; 38.163171ms)
May 21 07:45:07.487: INFO: (18) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:81/: bar (200; 38.53346ms)
May 21 07:45:07.487: INFO: (18) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:443/: tls baz (200; 38.809399ms)
May 21 07:45:07.487: INFO: (18) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:81/: bar (200; 38.669504ms)
May 21 07:45:07.492: INFO: (18) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:80/: foo (200; 43.470448ms)
May 21 07:45:07.547: INFO: (19) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/: tls qux (200; 54.354653ms)
May 21 07:45:07.547: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/proxy/: bar (200; 54.722388ms)
May 21 07:45:07.547: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname2/proxy/: tls qux (200; 54.580867ms)
May 21 07:45:07.548: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/proxy/: bar (200; 55.315859ms)
May 21 07:45:07.548: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/proxy/: foo (200; 55.316562ms)
May 21 07:45:07.548: INFO: (19) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/: foo (200; 55.740004ms)
May 21 07:45:07.548: INFO: (19) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/: tls baz (200; 55.773464ms)
May 21 07:45:07.549: INFO: (19) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:443/: tls baz (200; 56.883711ms)
May 21 07:45:07.549: INFO: (19) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:81/: bar (200; 56.596756ms)
May 21 07:45:07.549: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:tlsportname1/proxy/: tls baz (200; 57.088569ms)
May 21 07:45:07.550: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/proxy/: bar (200; 57.752774ms)
May 21 07:45:07.551: INFO: (19) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/: foo (200; 59.462568ms)
May 21 07:45:07.551: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/proxy/rewri... (200; 59.150047ms)
May 21 07:45:07.552: INFO: (19) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:81/: bar (200; 59.641782ms)
May 21 07:45:07.552: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt/proxy/rewriteme"... (200; 59.441231ms)
May 21 07:45:07.552: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname1/proxy/: foo (200; 59.91462ms)
May 21 07:45:07.552: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:462/proxy/: tls qux (200; 60.028838ms)
May 21 07:45:07.552: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/proxy/: bar (200; 60.165037ms)
May 21 07:45:07.561: INFO: (19) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/https:proxy-service-6br87:444/: tls qux (200; 68.807289ms)
May 21 07:45:07.561: INFO: (19) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname2/: bar (200; 69.408973ms)
May 21 07:45:07.561: INFO: (19) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:160/: foo (200; 69.270732ms)
May 21 07:45:07.561: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/proxy/: foo (200; 69.003686ms)
May 21 07:45:07.561: INFO: (19) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/... (200; 69.30913ms)
May 21 07:45:07.561: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:460/proxy/: tls baz (200; 69.021461ms)
May 21 07:45:07.562: INFO: (19) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:portname2/: bar (200; 69.434769ms)
May 21 07:45:07.562: INFO: (19) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/http:proxy-service-6br87:80/: foo (200; 69.230711ms)
May 21 07:45:07.562: INFO: (19) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:portname1/: foo (200; 69.078833ms)
May 21 07:45:07.562: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/https:proxy-service-6br87-qgztt:443/proxy/... (200; 69.714727ms)
May 21 07:45:07.562: INFO: (19) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/: <a href="/api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:1080/rewri... (200; 69.591241ms)
May 21 07:45:07.562: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:160/proxy/: foo (200; 69.103364ms)
May 21 07:45:07.562: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:1080/proxy/... (200; 69.15135ms)
May 21 07:45:07.562: INFO: (19) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/proxy-service-6br87-qgztt:162/: bar (200; 69.21038ms)
May 21 07:45:07.562: INFO: (19) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/pods/http:proxy-service-6br87-qgztt:162/: bar (200; 69.639158ms)
May 21 07:45:07.562: INFO: (19) /api/v1/proxy/namespaces/e2e-tests-proxy-wq6n8/services/proxy-service-6br87:80/: foo (200; 69.370046ms)
STEP: deleting { ReplicationController} proxy-service-6br87 in namespace e2e-tests-proxy-wq6n8
May 21 07:45:07.750: INFO: Deleting { ReplicationController} proxy-service-6br87 took: 122.484681ms
May 21 07:45:07.750: INFO: Terminating { ReplicationController} proxy-service-6br87 pods took: 41.863µs
May 21 07:45:16.150: INFO: Garbage collecting { ReplicationController} proxy-service-6br87 pods took: 8.522747902s
[AfterEach] version v1
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:45:16.150: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-wq6n8" for this suite.
May 21 07:45:22.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:45:23.618: INFO: namespace: e2e-tests-proxy-wq6n8, resource: bindings, ignored listing per whitelist
May 21 07:45:23.697: INFO: namespace e2e-tests-proxy-wq6n8 deletion completed in 7.516393002s

• [SLOW TEST:25.334 seconds]
[sig-network] Proxy
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:60
    should proxy through a service and a pod  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] Variable Expansion
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:45:23.697: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test env composition
May 21 07:45:23.858: INFO: Waiting up to 5m0s for pod "var-expansion-eb74663c-5cca-11e8-849c-0e182f31d764" in namespace "e2e-tests-var-expansion-gbnb4" to be "success or failure"
May 21 07:45:23.876: INFO: Pod "var-expansion-eb74663c-5cca-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 18.44162ms
May 21 07:45:25.893: INFO: Pod "var-expansion-eb74663c-5cca-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034547643s
May 21 07:45:27.909: INFO: Pod "var-expansion-eb74663c-5cca-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050856612s
STEP: Saw pod success
May 21 07:45:27.909: INFO: Pod "var-expansion-eb74663c-5cca-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:45:27.925: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod var-expansion-eb74663c-5cca-11e8-849c-0e182f31d764 container dapi-container: <nil>
STEP: delete the pod
May 21 07:45:27.979: INFO: Waiting for pod var-expansion-eb74663c-5cca-11e8-849c-0e182f31d764 to disappear
May 21 07:45:27.995: INFO: Pod var-expansion-eb74663c-5cca-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:45:27.995: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-gbnb4" for this suite.
May 21 07:45:34.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:45:34.715: INFO: namespace: e2e-tests-var-expansion-gbnb4, resource: bindings, ignored listing per whitelist
May 21 07:45:35.534: INFO: namespace e2e-tests-var-expansion-gbnb4 deletion completed in 7.509390523s

• [SLOW TEST:11.837 seconds]
[k8s.io] Variable Expansion
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  should allow composing env vars into new env vars  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-network] Networking
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:45:35.534: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-hch2k
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 21 07:45:35.666: INFO: Waiting up to 10m0s for all (but 1) nodes to be schedulable
STEP: Creating test pods
May 21 07:46:00.000: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.6.53:8080/dial?request=hostName&protocol=http&host=172.16.2.45&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-hch2k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:46:00.000: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
May 21 07:46:00.314: INFO: Waiting for endpoints: map[]
May 21 07:46:00.330: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.6.53:8080/dial?request=hostName&protocol=http&host=172.16.4.46&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-hch2k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:46:00.330: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
May 21 07:46:00.518: INFO: Waiting for endpoints: map[]
May 21 07:46:00.535: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.6.53:8080/dial?request=hostName&protocol=http&host=172.16.6.52&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-hch2k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:46:00.535: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
May 21 07:46:00.726: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:46:00.726: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-hch2k" for this suite.
May 21 07:46:22.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:46:23.848: INFO: namespace: e2e-tests-pod-network-test-hch2k, resource: bindings, ignored listing per whitelist
May 21 07:46:24.264: INFO: namespace e2e-tests-pod-network-test-hch2k deletion completed in 23.507242183s

• [SLOW TEST:48.730 seconds]
[sig-network] Networking
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] ConfigMap
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:46:24.264: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating configMap with name configmap-test-volume-0f8efd00-5ccb-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume configMaps
May 21 07:46:24.431: INFO: Waiting up to 5m0s for pod "pod-configmaps-0f919013-5ccb-11e8-849c-0e182f31d764" in namespace "e2e-tests-configmap-pv569" to be "success or failure"
May 21 07:46:24.449: INFO: Pod "pod-configmaps-0f919013-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 18.062639ms
May 21 07:46:26.465: INFO: Pod "pod-configmaps-0f919013-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034197927s
May 21 07:46:28.481: INFO: Pod "pod-configmaps-0f919013-5ccb-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050631285s
STEP: Saw pod success
May 21 07:46:28.481: INFO: Pod "pod-configmaps-0f919013-5ccb-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:46:28.498: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod pod-configmaps-0f919013-5ccb-11e8-849c-0e182f31d764 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 07:46:28.542: INFO: Waiting for pod pod-configmaps-0f919013-5ccb-11e8-849c-0e182f31d764 to disappear
May 21 07:46:28.557: INFO: Pod pod-configmaps-0f919013-5ccb-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:46:28.557: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-pv569" for this suite.
May 21 07:46:34.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:46:35.532: INFO: namespace: e2e-tests-configmap-pv569, resource: bindings, ignored listing per whitelist
May 21 07:46:36.100: INFO: namespace e2e-tests-configmap-pv569 deletion completed in 7.51296453s

• [SLOW TEST:11.835 seconds]
[sig-storage] ConfigMap
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-auth] ServiceAccounts
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:46:36.100: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: getting the auto-created API token
May 21 07:46:36.813: INFO: created pod pod-service-account-defaultsa
May 21 07:46:36.813: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May 21 07:46:36.830: INFO: created pod pod-service-account-mountsa
May 21 07:46:36.830: INFO: pod pod-service-account-mountsa service account token volume mount: true
May 21 07:46:36.847: INFO: created pod pod-service-account-nomountsa
May 21 07:46:36.847: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May 21 07:46:36.864: INFO: created pod pod-service-account-defaultsa-mountspec
May 21 07:46:36.864: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May 21 07:46:36.882: INFO: created pod pod-service-account-mountsa-mountspec
May 21 07:46:36.882: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May 21 07:46:36.902: INFO: created pod pod-service-account-nomountsa-mountspec
May 21 07:46:36.902: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May 21 07:46:36.921: INFO: created pod pod-service-account-defaultsa-nomountspec
May 21 07:46:36.921: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May 21 07:46:36.940: INFO: created pod pod-service-account-mountsa-nomountspec
May 21 07:46:36.940: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May 21 07:46:36.960: INFO: created pod pod-service-account-nomountsa-nomountspec
May 21 07:46:36.960: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:46:36.960: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-l4w4n" for this suite.
May 21 07:46:43.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:46:44.460: INFO: namespace: e2e-tests-svcaccounts-l4w4n, resource: bindings, ignored listing per whitelist
May 21 07:46:44.491: INFO: namespace e2e-tests-svcaccounts-l4w4n deletion completed in 7.515811783s

• [SLOW TEST:8.391 seconds]
[sig-auth] ServiceAccounts
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-network] Service endpoints latency
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:46:44.491: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-lt8c4
I0521 07:46:44.669967   24333 runners.go:178] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-lt8c4, replica count: 1
I0521 07:46:45.720442   24333 runners.go:178] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0521 07:46:46.720686   24333 runners.go:178] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0521 07:46:47.720932   24333 runners.go:178] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0521 07:46:48.721202   24333 runners.go:178] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 21 07:46:48.840: INFO: Created: latency-svc-rlz4j
May 21 07:46:48.854: INFO: Got endpoints: latency-svc-rlz4j [32.566868ms]
May 21 07:46:48.902: INFO: Created: latency-svc-bwxm2
May 21 07:46:48.906: INFO: Got endpoints: latency-svc-bwxm2 [52.679154ms]
May 21 07:46:48.913: INFO: Created: latency-svc-jjtmr
May 21 07:46:48.919: INFO: Got endpoints: latency-svc-jjtmr [64.897981ms]
May 21 07:46:48.927: INFO: Created: latency-svc-wwxkc
May 21 07:46:48.931: INFO: Created: latency-svc-g229f
May 21 07:46:48.934: INFO: Got endpoints: latency-svc-wwxkc [80.220872ms]
May 21 07:46:48.936: INFO: Got endpoints: latency-svc-g229f [82.229327ms]
May 21 07:46:48.945: INFO: Created: latency-svc-x4rrn
May 21 07:46:48.948: INFO: Got endpoints: latency-svc-x4rrn [94.64832ms]
May 21 07:46:48.955: INFO: Created: latency-svc-85r7r
May 21 07:46:48.961: INFO: Got endpoints: latency-svc-85r7r [106.863268ms]
May 21 07:46:48.967: INFO: Created: latency-svc-fbjnn
May 21 07:46:48.978: INFO: Got endpoints: latency-svc-fbjnn [124.20423ms]
May 21 07:46:48.982: INFO: Created: latency-svc-m9c7l
May 21 07:46:48.990: INFO: Created: latency-svc-z2gg4
May 21 07:46:48.996: INFO: Got endpoints: latency-svc-m9c7l [142.220646ms]
May 21 07:46:48.999: INFO: Got endpoints: latency-svc-z2gg4 [145.202263ms]
May 21 07:46:49.003: INFO: Created: latency-svc-z7lf5
May 21 07:46:49.007: INFO: Got endpoints: latency-svc-z7lf5 [153.751657ms]
May 21 07:46:49.015: INFO: Created: latency-svc-jd9dg
May 21 07:46:49.017: INFO: Created: latency-svc-kdtld
May 21 07:46:49.018: INFO: Got endpoints: latency-svc-kdtld [163.935201ms]
May 21 07:46:49.027: INFO: Got endpoints: latency-svc-jd9dg [172.852994ms]
May 21 07:46:49.031: INFO: Created: latency-svc-s4cdt
May 21 07:46:49.034: INFO: Created: latency-svc-nv2f5
May 21 07:46:49.036: INFO: Got endpoints: latency-svc-s4cdt [181.702095ms]
May 21 07:46:49.043: INFO: Created: latency-svc-crwwj
May 21 07:46:49.044: INFO: Got endpoints: latency-svc-nv2f5 [190.381533ms]
May 21 07:46:49.051: INFO: Got endpoints: latency-svc-crwwj [196.909259ms]
May 21 07:46:49.071: INFO: Created: latency-svc-zjs4b
May 21 07:46:49.073: INFO: Created: latency-svc-zpgvj
May 21 07:46:49.073: INFO: Got endpoints: latency-svc-zjs4b [166.696512ms]
May 21 07:46:49.081: INFO: Got endpoints: latency-svc-zpgvj [161.969229ms]
May 21 07:46:49.083: INFO: Created: latency-svc-vcccg
May 21 07:46:49.084: INFO: Got endpoints: latency-svc-vcccg [149.965289ms]
May 21 07:46:49.092: INFO: Created: latency-svc-bd9hp
May 21 07:46:49.092: INFO: Created: latency-svc-n4qxz
May 21 07:46:49.100: INFO: Created: latency-svc-wrpf4
May 21 07:46:49.102: INFO: Got endpoints: latency-svc-n4qxz [165.737992ms]
May 21 07:46:49.107: INFO: Created: latency-svc-l9hb7
May 21 07:46:49.112: INFO: Got endpoints: latency-svc-bd9hp [163.668235ms]
May 21 07:46:49.118: INFO: Created: latency-svc-ghqhs
May 21 07:46:49.120: INFO: Got endpoints: latency-svc-l9hb7 [142.386223ms]
May 21 07:46:49.121: INFO: Got endpoints: latency-svc-wrpf4 [159.956073ms]
May 21 07:46:49.128: INFO: Got endpoints: latency-svc-ghqhs [131.755428ms]
May 21 07:46:49.137: INFO: Created: latency-svc-vwh8k
May 21 07:46:49.137: INFO: Got endpoints: latency-svc-vwh8k [138.371184ms]
May 21 07:46:49.141: INFO: Created: latency-svc-hdmxt
May 21 07:46:49.150: INFO: Created: latency-svc-mpksr
May 21 07:46:49.153: INFO: Got endpoints: latency-svc-hdmxt [145.139204ms]
May 21 07:46:49.156: INFO: Created: latency-svc-fmktz
May 21 07:46:49.160: INFO: Got endpoints: latency-svc-fmktz [133.321776ms]
May 21 07:46:49.162: INFO: Created: latency-svc-77sgs
May 21 07:46:49.165: INFO: Got endpoints: latency-svc-mpksr [147.241563ms]
May 21 07:46:49.169: INFO: Created: latency-svc-wxpd4
May 21 07:46:49.171: INFO: Got endpoints: latency-svc-77sgs [135.334519ms]
May 21 07:46:49.180: INFO: Created: latency-svc-bbtmk
May 21 07:46:49.182: INFO: Got endpoints: latency-svc-wxpd4 [138.256856ms]
May 21 07:46:49.189: INFO: Got endpoints: latency-svc-bbtmk [138.174867ms]
May 21 07:46:49.200: INFO: Created: latency-svc-jsntf
May 21 07:46:49.207: INFO: Got endpoints: latency-svc-jsntf [133.645131ms]
May 21 07:46:49.209: INFO: Created: latency-svc-j9gpb
May 21 07:46:49.213: INFO: Created: latency-svc-9vlw9
May 21 07:46:49.225: INFO: Created: latency-svc-7d5xm
May 21 07:46:49.227: INFO: Got endpoints: latency-svc-j9gpb [146.352159ms]
May 21 07:46:49.227: INFO: Got endpoints: latency-svc-9vlw9 [143.220675ms]
May 21 07:46:49.235: INFO: Created: latency-svc-sm5ck
May 21 07:46:49.243: INFO: Created: latency-svc-67kn5
May 21 07:46:49.246: INFO: Got endpoints: latency-svc-7d5xm [144.123387ms]
May 21 07:46:49.246: INFO: Got endpoints: latency-svc-sm5ck [134.015927ms]
May 21 07:46:49.253: INFO: Got endpoints: latency-svc-67kn5 [132.479912ms]
May 21 07:46:49.256: INFO: Created: latency-svc-4j6v7
May 21 07:46:49.274: INFO: Got endpoints: latency-svc-4j6v7 [152.861464ms]
May 21 07:46:49.274: INFO: Created: latency-svc-dbdp2
May 21 07:46:49.274: INFO: Created: latency-svc-8jm86
May 21 07:46:49.274: INFO: Created: latency-svc-xlfxm
May 21 07:46:49.276: INFO: Created: latency-svc-92vq7
May 21 07:46:49.281: INFO: Created: latency-svc-f694d
May 21 07:46:49.286: INFO: Created: latency-svc-htc8m
May 21 07:46:49.290: INFO: Got endpoints: latency-svc-8jm86 [162.416451ms]
May 21 07:46:49.292: INFO: Got endpoints: latency-svc-f694d [127.247742ms]
May 21 07:46:49.299: INFO: Created: latency-svc-9t2xg
May 21 07:46:49.310: INFO: Created: latency-svc-4nxv5
May 21 07:46:49.315: INFO: Got endpoints: latency-svc-92vq7 [155.552706ms]
May 21 07:46:49.316: INFO: Got endpoints: latency-svc-dbdp2 [178.129034ms]
May 21 07:46:49.316: INFO: Got endpoints: latency-svc-xlfxm [163.031835ms]
May 21 07:46:49.324: INFO: Got endpoints: latency-svc-9t2xg [141.943635ms]
May 21 07:46:49.325: INFO: Got endpoints: latency-svc-htc8m [153.519828ms]
May 21 07:46:49.332: INFO: Created: latency-svc-jfhvf
May 21 07:46:49.332: INFO: Got endpoints: latency-svc-4nxv5 [143.121894ms]
May 21 07:46:49.340: INFO: Created: latency-svc-kbzbc
May 21 07:46:49.342: INFO: Got endpoints: latency-svc-jfhvf [135.398384ms]
May 21 07:46:49.352: INFO: Got endpoints: latency-svc-kbzbc [125.315434ms]
May 21 07:46:49.355: INFO: Created: latency-svc-f89f2
May 21 07:46:49.359: INFO: Got endpoints: latency-svc-f89f2 [132.036649ms]
May 21 07:46:49.361: INFO: Created: latency-svc-2rlmw
May 21 07:46:49.368: INFO: Got endpoints: latency-svc-2rlmw [122.360155ms]
May 21 07:46:49.368: INFO: Created: latency-svc-xnplk
May 21 07:46:49.375: INFO: Created: latency-svc-689ls
May 21 07:46:49.383: INFO: Got endpoints: latency-svc-689ls [129.952459ms]
May 21 07:46:49.383: INFO: Got endpoints: latency-svc-xnplk [136.865488ms]
May 21 07:46:49.386: INFO: Created: latency-svc-7fmg4
May 21 07:46:49.390: INFO: Got endpoints: latency-svc-7fmg4 [116.01498ms]
May 21 07:46:49.397: INFO: Created: latency-svc-hqpj2
May 21 07:46:49.401: INFO: Got endpoints: latency-svc-hqpj2 [41.852938ms]
May 21 07:46:49.401: INFO: Created: latency-svc-npxxx
May 21 07:46:49.413: INFO: Got endpoints: latency-svc-npxxx [122.590236ms]
May 21 07:46:49.419: INFO: Created: latency-svc-sgnjd
May 21 07:46:49.423: INFO: Created: latency-svc-s6j7r
May 21 07:46:49.428: INFO: Got endpoints: latency-svc-s6j7r [112.818659ms]
May 21 07:46:49.429: INFO: Got endpoints: latency-svc-sgnjd [136.11763ms]
May 21 07:46:49.431: INFO: Created: latency-svc-s7n5t
May 21 07:46:49.437: INFO: Got endpoints: latency-svc-s7n5t [120.837252ms]
May 21 07:46:49.441: INFO: Created: latency-svc-6gjj9
May 21 07:46:49.446: INFO: Got endpoints: latency-svc-6gjj9 [130.499457ms]
May 21 07:46:49.449: INFO: Created: latency-svc-4hkhj
May 21 07:46:49.461: INFO: Got endpoints: latency-svc-4hkhj [136.354476ms]
May 21 07:46:49.463: INFO: Created: latency-svc-n8jj5
May 21 07:46:49.473: INFO: Created: latency-svc-zmkxc
May 21 07:46:49.478: INFO: Created: latency-svc-kjtnw
May 21 07:46:49.482: INFO: Got endpoints: latency-svc-zmkxc [150.1962ms]
May 21 07:46:49.482: INFO: Got endpoints: latency-svc-n8jj5 [157.777923ms]
May 21 07:46:49.485: INFO: Got endpoints: latency-svc-kjtnw [142.874839ms]
May 21 07:46:49.490: INFO: Created: latency-svc-8qrkp
May 21 07:46:49.493: INFO: Created: latency-svc-dflzz
May 21 07:46:49.499: INFO: Got endpoints: latency-svc-dflzz [130.1578ms]
May 21 07:46:49.499: INFO: Got endpoints: latency-svc-8qrkp [146.491092ms]
May 21 07:46:49.505: INFO: Created: latency-svc-fc8c7
May 21 07:46:49.514: INFO: Got endpoints: latency-svc-fc8c7 [131.391858ms]
May 21 07:46:49.520: INFO: Created: latency-svc-tpklp
May 21 07:46:49.526: INFO: Created: latency-svc-5d7nr
May 21 07:46:49.526: INFO: Created: latency-svc-jzxmb
May 21 07:46:49.532: INFO: Got endpoints: latency-svc-tpklp [148.410484ms]
May 21 07:46:49.541: INFO: Got endpoints: latency-svc-5d7nr [151.053438ms]
May 21 07:46:49.557: INFO: Got endpoints: latency-svc-jzxmb [155.826246ms]
May 21 07:46:49.558: INFO: Created: latency-svc-4hmp7
May 21 07:46:49.558: INFO: Got endpoints: latency-svc-4hmp7 [145.031213ms]
May 21 07:46:49.560: INFO: Created: latency-svc-sd8tm
May 21 07:46:49.560: INFO: Created: latency-svc-5kmj2
May 21 07:46:49.560: INFO: Created: latency-svc-kknwz
May 21 07:46:49.582: INFO: Got endpoints: latency-svc-sd8tm [153.450573ms]
May 21 07:46:49.582: INFO: Got endpoints: latency-svc-5kmj2 [145.345685ms]
May 21 07:46:49.582: INFO: Got endpoints: latency-svc-kknwz [153.416155ms]
May 21 07:46:49.589: INFO: Created: latency-svc-fpqjb
May 21 07:46:49.594: INFO: Created: latency-svc-z4xqg
May 21 07:46:49.607: INFO: Created: latency-svc-6pth6
May 21 07:46:49.617: INFO: Created: latency-svc-7z8qp
May 21 07:46:49.629: INFO: Got endpoints: latency-svc-6pth6 [146.457397ms]
May 21 07:46:49.629: INFO: Got endpoints: latency-svc-fpqjb [182.71315ms]
May 21 07:46:49.631: INFO: Got endpoints: latency-svc-z4xqg [170.661464ms]
May 21 07:46:49.640: INFO: Got endpoints: latency-svc-7z8qp [157.082905ms]
May 21 07:46:49.648: INFO: Created: latency-svc-wf7m2
May 21 07:46:49.649: INFO: Created: latency-svc-4vk6b
May 21 07:46:49.650: INFO: Created: latency-svc-f4n6k
May 21 07:46:49.654: INFO: Created: latency-svc-wxvp9
May 21 07:46:49.669: INFO: Got endpoints: latency-svc-f4n6k [169.857089ms]
May 21 07:46:49.669: INFO: Created: latency-svc-2qc7s
May 21 07:46:49.682: INFO: Got endpoints: latency-svc-2qc7s [150.38441ms]
May 21 07:46:49.682: INFO: Got endpoints: latency-svc-wf7m2 [183.459267ms]
May 21 07:46:49.688: INFO: Created: latency-svc-wzcqn
May 21 07:46:49.688: INFO: Created: latency-svc-k47hb
May 21 07:46:49.693: INFO: Created: latency-svc-tcrth
May 21 07:46:49.700: INFO: Got endpoints: latency-svc-4vk6b [215.435967ms]
May 21 07:46:49.701: INFO: Got endpoints: latency-svc-wxvp9 [186.235693ms]
May 21 07:46:49.701: INFO: Created: latency-svc-9wgcd
May 21 07:46:49.709: INFO: Got endpoints: latency-svc-wzcqn [151.850669ms]
May 21 07:46:49.709: INFO: Got endpoints: latency-svc-k47hb [168.198442ms]
May 21 07:46:49.714: INFO: Got endpoints: latency-svc-9wgcd [132.486187ms]
May 21 07:46:49.714: INFO: Got endpoints: latency-svc-tcrth [156.512589ms]
May 21 07:46:49.716: INFO: Created: latency-svc-q5v8r
May 21 07:46:49.723: INFO: Created: latency-svc-749hn
May 21 07:46:49.781: INFO: Got endpoints: latency-svc-749hn [199.436218ms]
May 21 07:46:49.781: INFO: Got endpoints: latency-svc-q5v8r [199.478265ms]
May 21 07:46:49.805: INFO: Created: latency-svc-nkrnc
May 21 07:46:49.851: INFO: Created: latency-svc-qgm6d
May 21 07:46:49.860: INFO: Got endpoints: latency-svc-nkrnc [230.739228ms]
May 21 07:46:49.869: INFO: Created: latency-svc-sp52m
May 21 07:46:49.891: INFO: Got endpoints: latency-svc-sp52m [259.850884ms]
May 21 07:46:49.891: INFO: Got endpoints: latency-svc-qgm6d [262.535401ms]
May 21 07:46:49.917: INFO: Created: latency-svc-bbfcc
May 21 07:46:49.920: INFO: Got endpoints: latency-svc-bbfcc [280.16716ms]
May 21 07:46:49.950: INFO: Created: latency-svc-7gslp
May 21 07:46:49.964: INFO: Created: latency-svc-kf87d
May 21 07:46:49.978: INFO: Created: latency-svc-qc6xg
May 21 07:46:49.991: INFO: Created: latency-svc-khgnw
May 21 07:46:50.008: INFO: Got endpoints: latency-svc-kf87d [326.015409ms]
May 21 07:46:50.017: INFO: Created: latency-svc-5r2m8
May 21 07:46:50.047: INFO: Created: latency-svc-zkbzx
May 21 07:46:50.051: INFO: Got endpoints: latency-svc-5r2m8 [350.038364ms]
May 21 07:46:50.096: INFO: Created: latency-svc-sjbjc
May 21 07:46:50.096: INFO: Got endpoints: latency-svc-khgnw [395.227628ms]
May 21 07:46:50.096: INFO: Got endpoints: latency-svc-7gslp [427.195903ms]
May 21 07:46:50.096: INFO: Got endpoints: latency-svc-qc6xg [413.779751ms]
May 21 07:46:50.128: INFO: Got endpoints: latency-svc-sjbjc [413.584664ms]
May 21 07:46:50.128: INFO: Got endpoints: latency-svc-zkbzx [419.417959ms]
May 21 07:46:50.151: INFO: Created: latency-svc-p7fd9
May 21 07:46:50.182: INFO: Got endpoints: latency-svc-p7fd9 [473.243972ms]
May 21 07:46:50.188: INFO: Created: latency-svc-m9t4v
May 21 07:46:50.196: INFO: Got endpoints: latency-svc-m9t4v [482.095799ms]
May 21 07:46:50.202: INFO: Created: latency-svc-mgvlq
May 21 07:46:50.209: INFO: Got endpoints: latency-svc-mgvlq [428.026382ms]
May 21 07:46:50.225: INFO: Created: latency-svc-79ftv
May 21 07:46:50.240: INFO: Got endpoints: latency-svc-79ftv [458.558685ms]
May 21 07:46:50.247: INFO: Created: latency-svc-2cjv9
May 21 07:46:50.248: INFO: Created: latency-svc-k4ctt
May 21 07:46:50.254: INFO: Created: latency-svc-2rk95
May 21 07:46:50.270: INFO: Created: latency-svc-2w7z7
May 21 07:46:50.272: INFO: Got endpoints: latency-svc-2rk95 [380.121551ms]
May 21 07:46:50.272: INFO: Got endpoints: latency-svc-2cjv9 [412.165058ms]
May 21 07:46:50.272: INFO: Got endpoints: latency-svc-k4ctt [380.392933ms]
May 21 07:46:50.282: INFO: Created: latency-svc-jgqpd
May 21 07:46:50.285: INFO: Got endpoints: latency-svc-2w7z7 [364.856033ms]
May 21 07:46:50.296: INFO: Got endpoints: latency-svc-jgqpd [287.900955ms]
May 21 07:46:50.298: INFO: Created: latency-svc-wkwnq
May 21 07:46:50.298: INFO: Created: latency-svc-2894z
May 21 07:46:50.298: INFO: Got endpoints: latency-svc-2894z [247.627202ms]
May 21 07:46:50.303: INFO: Created: latency-svc-nrxxz
May 21 07:46:50.307: INFO: Got endpoints: latency-svc-wkwnq [211.106674ms]
May 21 07:46:50.311: INFO: Created: latency-svc-xjq72
May 21 07:46:50.321: INFO: Got endpoints: latency-svc-nrxxz [225.491735ms]
May 21 07:46:50.325: INFO: Created: latency-svc-sd77t
May 21 07:46:50.327: INFO: Got endpoints: latency-svc-xjq72 [231.044803ms]
May 21 07:46:50.329: INFO: Got endpoints: latency-svc-sd77t [200.325598ms]
May 21 07:46:50.334: INFO: Created: latency-svc-skg5w
May 21 07:46:50.339: INFO: Created: latency-svc-qmdbs
May 21 07:46:50.345: INFO: Created: latency-svc-8q27p
May 21 07:46:50.345: INFO: Got endpoints: latency-svc-qmdbs [163.296584ms]
May 21 07:46:50.345: INFO: Got endpoints: latency-svc-skg5w [217.341553ms]
May 21 07:46:50.350: INFO: Got endpoints: latency-svc-8q27p [153.631408ms]
May 21 07:46:50.355: INFO: Created: latency-svc-rc787
May 21 07:46:50.356: INFO: Got endpoints: latency-svc-rc787 [146.595674ms]
May 21 07:46:50.365: INFO: Created: latency-svc-77n9s
May 21 07:46:50.368: INFO: Got endpoints: latency-svc-77n9s [127.702311ms]
May 21 07:46:50.370: INFO: Created: latency-svc-ndnn5
May 21 07:46:50.374: INFO: Got endpoints: latency-svc-ndnn5 [102.24063ms]
May 21 07:46:50.375: INFO: Created: latency-svc-z5kp9
May 21 07:46:50.383: INFO: Created: latency-svc-nkj5h
May 21 07:46:50.392: INFO: Created: latency-svc-ss7h6
May 21 07:46:50.397: INFO: Got endpoints: latency-svc-nkj5h [125.522301ms]
May 21 07:46:50.397: INFO: Got endpoints: latency-svc-z5kp9 [125.629035ms]
May 21 07:46:50.409: INFO: Got endpoints: latency-svc-ss7h6 [124.370058ms]
May 21 07:46:50.412: INFO: Created: latency-svc-xtjms
May 21 07:46:50.412: INFO: Got endpoints: latency-svc-xtjms [116.246324ms]
May 21 07:46:50.420: INFO: Created: latency-svc-n8hsw
May 21 07:46:50.425: INFO: Got endpoints: latency-svc-n8hsw [126.627883ms]
May 21 07:46:50.435: INFO: Created: latency-svc-fjb6z
May 21 07:46:50.436: INFO: Got endpoints: latency-svc-fjb6z [129.133586ms]
May 21 07:46:50.436: INFO: Created: latency-svc-5r6jp
May 21 07:46:50.438: INFO: Got endpoints: latency-svc-5r6jp [116.289357ms]
May 21 07:46:50.442: INFO: Created: latency-svc-2mmdd
May 21 07:46:50.446: INFO: Created: latency-svc-w8qcz
May 21 07:46:50.449: INFO: Got endpoints: latency-svc-2mmdd [122.154594ms]
May 21 07:46:50.459: INFO: Got endpoints: latency-svc-w8qcz [130.641887ms]
May 21 07:46:50.460: INFO: Created: latency-svc-2sttj
May 21 07:46:50.476: INFO: Created: latency-svc-cr7dp
May 21 07:46:50.476: INFO: Created: latency-svc-jr9kr
May 21 07:46:50.480: INFO: Created: latency-svc-dmlzx
May 21 07:46:50.481: INFO: Got endpoints: latency-svc-2sttj [135.951597ms]
May 21 07:46:50.482: INFO: Got endpoints: latency-svc-jr9kr [131.498176ms]
May 21 07:46:50.482: INFO: Got endpoints: latency-svc-cr7dp [136.124146ms]
May 21 07:46:50.489: INFO: Got endpoints: latency-svc-dmlzx [133.08424ms]
May 21 07:46:50.496: INFO: Created: latency-svc-js6rj
May 21 07:46:50.503: INFO: Created: latency-svc-zmwxb
May 21 07:46:50.504: INFO: Got endpoints: latency-svc-js6rj [136.486638ms]
May 21 07:46:50.507: INFO: Created: latency-svc-9967s
May 21 07:46:50.512: INFO: Got endpoints: latency-svc-9967s [138.304903ms]
May 21 07:46:50.515: INFO: Got endpoints: latency-svc-zmwxb [117.782026ms]
May 21 07:46:50.522: INFO: Created: latency-svc-vn4hb
May 21 07:46:50.522: INFO: Got endpoints: latency-svc-vn4hb [124.963334ms]
May 21 07:46:50.527: INFO: Created: latency-svc-vgj4v
May 21 07:46:50.536: INFO: Created: latency-svc-tvnf9
May 21 07:46:50.536: INFO: Got endpoints: latency-svc-vgj4v [127.369091ms]
May 21 07:46:50.543: INFO: Got endpoints: latency-svc-tvnf9 [130.388841ms]
May 21 07:46:50.547: INFO: Created: latency-svc-k4v6d
May 21 07:46:50.554: INFO: Created: latency-svc-mm626
May 21 07:46:50.559: INFO: Created: latency-svc-rvx6z
May 21 07:46:50.563: INFO: Got endpoints: latency-svc-mm626 [126.604133ms]
May 21 07:46:50.563: INFO: Got endpoints: latency-svc-k4v6d [137.743626ms]
May 21 07:46:50.576: INFO: Got endpoints: latency-svc-rvx6z [137.737764ms]
May 21 07:46:50.578: INFO: Created: latency-svc-ff2lf
May 21 07:46:50.584: INFO: Got endpoints: latency-svc-ff2lf [135.222048ms]
May 21 07:46:50.588: INFO: Created: latency-svc-kbwjg
May 21 07:46:50.601: INFO: Created: latency-svc-lkmqj
May 21 07:46:50.602: INFO: Got endpoints: latency-svc-kbwjg [143.205382ms]
May 21 07:46:50.605: INFO: Created: latency-svc-sg9wc
May 21 07:46:50.609: INFO: Got endpoints: latency-svc-lkmqj [127.233016ms]
May 21 07:46:50.610: INFO: Created: latency-svc-b9qfq
May 21 07:46:50.614: INFO: Got endpoints: latency-svc-sg9wc [131.858675ms]
May 21 07:46:50.620: INFO: Got endpoints: latency-svc-b9qfq [138.690093ms]
May 21 07:46:50.626: INFO: Created: latency-svc-6z7lr
May 21 07:46:50.631: INFO: Got endpoints: latency-svc-6z7lr [142.055661ms]
May 21 07:46:50.635: INFO: Created: latency-svc-lg9w4
May 21 07:46:50.639: INFO: Created: latency-svc-z5rfm
May 21 07:46:50.643: INFO: Got endpoints: latency-svc-z5rfm [130.621691ms]
May 21 07:46:50.644: INFO: Created: latency-svc-4q4vt
May 21 07:46:50.647: INFO: Got endpoints: latency-svc-lg9w4 [142.449931ms]
May 21 07:46:50.650: INFO: Got endpoints: latency-svc-4q4vt [135.299302ms]
May 21 07:46:50.655: INFO: Created: latency-svc-gbv49
May 21 07:46:50.661: INFO: Got endpoints: latency-svc-gbv49 [138.936523ms]
May 21 07:46:50.665: INFO: Created: latency-svc-czkr7
May 21 07:46:50.671: INFO: Got endpoints: latency-svc-czkr7 [134.592603ms]
May 21 07:46:50.677: INFO: Created: latency-svc-srwlt
May 21 07:46:50.702: INFO: Created: latency-svc-db2bm
May 21 07:46:50.704: INFO: Created: latency-svc-s975m
May 21 07:46:50.707: INFO: Created: latency-svc-htmtv
May 21 07:46:50.707: INFO: Got endpoints: latency-svc-s975m [144.221976ms]
May 21 07:46:50.707: INFO: Got endpoints: latency-svc-srwlt [164.364844ms]
May 21 07:46:50.717: INFO: Got endpoints: latency-svc-db2bm [153.690051ms]
May 21 07:46:50.724: INFO: Created: latency-svc-7jfj7
May 21 07:46:50.724: INFO: Got endpoints: latency-svc-htmtv [148.336898ms]
May 21 07:46:50.732: INFO: Created: latency-svc-g7g4h
May 21 07:46:50.735: INFO: Got endpoints: latency-svc-g7g4h [133.0336ms]
May 21 07:46:50.738: INFO: Got endpoints: latency-svc-7jfj7 [153.981675ms]
May 21 07:46:50.755: INFO: Created: latency-svc-m8s76
May 21 07:46:50.764: INFO: Got endpoints: latency-svc-m8s76 [155.599815ms]
May 21 07:46:50.768: INFO: Created: latency-svc-9bfp5
May 21 07:46:50.774: INFO: Created: latency-svc-w45gj
May 21 07:46:50.783: INFO: Got endpoints: latency-svc-w45gj [162.901697ms]
May 21 07:46:50.783: INFO: Got endpoints: latency-svc-9bfp5 [169.899714ms]
May 21 07:46:50.791: INFO: Created: latency-svc-q9dkm
May 21 07:46:50.791: INFO: Got endpoints: latency-svc-q9dkm [159.720781ms]
May 21 07:46:50.800: INFO: Created: latency-svc-c4dxv
May 21 07:46:50.802: INFO: Got endpoints: latency-svc-c4dxv [159.323112ms]
May 21 07:46:50.818: INFO: Created: latency-svc-ms2vr
May 21 07:46:50.823: INFO: Got endpoints: latency-svc-ms2vr [176.671735ms]
May 21 07:46:50.829: INFO: Created: latency-svc-xm2qm
May 21 07:46:50.842: INFO: Created: latency-svc-qx4h7
May 21 07:46:50.842: INFO: Got endpoints: latency-svc-xm2qm [191.954423ms]
May 21 07:46:50.849: INFO: Created: latency-svc-87zmn
May 21 07:46:50.852: INFO: Got endpoints: latency-svc-qx4h7 [190.868805ms]
May 21 07:46:50.860: INFO: Got endpoints: latency-svc-87zmn [188.435226ms]
May 21 07:46:50.860: INFO: Created: latency-svc-dptpv
May 21 07:46:50.875: INFO: Created: latency-svc-scvzw
May 21 07:46:50.876: INFO: Created: latency-svc-jlz95
May 21 07:46:50.876: INFO: Got endpoints: latency-svc-dptpv [168.84917ms]
May 21 07:46:50.876: INFO: Got endpoints: latency-svc-scvzw [169.084879ms]
May 21 07:46:50.882: INFO: Got endpoints: latency-svc-jlz95 [165.577682ms]
May 21 07:46:50.883: INFO: Created: latency-svc-v8mmt
May 21 07:46:50.892: INFO: Created: latency-svc-fxr7d
May 21 07:46:50.896: INFO: Got endpoints: latency-svc-v8mmt [160.425475ms]
May 21 07:46:50.902: INFO: Got endpoints: latency-svc-fxr7d [163.61891ms]
May 21 07:46:50.914: INFO: Created: latency-svc-fcfhv
May 21 07:46:50.921: INFO: Got endpoints: latency-svc-fcfhv [197.160491ms]
May 21 07:46:50.921: INFO: Created: latency-svc-zlqlm
May 21 07:46:50.928: INFO: Created: latency-svc-k5hzm
May 21 07:46:50.929: INFO: Got endpoints: latency-svc-zlqlm [164.225774ms]
May 21 07:46:50.940: INFO: Got endpoints: latency-svc-k5hzm [157.134234ms]
May 21 07:46:50.944: INFO: Created: latency-svc-74tkj
May 21 07:46:50.947: INFO: Got endpoints: latency-svc-74tkj [163.461908ms]
May 21 07:46:50.961: INFO: Created: latency-svc-npxq5
May 21 07:46:50.962: INFO: Created: latency-svc-fhwb6
May 21 07:46:50.962: INFO: Got endpoints: latency-svc-fhwb6 [171.353708ms]
May 21 07:46:50.970: INFO: Created: latency-svc-llw98
May 21 07:46:50.976: INFO: Got endpoints: latency-svc-npxq5 [173.355363ms]
May 21 07:46:50.986: INFO: Created: latency-svc-97qkp
May 21 07:46:50.987: INFO: Got endpoints: latency-svc-llw98 [163.498186ms]
May 21 07:46:50.997: INFO: Created: latency-svc-lwjvw
May 21 07:46:50.997: INFO: Got endpoints: latency-svc-lwjvw [144.841544ms]
May 21 07:46:50.997: INFO: Got endpoints: latency-svc-97qkp [154.778795ms]
May 21 07:46:51.002: INFO: Created: latency-svc-gw486
May 21 07:46:51.004: INFO: Got endpoints: latency-svc-gw486 [144.830247ms]
May 21 07:46:51.007: INFO: Created: latency-svc-qgflx
May 21 07:46:51.024: INFO: Created: latency-svc-p74nw
May 21 07:46:51.025: INFO: Got endpoints: latency-svc-qgflx [149.036785ms]
May 21 07:46:51.029: INFO: Got endpoints: latency-svc-p74nw [152.98309ms]
May 21 07:46:51.036: INFO: Created: latency-svc-4lfdb
May 21 07:46:51.049: INFO: Got endpoints: latency-svc-4lfdb [166.93779ms]
May 21 07:46:51.071: INFO: Created: latency-svc-sfggd
May 21 07:46:51.077: INFO: Got endpoints: latency-svc-sfggd [181.024823ms]
May 21 07:46:51.079: INFO: Created: latency-svc-jjlz2
May 21 07:46:51.088: INFO: Got endpoints: latency-svc-jjlz2 [186.300408ms]
May 21 07:46:51.096: INFO: Created: latency-svc-zv4dn
May 21 07:46:51.108: INFO: Got endpoints: latency-svc-zv4dn [186.561335ms]
May 21 07:46:51.115: INFO: Created: latency-svc-dccg6
May 21 07:46:51.115: INFO: Got endpoints: latency-svc-dccg6 [186.06346ms]
May 21 07:46:51.118: INFO: Created: latency-svc-s7thr
May 21 07:46:51.132: INFO: Got endpoints: latency-svc-s7thr [191.934238ms]
May 21 07:46:51.150: INFO: Created: latency-svc-d94n9
May 21 07:46:51.160: INFO: Created: latency-svc-hcktd
May 21 07:46:51.164: INFO: Got endpoints: latency-svc-d94n9 [216.971414ms]
May 21 07:46:51.175: INFO: Created: latency-svc-dn27n
May 21 07:46:51.176: INFO: Got endpoints: latency-svc-hcktd [213.744188ms]
May 21 07:46:51.178: INFO: Got endpoints: latency-svc-dn27n [202.703839ms]
May 21 07:46:51.191: INFO: Created: latency-svc-rq9qz
May 21 07:46:51.192: INFO: Got endpoints: latency-svc-rq9qz [205.128105ms]
May 21 07:46:51.204: INFO: Created: latency-svc-nbr5f
May 21 07:46:51.205: INFO: Got endpoints: latency-svc-nbr5f [207.378531ms]
May 21 07:46:51.214: INFO: Created: latency-svc-cxchf
May 21 07:46:51.231: INFO: Got endpoints: latency-svc-cxchf [233.718514ms]
May 21 07:46:51.250: INFO: Created: latency-svc-m2lx8
May 21 07:46:51.262: INFO: Got endpoints: latency-svc-m2lx8 [257.894883ms]
May 21 07:46:51.276: INFO: Created: latency-svc-nc6l8
May 21 07:46:51.287: INFO: Got endpoints: latency-svc-nc6l8 [262.437051ms]
May 21 07:46:51.287: INFO: Created: latency-svc-m8tpf
May 21 07:46:51.306: INFO: Got endpoints: latency-svc-m8tpf [276.474674ms]
May 21 07:46:51.320: INFO: Created: latency-svc-8lsb8
May 21 07:46:51.326: INFO: Got endpoints: latency-svc-8lsb8 [276.738947ms]
May 21 07:46:51.328: INFO: Created: latency-svc-qsct2
May 21 07:46:51.336: INFO: Got endpoints: latency-svc-qsct2 [259.165484ms]
May 21 07:46:51.336: INFO: Latencies: [41.852938ms 52.679154ms 64.897981ms 80.220872ms 82.229327ms 94.64832ms 102.24063ms 106.863268ms 112.818659ms 116.01498ms 116.246324ms 116.289357ms 117.782026ms 120.837252ms 122.154594ms 122.360155ms 122.590236ms 124.20423ms 124.370058ms 124.963334ms 125.315434ms 125.522301ms 125.629035ms 126.604133ms 126.627883ms 127.233016ms 127.247742ms 127.369091ms 127.702311ms 129.133586ms 129.952459ms 130.1578ms 130.388841ms 130.499457ms 130.621691ms 130.641887ms 131.391858ms 131.498176ms 131.755428ms 131.858675ms 132.036649ms 132.479912ms 132.486187ms 133.0336ms 133.08424ms 133.321776ms 133.645131ms 134.015927ms 134.592603ms 135.222048ms 135.299302ms 135.334519ms 135.398384ms 135.951597ms 136.11763ms 136.124146ms 136.354476ms 136.486638ms 136.865488ms 137.737764ms 137.743626ms 138.174867ms 138.256856ms 138.304903ms 138.371184ms 138.690093ms 138.936523ms 141.943635ms 142.055661ms 142.220646ms 142.386223ms 142.449931ms 142.874839ms 143.121894ms 143.205382ms 143.220675ms 144.123387ms 144.221976ms 144.830247ms 144.841544ms 145.031213ms 145.139204ms 145.202263ms 145.345685ms 146.352159ms 146.457397ms 146.491092ms 146.595674ms 147.241563ms 148.336898ms 148.410484ms 149.036785ms 149.965289ms 150.1962ms 150.38441ms 151.053438ms 151.850669ms 152.861464ms 152.98309ms 153.416155ms 153.450573ms 153.519828ms 153.631408ms 153.690051ms 153.751657ms 153.981675ms 154.778795ms 155.552706ms 155.599815ms 155.826246ms 156.512589ms 157.082905ms 157.134234ms 157.777923ms 159.323112ms 159.720781ms 159.956073ms 160.425475ms 161.969229ms 162.416451ms 162.901697ms 163.031835ms 163.296584ms 163.461908ms 163.498186ms 163.61891ms 163.668235ms 163.935201ms 164.225774ms 164.364844ms 165.577682ms 165.737992ms 166.696512ms 166.93779ms 168.198442ms 168.84917ms 169.084879ms 169.857089ms 169.899714ms 170.661464ms 171.353708ms 172.852994ms 173.355363ms 176.671735ms 178.129034ms 181.024823ms 181.702095ms 182.71315ms 183.459267ms 186.06346ms 186.235693ms 186.300408ms 186.561335ms 188.435226ms 190.381533ms 190.868805ms 191.934238ms 191.954423ms 196.909259ms 197.160491ms 199.436218ms 199.478265ms 200.325598ms 202.703839ms 205.128105ms 207.378531ms 211.106674ms 213.744188ms 215.435967ms 216.971414ms 217.341553ms 225.491735ms 230.739228ms 231.044803ms 233.718514ms 247.627202ms 257.894883ms 259.165484ms 259.850884ms 262.437051ms 262.535401ms 276.474674ms 276.738947ms 280.16716ms 287.900955ms 326.015409ms 350.038364ms 364.856033ms 380.121551ms 380.392933ms 395.227628ms 412.165058ms 413.584664ms 413.779751ms 419.417959ms 427.195903ms 428.026382ms 458.558685ms 473.243972ms 482.095799ms]
May 21 07:46:51.336: INFO: 50 %ile: 153.450573ms
May 21 07:46:51.336: INFO: 90 %ile: 262.535401ms
May 21 07:46:51.336: INFO: 99 %ile: 473.243972ms
May 21 07:46:51.336: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:46:51.336: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-lt8c4" for this suite.
May 21 07:47:05.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:47:06.409: INFO: namespace: e2e-tests-svc-latency-lt8c4, resource: bindings, ignored listing per whitelist
May 21 07:47:06.880: INFO: namespace e2e-tests-svc-latency-lt8c4 deletion completed in 15.516592925s

• [SLOW TEST:22.389 seconds]
[sig-network] Service endpoints latency
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-api-machinery] ConfigMap
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:47:06.881: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating configMap e2e-tests-configmap-6q2px/configmap-test-28f6e0fd-5ccb-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume configMaps
May 21 07:47:07.068: INFO: Waiting up to 5m0s for pod "pod-configmaps-28f9b812-5ccb-11e8-849c-0e182f31d764" in namespace "e2e-tests-configmap-6q2px" to be "success or failure"
May 21 07:47:07.085: INFO: Pod "pod-configmaps-28f9b812-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 16.320866ms
May 21 07:47:09.101: INFO: Pod "pod-configmaps-28f9b812-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032610502s
May 21 07:47:11.119: INFO: Pod "pod-configmaps-28f9b812-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050568893s
May 21 07:47:13.135: INFO: Pod "pod-configmaps-28f9b812-5ccb-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.06683855s
STEP: Saw pod success
May 21 07:47:13.135: INFO: Pod "pod-configmaps-28f9b812-5ccb-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:47:13.151: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod pod-configmaps-28f9b812-5ccb-11e8-849c-0e182f31d764 container env-test: <nil>
STEP: delete the pod
May 21 07:47:13.202: INFO: Waiting for pod pod-configmaps-28f9b812-5ccb-11e8-849c-0e182f31d764 to disappear
May 21 07:47:13.218: INFO: Pod pod-configmaps-28f9b812-5ccb-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:47:13.218: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6q2px" for this suite.
May 21 07:47:19.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:47:20.361: INFO: namespace: e2e-tests-configmap-6q2px, resource: bindings, ignored listing per whitelist
May 21 07:47:20.929: INFO: namespace e2e-tests-configmap-6q2px deletion completed in 7.68187463s

• [SLOW TEST:14.049 seconds]
[sig-api-machinery] ConfigMap
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:29
  should be consumable via environment variable  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:47:20.929: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating projection with secret that has name projected-secret-test-map-316c6d35-5ccb-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume secrets
May 21 07:47:21.285: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3171773b-5ccb-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-2fc8m" to be "success or failure"
May 21 07:47:21.304: INFO: Pod "pod-projected-secrets-3171773b-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 18.927483ms
May 21 07:47:23.320: INFO: Pod "pod-projected-secrets-3171773b-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03489383s
May 21 07:47:25.336: INFO: Pod "pod-projected-secrets-3171773b-5ccb-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051000519s
STEP: Saw pod success
May 21 07:47:25.336: INFO: Pod "pod-projected-secrets-3171773b-5ccb-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:47:25.351: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod pod-projected-secrets-3171773b-5ccb-11e8-849c-0e182f31d764 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 07:47:25.395: INFO: Waiting for pod pod-projected-secrets-3171773b-5ccb-11e8-849c-0e182f31d764 to disappear
May 21 07:47:25.410: INFO: Pod pod-projected-secrets-3171773b-5ccb-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:47:25.410: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2fc8m" for this suite.
May 21 07:47:31.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:47:32.208: INFO: namespace: e2e-tests-projected-2fc8m, resource: bindings, ignored listing per whitelist
May 21 07:47:33.034: INFO: namespace e2e-tests-projected-2fc8m deletion completed in 7.594551972s

• [SLOW TEST:12.105 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings and Item Mode set [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:47:33.035: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support --unix-socket=/path  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Starting the proxy
May 21 07:47:33.230: INFO: Asynchronously running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig proxy --unix-socket=/tmp/kubectl-proxy-unix096084049/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:47:33.325: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8tc7t" for this suite.
May 21 07:47:39.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:47:40.736: INFO: namespace: e2e-tests-kubectl-8tc7t, resource: bindings, ignored listing per whitelist
May 21 07:47:40.858: INFO: namespace e2e-tests-kubectl-8tc7t deletion completed in 7.503090076s

• [SLOW TEST:7.824 seconds]
[sig-cli] Kubectl client
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should support --unix-socket=/path  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[k8s.io] Pods 
  should contain environment variables for services  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] Pods
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:47:40.858: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should contain environment variables for services  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
May 21 07:47:45.097: INFO: Waiting up to 5m0s for pod "client-envvars-3fa3e33d-5ccb-11e8-849c-0e182f31d764" in namespace "e2e-tests-pods-k9nkp" to be "success or failure"
May 21 07:47:45.115: INFO: Pod "client-envvars-3fa3e33d-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 18.584839ms
May 21 07:47:47.131: INFO: Pod "client-envvars-3fa3e33d-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034222162s
May 21 07:47:49.147: INFO: Pod "client-envvars-3fa3e33d-5ccb-11e8-849c-0e182f31d764": Phase="Running", Reason="", readiness=true. Elapsed: 4.050158478s
May 21 07:47:51.163: INFO: Pod "client-envvars-3fa3e33d-5ccb-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.066058466s
STEP: Saw pod success
May 21 07:47:51.163: INFO: Pod "client-envvars-3fa3e33d-5ccb-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:47:51.178: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod client-envvars-3fa3e33d-5ccb-11e8-849c-0e182f31d764 container env3cont: <nil>
STEP: delete the pod
May 21 07:47:51.221: INFO: Waiting for pod client-envvars-3fa3e33d-5ccb-11e8-849c-0e182f31d764 to disappear
May 21 07:47:51.238: INFO: Pod client-envvars-3fa3e33d-5ccb-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [k8s.io] Pods
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:47:51.238: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-k9nkp" for this suite.
May 21 07:48:13.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:48:14.416: INFO: namespace: e2e-tests-pods-k9nkp, resource: bindings, ignored listing per whitelist
May 21 07:48:14.777: INFO: namespace e2e-tests-pods-k9nkp deletion completed in 23.507107326s

• [SLOW TEST:33.919 seconds]
[k8s.io] Pods
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  should contain environment variables for services  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Secrets
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:48:14.777: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating secret with name secret-test-51739e5e-5ccb-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume secrets
May 21 07:48:15.032: INFO: Waiting up to 5m0s for pod "pod-secrets-5176b177-5ccb-11e8-849c-0e182f31d764" in namespace "e2e-tests-secrets-5q84c" to be "success or failure"
May 21 07:48:15.056: INFO: Pod "pod-secrets-5176b177-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 23.355932ms
May 21 07:48:17.072: INFO: Pod "pod-secrets-5176b177-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039106205s
May 21 07:48:19.088: INFO: Pod "pod-secrets-5176b177-5ccb-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055955282s
STEP: Saw pod success
May 21 07:48:19.088: INFO: Pod "pod-secrets-5176b177-5ccb-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:48:19.104: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod pod-secrets-5176b177-5ccb-11e8-849c-0e182f31d764 container secret-volume-test: <nil>
STEP: delete the pod
May 21 07:48:19.149: INFO: Waiting for pod pod-secrets-5176b177-5ccb-11e8-849c-0e182f31d764 to disappear
May 21 07:48:19.166: INFO: Pod pod-secrets-5176b177-5ccb-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Secrets
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:48:19.166: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5q84c" for this suite.
May 21 07:48:25.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:48:26.564: INFO: namespace: e2e-tests-secrets-5q84c, resource: bindings, ignored listing per whitelist
May 21 07:48:26.690: INFO: namespace e2e-tests-secrets-5q84c deletion completed in 7.49437248s

• [SLOW TEST:11.913 seconds]
[sig-storage] Secrets
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-network] Networking
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:48:26.690: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-rwgff
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 21 07:48:26.830: INFO: Waiting up to 10m0s for all (but 1) nodes to be schedulable
STEP: Creating test pods
May 21 07:48:51.229: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.6.65:8080/dial?request=hostName&protocol=udp&host=172.16.4.53&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-rwgff PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:48:51.230: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
May 21 07:48:51.530: INFO: Waiting for endpoints: map[]
May 21 07:48:51.547: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.6.65:8080/dial?request=hostName&protocol=udp&host=172.16.6.64&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-rwgff PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:48:51.547: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
May 21 07:48:51.745: INFO: Waiting for endpoints: map[]
May 21 07:48:51.761: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.6.65:8080/dial?request=hostName&protocol=udp&host=172.16.2.51&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-rwgff PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:48:51.761: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
May 21 07:48:51.950: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:48:51.950: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-rwgff" for this suite.
May 21 07:49:14.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:49:14.832: INFO: namespace: e2e-tests-pod-network-test-rwgff, resource: bindings, ignored listing per whitelist
May 21 07:49:15.501: INFO: namespace e2e-tests-pod-network-test-rwgff deletion completed in 23.512576177s

• [SLOW TEST:48.811 seconds]
[sig-network] Networking
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-api-machinery] ConfigMap
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:49:15.502: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating configMap e2e-tests-configmap-zndt6/configmap-test-75a00af4-5ccb-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume configMaps
May 21 07:49:15.678: INFO: Waiting up to 5m0s for pod "pod-configmaps-75a29ab1-5ccb-11e8-849c-0e182f31d764" in namespace "e2e-tests-configmap-zndt6" to be "success or failure"
May 21 07:49:15.694: INFO: Pod "pod-configmaps-75a29ab1-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 16.145335ms
May 21 07:49:17.710: INFO: Pod "pod-configmaps-75a29ab1-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032222886s
May 21 07:49:19.727: INFO: Pod "pod-configmaps-75a29ab1-5ccb-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049102225s
STEP: Saw pod success
May 21 07:49:19.727: INFO: Pod "pod-configmaps-75a29ab1-5ccb-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:49:19.743: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod pod-configmaps-75a29ab1-5ccb-11e8-849c-0e182f31d764 container env-test: <nil>
STEP: delete the pod
May 21 07:49:19.786: INFO: Waiting for pod pod-configmaps-75a29ab1-5ccb-11e8-849c-0e182f31d764 to disappear
May 21 07:49:19.802: INFO: Pod pod-configmaps-75a29ab1-5ccb-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:49:19.802: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zndt6" for this suite.
May 21 07:49:25.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:49:27.193: INFO: namespace: e2e-tests-configmap-zndt6, resource: bindings, ignored listing per whitelist
May 21 07:49:27.348: INFO: namespace e2e-tests-configmap-zndt6 deletion completed in 7.516426131s

• [SLOW TEST:11.846 seconds]
[sig-api-machinery] ConfigMap
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:29
  should be consumable via the environment  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:49:27.348: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating configMap with name projected-configmap-test-volume-map-7cae0ac4-5ccb-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume configMaps
May 21 07:49:27.507: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7cb09ac9-5ccb-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-mf7mz" to be "success or failure"
May 21 07:49:27.524: INFO: Pod "pod-projected-configmaps-7cb09ac9-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 16.873039ms
May 21 07:49:29.540: INFO: Pod "pod-projected-configmaps-7cb09ac9-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032914842s
May 21 07:49:31.556: INFO: Pod "pod-projected-configmaps-7cb09ac9-5ccb-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049253515s
STEP: Saw pod success
May 21 07:49:31.556: INFO: Pod "pod-projected-configmaps-7cb09ac9-5ccb-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:49:31.572: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod pod-projected-configmaps-7cb09ac9-5ccb-11e8-849c-0e182f31d764 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 07:49:31.618: INFO: Waiting for pod pod-projected-configmaps-7cb09ac9-5ccb-11e8-849c-0e182f31d764 to disappear
May 21 07:49:31.633: INFO: Pod pod-projected-configmaps-7cb09ac9-5ccb-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:49:31.633: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mf7mz" for this suite.
May 21 07:49:37.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:49:38.778: INFO: namespace: e2e-tests-projected-mf7mz, resource: bindings, ignored listing per whitelist
May 21 07:49:39.165: INFO: namespace e2e-tests-projected-mf7mz deletion completed in 7.501924312s

• [SLOW TEST:11.817 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-api-machinery] Secrets
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:49:39.165: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating secret with name secret-test-83b6dcf0-5ccb-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume secrets
May 21 07:49:39.315: INFO: Waiting up to 5m0s for pod "pod-secrets-83b96a74-5ccb-11e8-849c-0e182f31d764" in namespace "e2e-tests-secrets-p7brj" to be "success or failure"
May 21 07:49:39.330: INFO: Pod "pod-secrets-83b96a74-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.238398ms
May 21 07:49:41.346: INFO: Pod "pod-secrets-83b96a74-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031272808s
May 21 07:49:43.363: INFO: Pod "pod-secrets-83b96a74-5ccb-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047637797s
STEP: Saw pod success
May 21 07:49:43.363: INFO: Pod "pod-secrets-83b96a74-5ccb-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:49:43.378: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod pod-secrets-83b96a74-5ccb-11e8-849c-0e182f31d764 container secret-env-test: <nil>
STEP: delete the pod
May 21 07:49:43.424: INFO: Waiting for pod pod-secrets-83b96a74-5ccb-11e8-849c-0e182f31d764 to disappear
May 21 07:49:43.439: INFO: Pod pod-secrets-83b96a74-5ccb-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:49:43.439: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-p7brj" for this suite.
May 21 07:49:49.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:49:50.338: INFO: namespace: e2e-tests-secrets-p7brj, resource: bindings, ignored listing per whitelist
May 21 07:49:50.973: INFO: namespace e2e-tests-secrets-p7brj deletion completed in 7.503922238s

• [SLOW TEST:11.808 seconds]
[sig-api-machinery] Secrets
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:30
  should be consumable from pods in env vars  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-network] Networking
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:49:50.973: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-7fhxm
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 21 07:49:51.092: INFO: Waiting up to 10m0s for all (but 1) nodes to be schedulable
STEP: Creating test pods
May 21 07:50:17.456: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.16.6.67 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-7fhxm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:50:17.456: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
May 21 07:50:18.680: INFO: Found all expected endpoints: [netserver-0]
May 21 07:50:18.696: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.16.4.55 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-7fhxm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:50:18.696: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
May 21 07:50:19.875: INFO: Found all expected endpoints: [netserver-1]
May 21 07:50:19.891: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.16.2.54 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-7fhxm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:50:19.891: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
May 21 07:50:21.075: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:50:21.075: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-7fhxm" for this suite.
May 21 07:50:43.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:50:44.221: INFO: namespace: e2e-tests-pod-network-test-7fhxm, resource: bindings, ignored listing per whitelist
May 21 07:50:44.626: INFO: namespace e2e-tests-pod-network-test-7fhxm deletion completed in 23.520893721s

• [SLOW TEST:53.653 seconds]
[sig-network] Networking
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:50:44.626: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward API volume plugin
May 21 07:50:44.809: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aac398ae-5ccb-11e8-849c-0e182f31d764" in namespace "e2e-tests-downward-api-q4hqv" to be "success or failure"
May 21 07:50:44.825: INFO: Pod "downwardapi-volume-aac398ae-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 16.390094ms
May 21 07:50:46.841: INFO: Pod "downwardapi-volume-aac398ae-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032239568s
May 21 07:50:48.857: INFO: Pod "downwardapi-volume-aac398ae-5ccb-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048566699s
STEP: Saw pod success
May 21 07:50:48.857: INFO: Pod "downwardapi-volume-aac398ae-5ccb-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:50:48.873: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod downwardapi-volume-aac398ae-5ccb-11e8-849c-0e182f31d764 container client-container: <nil>
STEP: delete the pod
May 21 07:50:48.917: INFO: Waiting for pod downwardapi-volume-aac398ae-5ccb-11e8-849c-0e182f31d764 to disappear
May 21 07:50:48.932: INFO: Pod downwardapi-volume-aac398ae-5ccb-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:50:48.932: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-q4hqv" for this suite.
May 21 07:50:55.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:50:55.990: INFO: namespace: e2e-tests-downward-api-q4hqv, resource: bindings, ignored listing per whitelist
May 21 07:50:56.466: INFO: namespace e2e-tests-downward-api-q4hqv deletion completed in 7.504146295s

• [SLOW TEST:11.840 seconds]
[sig-storage] Downward API volume
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:50:56.466: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 21 07:50:56.620: INFO: Waiting up to 1m0s for all nodes to be ready
May 21 07:51:56.755: INFO: Waiting for terminating namespaces to be deleted...
May 21 07:51:56.786: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 21 07:51:56.833: INFO: 0 / 0 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 21 07:51:56.833: INFO: expected 0 pod replicas in namespace 'kube-system', 0 are Running and Ready.
May 21 07:51:56.848: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
May 21 07:51:56.848: INFO: 
Logging pods the kubelet thinks is on node prtest-7d230a7-103-ig-n-3zcc before test
May 21 07:51:56.870: INFO: 
Logging pods the kubelet thinks is on node prtest-7d230a7-103-ig-n-hmsw before test
May 21 07:51:56.889: INFO: registry-console-1-w8zl4 from default started at 2018-05-21 06:56:59 +0000 UTC (1 container statuses recorded)
May 21 07:51:56.889: INFO: 	Container registry-console ready: true, restart count 0
May 21 07:51:56.889: INFO: 
Logging pods the kubelet thinks is on node prtest-7d230a7-103-ig-n-wbpf before test
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1530998fe580dea6], Reason = [FailedScheduling], Message = [0/4 nodes are available: 1 NodeUnschedulable, 4 MatchNodeSelector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:51:58.011: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-4qjkw" for this suite.
May 21 07:52:20.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:52:21.411: INFO: namespace: e2e-tests-sched-pred-4qjkw, resource: bindings, ignored listing per whitelist
May 21 07:52:21.581: INFO: namespace e2e-tests-sched-pred-4qjkw deletion completed in 23.539257462s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:85.115 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:52:21.581: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's memory limit  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward API volume plugin
May 21 07:52:21.774: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e48f24dc-5ccb-11e8-849c-0e182f31d764" in namespace "e2e-tests-downward-api-5vvjk" to be "success or failure"
May 21 07:52:21.790: INFO: Pod "downwardapi-volume-e48f24dc-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.682185ms
May 21 07:52:23.806: INFO: Pod "downwardapi-volume-e48f24dc-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031909301s
May 21 07:52:25.822: INFO: Pod "downwardapi-volume-e48f24dc-5ccb-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048022604s
STEP: Saw pod success
May 21 07:52:25.822: INFO: Pod "downwardapi-volume-e48f24dc-5ccb-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:52:25.838: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod downwardapi-volume-e48f24dc-5ccb-11e8-849c-0e182f31d764 container client-container: <nil>
STEP: delete the pod
May 21 07:52:25.884: INFO: Waiting for pod downwardapi-volume-e48f24dc-5ccb-11e8-849c-0e182f31d764 to disappear
May 21 07:52:25.900: INFO: Pod downwardapi-volume-e48f24dc-5ccb-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:52:25.900: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5vvjk" for this suite.
May 21 07:52:31.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:52:32.625: INFO: namespace: e2e-tests-downward-api-5vvjk, resource: bindings, ignored listing per whitelist
May 21 07:52:33.408: INFO: namespace e2e-tests-downward-api-5vvjk deletion completed in 7.478224133s

• [SLOW TEST:11.827 seconds]
[sig-storage] Downward API volume
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's memory limit  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-api-machinery] Downward API
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:52:33.408: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward api env vars
May 21 07:52:33.523: INFO: Waiting up to 5m0s for pod "downward-api-eb8f783e-5ccb-11e8-849c-0e182f31d764" in namespace "e2e-tests-downward-api-2njhb" to be "success or failure"
May 21 07:52:33.537: INFO: Pod "downward-api-eb8f783e-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 14.756875ms
May 21 07:52:35.553: INFO: Pod "downward-api-eb8f783e-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03056707s
May 21 07:52:37.569: INFO: Pod "downward-api-eb8f783e-5ccb-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 4.046669367s
May 21 07:52:39.586: INFO: Pod "downward-api-eb8f783e-5ccb-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.063126955s
STEP: Saw pod success
May 21 07:52:39.586: INFO: Pod "downward-api-eb8f783e-5ccb-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:52:39.601: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod downward-api-eb8f783e-5ccb-11e8-849c-0e182f31d764 container dapi-container: <nil>
STEP: delete the pod
May 21 07:52:39.655: INFO: Waiting for pod downward-api-eb8f783e-5ccb-11e8-849c-0e182f31d764 to disappear
May 21 07:52:39.670: INFO: Pod downward-api-eb8f783e-5ccb-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:52:39.670: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2njhb" for this suite.
May 21 07:52:45.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:52:46.933: INFO: namespace: e2e-tests-downward-api-2njhb, resource: bindings, ignored listing per whitelist
May 21 07:52:47.191: INFO: namespace e2e-tests-downward-api-2njhb deletion completed in 7.491352271s

• [SLOW TEST:13.783 seconds]
[sig-api-machinery] Downward API
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide host IP as an env var  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:52:47.191: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run pod
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1355
[It] should create a pod from an image when restart is Never  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: running the image gcr.io/google-containers/nginx-slim-amd64:0.20
May 21 07:52:47.310: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=gcr.io/google-containers/nginx-slim-amd64:0.20 --namespace=e2e-tests-kubectl-hk499'
May 21 07:52:48.155: INFO: stderr: ""
May 21 07:52:48.155: INFO: stdout: "pod \"e2e-test-nginx-pod\" created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1360
May 21 07:52:48.172: INFO: Running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-hk499'
May 21 07:52:48.407: INFO: stderr: ""
May 21 07:52:48.407: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:52:48.407: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hk499" for this suite.
May 21 07:52:54.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:52:55.900: INFO: namespace: e2e-tests-kubectl-hk499, resource: bindings, ignored listing per whitelist
May 21 07:52:55.949: INFO: namespace e2e-tests-kubectl-hk499 deletion completed in 7.513159088s

• [SLOW TEST:8.758 seconds]
[sig-cli] Kubectl client
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should create a pod from an image when restart is Never  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] version v1
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:52:55.949: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] version v1
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:68
[It] should proxy logs on node using proxy subresource  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
May 21 07:52:56.155: INFO: (0) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 19.622966ms)
May 21 07:52:56.172: INFO: (1) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.926785ms)
May 21 07:52:56.189: INFO: (2) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.726141ms)
May 21 07:52:56.206: INFO: (3) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.662215ms)
May 21 07:52:56.222: INFO: (4) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.653765ms)
May 21 07:52:56.240: INFO: (5) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.678782ms)
May 21 07:52:56.257: INFO: (6) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.919055ms)
May 21 07:52:56.274: INFO: (7) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.706616ms)
May 21 07:52:56.291: INFO: (8) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.521293ms)
May 21 07:52:56.308: INFO: (9) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.980289ms)
May 21 07:52:56.325: INFO: (10) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.007871ms)
May 21 07:52:56.342: INFO: (11) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.677421ms)
May 21 07:52:56.360: INFO: (12) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.927695ms)
May 21 07:52:56.377: INFO: (13) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.772246ms)
May 21 07:52:56.394: INFO: (14) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.76498ms)
May 21 07:52:56.411: INFO: (15) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.991266ms)
May 21 07:52:56.428: INFO: (16) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.20424ms)
May 21 07:52:56.445: INFO: (17) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.036711ms)
May 21 07:52:56.462: INFO: (18) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 16.793596ms)
May 21 07:52:56.479: INFO: (19) /api/v1/nodes/prtest-7d230a7-103-ig-n-3zcc/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.382174ms)
[AfterEach] version v1
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:52:56.479: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-bhrq9" for this suite.
May 21 07:53:02.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:53:03.886: INFO: namespace: e2e-tests-proxy-bhrq9, resource: bindings, ignored listing per whitelist
May 21 07:53:04.013: INFO: namespace e2e-tests-proxy-bhrq9 deletion completed in 7.517175593s

• [SLOW TEST:8.064 seconds]
[sig-network] Proxy
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:60
    should proxy logs on node using proxy subresource  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] [sig-node] Events
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:53:04.013: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-fdd5cd9a-5ccb-11e8-849c-0e182f31d764,GenerateName:,Namespace:e2e-tests-events-qrs5g,SelfLink:/api/v1/namespaces/e2e-tests-events-qrs5g/pods/send-events-fdd5cd9a-5ccb-11e8-849c-0e182f31d764,UID:fdd785ac-5ccb-11e8-bb49-42010a8e0002,ResourceVersion:17809,Generation:0,CreationTimestamp:2018-05-21 07:53:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 156411736,},Annotations:map[string]string{openshift.io/scc: privileged,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tkvgf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tkvgf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-tkvgf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{role: app,},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:prtest-7d230a7-103-ig-n-wbpf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,},ImagePullSecrets:[{default-dockercfg-ckv6h}],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 07:53:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 07:53:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 07:53:04 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.4,PodIP:172.16.6.70,StartTime:2018-05-21 07:53:04 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-05-21 07:53:06 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64@sha256:2dd4032e98a0450d95a0ac71a5e465f542a900812d8c41bc6ca635aed1a5fc91 docker://da2b4de40314b414f06ff3549d02d673bdcfd08c693fc145165519bef0a8de0e}],QOSClass:BestEffort,InitContainerStatuses:[],},}
STEP: checking for scheduler event about the pod
Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:53:12.289: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-qrs5g" for this suite.
May 21 07:53:18.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:53:19.369: INFO: namespace: e2e-tests-events-qrs5g, resource: bindings, ignored listing per whitelist
May 21 07:53:19.788: INFO: namespace e2e-tests-events-qrs5g deletion completed in 7.47071366s

• [SLOW TEST:15.775 seconds]
[k8s.io] [sig-node] Events
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:53:19.789: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating secret with name projected-secret-test-073861e2-5ccc-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume secrets
May 21 07:53:19.937: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-073ae05b-5ccc-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-5cjcm" to be "success or failure"
May 21 07:53:19.952: INFO: Pod "pod-projected-secrets-073ae05b-5ccc-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 14.540323ms
May 21 07:53:21.968: INFO: Pod "pod-projected-secrets-073ae05b-5ccc-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030416326s
May 21 07:53:23.984: INFO: Pod "pod-projected-secrets-073ae05b-5ccc-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046893444s
STEP: Saw pod success
May 21 07:53:23.984: INFO: Pod "pod-projected-secrets-073ae05b-5ccc-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:53:24.000: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod pod-projected-secrets-073ae05b-5ccc-11e8-849c-0e182f31d764 container secret-volume-test: <nil>
STEP: delete the pod
May 21 07:53:24.042: INFO: Waiting for pod pod-projected-secrets-073ae05b-5ccc-11e8-849c-0e182f31d764 to disappear
May 21 07:53:24.058: INFO: Pod pod-projected-secrets-073ae05b-5ccc-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:53:24.058: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5cjcm" for this suite.
May 21 07:53:30.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:53:31.289: INFO: namespace: e2e-tests-projected-5cjcm, resource: bindings, ignored listing per whitelist
May 21 07:53:31.598: INFO: namespace e2e-tests-projected-5cjcm deletion completed in 7.51062926s

• [SLOW TEST:11.809 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable in multiple volumes in a pod [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:53:31.598: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 21 07:53:31.739: INFO: Waiting up to 1m0s for all nodes to be ready
May 21 07:54:31.874: INFO: Waiting for terminating namespaces to be deleted...
May 21 07:54:31.905: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 21 07:54:31.952: INFO: 0 / 0 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 21 07:54:31.952: INFO: expected 0 pod replicas in namespace 'kube-system', 0 are Running and Ready.
May 21 07:54:31.967: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
May 21 07:54:31.967: INFO: 
Logging pods the kubelet thinks is on node prtest-7d230a7-103-ig-n-3zcc before test
May 21 07:54:31.985: INFO: 
Logging pods the kubelet thinks is on node prtest-7d230a7-103-ig-n-hmsw before test
May 21 07:54:32.005: INFO: registry-console-1-w8zl4 from default started at 2018-05-21 06:56:59 +0000 UTC (1 container statuses recorded)
May 21 07:54:32.005: INFO: 	Container registry-console ready: true, restart count 0
May 21 07:54:32.005: INFO: 
Logging pods the kubelet thinks is on node prtest-7d230a7-103-ig-n-wbpf before test
[It] validates that NodeSelector is respected if matching  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-3376173e-5ccc-11e8-849c-0e182f31d764 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-3376173e-5ccc-11e8-849c-0e182f31d764 off the node prtest-7d230a7-103-ig-n-3zcc
STEP: verifying the node doesn't have the label kubernetes.io/e2e-3376173e-5ccc-11e8-849c-0e182f31d764
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:54:38.287: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-7ldx6" for this suite.
May 21 07:55:00.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:55:01.610: INFO: namespace: e2e-tests-sched-pred-7ldx6, resource: bindings, ignored listing per whitelist
May 21 07:55:01.810: INFO: namespace e2e-tests-sched-pred-7ldx6 deletion completed in 23.507707778s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:90.212 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] ConfigMap
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:55:01.810: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating configMap with name configmap-test-volume-4408a19c-5ccc-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume configMaps
May 21 07:55:01.968: INFO: Waiting up to 5m0s for pod "pod-configmaps-440b82e2-5ccc-11e8-849c-0e182f31d764" in namespace "e2e-tests-configmap-98wdr" to be "success or failure"
May 21 07:55:01.982: INFO: Pod "pod-configmaps-440b82e2-5ccc-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 14.883994ms
May 21 07:55:03.999: INFO: Pod "pod-configmaps-440b82e2-5ccc-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030975552s
May 21 07:55:06.015: INFO: Pod "pod-configmaps-440b82e2-5ccc-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047193755s
STEP: Saw pod success
May 21 07:55:06.015: INFO: Pod "pod-configmaps-440b82e2-5ccc-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:55:06.030: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod pod-configmaps-440b82e2-5ccc-11e8-849c-0e182f31d764 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 07:55:06.074: INFO: Waiting for pod pod-configmaps-440b82e2-5ccc-11e8-849c-0e182f31d764 to disappear
May 21 07:55:06.089: INFO: Pod pod-configmaps-440b82e2-5ccc-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:55:06.089: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-98wdr" for this suite.
May 21 07:55:12.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:55:13.495: INFO: namespace: e2e-tests-configmap-98wdr, resource: bindings, ignored listing per whitelist
May 21 07:55:13.632: INFO: namespace e2e-tests-configmap-98wdr deletion completed in 7.513989178s

• [SLOW TEST:11.822 seconds]
[sig-storage] ConfigMap
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-network] DNS
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:55:13.633: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-8f67m A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-8f67m;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-8f67m A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-8f67m;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-8f67m.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-8f67m.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-8f67m.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-8f67m.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-8f67m.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-8f67m.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-8f67m.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8f67m.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-8f67m.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-8f67m.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-8f67m.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-8f67m.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-8f67m.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 251.149.30.172.in-addr.arpa. PTR)" && echo OK > /results/172.30.149.251_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 251.149.30.172.in-addr.arpa. PTR)" && echo OK > /results/172.30.149.251_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-8f67m A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-8f67m;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-8f67m A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-8f67m;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-8f67m.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-8f67m.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-8f67m.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-8f67m.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-8f67m.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-8f67m.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-8f67m.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8f67m.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-8f67m.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-8f67m.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-8f67m.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-8f67m.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-8f67m.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 251.149.30.172.in-addr.arpa. PTR)" && echo OK > /results/172.30.149.251_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 251.149.30.172.in-addr.arpa. PTR)" && echo OK > /results/172.30.149.251_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 21 07:55:34.406: INFO: DNS probes using dns-test-4b228f2a-5ccc-11e8-849c-0e182f31d764 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:55:34.525: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-8f67m" for this suite.
May 21 07:55:40.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:55:41.335: INFO: namespace: e2e-tests-dns-8f67m, resource: bindings, ignored listing per whitelist
May 21 07:55:42.041: INFO: namespace e2e-tests-dns-8f67m deletion completed in 7.499184283s

• [SLOW TEST:28.408 seconds]
[sig-network] DNS
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] Variable Expansion
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:55:42.041: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test substitution in container's args
May 21 07:55:42.206: INFO: Waiting up to 5m0s for pod "var-expansion-5c05fd03-5ccc-11e8-849c-0e182f31d764" in namespace "e2e-tests-var-expansion-h7lgr" to be "success or failure"
May 21 07:55:42.221: INFO: Pod "var-expansion-5c05fd03-5ccc-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.029582ms
May 21 07:55:44.237: INFO: Pod "var-expansion-5c05fd03-5ccc-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030958538s
May 21 07:55:46.253: INFO: Pod "var-expansion-5c05fd03-5ccc-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 4.046998122s
May 21 07:55:48.269: INFO: Pod "var-expansion-5c05fd03-5ccc-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.062994359s
STEP: Saw pod success
May 21 07:55:48.269: INFO: Pod "var-expansion-5c05fd03-5ccc-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 07:55:48.285: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod var-expansion-5c05fd03-5ccc-11e8-849c-0e182f31d764 container dapi-container: <nil>
STEP: delete the pod
May 21 07:55:48.329: INFO: Waiting for pod var-expansion-5c05fd03-5ccc-11e8-849c-0e182f31d764 to disappear
May 21 07:55:48.344: INFO: Pod var-expansion-5c05fd03-5ccc-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:55:48.344: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-h7lgr" for this suite.
May 21 07:55:54.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:55:55.644: INFO: namespace: e2e-tests-var-expansion-h7lgr, resource: bindings, ignored listing per whitelist
May 21 07:55:55.859: INFO: namespace e2e-tests-var-expansion-h7lgr deletion completed in 7.484066791s

• [SLOW TEST:13.818 seconds]
[k8s.io] Variable Expansion
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  should allow substituting values in a container's args  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:55:55.859: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
May 21 07:55:55.994: INFO: Couldn't get node TTL annotation (using default value of 0): No TTL annotation found on the node
STEP: Creating configMap with name cm-test-opt-del-64422fbc-5ccc-11e8-849c-0e182f31d764
STEP: Creating configMap with name cm-test-opt-upd-64423003-5ccc-11e8-849c-0e182f31d764
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-64422fbc-5ccc-11e8-849c-0e182f31d764
STEP: Updating configmap cm-test-opt-upd-64423003-5ccc-11e8-849c-0e182f31d764
STEP: Creating configMap with name cm-test-opt-create-64423020-5ccc-11e8-849c-0e182f31d764
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:57:02.972: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6hzwm" for this suite.
May 21 07:57:25.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:57:25.770: INFO: namespace: e2e-tests-projected-6hzwm, resource: bindings, ignored listing per whitelist
May 21 07:57:26.502: INFO: namespace e2e-tests-projected-6hzwm deletion completed in 23.501352879s

• [SLOW TEST:90.643 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  optional updates should be reflected in volume [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be updated  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] Pods
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:57:26.503: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should be updated  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 21 07:57:31.268: INFO: Successfully updated pod "pod-update-9a4a7cba-5ccc-11e8-849c-0e182f31d764"
STEP: verifying the updated pod is in kubernetes
May 21 07:57:31.299: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:57:31.299: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-k2drl" for this suite.
May 21 07:57:53.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:57:54.519: INFO: namespace: e2e-tests-pods-k2drl, resource: bindings, ignored listing per whitelist
May 21 07:57:54.824: INFO: namespace e2e-tests-pods-k2drl deletion completed in 23.494802062s

• [SLOW TEST:28.321 seconds]
[k8s.io] Pods
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  should be updated  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:57:54.824: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
May 21 07:58:01.070: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jwl8t PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:58:01.070: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
May 21 07:58:01.351: INFO: Exec stderr: ""
May 21 07:58:01.351: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jwl8t PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:58:01.351: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
May 21 07:58:01.543: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
May 21 07:58:01.543: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jwl8t PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:58:01.543: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
May 21 07:58:01.732: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
May 21 07:58:01.732: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jwl8t PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:58:01.732: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
May 21 07:58:01.941: INFO: Exec stderr: ""
May 21 07:58:01.941: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jwl8t PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:58:01.941: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
May 21 07:58:02.136: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:58:02.136: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-jwl8t" for this suite.
May 21 07:58:48.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:58:49.272: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-jwl8t, resource: bindings, ignored listing per whitelist
May 21 07:58:49.672: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-jwl8t deletion completed in 47.505525484s

• [SLOW TEST:54.848 seconds]
[k8s.io] KubeletManagedEtcHosts
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  should test kubelet managed /etc/hosts file  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:58:49.672: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:199
[It] should be submitted and removed  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:58:49.863: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-h2jd9" for this suite.
May 21 07:59:11.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:59:13.232: INFO: namespace: e2e-tests-pods-h2jd9, resource: bindings, ignored listing per whitelist
May 21 07:59:13.384: INFO: namespace e2e-tests-pods-h2jd9 deletion completed in 23.491539547s

• [SLOW TEST:23.712 seconds]
[k8s.io] [sig-node] Pods Extended
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  [k8s.io] Pods Set QOS Class
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should be submitted and removed  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:59:13.385: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
May 21 07:59:13.530: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:59:13.699: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-w26f5" for this suite.
May 21 07:59:19.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:59:21.152: INFO: namespace: e2e-tests-custom-resource-definition-w26f5, resource: bindings, ignored listing per whitelist
May 21 07:59:21.228: INFO: namespace e2e-tests-custom-resource-definition-w26f5 deletion completed in 7.499308815s

• [SLOW TEST:7.843 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
S
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-network] Services
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:59:21.228: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:51
[It] should serve a basic endpoint from pods  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: creating service endpoint-test2 in namespace e2e-tests-services-6ddrt
STEP: waiting up to 1m0s for service endpoint-test2 in namespace e2e-tests-services-6ddrt to expose endpoints map[]
May 21 07:59:21.465: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-6ddrt exposes endpoints map[] (29.477783ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-6ddrt
STEP: waiting up to 1m0s for service endpoint-test2 in namespace e2e-tests-services-6ddrt to expose endpoints map[pod1:[80]]
May 21 07:59:24.635: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-6ddrt exposes endpoints map[pod1:[80]] (3.133808616s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-6ddrt
STEP: waiting up to 1m0s for service endpoint-test2 in namespace e2e-tests-services-6ddrt to expose endpoints map[pod2:[80] pod1:[80]]
May 21 07:59:27.860: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-6ddrt exposes endpoints map[pod1:[80] pod2:[80]] (3.192624479s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-6ddrt
STEP: waiting up to 1m0s for service endpoint-test2 in namespace e2e-tests-services-6ddrt to expose endpoints map[pod2:[80]]
May 21 07:59:27.908: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-6ddrt exposes endpoints map[pod2:[80]] (31.585195ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-6ddrt
STEP: waiting up to 1m0s for service endpoint-test2 in namespace e2e-tests-services-6ddrt to expose endpoints map[]
May 21 07:59:27.940: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-6ddrt exposes endpoints map[] (16.219082ms elapsed)
[AfterEach] [sig-network] Services
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 07:59:27.972: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-6ddrt" for this suite.
May 21 07:59:46.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:59:46.693: INFO: namespace: e2e-tests-services-6ddrt, resource: bindings, ignored listing per whitelist
May 21 07:59:47.508: INFO: namespace e2e-tests-services-6ddrt deletion completed in 19.507452678s
[AfterEach] [sig-network] Services
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:56

• [SLOW TEST:26.281 seconds]
[sig-network] Services
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-network] DNS
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 07:59:47.509: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-gpwhn.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-gpwhn.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-gpwhn.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-gpwhn.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-gpwhn.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-gpwhn.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 21 08:00:02.026: INFO: DNS probes using dns-test-ee4d68cf-5ccc-11e8-849c-0e182f31d764 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 08:00:02.062: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-gpwhn" for this suite.
May 21 08:00:08.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:00:09.459: INFO: namespace: e2e-tests-dns-gpwhn, resource: bindings, ignored listing per whitelist
May 21 08:00:09.581: INFO: namespace e2e-tests-dns-gpwhn deletion completed in 7.488696526s

• [SLOW TEST:22.072 seconds]
[sig-network] DNS
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 08:00:09.581: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-lt8mk
May 21 08:00:13.741: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-lt8mk
STEP: checking the pod's current state and verifying that restartCount is present
May 21 08:00:13.756: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 08:02:14.751: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-lt8mk" for this suite.
May 21 08:02:20.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:02:21.529: INFO: namespace: e2e-tests-container-probe-lt8mk, resource: bindings, ignored listing per whitelist
May 21 08:02:22.281: INFO: namespace e2e-tests-container-probe-lt8mk deletion completed in 7.500201889s

• [SLOW TEST:132.700 seconds]
[k8s.io] Probing container
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  should *not* be restarted with a /healthz http liveness probe  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 08:02:22.281: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test emptydir 0666 on node default medium
May 21 08:02:22.457: INFO: Waiting up to 5m0s for pod "pod-4a984d75-5ccd-11e8-849c-0e182f31d764" in namespace "e2e-tests-emptydir-btqh4" to be "success or failure"
May 21 08:02:22.473: INFO: Pod "pod-4a984d75-5ccd-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.349592ms
May 21 08:02:24.489: INFO: Pod "pod-4a984d75-5ccd-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031706915s
May 21 08:02:26.505: INFO: Pod "pod-4a984d75-5ccd-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047967026s
STEP: Saw pod success
May 21 08:02:26.506: INFO: Pod "pod-4a984d75-5ccd-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 08:02:26.521: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod pod-4a984d75-5ccd-11e8-849c-0e182f31d764 container test-container: <nil>
STEP: delete the pod
May 21 08:02:26.566: INFO: Waiting for pod pod-4a984d75-5ccd-11e8-849c-0e182f31d764 to disappear
May 21 08:02:26.582: INFO: Pod pod-4a984d75-5ccd-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 08:02:26.582: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-btqh4" for this suite.
May 21 08:02:32.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:02:33.596: INFO: namespace: e2e-tests-emptydir-btqh4, resource: bindings, ignored listing per whitelist
May 21 08:02:34.132: INFO: namespace e2e-tests-emptydir-btqh4 deletion completed in 7.520515964s

• [SLOW TEST:11.851 seconds]
[sig-storage] EmptyDir volumes
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 08:02:34.132: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test downward API volume plugin
May 21 08:02:34.267: INFO: Waiting up to 5m0s for pod "downwardapi-volume-51a26c59-5ccd-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-gf486" to be "success or failure"
May 21 08:02:34.283: INFO: Pod "downwardapi-volume-51a26c59-5ccd-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.820653ms
May 21 08:02:36.299: INFO: Pod "downwardapi-volume-51a26c59-5ccd-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031881242s
May 21 08:02:38.315: INFO: Pod "downwardapi-volume-51a26c59-5ccd-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048005755s
STEP: Saw pod success
May 21 08:02:38.315: INFO: Pod "downwardapi-volume-51a26c59-5ccd-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 08:02:38.331: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod downwardapi-volume-51a26c59-5ccd-11e8-849c-0e182f31d764 container client-container: <nil>
STEP: delete the pod
May 21 08:02:38.379: INFO: Waiting for pod downwardapi-volume-51a26c59-5ccd-11e8-849c-0e182f31d764 to disappear
May 21 08:02:38.395: INFO: Pod downwardapi-volume-51a26c59-5ccd-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 08:02:38.395: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gf486" for this suite.
May 21 08:02:44.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:02:45.758: INFO: namespace: e2e-tests-projected-gf486, resource: bindings, ignored listing per whitelist
May 21 08:02:45.926: INFO: namespace e2e-tests-projected-gf486 deletion completed in 7.501165618s

• [SLOW TEST:11.794 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should set mode on item file [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] ConfigMap
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 08:02:45.926: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
May 21 08:02:46.065: INFO: Couldn't get node TTL annotation (using default value of 0): No TTL annotation found on the node
STEP: Creating configMap with name cm-test-opt-del-58ae280f-5ccd-11e8-849c-0e182f31d764
STEP: Creating configMap with name cm-test-opt-upd-58ae284e-5ccd-11e8-849c-0e182f31d764
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-58ae280f-5ccd-11e8-849c-0e182f31d764
STEP: Updating configmap cm-test-opt-upd-58ae284e-5ccd-11e8-849c-0e182f31d764
STEP: Creating configMap with name cm-test-opt-create-58ae286f-5ccd-11e8-849c-0e182f31d764
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 08:03:59.141: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5n42p" for this suite.
May 21 08:04:21.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:04:22.616: INFO: namespace: e2e-tests-configmap-5n42p, resource: bindings, ignored listing per whitelist
May 21 08:04:22.663: INFO: namespace e2e-tests-configmap-5n42p deletion completed in 23.493396039s

• [SLOW TEST:96.737 seconds]
[sig-storage] ConfigMap
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] [sig-node] PreStop
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 08:04:22.664: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating server pod server in namespace e2e-tests-prestop-bs7kj
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-bs7kj
STEP: Deleting pre-stop pod
May 21 08:04:35.947: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 08:04:35.965: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-bs7kj" for this suite.
May 21 08:05:14.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:05:15.333: INFO: namespace: e2e-tests-prestop-bs7kj, resource: bindings, ignored listing per whitelist
May 21 08:05:15.482: INFO: namespace e2e-tests-prestop-bs7kj deletion completed in 39.488468592s

• [SLOW TEST:52.819 seconds]
[k8s.io] [sig-node] PreStop
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  should call prestop when killing a pod  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 08:05:15.482: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating configMap with name projected-configmap-test-volume-b1cb58c6-5ccd-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume configMaps
May 21 08:05:15.607: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b1cdb20e-5ccd-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-nqf5f" to be "success or failure"
May 21 08:05:15.622: INFO: Pod "pod-projected-configmaps-b1cdb20e-5ccd-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 14.843665ms
May 21 08:05:17.638: INFO: Pod "pod-projected-configmaps-b1cdb20e-5ccd-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03105044s
May 21 08:05:19.654: INFO: Pod "pod-projected-configmaps-b1cdb20e-5ccd-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047267339s
STEP: Saw pod success
May 21 08:05:19.654: INFO: Pod "pod-projected-configmaps-b1cdb20e-5ccd-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 08:05:19.670: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod pod-projected-configmaps-b1cdb20e-5ccd-11e8-849c-0e182f31d764 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 08:05:19.712: INFO: Waiting for pod pod-projected-configmaps-b1cdb20e-5ccd-11e8-849c-0e182f31d764 to disappear
May 21 08:05:19.728: INFO: Pod pod-projected-configmaps-b1cdb20e-5ccd-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 08:05:19.728: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nqf5f" for this suite.
May 21 08:05:25.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:05:26.860: INFO: namespace: e2e-tests-projected-nqf5f, resource: bindings, ignored listing per whitelist
May 21 08:05:27.261: INFO: namespace e2e-tests-projected-nqf5f deletion completed in 7.504122419s

• [SLOW TEST:11.779 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume as non-root [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 08:05:27.261: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test emptydir 0644 on node default medium
May 21 08:05:27.386: INFO: Waiting up to 5m0s for pod "pod-b8d2e21e-5ccd-11e8-849c-0e182f31d764" in namespace "e2e-tests-emptydir-fvrjb" to be "success or failure"
May 21 08:05:27.401: INFO: Pod "pod-b8d2e21e-5ccd-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.205784ms
May 21 08:05:29.418: INFO: Pod "pod-b8d2e21e-5ccd-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032823307s
May 21 08:05:31.435: INFO: Pod "pod-b8d2e21e-5ccd-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048891406s
STEP: Saw pod success
May 21 08:05:31.435: INFO: Pod "pod-b8d2e21e-5ccd-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 08:05:31.450: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod pod-b8d2e21e-5ccd-11e8-849c-0e182f31d764 container test-container: <nil>
STEP: delete the pod
May 21 08:05:31.494: INFO: Waiting for pod pod-b8d2e21e-5ccd-11e8-849c-0e182f31d764 to disappear
May 21 08:05:31.509: INFO: Pod pod-b8d2e21e-5ccd-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 08:05:31.509: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fvrjb" for this suite.
May 21 08:05:37.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:05:38.360: INFO: namespace: e2e-tests-emptydir-fvrjb, resource: bindings, ignored listing per whitelist
May 21 08:05:39.029: INFO: namespace e2e-tests-emptydir-fvrjb deletion completed in 7.490066731s

• [SLOW TEST:11.767 seconds]
[sig-storage] EmptyDir volumes
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-auth] ServiceAccounts
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 08:05:39.029: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
May 21 08:05:39.693: INFO: Waiting up to 5m0s for pod "pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-m2hnb" in namespace "e2e-tests-svcaccounts-sb6bl" to be "success or failure"
May 21 08:05:39.709: INFO: Pod "pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-m2hnb": Phase="Pending", Reason="", readiness=false. Elapsed: 15.211423ms
May 21 08:05:41.725: INFO: Pod "pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-m2hnb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031520172s
May 21 08:05:43.741: INFO: Pod "pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-m2hnb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047733884s
STEP: Saw pod success
May 21 08:05:43.741: INFO: Pod "pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-m2hnb" satisfied condition "success or failure"
May 21 08:05:43.757: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-m2hnb container token-test: <nil>
STEP: delete the pod
May 21 08:05:43.799: INFO: Waiting for pod pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-m2hnb to disappear
May 21 08:05:43.814: INFO: Pod pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-m2hnb no longer exists
STEP: Creating a pod to test consume service account root CA
May 21 08:05:43.848: INFO: Waiting up to 5m0s for pod "pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-lq8xv" in namespace "e2e-tests-svcaccounts-sb6bl" to be "success or failure"
May 21 08:05:43.864: INFO: Pod "pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-lq8xv": Phase="Pending", Reason="", readiness=false. Elapsed: 15.888448ms
May 21 08:05:45.879: INFO: Pod "pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-lq8xv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031707622s
May 21 08:05:47.895: INFO: Pod "pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-lq8xv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047555487s
STEP: Saw pod success
May 21 08:05:47.895: INFO: Pod "pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-lq8xv" satisfied condition "success or failure"
May 21 08:05:47.910: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-lq8xv container root-ca-test: <nil>
STEP: delete the pod
May 21 08:05:47.953: INFO: Waiting for pod pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-lq8xv to disappear
May 21 08:05:47.968: INFO: Pod pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-lq8xv no longer exists
STEP: Creating a pod to test consume service account namespace
May 21 08:05:47.986: INFO: Waiting up to 5m0s for pod "pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-6kh9d" in namespace "e2e-tests-svcaccounts-sb6bl" to be "success or failure"
May 21 08:05:48.001: INFO: Pod "pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-6kh9d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.860381ms
May 21 08:05:50.017: INFO: Pod "pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-6kh9d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03102741s
May 21 08:05:52.033: INFO: Pod "pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-6kh9d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047257411s
STEP: Saw pod success
May 21 08:05:52.033: INFO: Pod "pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-6kh9d" satisfied condition "success or failure"
May 21 08:05:52.049: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-6kh9d container namespace-test: <nil>
STEP: delete the pod
May 21 08:05:52.090: INFO: Waiting for pod pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-6kh9d to disappear
May 21 08:05:52.105: INFO: Pod pod-service-account-c028d324-5ccd-11e8-849c-0e182f31d764-6kh9d no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 08:05:52.105: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-sb6bl" for this suite.
May 21 08:05:58.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:05:59.139: INFO: namespace: e2e-tests-svcaccounts-sb6bl, resource: bindings, ignored listing per whitelist
May 21 08:05:59.619: INFO: namespace e2e-tests-svcaccounts-sb6bl deletion completed in 7.484568724s

• [SLOW TEST:20.590 seconds]
[sig-auth] ServiceAccounts
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed  [Flaky] [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 08:05:59.619: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:46
[It] should be submitted and removed  [Flaky] [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
May 21 08:06:03.860: INFO: Asynchronously running '/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/bin/linux/amd64/kubectl kubectl --kubeconfig=/tmp/cluster-admin.kubeconfig proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 08:06:14.444: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-9r46f" for this suite.
May 21 08:06:20.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:06:21.269: INFO: namespace: e2e-tests-pods-9r46f, resource: bindings, ignored listing per whitelist
May 21 08:06:21.937: INFO: namespace e2e-tests-pods-9r46f deletion completed in 7.464157776s

• [SLOW TEST:22.317 seconds]
[k8s.io] [sig-node] Pods Extended
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  [k8s.io] Delete Grace Period
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
    should be submitted and removed  [Flaky] [Conformance]
    /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-apps] ReplicaSet
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 08:06:21.937: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
May 21 08:06:22.042: INFO: Creating ReplicaSet my-hostname-basic-d9699288-5ccd-11e8-849c-0e182f31d764
May 21 08:06:22.080: INFO: Pod name my-hostname-basic-d9699288-5ccd-11e8-849c-0e182f31d764: Found 1 pods out of 1
May 21 08:06:22.080: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-d9699288-5ccd-11e8-849c-0e182f31d764" is running
May 21 08:06:24.114: INFO: Pod "my-hostname-basic-d9699288-5ccd-11e8-849c-0e182f31d764-4gldj" is running (conditions: [])
May 21 08:06:24.114: INFO: Trying to dial the pod
May 21 08:06:29.165: INFO: Controller my-hostname-basic-d9699288-5ccd-11e8-849c-0e182f31d764: Got expected result from replica 1 [my-hostname-basic-d9699288-5ccd-11e8-849c-0e182f31d764-4gldj]: "my-hostname-basic-d9699288-5ccd-11e8-849c-0e182f31d764-4gldj", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 08:06:29.165: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-8wc9h" for this suite.
May 21 08:06:35.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:06:36.307: INFO: namespace: e2e-tests-replicaset-8wc9h, resource: bindings, ignored listing per whitelist
May 21 08:06:36.665: INFO: namespace e2e-tests-replicaset-8wc9h deletion completed in 7.470132324s

• [SLOW TEST:14.728 seconds]
[sig-apps] ReplicaSet
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 08:06:36.665: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test emptydir 0644 on node default medium
May 21 08:06:36.781: INFO: Waiting up to 5m0s for pod "pod-e22fc83e-5ccd-11e8-849c-0e182f31d764" in namespace "e2e-tests-emptydir-pr5hb" to be "success or failure"
May 21 08:06:36.799: INFO: Pod "pod-e22fc83e-5ccd-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 17.35037ms
May 21 08:06:38.814: INFO: Pod "pod-e22fc83e-5ccd-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032838663s
May 21 08:06:40.830: INFO: Pod "pod-e22fc83e-5ccd-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048877576s
STEP: Saw pod success
May 21 08:06:40.830: INFO: Pod "pod-e22fc83e-5ccd-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 08:06:40.845: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod pod-e22fc83e-5ccd-11e8-849c-0e182f31d764 container test-container: <nil>
STEP: delete the pod
May 21 08:06:40.886: INFO: Waiting for pod pod-e22fc83e-5ccd-11e8-849c-0e182f31d764 to disappear
May 21 08:06:40.901: INFO: Pod pod-e22fc83e-5ccd-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 08:06:40.901: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pr5hb" for this suite.
May 21 08:06:46.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:06:48.353: INFO: namespace: e2e-tests-emptydir-pr5hb, resource: bindings, ignored listing per whitelist
May 21 08:06:48.428: INFO: namespace e2e-tests-emptydir-pr5hb deletion completed in 7.496157424s

• [SLOW TEST:11.763 seconds]
[sig-storage] EmptyDir volumes
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 08:06:48.428: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[AfterEach] [k8s.io] Probing container
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 08:07:48.593: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-n7kpt" for this suite.
May 21 08:08:10.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:08:11.420: INFO: namespace: e2e-tests-container-probe-n7kpt, resource: bindings, ignored listing per whitelist
May 21 08:08:12.102: INFO: namespace e2e-tests-container-probe-n7kpt deletion completed in 23.478803324s

• [SLOW TEST:83.674 seconds]
[k8s.io] Probing container
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:643
  with readiness probe that fails should never be ready and never restart  [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 08:08:12.102: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test emptydir 0666 on node default medium
May 21 08:08:12.256: INFO: Waiting up to 5m0s for pod "pod-1b17744b-5cce-11e8-849c-0e182f31d764" in namespace "e2e-tests-emptydir-v5n4s" to be "success or failure"
May 21 08:08:12.272: INFO: Pod "pod-1b17744b-5cce-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 15.24302ms
May 21 08:08:14.288: INFO: Pod "pod-1b17744b-5cce-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031263589s
May 21 08:08:16.304: INFO: Pod "pod-1b17744b-5cce-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047342474s
STEP: Saw pod success
May 21 08:08:16.304: INFO: Pod "pod-1b17744b-5cce-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 08:08:16.319: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-3zcc pod pod-1b17744b-5cce-11e8-849c-0e182f31d764 container test-container: <nil>
STEP: delete the pod
May 21 08:08:16.362: INFO: Waiting for pod pod-1b17744b-5cce-11e8-849c-0e182f31d764 to disappear
May 21 08:08:16.377: INFO: Pod pod-1b17744b-5cce-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 08:08:16.377: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-v5n4s" for this suite.
May 21 08:08:22.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:08:23.856: INFO: namespace: e2e-tests-emptydir-v5n4s, resource: bindings, ignored listing per whitelist
May 21 08:08:23.871: INFO: namespace e2e-tests-emptydir-v5n4s deletion completed in 7.465770975s

• [SLOW TEST:11.770 seconds]
[sig-storage] EmptyDir volumes
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 08:08:23.871: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating configMap with name projected-configmap-test-volume-22166305-5cce-11e8-849c-0e182f31d764
STEP: Creating a pod to test consume configMaps
May 21 08:08:24.014: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2218f1aa-5cce-11e8-849c-0e182f31d764" in namespace "e2e-tests-projected-45w6r" to be "success or failure"
May 21 08:08:24.030: INFO: Pod "pod-projected-configmaps-2218f1aa-5cce-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 16.097464ms
May 21 08:08:26.046: INFO: Pod "pod-projected-configmaps-2218f1aa-5cce-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031847924s
May 21 08:08:28.062: INFO: Pod "pod-projected-configmaps-2218f1aa-5cce-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047638695s
STEP: Saw pod success
May 21 08:08:28.062: INFO: Pod "pod-projected-configmaps-2218f1aa-5cce-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 08:08:28.077: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-wbpf pod pod-projected-configmaps-2218f1aa-5cce-11e8-849c-0e182f31d764 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 08:08:28.121: INFO: Waiting for pod pod-projected-configmaps-2218f1aa-5cce-11e8-849c-0e182f31d764 to disappear
May 21 08:08:28.136: INFO: Pod pod-projected-configmaps-2218f1aa-5cce-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] Projected
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 08:08:28.136: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-45w6r" for this suite.
May 21 08:08:34.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:08:35.524: INFO: namespace: e2e-tests-projected-45w6r, resource: bindings, ignored listing per whitelist
May 21 08:08:35.645: INFO: namespace e2e-tests-projected-45w6r deletion completed in 7.479486765s

• [SLOW TEST:11.773 seconds]
[sig-storage] Projected
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable in multiple volumes in the same pod [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
[BeforeEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:134
STEP: Creating a kubernetes client
May 21 08:08:35.645: INFO: >>> kubeConfig: /tmp/cluster-admin.kubeconfig
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 21 08:08:35.777: INFO: Waiting up to 5m0s for pod "pod-291b5b55-5cce-11e8-849c-0e182f31d764" in namespace "e2e-tests-emptydir-mnknp" to be "success or failure"
May 21 08:08:35.793: INFO: Pod "pod-291b5b55-5cce-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 16.040713ms
May 21 08:08:37.809: INFO: Pod "pod-291b5b55-5cce-11e8-849c-0e182f31d764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032279818s
May 21 08:08:39.825: INFO: Pod "pod-291b5b55-5cce-11e8-849c-0e182f31d764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04841972s
STEP: Saw pod success
May 21 08:08:39.825: INFO: Pod "pod-291b5b55-5cce-11e8-849c-0e182f31d764" satisfied condition "success or failure"
May 21 08:08:39.840: INFO: Trying to get logs from node prtest-7d230a7-103-ig-n-hmsw pod pod-291b5b55-5cce-11e8-849c-0e182f31d764 container test-container: <nil>
STEP: delete the pod
May 21 08:08:39.884: INFO: Waiting for pod pod-291b5b55-5cce-11e8-849c-0e182f31d764 to disappear
May 21 08:08:39.899: INFO: Pod pod-291b5b55-5cce-11e8-849c-0e182f31d764 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:135
May 21 08:08:39.899: INFO: Waiting up to 3m0s for all (but 1) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mnknp" for this suite.
May 21 08:08:45.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:08:47.146: INFO: namespace: e2e-tests-emptydir-mnknp, resource: bindings, ignored listing per whitelist
May 21 08:08:47.423: INFO: namespace e2e-tests-emptydir-mnknp deletion completed in 7.495562196s

• [SLOW TEST:11.778 seconds]
[sig-storage] EmptyDir volumes
/data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [Conformance]
  /data/src/github.com/openshift/origin/_output/components/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:648
------------------------------
SSSSMay 21 08:08:47.424: INFO: Running AfterSuite actions on all node
May 21 08:08:47.424: INFO: Running AfterSuite actions on node 1
May 21 08:08:47.424: INFO: Dumping logs locally to: /data/src/github.com/openshift/origin/_output/scripts/conformance-k8s/artifacts
May 21 08:08:47.424: INFO: Error running cluster/log-dump/log-dump.sh: fork/exec ../../cluster/log-dump/log-dump.sh: no such file or directory

Ran 147 of 843 Specs in 3794.279 seconds
SUCCESS! -- 147 Passed | 0 Failed | 0 Pending | 696 Skipped PASS

